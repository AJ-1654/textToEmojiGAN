{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextToEmojiGAN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ukGyEEqi_sa",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Erf8txy-jDYy",
        "colab_type": "code",
        "outputId": "31286924-c82f-465c-982e-a5fba9eaa2e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/My\\ Drive/EmojiGAN"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/EmojiGAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iMUxNOvjDqJ",
        "colab_type": "code",
        "outputId": "bb97b2d4-f276-4cc2-c9c1-e44a7e401fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cgan_emoji.py  \u001b[0m\u001b[01;34mimages\u001b[0m/                \u001b[01;34m__pycache__\u001b[0m/  temp.py\n",
            "classifier.py  inception_score.py     \u001b[01;34msample\u001b[0m/       \u001b[01;34mutils\u001b[0m/\n",
            "\u001b[01;34memoji\u001b[0m/         preprocess_dataset.py  \u001b[01;34msaved_model\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tim4Ji4vjDsu",
        "colab_type": "code",
        "outputId": "cb357435-cd37-46a3-8c55-60f2e03846e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python3 temp.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irpyYeBSjD4K",
        "colab_type": "code",
        "outputId": "46171a56-bf58-4118-8f11-b21cee707214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!python3 preprocess_dataset.py \"./emoji/original/EmojiOne_5.5.1_64x64_png\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing emoji dataset...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGyboYh4jEBd",
        "colab_type": "code",
        "outputId": "bdedb280-1561-4dc5-86dc-59c6c1ec2f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cgan_emoji.py  \u001b[0m\u001b[01;34memoji\u001b[0m/              preprocess_dataset.py  temp.py\n",
            "classifier.py  inception_score.py  \u001b[01;34msample\u001b[0m/                \u001b[01;34mutils\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGgQovpYjED3",
        "colab_type": "code",
        "outputId": "e7f77fbe-c536-466c-f290-1a2c1e1a2b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!python3 preprocess_dataset.py \"./emoji/original/EmojiOne_5.5.1_64x64_png\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing emoji dataset...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsdPqP66jEOu",
        "colab_type": "code",
        "outputId": "49683314-3797-4235-88f8-4dd92e11edbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEbqGGDFjERY",
        "colab_type": "code",
        "outputId": "943962a5-dfcb-4245-d49c-f00f0f8d4d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/My\\ Drive/EmojiGAN"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/EmojiGAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE8x8JYajEUw",
        "colab_type": "code",
        "outputId": "490b2ee1-d0d3-47f2-ef5f-c228d4e87a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cgan_emoji.py  \u001b[0m\u001b[01;34memoji\u001b[0m/              preprocess_dataset.py  temp.py\n",
            "classifier.py  inception_score.py  \u001b[01;34msample\u001b[0m/                \u001b[01;34mutils\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clQnx_LFjEey",
        "colab_type": "code",
        "outputId": "16bf1ef4-a1d0-432c-8bf7-e940b6351751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "!python3 cgan_emoji.py 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From cgan_emoji.py:26: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From cgan_emoji.py:27: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From cgan_emoji.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-03-11 18:46:28.992542: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-03-11 18:46:28.994342: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1ababc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-11 18:46:28.994374: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-03-11 18:46:29.002062: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-03-11 18:46:29.069582: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: no supported devices found for platform CUDA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sQQhvGCjEMK",
        "colab_type": "code",
        "outputId": "dccb62da-847c-47fb-f563-3f66be17c168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%cd drive/My\\ Drive/EmojiGAN"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/EmojiGAN'\n",
            "/content/drive/My Drive/EmojiGAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUjAp4P9jDn2",
        "colab_type": "code",
        "outputId": "e3bf628f-3b69-4a02-81b2-47b9bf3eea38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cgan_emoji.py  \u001b[0m\u001b[01;34memoji\u001b[0m/              preprocess_dataset.py  \u001b[01;34msaved_model\u001b[0m/  \u001b[01;34mutils\u001b[0m/\n",
            "classifier.py  inception_score.py  \u001b[01;34msample\u001b[0m/                temp.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCz5X2kHDLGx",
        "colab_type": "code",
        "outputId": "99d61f80-bf21-4954-d0b6-244aba9a2b69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 cgan_emoji.py 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Using colab GPU\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-03-11 19:30:34.852596: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-03-11 19:30:34.852918: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14c2bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-11 19:30:34.852955: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-03-11 19:30:34.855110: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-03-11 19:30:34.980324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-11 19:30:34.981208: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14c2d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-11 19:30:34.981244: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-03-11 19:30:34.982715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-11 19:30:34.983475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-11 19:30:35.005680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-11 19:30:35.276379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-11 19:30:35.408150: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-03-11 19:30:35.443416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-03-11 19:30:35.736858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-03-11 19:30:35.775280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-03-11 19:30:36.310872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-11 19:30:36.311146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-11 19:30:36.312012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-11 19:30:36.312698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-03-11 19:30:36.318674: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-11 19:30:36.320400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-11 19:30:36.320434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-03-11 19:30:36.320448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-03-11 19:30:36.321931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-11 19:30:36.322730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-11 19:30:36.323422: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-03-11 19:30:36.323468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "d_input (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 64)   1792        d_input[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 64)   0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 16, 16, 128)  73856       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 17, 17, 128)  0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 17, 17, 128)  512         zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 17, 17, 128)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 17, 17, 128)  0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 17, 17, 256)  295168      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 17, 17, 256)  1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 17, 17, 256)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 17, 17, 256)  0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "cond_d_input (InputLayer)       (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 9, 9, 512)    1180160     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          30100       cond_d_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 9, 9, 512)    2048        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 1, 100)    0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 9, 9, 512)    0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 9, 9, 100)    0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 9, 9, 612)    0           leaky_re_lu_4[0][0]              \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 9, 9, 512)    2820608     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 9, 9, 512)    2048        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 9, 9, 512)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 9, 9, 512)    0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 41472)        0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            41473       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,448,789\n",
            "Trainable params: 4,445,973\n",
            "Non-trainable params: 2,816\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "cond_g_input (InputLayer)       (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "g_input (InputLayer)            (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 100)          30100       cond_g_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 200)          0           g_input[0][0]                    \n",
            "                                                                 dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 16384)        3293184     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 8, 8, 256)    0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 256)  0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 256)  590080      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 256)  1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 16, 16, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 256)  0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 128)  295040      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 128)  0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 64)   73792       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 64, 64)   256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 64, 64, 3)    1731        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64, 64, 3)    0           conv2d_9[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 4,285,719\n",
            "Trainable params: 4,284,823\n",
            "Non-trainable params: 896\n",
            "__________________________________________________________________________________________________\n",
            "Acquiring images & labels...\n",
            "Traceback (most recent call last):\n",
            "  File \"cgan_emoji.py\", line 340, in <module>\n",
            "    train_mode()\n",
            "  File \"cgan_emoji.py\", line 333, in train_mode\n",
            "    dcgan.train(epochs=5000, batch_size=26, save_interval=50)\n",
            "  File \"cgan_emoji.py\", line 147, in train\n",
            "    X_train, Captions, X_test, Captions_test, Labels = load_dataset(self.img_path, self.txt_path, self.img_shape)\n",
            "  File \"/content/drive/My Drive/EmojiGAN/utils/dataset_utils.py\", line 47, in load_dataset\n",
            "    tokenized = sent_tokenize(text)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\", line 94, in sent_tokenize\n",
            "    tokenizer = load('tokenizers/punkt/{0}.pickle'.format(language))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/nltk/data.py\", line 834, in load\n",
            "    opened_resource = _open(resource_url)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/nltk/data.py\", line 952, in _open\n",
            "    return find(path_, path + ['']).open()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/nltk/data.py\", line 673, in find\n",
            "    raise LookupError(resource_not_found)\n",
            "LookupError: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt')\n",
            "  \u001b[0m\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - ''\n",
            "**********************************************************************\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFOnVY1_DXN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMqj0nACF0Uk",
        "colab_type": "code",
        "outputId": "9fa6ea23-1144-49ce-e758-c1a6151ff94b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyW2LRB5F4Lh",
        "colab_type": "code",
        "outputId": "cd83f958-6c10-4e32-fb4a-8126358c2017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 cgan_emoji.py 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Using colab GPU\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-03-11 19:42:22.377584: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-03-11 19:42:22.377842: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x258cbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-11 19:42:22.377879: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-03-11 19:42:22.380070: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-03-11 19:42:22.454493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-11 19:42:22.455528: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x258cd80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-11 19:42:22.455561: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-03-11 19:42:22.455757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-11 19:42:22.456466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-11 19:42:22.456767: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-11 19:42:22.458719: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-11 19:42:22.460592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-03-11 19:42:22.460952: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-03-11 19:42:22.463130: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-03-11 19:42:22.464240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-03-11 19:42:22.468846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-11 19:42:22.468995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-11 19:42:22.469731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-11 19:42:22.470430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-03-11 19:42:22.470488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-11 19:42:22.472380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-11 19:42:22.472412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-03-11 19:42:22.472425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-03-11 19:42:22.472567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-11 19:42:22.473399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-11 19:42:22.474122: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-03-11 19:42:22.474166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "d_input (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 64)   1792        d_input[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 64)   0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 16, 16, 128)  73856       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 17, 17, 128)  0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 17, 17, 128)  512         zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 17, 17, 128)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 17, 17, 128)  0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 17, 17, 256)  295168      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 17, 17, 256)  1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 17, 17, 256)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 17, 17, 256)  0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "cond_d_input (InputLayer)       (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 9, 9, 512)    1180160     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          30100       cond_d_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 9, 9, 512)    2048        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 1, 100)    0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 9, 9, 512)    0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 9, 9, 100)    0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 9, 9, 612)    0           leaky_re_lu_4[0][0]              \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 9, 9, 512)    2820608     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 9, 9, 512)    2048        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 9, 9, 512)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 9, 9, 512)    0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 41472)        0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            41473       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,448,789\n",
            "Trainable params: 4,445,973\n",
            "Non-trainable params: 2,816\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "cond_g_input (InputLayer)       (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "g_input (InputLayer)            (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 100)          30100       cond_g_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 200)          0           g_input[0][0]                    \n",
            "                                                                 dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 16384)        3293184     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 8, 8, 256)    0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 256)  0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 256)  590080      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 256)  1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 16, 16, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 256)  0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 128)  295040      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 128)  0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 64)   73792       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 64, 64)   256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 64, 64, 3)    1731        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64, 64, 3)    0           conv2d_9[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 4,285,719\n",
            "Trainable params: 4,284,823\n",
            "Non-trainable params: 896\n",
            "__________________________________________________________________________________________________\n",
            "Acquiring images & labels...\n",
            "Done!\n",
            ">>> Dataset Size: 260\n",
            "2020-03-11 19:42:25.715133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-11 19:42:25.898903: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "0-0 [D loss: 1.270864, acc.: 11.54%] [G loss: 0.404216] [Time: 5.872198]\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "0-1 [D loss: 1.100208, acc.: 50.00%] [G loss: 0.483570] [Time: 0.259531]\n",
            "0-2 [D loss: 1.008180, acc.: 50.00%] [G loss: 0.586685] [Time: 0.246722]\n",
            "0-3 [D loss: 0.874440, acc.: 48.08%] [G loss: 0.863485] [Time: 0.250133]\n",
            "0-4 [D loss: 0.749025, acc.: 48.08%] [G loss: 1.102485] [Time: 0.247895]\n",
            "0-5 [D loss: 0.930391, acc.: 57.69%] [G loss: 1.081522] [Time: 0.249450]\n",
            "0-6 [D loss: 1.064058, acc.: 38.46%] [G loss: 1.072844] [Time: 0.245268]\n",
            "0-7 [D loss: 1.010747, acc.: 38.46%] [G loss: 1.025478] [Time: 0.247121]\n",
            "0-8 [D loss: 1.309271, acc.: 38.46%] [G loss: 0.828162] [Time: 0.248670]\n",
            "0 (test) [D loss: 1.068226, acc.: 50.00%] [G loss: 1.891021] [Time: 0.671307]\n",
            "1-0 [D loss: 0.915594, acc.: 51.92%] [G loss: 1.269279] [Time: 0.309803]\n",
            "1-1 [D loss: 1.204591, acc.: 36.54%] [G loss: 1.279647] [Time: 0.266097]\n",
            "1-2 [D loss: 1.024184, acc.: 38.46%] [G loss: 0.810525] [Time: 0.245896]\n",
            "1-3 [D loss: 1.112485, acc.: 30.77%] [G loss: 0.964762] [Time: 0.248282]\n",
            "1-4 [D loss: 1.112912, acc.: 34.62%] [G loss: 1.252270] [Time: 0.247353]\n",
            "1-5 [D loss: 1.376153, acc.: 15.38%] [G loss: 1.055384] [Time: 0.247464]\n",
            "1-6 [D loss: 1.163513, acc.: 30.77%] [G loss: 0.979193] [Time: 0.248929]\n",
            "1-7 [D loss: 1.449587, acc.: 15.38%] [G loss: 0.842079] [Time: 0.248405]\n",
            "1-8 [D loss: 1.324392, acc.: 28.85%] [G loss: 1.009158] [Time: 0.248398]\n",
            "1 (test) [D loss: 1.098220, acc.: 50.00%] [G loss: 1.945665] [Time: 0.087317]\n",
            "2-0 [D loss: 1.315583, acc.: 32.69%] [G loss: 0.895238] [Time: 0.250501]\n",
            "2-1 [D loss: 1.196914, acc.: 36.54%] [G loss: 0.931105] [Time: 0.248246]\n",
            "2-2 [D loss: 1.199160, acc.: 30.77%] [G loss: 0.622330] [Time: 0.249468]\n",
            "2-3 [D loss: 1.251548, acc.: 38.46%] [G loss: 0.768079] [Time: 0.252788]\n",
            "2-4 [D loss: 1.199372, acc.: 21.15%] [G loss: 1.079362] [Time: 0.247776]\n",
            "2-5 [D loss: 1.113779, acc.: 32.69%] [G loss: 1.029418] [Time: 0.244666]\n",
            "2-6 [D loss: 1.144722, acc.: 30.77%] [G loss: 0.933102] [Time: 0.247520]\n",
            "2-7 [D loss: 1.276869, acc.: 17.31%] [G loss: 1.040892] [Time: 0.249894]\n",
            "2-8 [D loss: 1.300932, acc.: 25.00%] [G loss: 0.987441] [Time: 0.248590]\n",
            "2 (test) [D loss: 0.931465, acc.: 50.00%] [G loss: 1.545570] [Time: 0.080286]\n",
            "3-0 [D loss: 1.200923, acc.: 42.31%] [G loss: 1.056875] [Time: 0.246656]\n",
            "3-1 [D loss: 1.211611, acc.: 32.69%] [G loss: 1.295881] [Time: 0.246844]\n",
            "3-2 [D loss: 1.287737, acc.: 25.00%] [G loss: 0.886737] [Time: 0.249053]\n",
            "3-3 [D loss: 1.394626, acc.: 28.85%] [G loss: 0.885434] [Time: 0.246026]\n",
            "3-4 [D loss: 1.373389, acc.: 19.23%] [G loss: 0.869456] [Time: 0.248660]\n",
            "3-5 [D loss: 1.296062, acc.: 21.15%] [G loss: 0.960261] [Time: 0.253317]\n",
            "3-6 [D loss: 1.322340, acc.: 25.00%] [G loss: 1.077013] [Time: 0.247470]\n",
            "3-7 [D loss: 1.451693, acc.: 15.38%] [G loss: 1.155565] [Time: 0.250062]\n",
            "3-8 [D loss: 1.063706, acc.: 21.15%] [G loss: 1.013490] [Time: 0.252513]\n",
            "3 (test) [D loss: 1.003516, acc.: 50.00%] [G loss: 1.709996] [Time: 0.077167]\n",
            "4-0 [D loss: 1.117421, acc.: 28.85%] [G loss: 1.031638] [Time: 0.250947]\n",
            "4-1 [D loss: 1.378777, acc.: 19.23%] [G loss: 1.396315] [Time: 0.250949]\n",
            "4-2 [D loss: 0.921192, acc.: 48.08%] [G loss: 1.104680] [Time: 0.249433]\n",
            "4-3 [D loss: 1.132768, acc.: 25.00%] [G loss: 0.893834] [Time: 0.250272]\n",
            "4-4 [D loss: 1.375142, acc.: 13.46%] [G loss: 0.985329] [Time: 0.250427]\n",
            "4-5 [D loss: 1.242636, acc.: 25.00%] [G loss: 1.085804] [Time: 0.247254]\n",
            "4-6 [D loss: 1.365238, acc.: 21.15%] [G loss: 1.100544] [Time: 0.249287]\n",
            "4-7 [D loss: 1.413683, acc.: 21.15%] [G loss: 1.136188] [Time: 0.249949]\n",
            "4-8 [D loss: 1.252195, acc.: 21.15%] [G loss: 1.114009] [Time: 0.251736]\n",
            "4 (test) [D loss: 1.043962, acc.: 50.00%] [G loss: 1.796755] [Time: 0.077925]\n",
            "5-0 [D loss: 1.325269, acc.: 28.85%] [G loss: 0.808070] [Time: 0.252191]\n",
            "5-1 [D loss: 1.330105, acc.: 28.85%] [G loss: 1.131018] [Time: 0.247986]\n",
            "5-2 [D loss: 1.201638, acc.: 17.31%] [G loss: 0.936820] [Time: 0.247631]\n",
            "5-3 [D loss: 1.436519, acc.: 26.92%] [G loss: 0.750714] [Time: 0.248878]\n",
            "5-4 [D loss: 1.471633, acc.: 5.77%] [G loss: 0.878306] [Time: 0.250108]\n",
            "5-5 [D loss: 1.246434, acc.: 19.23%] [G loss: 0.969994] [Time: 0.246831]\n",
            "5-6 [D loss: 1.269401, acc.: 17.31%] [G loss: 1.092498] [Time: 0.247105]\n",
            "5-7 [D loss: 1.333279, acc.: 21.15%] [G loss: 1.040493] [Time: 0.249284]\n",
            "5-8 [D loss: 1.375890, acc.: 15.38%] [G loss: 1.067150] [Time: 0.254618]\n",
            "5 (test) [D loss: 0.892682, acc.: 50.00%] [G loss: 1.442404] [Time: 0.077270]\n",
            "6-0 [D loss: 1.129330, acc.: 36.54%] [G loss: 0.869097] [Time: 0.248488]\n",
            "6-1 [D loss: 1.286774, acc.: 30.77%] [G loss: 1.306688] [Time: 0.248636]\n",
            "6-2 [D loss: 1.255952, acc.: 17.31%] [G loss: 0.848111] [Time: 0.251974]\n",
            "6-3 [D loss: 1.499728, acc.: 17.31%] [G loss: 0.778640] [Time: 0.251203]\n",
            "6-4 [D loss: 1.428830, acc.: 11.54%] [G loss: 1.115346] [Time: 0.246262]\n",
            "6-5 [D loss: 1.257624, acc.: 21.15%] [G loss: 0.978008] [Time: 0.247117]\n",
            "6-6 [D loss: 1.253988, acc.: 23.08%] [G loss: 0.889562] [Time: 0.249533]\n",
            "6-7 [D loss: 1.173119, acc.: 28.85%] [G loss: 0.980835] [Time: 0.254295]\n",
            "6-8 [D loss: 1.148487, acc.: 21.15%] [G loss: 1.243860] [Time: 0.248743]\n",
            "6 (test) [D loss: 0.894801, acc.: 50.00%] [G loss: 1.429636] [Time: 0.079138]\n",
            "7-0 [D loss: 1.276028, acc.: 21.15%] [G loss: 0.767505] [Time: 0.252137]\n",
            "7-1 [D loss: 1.215352, acc.: 25.00%] [G loss: 1.159476] [Time: 0.249987]\n",
            "7-2 [D loss: 1.105054, acc.: 23.08%] [G loss: 0.906445] [Time: 0.249620]\n",
            "7-3 [D loss: 1.200126, acc.: 25.00%] [G loss: 0.866957] [Time: 0.250394]\n",
            "7-4 [D loss: 1.225986, acc.: 23.08%] [G loss: 0.913374] [Time: 0.249483]\n",
            "7-5 [D loss: 1.177531, acc.: 26.92%] [G loss: 0.861673] [Time: 0.248869]\n",
            "7-6 [D loss: 1.277236, acc.: 21.15%] [G loss: 0.904479] [Time: 0.253682]\n",
            "7-7 [D loss: 1.243620, acc.: 21.15%] [G loss: 0.854389] [Time: 0.248349]\n",
            "7-8 [D loss: 1.195106, acc.: 15.38%] [G loss: 0.940881] [Time: 0.249611]\n",
            "7 (test) [D loss: 0.899308, acc.: 50.00%] [G loss: 1.464960] [Time: 0.079024]\n",
            "8-0 [D loss: 1.048702, acc.: 40.38%] [G loss: 0.867104] [Time: 0.247564]\n",
            "8-1 [D loss: 1.179429, acc.: 25.00%] [G loss: 1.003656] [Time: 0.251830]\n",
            "8-2 [D loss: 1.302819, acc.: 21.15%] [G loss: 0.809823] [Time: 0.252153]\n",
            "8-3 [D loss: 1.188109, acc.: 25.00%] [G loss: 0.861296] [Time: 0.246092]\n",
            "8-4 [D loss: 1.288348, acc.: 21.15%] [G loss: 1.079922] [Time: 0.247171]\n",
            "8-5 [D loss: 1.193892, acc.: 11.54%] [G loss: 0.974579] [Time: 0.247717]\n",
            "8-6 [D loss: 1.100129, acc.: 32.69%] [G loss: 0.937321] [Time: 0.252195]\n",
            "8-7 [D loss: 1.168015, acc.: 26.92%] [G loss: 0.964124] [Time: 0.247268]\n",
            "8-8 [D loss: 1.153067, acc.: 21.15%] [G loss: 1.043716] [Time: 0.248177]\n",
            "8 (test) [D loss: 0.873903, acc.: 50.00%] [G loss: 1.386928] [Time: 0.077405]\n",
            "9-0 [D loss: 1.116385, acc.: 34.62%] [G loss: 0.873205] [Time: 0.253305]\n",
            "9-1 [D loss: 1.196848, acc.: 28.85%] [G loss: 0.954021] [Time: 0.250024]\n",
            "9-2 [D loss: 1.132390, acc.: 21.15%] [G loss: 0.845349] [Time: 0.249813]\n",
            "9-3 [D loss: 1.052609, acc.: 32.69%] [G loss: 1.072965] [Time: 0.244599]\n",
            "9-4 [D loss: 1.211648, acc.: 26.92%] [G loss: 0.986046] [Time: 0.255073]\n",
            "9-5 [D loss: 1.138164, acc.: 15.38%] [G loss: 0.850626] [Time: 0.247282]\n",
            "9-6 [D loss: 0.974310, acc.: 40.38%] [G loss: 0.858522] [Time: 0.247363]\n",
            "9-7 [D loss: 1.229421, acc.: 21.15%] [G loss: 1.185087] [Time: 0.248078]\n",
            "9-8 [D loss: 1.220999, acc.: 13.46%] [G loss: 0.981910] [Time: 0.254969]\n",
            "9 (test) [D loss: 0.880503, acc.: 50.00%] [G loss: 1.370754] [Time: 0.077125]\n",
            "10-0 [D loss: 1.340833, acc.: 13.46%] [G loss: 0.647717] [Time: 0.252459]\n",
            "10-1 [D loss: 1.251640, acc.: 15.38%] [G loss: 1.189879] [Time: 0.245825]\n",
            "10-2 [D loss: 1.178351, acc.: 28.85%] [G loss: 0.803161] [Time: 0.248942]\n",
            "10-3 [D loss: 1.228211, acc.: 28.85%] [G loss: 0.910622] [Time: 0.247752]\n",
            "10-4 [D loss: 1.291535, acc.: 19.23%] [G loss: 0.957749] [Time: 0.248880]\n",
            "10-5 [D loss: 1.025076, acc.: 23.08%] [G loss: 1.092479] [Time: 0.246723]\n",
            "10-6 [D loss: 1.196579, acc.: 26.92%] [G loss: 1.018587] [Time: 0.246211]\n",
            "10-7 [D loss: 1.232193, acc.: 21.15%] [G loss: 0.986208] [Time: 0.248664]\n",
            "10-8 [D loss: 1.178725, acc.: 11.54%] [G loss: 0.819366] [Time: 0.248824]\n",
            "10 (test) [D loss: 0.823390, acc.: 50.00%] [G loss: 1.250793] [Time: 0.076113]\n",
            "11-0 [D loss: 1.147035, acc.: 28.85%] [G loss: 0.964433] [Time: 0.251715]\n",
            "11-1 [D loss: 1.025683, acc.: 26.92%] [G loss: 1.232903] [Time: 0.252309]\n",
            "11-2 [D loss: 1.137860, acc.: 30.77%] [G loss: 0.898310] [Time: 0.248758]\n",
            "11-3 [D loss: 1.053980, acc.: 26.92%] [G loss: 0.748313] [Time: 0.249134]\n",
            "11-4 [D loss: 1.290682, acc.: 19.23%] [G loss: 0.915431] [Time: 0.246299]\n",
            "11-5 [D loss: 0.961324, acc.: 34.62%] [G loss: 1.047205] [Time: 0.247993]\n",
            "11-6 [D loss: 1.146109, acc.: 23.08%] [G loss: 0.991717] [Time: 0.249332]\n",
            "11-7 [D loss: 1.064255, acc.: 30.77%] [G loss: 1.071903] [Time: 0.245118]\n",
            "11-8 [D loss: 1.109328, acc.: 21.15%] [G loss: 0.830863] [Time: 0.249107]\n",
            "11 (test) [D loss: 0.822145, acc.: 50.00%] [G loss: 1.243754] [Time: 0.077295]\n",
            "12-0 [D loss: 1.198612, acc.: 34.62%] [G loss: 0.986706] [Time: 0.250722]\n",
            "12-1 [D loss: 1.026526, acc.: 30.77%] [G loss: 1.099885] [Time: 0.252632]\n",
            "12-2 [D loss: 1.158347, acc.: 17.31%] [G loss: 0.871875] [Time: 0.247550]\n",
            "12-3 [D loss: 1.146327, acc.: 17.31%] [G loss: 0.903035] [Time: 0.247537]\n",
            "12-4 [D loss: 1.273468, acc.: 15.38%] [G loss: 0.901215] [Time: 0.247830]\n",
            "12-5 [D loss: 1.322751, acc.: 15.38%] [G loss: 0.893705] [Time: 0.247930]\n",
            "12-6 [D loss: 1.061033, acc.: 32.69%] [G loss: 0.925135] [Time: 0.245923]\n",
            "12-7 [D loss: 1.326005, acc.: 13.46%] [G loss: 0.962462] [Time: 0.245593]\n",
            "12-8 [D loss: 1.113767, acc.: 23.08%] [G loss: 0.989432] [Time: 0.249106]\n",
            "12 (test) [D loss: 0.873627, acc.: 50.00%] [G loss: 1.376199] [Time: 0.078077]\n",
            "13-0 [D loss: 1.113122, acc.: 21.15%] [G loss: 0.966896] [Time: 0.251698]\n",
            "13-1 [D loss: 1.004505, acc.: 40.38%] [G loss: 1.095884] [Time: 0.244445]\n",
            "13-2 [D loss: 1.059756, acc.: 32.69%] [G loss: 0.920457] [Time: 0.247432]\n",
            "13-3 [D loss: 1.077931, acc.: 25.00%] [G loss: 1.026959] [Time: 0.247690]\n",
            "13-4 [D loss: 1.243557, acc.: 19.23%] [G loss: 1.098395] [Time: 0.253348]\n",
            "13-5 [D loss: 1.038157, acc.: 25.00%] [G loss: 1.093312] [Time: 0.245446]\n",
            "13-6 [D loss: 1.080938, acc.: 21.15%] [G loss: 0.869118] [Time: 0.247286]\n",
            "13-7 [D loss: 1.111418, acc.: 25.00%] [G loss: 1.083088] [Time: 0.246213]\n",
            "13-8 [D loss: 1.043782, acc.: 23.08%] [G loss: 0.984586] [Time: 0.250600]\n",
            "13 (test) [D loss: 0.896769, acc.: 50.00%] [G loss: 1.442244] [Time: 0.075952]\n",
            "14-0 [D loss: 1.244815, acc.: 11.54%] [G loss: 0.981101] [Time: 0.248597]\n",
            "14-1 [D loss: 0.926652, acc.: 32.69%] [G loss: 1.078739] [Time: 0.248090]\n",
            "14-2 [D loss: 0.915686, acc.: 32.69%] [G loss: 0.871918] [Time: 0.251230]\n",
            "14-3 [D loss: 1.112871, acc.: 26.92%] [G loss: 0.791135] [Time: 0.246636]\n",
            "14-4 [D loss: 1.143581, acc.: 17.31%] [G loss: 0.925626] [Time: 0.249358]\n",
            "14-5 [D loss: 0.924774, acc.: 34.62%] [G loss: 0.941453] [Time: 0.249683]\n",
            "14-6 [D loss: 1.066674, acc.: 19.23%] [G loss: 0.953003] [Time: 0.246993]\n",
            "14-7 [D loss: 1.225233, acc.: 17.31%] [G loss: 1.013064] [Time: 0.248237]\n",
            "14-8 [D loss: 1.241204, acc.: 19.23%] [G loss: 0.900411] [Time: 0.248637]\n",
            "14 (test) [D loss: 0.913971, acc.: 50.00%] [G loss: 1.486379] [Time: 0.078261]\n",
            "15-0 [D loss: 1.044734, acc.: 34.62%] [G loss: 0.879332] [Time: 0.249509]\n",
            "15-1 [D loss: 1.047635, acc.: 23.08%] [G loss: 1.041090] [Time: 0.254396]\n",
            "15-2 [D loss: 1.020193, acc.: 21.15%] [G loss: 0.918296] [Time: 0.246881]\n",
            "15-3 [D loss: 1.113467, acc.: 25.00%] [G loss: 0.979020] [Time: 0.247550]\n",
            "15-4 [D loss: 1.147390, acc.: 21.15%] [G loss: 0.872747] [Time: 0.248600]\n",
            "15-5 [D loss: 0.986798, acc.: 17.31%] [G loss: 0.961398] [Time: 0.248785]\n",
            "15-6 [D loss: 0.957421, acc.: 30.77%] [G loss: 1.091661] [Time: 0.247872]\n",
            "15-7 [D loss: 1.130041, acc.: 26.92%] [G loss: 1.083210] [Time: 0.244210]\n",
            "15-8 [D loss: 1.031236, acc.: 21.15%] [G loss: 0.805399] [Time: 0.245492]\n",
            "15 (test) [D loss: 0.846446, acc.: 50.00%] [G loss: 1.319903] [Time: 0.077303]\n",
            "16-0 [D loss: 1.072926, acc.: 30.77%] [G loss: 0.969312] [Time: 0.251309]\n",
            "16-1 [D loss: 0.932415, acc.: 19.23%] [G loss: 1.115516] [Time: 0.243718]\n",
            "16-2 [D loss: 0.923585, acc.: 36.54%] [G loss: 0.977470] [Time: 0.255386]\n",
            "16-3 [D loss: 1.016962, acc.: 25.00%] [G loss: 1.293772] [Time: 0.244980]\n",
            "16-4 [D loss: 1.208655, acc.: 7.69%] [G loss: 1.114433] [Time: 0.250504]\n",
            "16-5 [D loss: 1.058777, acc.: 25.00%] [G loss: 1.078489] [Time: 0.249102]\n",
            "16-6 [D loss: 0.772601, acc.: 48.08%] [G loss: 0.915952] [Time: 0.247236]\n",
            "16-7 [D loss: 1.030000, acc.: 25.00%] [G loss: 0.869441] [Time: 0.248523]\n",
            "16-8 [D loss: 1.042702, acc.: 30.77%] [G loss: 0.931392] [Time: 0.248066]\n",
            "16 (test) [D loss: 0.875695, acc.: 50.00%] [G loss: 1.398099] [Time: 0.076351]\n",
            "17-0 [D loss: 1.103735, acc.: 26.92%] [G loss: 0.977434] [Time: 0.250534]\n",
            "17-1 [D loss: 1.092237, acc.: 19.23%] [G loss: 1.132371] [Time: 0.247086]\n",
            "17-2 [D loss: 1.013534, acc.: 21.15%] [G loss: 0.964745] [Time: 0.249575]\n",
            "17-3 [D loss: 0.963269, acc.: 28.85%] [G loss: 1.223224] [Time: 0.250880]\n",
            "17-4 [D loss: 0.987911, acc.: 34.62%] [G loss: 1.040795] [Time: 0.247604]\n",
            "17-5 [D loss: 1.008606, acc.: 28.85%] [G loss: 1.017696] [Time: 0.249971]\n",
            "17-6 [D loss: 0.934300, acc.: 32.69%] [G loss: 0.970878] [Time: 0.247165]\n",
            "17-7 [D loss: 1.023259, acc.: 32.69%] [G loss: 0.988510] [Time: 0.249351]\n",
            "17-8 [D loss: 0.898493, acc.: 30.77%] [G loss: 0.982632] [Time: 0.249014]\n",
            "17 (test) [D loss: 0.960980, acc.: 50.00%] [G loss: 1.627185] [Time: 0.077065]\n",
            "18-0 [D loss: 1.048122, acc.: 21.15%] [G loss: 0.894294] [Time: 0.249924]\n",
            "18-1 [D loss: 0.989739, acc.: 25.00%] [G loss: 1.153438] [Time: 0.251530]\n",
            "18-2 [D loss: 0.928500, acc.: 28.85%] [G loss: 1.047736] [Time: 0.248149]\n",
            "18-3 [D loss: 1.055948, acc.: 23.08%] [G loss: 1.144319] [Time: 0.247454]\n",
            "18-4 [D loss: 1.036290, acc.: 30.77%] [G loss: 1.002033] [Time: 0.250686]\n",
            "18-5 [D loss: 1.013996, acc.: 34.62%] [G loss: 1.100931] [Time: 0.244545]\n",
            "18-6 [D loss: 0.830015, acc.: 44.23%] [G loss: 1.180625] [Time: 0.253210]\n",
            "18-7 [D loss: 0.898652, acc.: 44.23%] [G loss: 1.105926] [Time: 0.248161]\n",
            "18-8 [D loss: 0.998687, acc.: 38.46%] [G loss: 0.983580] [Time: 0.245140]\n",
            "18 (test) [D loss: 0.854501, acc.: 50.00%] [G loss: 1.334214] [Time: 0.077593]\n",
            "19-0 [D loss: 0.932357, acc.: 38.46%] [G loss: 0.937590] [Time: 0.250168]\n",
            "19-1 [D loss: 0.937740, acc.: 26.92%] [G loss: 1.043272] [Time: 0.247127]\n",
            "19-2 [D loss: 0.947215, acc.: 34.62%] [G loss: 0.954349] [Time: 0.245697]\n",
            "19-3 [D loss: 1.006755, acc.: 19.23%] [G loss: 1.086022] [Time: 0.250074]\n",
            "19-4 [D loss: 1.064208, acc.: 25.00%] [G loss: 0.839225] [Time: 0.245280]\n",
            "19-5 [D loss: 0.840719, acc.: 46.15%] [G loss: 0.874714] [Time: 0.254328]\n",
            "19-6 [D loss: 0.865651, acc.: 40.38%] [G loss: 0.920494] [Time: 0.247769]\n",
            "19-7 [D loss: 1.035987, acc.: 28.85%] [G loss: 0.997497] [Time: 0.251329]\n",
            "19-8 [D loss: 0.803963, acc.: 40.38%] [G loss: 1.194124] [Time: 0.248369]\n",
            "19 (test) [D loss: 0.983773, acc.: 50.00%] [G loss: 1.672201] [Time: 0.076915]\n",
            "20-0 [D loss: 0.862814, acc.: 32.69%] [G loss: 0.837479] [Time: 0.250995]\n",
            "20-1 [D loss: 0.948577, acc.: 26.92%] [G loss: 1.108618] [Time: 0.245998]\n",
            "20-2 [D loss: 0.908151, acc.: 38.46%] [G loss: 1.017250] [Time: 0.245845]\n",
            "20-3 [D loss: 0.841563, acc.: 38.46%] [G loss: 1.204186] [Time: 0.249746]\n",
            "20-4 [D loss: 1.100838, acc.: 23.08%] [G loss: 1.016670] [Time: 0.246434]\n",
            "20-5 [D loss: 0.825483, acc.: 51.92%] [G loss: 1.201182] [Time: 0.249210]\n",
            "20-6 [D loss: 0.896999, acc.: 34.62%] [G loss: 1.228759] [Time: 0.248023]\n",
            "20-7 [D loss: 0.880965, acc.: 42.31%] [G loss: 1.036604] [Time: 0.246180]\n",
            "20-8 [D loss: 0.875815, acc.: 40.38%] [G loss: 1.083444] [Time: 0.249513]\n",
            "20 (test) [D loss: 0.843524, acc.: 50.00%] [G loss: 1.322036] [Time: 0.076505]\n",
            "21-0 [D loss: 1.056544, acc.: 25.00%] [G loss: 0.940695] [Time: 0.247928]\n",
            "21-1 [D loss: 0.801300, acc.: 34.62%] [G loss: 1.192356] [Time: 0.251690]\n",
            "21-2 [D loss: 0.873013, acc.: 32.69%] [G loss: 1.117926] [Time: 0.247509]\n",
            "21-3 [D loss: 0.915147, acc.: 25.00%] [G loss: 1.042554] [Time: 0.248206]\n",
            "21-4 [D loss: 1.001020, acc.: 26.92%] [G loss: 1.092432] [Time: 0.255044]\n",
            "21-5 [D loss: 0.875062, acc.: 40.38%] [G loss: 1.065294] [Time: 0.247474]\n",
            "21-6 [D loss: 0.814634, acc.: 46.15%] [G loss: 1.087230] [Time: 0.245146]\n",
            "21-7 [D loss: 0.888563, acc.: 30.77%] [G loss: 1.173646] [Time: 0.251184]\n",
            "21-8 [D loss: 0.915254, acc.: 34.62%] [G loss: 0.956358] [Time: 0.246417]\n",
            "21 (test) [D loss: 0.951689, acc.: 50.00%] [G loss: 1.590424] [Time: 0.077982]\n",
            "22-0 [D loss: 0.913938, acc.: 36.54%] [G loss: 0.913886] [Time: 0.247520]\n",
            "22-1 [D loss: 0.888632, acc.: 38.46%] [G loss: 0.996069] [Time: 0.251332]\n",
            "22-2 [D loss: 0.859138, acc.: 38.46%] [G loss: 1.002772] [Time: 0.249718]\n",
            "22-3 [D loss: 0.755077, acc.: 48.08%] [G loss: 1.024629] [Time: 0.245063]\n",
            "22-4 [D loss: 0.866152, acc.: 44.23%] [G loss: 1.172025] [Time: 0.249486]\n",
            "22-5 [D loss: 0.773789, acc.: 50.00%] [G loss: 1.134056] [Time: 0.244701]\n",
            "22-6 [D loss: 0.907591, acc.: 40.38%] [G loss: 0.848793] [Time: 0.247035]\n",
            "22-7 [D loss: 0.975532, acc.: 21.15%] [G loss: 1.041877] [Time: 0.249285]\n",
            "22-8 [D loss: 0.954103, acc.: 28.85%] [G loss: 0.913839] [Time: 0.251165]\n",
            "22 (test) [D loss: 0.889280, acc.: 50.00%] [G loss: 1.428224] [Time: 0.076921]\n",
            "23-0 [D loss: 0.923737, acc.: 51.92%] [G loss: 0.964896] [Time: 0.246530]\n",
            "23-1 [D loss: 0.794447, acc.: 44.23%] [G loss: 1.088003] [Time: 0.247225]\n",
            "23-2 [D loss: 0.980531, acc.: 25.00%] [G loss: 1.010840] [Time: 0.249134]\n",
            "23-3 [D loss: 0.955911, acc.: 30.77%] [G loss: 0.928589] [Time: 0.251509]\n",
            "23-4 [D loss: 1.069228, acc.: 21.15%] [G loss: 1.050382] [Time: 0.246200]\n",
            "23-5 [D loss: 0.831138, acc.: 36.54%] [G loss: 1.040306] [Time: 0.248358]\n",
            "23-6 [D loss: 0.886492, acc.: 38.46%] [G loss: 0.974175] [Time: 0.249904]\n",
            "23-7 [D loss: 0.884956, acc.: 32.69%] [G loss: 1.098281] [Time: 0.247438]\n",
            "23-8 [D loss: 0.952549, acc.: 34.62%] [G loss: 1.158980] [Time: 0.248682]\n",
            "23 (test) [D loss: 0.861929, acc.: 50.00%] [G loss: 1.380627] [Time: 0.077549]\n",
            "24-0 [D loss: 1.007871, acc.: 28.85%] [G loss: 1.036695] [Time: 0.245197]\n",
            "24-1 [D loss: 0.731517, acc.: 51.92%] [G loss: 1.079330] [Time: 0.251877]\n",
            "24-2 [D loss: 0.998035, acc.: 32.69%] [G loss: 0.898635] [Time: 0.245976]\n",
            "24-3 [D loss: 0.948297, acc.: 30.77%] [G loss: 0.878936] [Time: 0.246064]\n",
            "24-4 [D loss: 1.110939, acc.: 26.92%] [G loss: 1.139789] [Time: 0.250032]\n",
            "24-5 [D loss: 0.820335, acc.: 51.92%] [G loss: 1.286189] [Time: 0.246940]\n",
            "24-6 [D loss: 0.882667, acc.: 34.62%] [G loss: 1.062134] [Time: 0.247123]\n",
            "24-7 [D loss: 0.874896, acc.: 30.77%] [G loss: 1.024879] [Time: 0.245698]\n",
            "24-8 [D loss: 0.784409, acc.: 44.23%] [G loss: 1.114270] [Time: 0.245890]\n",
            "24 (test) [D loss: 0.817648, acc.: 50.00%] [G loss: 1.245818] [Time: 0.077446]\n",
            "25-0 [D loss: 0.923478, acc.: 36.54%] [G loss: 1.287398] [Time: 0.245569]\n",
            "25-1 [D loss: 0.879208, acc.: 38.46%] [G loss: 1.245131] [Time: 0.244193]\n",
            "25-2 [D loss: 0.964450, acc.: 28.85%] [G loss: 1.161849] [Time: 0.251075]\n",
            "25-3 [D loss: 0.913685, acc.: 28.85%] [G loss: 1.248617] [Time: 0.247360]\n",
            "25-4 [D loss: 0.929832, acc.: 34.62%] [G loss: 1.369162] [Time: 0.244883]\n",
            "25-5 [D loss: 0.807199, acc.: 50.00%] [G loss: 1.259002] [Time: 0.248863]\n",
            "25-6 [D loss: 0.673478, acc.: 57.69%] [G loss: 1.443150] [Time: 0.246863]\n",
            "25-7 [D loss: 0.775043, acc.: 50.00%] [G loss: 1.410667] [Time: 0.251313]\n",
            "25-8 [D loss: 0.762633, acc.: 53.85%] [G loss: 1.057424] [Time: 0.248115]\n",
            "25 (test) [D loss: 0.887168, acc.: 50.00%] [G loss: 1.429993] [Time: 0.078061]\n",
            "26-0 [D loss: 0.884161, acc.: 42.31%] [G loss: 1.260835] [Time: 0.247177]\n",
            "26-1 [D loss: 0.931115, acc.: 28.85%] [G loss: 1.031420] [Time: 0.249624]\n",
            "26-2 [D loss: 0.951890, acc.: 28.85%] [G loss: 1.096502] [Time: 0.244966]\n",
            "26-3 [D loss: 0.876454, acc.: 40.38%] [G loss: 1.081363] [Time: 0.246221]\n",
            "26-4 [D loss: 0.951627, acc.: 30.77%] [G loss: 1.327827] [Time: 0.246384]\n",
            "26-5 [D loss: 0.730988, acc.: 48.08%] [G loss: 1.279663] [Time: 0.249722]\n",
            "26-6 [D loss: 0.706724, acc.: 55.77%] [G loss: 1.488546] [Time: 0.249809]\n",
            "26-7 [D loss: 0.722191, acc.: 57.69%] [G loss: 1.113199] [Time: 0.249705]\n",
            "26-8 [D loss: 0.953132, acc.: 34.62%] [G loss: 1.166301] [Time: 0.247727]\n",
            "26 (test) [D loss: 0.819777, acc.: 50.00%] [G loss: 1.255768] [Time: 0.075613]\n",
            "27-0 [D loss: 0.906353, acc.: 38.46%] [G loss: 1.304965] [Time: 0.249056]\n",
            "27-1 [D loss: 0.777450, acc.: 51.92%] [G loss: 1.483557] [Time: 0.246427]\n",
            "27-2 [D loss: 0.876027, acc.: 38.46%] [G loss: 1.365726] [Time: 0.250324]\n",
            "27-3 [D loss: 0.830180, acc.: 50.00%] [G loss: 1.223792] [Time: 0.250805]\n",
            "27-4 [D loss: 0.847305, acc.: 36.54%] [G loss: 1.241330] [Time: 0.249772]\n",
            "27-5 [D loss: 0.682364, acc.: 50.00%] [G loss: 1.462088] [Time: 0.246858]\n",
            "27-6 [D loss: 0.816112, acc.: 38.46%] [G loss: 1.273256] [Time: 0.244803]\n",
            "27-7 [D loss: 0.793273, acc.: 44.23%] [G loss: 1.242979] [Time: 0.248153]\n",
            "27-8 [D loss: 0.806232, acc.: 44.23%] [G loss: 1.356511] [Time: 0.251427]\n",
            "27 (test) [D loss: 0.948509, acc.: 50.00%] [G loss: 1.615193] [Time: 0.077446]\n",
            "28-0 [D loss: 1.013628, acc.: 32.69%] [G loss: 1.137139] [Time: 0.246866]\n",
            "28-1 [D loss: 0.889203, acc.: 34.62%] [G loss: 1.300466] [Time: 0.249218]\n",
            "28-2 [D loss: 0.791425, acc.: 44.23%] [G loss: 1.168692] [Time: 0.244483]\n",
            "28-3 [D loss: 0.717398, acc.: 55.77%] [G loss: 1.372514] [Time: 0.249440]\n",
            "28-4 [D loss: 0.966662, acc.: 28.85%] [G loss: 1.495832] [Time: 0.246093]\n",
            "28-5 [D loss: 0.767120, acc.: 50.00%] [G loss: 1.156424] [Time: 0.249236]\n",
            "28-6 [D loss: 0.841298, acc.: 44.23%] [G loss: 1.080179] [Time: 0.248585]\n",
            "28-7 [D loss: 0.915590, acc.: 36.54%] [G loss: 1.291234] [Time: 0.245954]\n",
            "28-8 [D loss: 0.950685, acc.: 34.62%] [G loss: 1.319116] [Time: 0.249884]\n",
            "28 (test) [D loss: 0.855136, acc.: 50.00%] [G loss: 1.393311] [Time: 0.080399]\n",
            "29-0 [D loss: 0.887737, acc.: 38.46%] [G loss: 1.467259] [Time: 0.246740]\n",
            "29-1 [D loss: 0.655374, acc.: 59.62%] [G loss: 1.317701] [Time: 0.249297]\n",
            "29-2 [D loss: 0.908946, acc.: 46.15%] [G loss: 1.272264] [Time: 0.247171]\n",
            "29-3 [D loss: 0.774242, acc.: 44.23%] [G loss: 1.270668] [Time: 0.247239]\n",
            "29-4 [D loss: 0.640710, acc.: 65.38%] [G loss: 1.434093] [Time: 0.246382]\n",
            "29-5 [D loss: 0.781361, acc.: 50.00%] [G loss: 1.322972] [Time: 0.250105]\n",
            "29-6 [D loss: 0.973059, acc.: 30.77%] [G loss: 1.117179] [Time: 0.245835]\n",
            "29-7 [D loss: 1.003339, acc.: 32.69%] [G loss: 1.296247] [Time: 0.246053]\n",
            "29-8 [D loss: 0.948652, acc.: 38.46%] [G loss: 1.249165] [Time: 0.246213]\n",
            "29 (test) [D loss: 0.809402, acc.: 50.00%] [G loss: 1.212446] [Time: 0.077762]\n",
            "30-0 [D loss: 0.824797, acc.: 42.31%] [G loss: 1.401611] [Time: 0.251532]\n",
            "30-1 [D loss: 0.754877, acc.: 55.77%] [G loss: 1.446864] [Time: 0.247375]\n",
            "30-2 [D loss: 0.783299, acc.: 42.31%] [G loss: 1.235229] [Time: 0.249424]\n",
            "30-3 [D loss: 0.712995, acc.: 55.77%] [G loss: 1.261564] [Time: 0.247046]\n",
            "30-4 [D loss: 0.942354, acc.: 38.46%] [G loss: 1.080732] [Time: 0.250275]\n",
            "30-5 [D loss: 0.602166, acc.: 71.15%] [G loss: 1.546666] [Time: 0.245328]\n",
            "30-6 [D loss: 0.841778, acc.: 46.15%] [G loss: 1.181288] [Time: 0.246251]\n",
            "30-7 [D loss: 0.760771, acc.: 50.00%] [G loss: 1.053119] [Time: 0.253422]\n",
            "30-8 [D loss: 0.697091, acc.: 61.54%] [G loss: 1.466393] [Time: 0.246313]\n",
            "30 (test) [D loss: 0.875867, acc.: 50.00%] [G loss: 1.437571] [Time: 0.077420]\n",
            "31-0 [D loss: 0.797915, acc.: 50.00%] [G loss: 1.145842] [Time: 0.251955]\n",
            "31-1 [D loss: 0.717381, acc.: 53.85%] [G loss: 1.191990] [Time: 0.249642]\n",
            "31-2 [D loss: 0.779791, acc.: 53.85%] [G loss: 1.135591] [Time: 0.245407]\n",
            "31-3 [D loss: 0.671386, acc.: 51.92%] [G loss: 1.721958] [Time: 0.252799]\n",
            "31-4 [D loss: 0.733470, acc.: 59.62%] [G loss: 1.669302] [Time: 0.248797]\n",
            "31-5 [D loss: 0.490541, acc.: 80.77%] [G loss: 1.792831] [Time: 0.248682]\n",
            "31-6 [D loss: 0.507691, acc.: 76.92%] [G loss: 1.611745] [Time: 0.246397]\n",
            "31-7 [D loss: 0.731017, acc.: 63.46%] [G loss: 1.566998] [Time: 0.251239]\n",
            "31-8 [D loss: 0.736402, acc.: 51.92%] [G loss: 1.456032] [Time: 0.244999]\n",
            "31 (test) [D loss: 0.736921, acc.: 50.00%] [G loss: 0.982852] [Time: 0.082561]\n",
            "32-0 [D loss: 0.850823, acc.: 50.00%] [G loss: 1.403963] [Time: 0.249999]\n",
            "32-1 [D loss: 0.814458, acc.: 42.31%] [G loss: 1.326404] [Time: 0.250718]\n",
            "32-2 [D loss: 0.808444, acc.: 42.31%] [G loss: 1.354743] [Time: 0.247032]\n",
            "32-3 [D loss: 0.754453, acc.: 55.77%] [G loss: 1.454325] [Time: 0.247040]\n",
            "32-4 [D loss: 0.803182, acc.: 48.08%] [G loss: 1.691841] [Time: 0.247669]\n",
            "32-5 [D loss: 0.554793, acc.: 76.92%] [G loss: 1.596282] [Time: 0.247729]\n",
            "32-6 [D loss: 0.669532, acc.: 67.31%] [G loss: 1.404660] [Time: 0.251130]\n",
            "32-7 [D loss: 0.782660, acc.: 55.77%] [G loss: 1.207375] [Time: 0.246250]\n",
            "32-8 [D loss: 0.827107, acc.: 46.15%] [G loss: 0.885224] [Time: 0.247164]\n",
            "32 (test) [D loss: 0.836285, acc.: 50.00%] [G loss: 1.353928] [Time: 0.080469]\n",
            "33-0 [D loss: 0.803726, acc.: 44.23%] [G loss: 1.109358] [Time: 0.251871]\n",
            "33-1 [D loss: 0.735934, acc.: 55.77%] [G loss: 1.305475] [Time: 0.246378]\n",
            "33-2 [D loss: 0.614930, acc.: 57.69%] [G loss: 1.145620] [Time: 0.248296]\n",
            "33-3 [D loss: 0.858749, acc.: 42.31%] [G loss: 1.139647] [Time: 0.245903]\n",
            "33-4 [D loss: 0.904711, acc.: 42.31%] [G loss: 1.230504] [Time: 0.248190]\n",
            "33-5 [D loss: 0.728404, acc.: 61.54%] [G loss: 1.420495] [Time: 0.247240]\n",
            "33-6 [D loss: 0.714789, acc.: 65.38%] [G loss: 1.103656] [Time: 0.245092]\n",
            "33-7 [D loss: 0.772034, acc.: 46.15%] [G loss: 1.156393] [Time: 0.248679]\n",
            "33-8 [D loss: 0.817659, acc.: 40.38%] [G loss: 1.371601] [Time: 0.246159]\n",
            "33 (test) [D loss: 0.854241, acc.: 50.00%] [G loss: 1.334449] [Time: 0.076614]\n",
            "34-0 [D loss: 0.774645, acc.: 42.31%] [G loss: 1.467635] [Time: 0.247738]\n",
            "34-1 [D loss: 0.810824, acc.: 42.31%] [G loss: 1.537808] [Time: 0.246775]\n",
            "34-2 [D loss: 0.654572, acc.: 63.46%] [G loss: 1.340067] [Time: 0.247670]\n",
            "34-3 [D loss: 0.562489, acc.: 76.92%] [G loss: 1.512831] [Time: 0.249416]\n",
            "34-4 [D loss: 0.564947, acc.: 75.00%] [G loss: 1.830804] [Time: 0.247204]\n",
            "34-5 [D loss: 0.560887, acc.: 82.69%] [G loss: 1.747250] [Time: 0.248620]\n",
            "34-6 [D loss: 0.456989, acc.: 82.69%] [G loss: 1.920080] [Time: 0.248192]\n",
            "34-7 [D loss: 0.833327, acc.: 57.69%] [G loss: 1.414593] [Time: 0.246593]\n",
            "34-8 [D loss: 0.612436, acc.: 55.77%] [G loss: 1.550788] [Time: 0.243712]\n",
            "34 (test) [D loss: 0.902623, acc.: 50.00%] [G loss: 1.476660] [Time: 0.080239]\n",
            "35-0 [D loss: 0.705736, acc.: 51.92%] [G loss: 1.179615] [Time: 0.247850]\n",
            "35-1 [D loss: 0.892544, acc.: 44.23%] [G loss: 0.996307] [Time: 0.245460]\n",
            "35-2 [D loss: 1.034815, acc.: 28.85%] [G loss: 0.957025] [Time: 0.247925]\n",
            "35-3 [D loss: 0.962540, acc.: 38.46%] [G loss: 1.154093] [Time: 0.246588]\n",
            "35-4 [D loss: 0.944303, acc.: 28.85%] [G loss: 1.652734] [Time: 0.245387]\n",
            "35-5 [D loss: 0.726178, acc.: 61.54%] [G loss: 2.014819] [Time: 0.245307]\n",
            "35-6 [D loss: 0.628071, acc.: 69.23%] [G loss: 1.690889] [Time: 0.249720]\n",
            "35-7 [D loss: 0.621390, acc.: 63.46%] [G loss: 1.514574] [Time: 0.247754]\n",
            "35-8 [D loss: 0.542341, acc.: 71.15%] [G loss: 1.445938] [Time: 0.252986]\n",
            "35 (test) [D loss: 0.904101, acc.: 50.00%] [G loss: 1.471986] [Time: 0.075881]\n",
            "36-0 [D loss: 0.494054, acc.: 75.00%] [G loss: 1.438073] [Time: 0.246375]\n",
            "36-1 [D loss: 0.578848, acc.: 73.08%] [G loss: 1.453394] [Time: 0.248123]\n",
            "36-2 [D loss: 0.716574, acc.: 55.77%] [G loss: 1.195985] [Time: 0.249211]\n",
            "36-3 [D loss: 0.682243, acc.: 55.77%] [G loss: 1.336959] [Time: 0.250199]\n",
            "36-4 [D loss: 0.618617, acc.: 67.31%] [G loss: 1.471011] [Time: 0.245526]\n",
            "36-5 [D loss: 0.673675, acc.: 73.08%] [G loss: 1.586234] [Time: 0.249383]\n",
            "36-6 [D loss: 0.726706, acc.: 51.92%] [G loss: 1.205184] [Time: 0.249037]\n",
            "36-7 [D loss: 0.865583, acc.: 40.38%] [G loss: 1.282049] [Time: 0.246441]\n",
            "36-8 [D loss: 0.843333, acc.: 42.31%] [G loss: 1.403605] [Time: 0.250385]\n",
            "36 (test) [D loss: 0.918152, acc.: 50.00%] [G loss: 1.536824] [Time: 0.079073]\n",
            "37-0 [D loss: 0.959274, acc.: 38.46%] [G loss: 1.286030] [Time: 0.245889]\n",
            "37-1 [D loss: 0.768596, acc.: 55.77%] [G loss: 1.608231] [Time: 0.247398]\n",
            "37-2 [D loss: 0.776283, acc.: 59.62%] [G loss: 1.440027] [Time: 0.247175]\n",
            "37-3 [D loss: 0.602826, acc.: 59.62%] [G loss: 1.341699] [Time: 0.246944]\n",
            "37-4 [D loss: 0.714146, acc.: 61.54%] [G loss: 1.631363] [Time: 0.247474]\n",
            "37-5 [D loss: 0.623504, acc.: 69.23%] [G loss: 1.273942] [Time: 0.251379]\n",
            "37-6 [D loss: 0.735567, acc.: 53.85%] [G loss: 1.340919] [Time: 0.249415]\n",
            "37-7 [D loss: 0.726527, acc.: 55.77%] [G loss: 1.306526] [Time: 0.250732]\n",
            "37-8 [D loss: 0.870091, acc.: 46.15%] [G loss: 1.224223] [Time: 0.244352]\n",
            "37 (test) [D loss: 0.981342, acc.: 50.00%] [G loss: 1.692589] [Time: 0.077502]\n",
            "38-0 [D loss: 0.985319, acc.: 30.77%] [G loss: 1.264458] [Time: 0.252640]\n",
            "38-1 [D loss: 0.857724, acc.: 44.23%] [G loss: 1.449333] [Time: 0.250772]\n",
            "38-2 [D loss: 0.834578, acc.: 38.46%] [G loss: 1.179932] [Time: 0.247604]\n",
            "38-3 [D loss: 0.807048, acc.: 46.15%] [G loss: 1.520484] [Time: 0.249084]\n",
            "38-4 [D loss: 0.768476, acc.: 50.00%] [G loss: 1.649513] [Time: 0.246845]\n",
            "38-5 [D loss: 0.743376, acc.: 50.00%] [G loss: 1.610818] [Time: 0.251148]\n",
            "38-6 [D loss: 0.675346, acc.: 61.54%] [G loss: 1.310633] [Time: 0.246316]\n",
            "38-7 [D loss: 0.865745, acc.: 36.54%] [G loss: 1.424494] [Time: 0.246225]\n",
            "38-8 [D loss: 0.775668, acc.: 53.85%] [G loss: 1.254532] [Time: 0.257595]\n",
            "38 (test) [D loss: 0.814417, acc.: 50.00%] [G loss: 1.284791] [Time: 0.075203]\n",
            "39-0 [D loss: 0.671168, acc.: 59.62%] [G loss: 1.270708] [Time: 0.250052]\n",
            "39-1 [D loss: 0.794543, acc.: 48.08%] [G loss: 1.298033] [Time: 0.247827]\n",
            "39-2 [D loss: 0.752362, acc.: 50.00%] [G loss: 1.297802] [Time: 0.250410]\n",
            "39-3 [D loss: 0.689771, acc.: 65.38%] [G loss: 1.661916] [Time: 0.248749]\n",
            "39-4 [D loss: 0.762015, acc.: 51.92%] [G loss: 1.545505] [Time: 0.245200]\n",
            "39-5 [D loss: 0.676297, acc.: 63.46%] [G loss: 1.486288] [Time: 0.248717]\n",
            "39-6 [D loss: 0.641867, acc.: 61.54%] [G loss: 1.435035] [Time: 0.246214]\n",
            "39-7 [D loss: 0.913883, acc.: 42.31%] [G loss: 1.355179] [Time: 0.246081]\n",
            "39-8 [D loss: 0.663188, acc.: 59.62%] [G loss: 1.269316] [Time: 0.246793]\n",
            "39 (test) [D loss: 0.837030, acc.: 50.00%] [G loss: 1.356663] [Time: 0.075952]\n",
            "40-0 [D loss: 0.727166, acc.: 57.69%] [G loss: 1.203750] [Time: 0.251883]\n",
            "40-1 [D loss: 0.682580, acc.: 57.69%] [G loss: 1.371729] [Time: 0.245107]\n",
            "40-2 [D loss: 0.678840, acc.: 53.85%] [G loss: 1.491608] [Time: 0.250035]\n",
            "40-3 [D loss: 0.658808, acc.: 63.46%] [G loss: 1.800854] [Time: 0.247263]\n",
            "40-4 [D loss: 0.679572, acc.: 59.62%] [G loss: 1.346359] [Time: 0.249740]\n",
            "40-5 [D loss: 0.526105, acc.: 78.85%] [G loss: 1.414768] [Time: 0.249069]\n",
            "40-6 [D loss: 0.535671, acc.: 75.00%] [G loss: 1.489585] [Time: 0.247658]\n",
            "40-7 [D loss: 0.687487, acc.: 55.77%] [G loss: 1.622107] [Time: 0.245810]\n",
            "40-8 [D loss: 0.615355, acc.: 67.31%] [G loss: 1.534959] [Time: 0.250570]\n",
            "40 (test) [D loss: 0.769845, acc.: 50.00%] [G loss: 1.125153] [Time: 0.078322]\n",
            "41-0 [D loss: 0.579251, acc.: 71.15%] [G loss: 1.608261] [Time: 0.246634]\n",
            "41-1 [D loss: 0.597169, acc.: 67.31%] [G loss: 1.487263] [Time: 0.249381]\n",
            "41-2 [D loss: 0.700270, acc.: 61.54%] [G loss: 1.549766] [Time: 0.247150]\n",
            "41-3 [D loss: 0.757010, acc.: 42.31%] [G loss: 1.514935] [Time: 0.246470]\n",
            "41-4 [D loss: 0.826445, acc.: 40.38%] [G loss: 1.711186] [Time: 0.252203]\n",
            "41-5 [D loss: 0.624069, acc.: 71.15%] [G loss: 1.529539] [Time: 0.249240]\n",
            "41-6 [D loss: 0.662711, acc.: 67.31%] [G loss: 1.379926] [Time: 0.251010]\n",
            "41-7 [D loss: 0.695995, acc.: 57.69%] [G loss: 1.596743] [Time: 0.249566]\n",
            "41-8 [D loss: 0.697412, acc.: 53.85%] [G loss: 1.336179] [Time: 0.250700]\n",
            "41 (test) [D loss: 0.811001, acc.: 50.00%] [G loss: 1.322873] [Time: 0.078239]\n",
            "42-0 [D loss: 0.641461, acc.: 71.15%] [G loss: 1.530756] [Time: 0.248261]\n",
            "42-1 [D loss: 0.473391, acc.: 82.69%] [G loss: 1.761723] [Time: 0.252042]\n",
            "42-2 [D loss: 0.505683, acc.: 86.54%] [G loss: 1.638233] [Time: 0.244944]\n",
            "42-3 [D loss: 0.480109, acc.: 80.77%] [G loss: 1.809145] [Time: 0.253833]\n",
            "42-4 [D loss: 0.377564, acc.: 86.54%] [G loss: 1.988447] [Time: 0.245069]\n",
            "42-5 [D loss: 0.634668, acc.: 61.54%] [G loss: 1.806358] [Time: 0.247650]\n",
            "42-6 [D loss: 0.500986, acc.: 84.62%] [G loss: 1.716596] [Time: 0.245012]\n",
            "42-7 [D loss: 0.596237, acc.: 69.23%] [G loss: 1.865733] [Time: 0.250471]\n",
            "42-8 [D loss: 0.449538, acc.: 80.77%] [G loss: 1.515490] [Time: 0.244894]\n",
            "42 (test) [D loss: 0.828426, acc.: 50.00%] [G loss: 1.275997] [Time: 0.076424]\n",
            "43-0 [D loss: 0.611618, acc.: 76.92%] [G loss: 1.302263] [Time: 0.250179]\n",
            "43-1 [D loss: 0.642359, acc.: 63.46%] [G loss: 1.533226] [Time: 0.249138]\n",
            "43-2 [D loss: 0.711914, acc.: 63.46%] [G loss: 1.643011] [Time: 0.249149]\n",
            "43-3 [D loss: 0.744812, acc.: 55.77%] [G loss: 1.894224] [Time: 0.245403]\n",
            "43-4 [D loss: 0.687666, acc.: 59.62%] [G loss: 1.940741] [Time: 0.245080]\n",
            "43-5 [D loss: 0.490220, acc.: 78.85%] [G loss: 2.139773] [Time: 0.252909]\n",
            "43-6 [D loss: 0.595136, acc.: 71.15%] [G loss: 1.850088] [Time: 0.247970]\n",
            "43-7 [D loss: 0.496013, acc.: 78.85%] [G loss: 1.766994] [Time: 0.247563]\n",
            "43-8 [D loss: 0.558222, acc.: 80.77%] [G loss: 1.770627] [Time: 0.247855]\n",
            "43 (test) [D loss: 0.957724, acc.: 50.00%] [G loss: 1.645928] [Time: 0.077702]\n",
            "44-0 [D loss: 0.572600, acc.: 69.23%] [G loss: 1.890719] [Time: 0.250962]\n",
            "44-1 [D loss: 0.469720, acc.: 78.85%] [G loss: 1.737113] [Time: 0.250233]\n",
            "44-2 [D loss: 0.588575, acc.: 67.31%] [G loss: 1.270715] [Time: 0.247462]\n",
            "44-3 [D loss: 0.739611, acc.: 55.77%] [G loss: 1.385458] [Time: 0.252760]\n",
            "44-4 [D loss: 0.778934, acc.: 51.92%] [G loss: 1.398939] [Time: 0.244570]\n",
            "44-5 [D loss: 0.758221, acc.: 50.00%] [G loss: 1.489890] [Time: 0.250094]\n",
            "44-6 [D loss: 0.687481, acc.: 53.85%] [G loss: 1.787197] [Time: 0.247522]\n",
            "44-7 [D loss: 0.804830, acc.: 57.69%] [G loss: 1.553080] [Time: 0.243346]\n",
            "44-8 [D loss: 0.645467, acc.: 61.54%] [G loss: 1.477858] [Time: 0.248548]\n",
            "44 (test) [D loss: 1.085100, acc.: 50.00%] [G loss: 1.974705] [Time: 0.076882]\n",
            "45-0 [D loss: 0.611613, acc.: 59.62%] [G loss: 1.437868] [Time: 0.245845]\n",
            "45-1 [D loss: 0.709682, acc.: 53.85%] [G loss: 1.420580] [Time: 0.243232]\n",
            "45-2 [D loss: 0.639954, acc.: 73.08%] [G loss: 1.435995] [Time: 0.248058]\n",
            "45-3 [D loss: 0.699196, acc.: 51.92%] [G loss: 1.501010] [Time: 0.248615]\n",
            "45-4 [D loss: 0.804890, acc.: 48.08%] [G loss: 1.227934] [Time: 0.248771]\n",
            "45-5 [D loss: 0.806782, acc.: 40.38%] [G loss: 1.282281] [Time: 0.249785]\n",
            "45-6 [D loss: 0.719193, acc.: 50.00%] [G loss: 1.336572] [Time: 0.251884]\n",
            "45-7 [D loss: 0.873650, acc.: 42.31%] [G loss: 1.618873] [Time: 0.248630]\n",
            "45-8 [D loss: 0.872092, acc.: 42.31%] [G loss: 1.215738] [Time: 0.244885]\n",
            "45 (test) [D loss: 1.014462, acc.: 50.00%] [G loss: 1.748416] [Time: 0.077790]\n",
            "46-0 [D loss: 0.886931, acc.: 46.15%] [G loss: 1.101013] [Time: 0.245080]\n",
            "46-1 [D loss: 0.790070, acc.: 51.92%] [G loss: 1.296807] [Time: 0.248026]\n",
            "46-2 [D loss: 0.754044, acc.: 61.54%] [G loss: 1.303314] [Time: 0.249174]\n",
            "46-3 [D loss: 0.787812, acc.: 55.77%] [G loss: 1.169131] [Time: 0.247108]\n",
            "46-4 [D loss: 0.712680, acc.: 50.00%] [G loss: 1.372286] [Time: 0.247975]\n",
            "46-5 [D loss: 0.871735, acc.: 48.08%] [G loss: 1.045015] [Time: 0.247225]\n",
            "46-6 [D loss: 0.699418, acc.: 55.77%] [G loss: 0.872540] [Time: 0.248102]\n",
            "46-7 [D loss: 0.933444, acc.: 26.92%] [G loss: 1.024050] [Time: 0.245915]\n",
            "46-8 [D loss: 0.814620, acc.: 44.23%] [G loss: 1.061306] [Time: 0.245385]\n",
            "46 (test) [D loss: 1.038162, acc.: 50.00%] [G loss: 1.826216] [Time: 0.078264]\n",
            "47-0 [D loss: 0.992631, acc.: 34.62%] [G loss: 0.949416] [Time: 0.253410]\n",
            "47-1 [D loss: 0.850898, acc.: 40.38%] [G loss: 1.063715] [Time: 0.247127]\n",
            "47-2 [D loss: 0.838832, acc.: 40.38%] [G loss: 1.108948] [Time: 0.243343]\n",
            "47-3 [D loss: 0.976097, acc.: 36.54%] [G loss: 1.128613] [Time: 0.247399]\n",
            "47-4 [D loss: 0.856923, acc.: 46.15%] [G loss: 1.362776] [Time: 0.247244]\n",
            "47-5 [D loss: 0.678387, acc.: 55.77%] [G loss: 1.296094] [Time: 0.251635]\n",
            "47-6 [D loss: 0.709438, acc.: 57.69%] [G loss: 1.288698] [Time: 0.249587]\n",
            "47-7 [D loss: 0.593547, acc.: 69.23%] [G loss: 1.518916] [Time: 0.250136]\n",
            "47-8 [D loss: 0.669676, acc.: 61.54%] [G loss: 1.330397] [Time: 0.246111]\n",
            "47 (test) [D loss: 0.840426, acc.: 50.00%] [G loss: 1.389801] [Time: 0.076739]\n",
            "48-0 [D loss: 0.739022, acc.: 51.92%] [G loss: 1.418972] [Time: 0.248041]\n",
            "48-1 [D loss: 0.823260, acc.: 46.15%] [G loss: 1.143893] [Time: 0.246255]\n",
            "48-2 [D loss: 0.679993, acc.: 61.54%] [G loss: 1.048869] [Time: 0.249091]\n",
            "48-3 [D loss: 0.576975, acc.: 71.15%] [G loss: 1.291164] [Time: 0.247101]\n",
            "48-4 [D loss: 0.932592, acc.: 32.69%] [G loss: 1.242029] [Time: 0.249677]\n",
            "48-5 [D loss: 0.676631, acc.: 63.46%] [G loss: 1.395741] [Time: 0.249391]\n",
            "48-6 [D loss: 0.618428, acc.: 59.62%] [G loss: 1.300830] [Time: 0.247092]\n",
            "48-7 [D loss: 0.534094, acc.: 71.15%] [G loss: 1.488937] [Time: 0.245432]\n",
            "48-8 [D loss: 0.746312, acc.: 48.08%] [G loss: 1.212199] [Time: 0.249918]\n",
            "48 (test) [D loss: 0.899393, acc.: 50.00%] [G loss: 1.558880] [Time: 0.077870]\n",
            "49-0 [D loss: 0.560984, acc.: 67.31%] [G loss: 1.382030] [Time: 0.247539]\n",
            "49-1 [D loss: 0.716552, acc.: 59.62%] [G loss: 1.204590] [Time: 0.250454]\n",
            "49-2 [D loss: 0.614589, acc.: 63.46%] [G loss: 1.281597] [Time: 0.246356]\n",
            "49-3 [D loss: 0.675411, acc.: 55.77%] [G loss: 1.679976] [Time: 0.252055]\n",
            "49-4 [D loss: 0.909026, acc.: 36.54%] [G loss: 1.309864] [Time: 0.247283]\n",
            "49-5 [D loss: 1.020606, acc.: 32.69%] [G loss: 1.171958] [Time: 0.248952]\n",
            "49-6 [D loss: 0.943027, acc.: 34.62%] [G loss: 1.413868] [Time: 0.245125]\n",
            "49-7 [D loss: 0.872619, acc.: 48.08%] [G loss: 1.602734] [Time: 0.247909]\n",
            "49-8 [D loss: 0.884232, acc.: 40.38%] [G loss: 1.295092] [Time: 0.246657]\n",
            "49 (test) [D loss: 1.069520, acc.: 50.00%] [G loss: 1.982041] [Time: 0.077178]\n",
            "50-0 [D loss: 0.700286, acc.: 57.69%] [G loss: 1.691938] [Time: 0.250031]\n",
            "50-1 [D loss: 0.685943, acc.: 57.69%] [G loss: 1.646487] [Time: 0.244478]\n",
            "50-2 [D loss: 0.740664, acc.: 55.77%] [G loss: 1.195639] [Time: 0.244990]\n",
            "50-3 [D loss: 0.832102, acc.: 53.85%] [G loss: 1.358969] [Time: 0.246730]\n",
            "50-4 [D loss: 0.883013, acc.: 44.23%] [G loss: 1.263355] [Time: 0.245641]\n",
            "50-5 [D loss: 0.909233, acc.: 46.15%] [G loss: 1.380446] [Time: 0.244027]\n",
            "50-6 [D loss: 0.828046, acc.: 48.08%] [G loss: 1.178107] [Time: 0.248482]\n",
            "50-7 [D loss: 0.881101, acc.: 48.08%] [G loss: 1.289093] [Time: 0.244624]\n",
            "50-8 [D loss: 0.986563, acc.: 26.92%] [G loss: 1.103898] [Time: 0.245488]\n",
            "50 (test) [D loss: 0.988359, acc.: 50.00%] [G loss: 1.737262] [Time: 0.078361]\n",
            "51-0 [D loss: 0.794858, acc.: 48.08%] [G loss: 1.243354] [Time: 0.241568]\n",
            "51-1 [D loss: 0.778123, acc.: 50.00%] [G loss: 1.322428] [Time: 0.240246]\n",
            "51-2 [D loss: 0.672820, acc.: 61.54%] [G loss: 1.250481] [Time: 0.248914]\n",
            "51-3 [D loss: 0.782560, acc.: 61.54%] [G loss: 1.161925] [Time: 0.243732]\n",
            "51-4 [D loss: 0.828460, acc.: 46.15%] [G loss: 1.029301] [Time: 0.241589]\n",
            "51-5 [D loss: 0.692147, acc.: 59.62%] [G loss: 1.197263] [Time: 0.246926]\n",
            "51-6 [D loss: 0.637296, acc.: 55.77%] [G loss: 1.203714] [Time: 0.248398]\n",
            "51-7 [D loss: 0.653764, acc.: 57.69%] [G loss: 1.293406] [Time: 0.246258]\n",
            "51-8 [D loss: 0.613515, acc.: 55.77%] [G loss: 1.419817] [Time: 0.249931]\n",
            "51 (test) [D loss: 1.001369, acc.: 50.00%] [G loss: 1.774402] [Time: 0.076730]\n",
            "52-0 [D loss: 0.646211, acc.: 63.46%] [G loss: 1.227423] [Time: 0.245799]\n",
            "52-1 [D loss: 0.677536, acc.: 59.62%] [G loss: 1.176428] [Time: 0.244740]\n",
            "52-2 [D loss: 0.732692, acc.: 48.08%] [G loss: 0.967487] [Time: 0.243311]\n",
            "52-3 [D loss: 0.704468, acc.: 55.77%] [G loss: 1.279099] [Time: 0.248577]\n",
            "52-4 [D loss: 0.849347, acc.: 44.23%] [G loss: 1.417819] [Time: 0.248419]\n",
            "52-5 [D loss: 0.666175, acc.: 57.69%] [G loss: 1.355285] [Time: 0.244295]\n",
            "52-6 [D loss: 0.607866, acc.: 63.46%] [G loss: 1.228125] [Time: 0.248013]\n",
            "52-7 [D loss: 0.687556, acc.: 51.92%] [G loss: 1.471683] [Time: 0.250033]\n",
            "52-8 [D loss: 0.698866, acc.: 57.69%] [G loss: 1.426687] [Time: 0.249330]\n",
            "52 (test) [D loss: 0.996410, acc.: 50.00%] [G loss: 1.777393] [Time: 0.076378]\n",
            "53-0 [D loss: 0.672658, acc.: 53.85%] [G loss: 1.242668] [Time: 0.250399]\n",
            "53-1 [D loss: 0.747602, acc.: 51.92%] [G loss: 1.600452] [Time: 0.251722]\n",
            "53-2 [D loss: 0.687952, acc.: 61.54%] [G loss: 1.703584] [Time: 0.248792]\n",
            "53-3 [D loss: 0.598425, acc.: 71.15%] [G loss: 1.929112] [Time: 0.245208]\n",
            "53-4 [D loss: 0.632442, acc.: 69.23%] [G loss: 1.569233] [Time: 0.242335]\n",
            "53-5 [D loss: 0.738274, acc.: 51.92%] [G loss: 1.212494] [Time: 0.244896]\n",
            "53-6 [D loss: 0.664346, acc.: 59.62%] [G loss: 1.443317] [Time: 0.245636]\n",
            "53-7 [D loss: 0.609692, acc.: 63.46%] [G loss: 1.360315] [Time: 0.244499]\n",
            "53-8 [D loss: 0.715290, acc.: 53.85%] [G loss: 1.136644] [Time: 0.248449]\n",
            "53 (test) [D loss: 0.953712, acc.: 50.00%] [G loss: 1.652114] [Time: 0.077201]\n",
            "54-0 [D loss: 0.682867, acc.: 57.69%] [G loss: 1.412169] [Time: 0.244483]\n",
            "54-1 [D loss: 0.767140, acc.: 48.08%] [G loss: 1.103468] [Time: 0.243480]\n",
            "54-2 [D loss: 0.728588, acc.: 53.85%] [G loss: 1.079144] [Time: 0.245952]\n",
            "54-3 [D loss: 0.678311, acc.: 55.77%] [G loss: 1.578302] [Time: 0.250721]\n",
            "54-4 [D loss: 0.921276, acc.: 40.38%] [G loss: 1.215267] [Time: 0.247215]\n",
            "54-5 [D loss: 0.766830, acc.: 55.77%] [G loss: 1.191225] [Time: 0.245558]\n",
            "54-6 [D loss: 0.667088, acc.: 61.54%] [G loss: 1.145904] [Time: 0.249836]\n",
            "54-7 [D loss: 0.549794, acc.: 71.15%] [G loss: 1.346342] [Time: 0.258745]\n",
            "54-8 [D loss: 0.587982, acc.: 67.31%] [G loss: 1.605991] [Time: 0.247347]\n",
            "54 (test) [D loss: 1.024293, acc.: 50.00%] [G loss: 1.809681] [Time: 0.077091]\n",
            "55-0 [D loss: 0.702830, acc.: 51.92%] [G loss: 1.440844] [Time: 0.252671]\n",
            "55-1 [D loss: 0.702080, acc.: 55.77%] [G loss: 1.244769] [Time: 0.256522]\n",
            "55-2 [D loss: 0.669982, acc.: 63.46%] [G loss: 1.201029] [Time: 0.247712]\n",
            "55-3 [D loss: 0.640040, acc.: 57.69%] [G loss: 1.477113] [Time: 0.250743]\n",
            "55-4 [D loss: 0.891784, acc.: 46.15%] [G loss: 1.227461] [Time: 0.248880]\n",
            "55-5 [D loss: 0.660012, acc.: 59.62%] [G loss: 1.556420] [Time: 0.243979]\n",
            "55-6 [D loss: 0.577166, acc.: 71.15%] [G loss: 1.576502] [Time: 0.251159]\n",
            "55-7 [D loss: 0.511076, acc.: 75.00%] [G loss: 1.613385] [Time: 0.249038]\n",
            "55-8 [D loss: 0.620622, acc.: 65.38%] [G loss: 1.400137] [Time: 0.245079]\n",
            "55 (test) [D loss: 1.027915, acc.: 50.00%] [G loss: 1.834798] [Time: 0.077919]\n",
            "56-0 [D loss: 0.798420, acc.: 51.92%] [G loss: 1.365814] [Time: 0.244515]\n",
            "56-1 [D loss: 0.807616, acc.: 44.23%] [G loss: 1.449592] [Time: 0.245479]\n",
            "56-2 [D loss: 0.601473, acc.: 67.31%] [G loss: 1.500806] [Time: 0.249485]\n",
            "56-3 [D loss: 0.612244, acc.: 71.15%] [G loss: 1.422977] [Time: 0.247036]\n",
            "56-4 [D loss: 0.547380, acc.: 67.31%] [G loss: 1.434933] [Time: 0.247586]\n",
            "56-5 [D loss: 0.666539, acc.: 63.46%] [G loss: 1.426461] [Time: 0.251134]\n",
            "56-6 [D loss: 0.738573, acc.: 57.69%] [G loss: 1.562010] [Time: 0.249405]\n",
            "56-7 [D loss: 0.615028, acc.: 67.31%] [G loss: 1.520757] [Time: 0.244028]\n",
            "56-8 [D loss: 0.772497, acc.: 46.15%] [G loss: 1.261480] [Time: 0.247987]\n",
            "56 (test) [D loss: 0.966197, acc.: 50.00%] [G loss: 1.699987] [Time: 0.075846]\n",
            "57-0 [D loss: 0.652162, acc.: 61.54%] [G loss: 1.263082] [Time: 0.253411]\n",
            "57-1 [D loss: 0.936081, acc.: 34.62%] [G loss: 1.226184] [Time: 0.246236]\n",
            "57-2 [D loss: 0.695908, acc.: 57.69%] [G loss: 1.409616] [Time: 0.244985]\n",
            "57-3 [D loss: 0.801986, acc.: 51.92%] [G loss: 1.239482] [Time: 0.248784]\n",
            "57-4 [D loss: 0.865079, acc.: 44.23%] [G loss: 1.251495] [Time: 0.249333]\n",
            "57-5 [D loss: 0.689000, acc.: 53.85%] [G loss: 1.856360] [Time: 0.243577]\n",
            "57-6 [D loss: 0.724588, acc.: 59.62%] [G loss: 1.532246] [Time: 0.245684]\n",
            "57-7 [D loss: 0.599873, acc.: 73.08%] [G loss: 1.461004] [Time: 0.248204]\n",
            "57-8 [D loss: 0.580324, acc.: 69.23%] [G loss: 1.520295] [Time: 0.250668]\n",
            "57 (test) [D loss: 0.887943, acc.: 50.00%] [G loss: 1.425169] [Time: 0.078639]\n",
            "58-0 [D loss: 0.584310, acc.: 73.08%] [G loss: 1.752428] [Time: 0.251878]\n",
            "58-1 [D loss: 0.592898, acc.: 73.08%] [G loss: 1.524057] [Time: 0.247742]\n",
            "58-2 [D loss: 0.477537, acc.: 78.85%] [G loss: 1.581683] [Time: 0.245180]\n",
            "58-3 [D loss: 0.477065, acc.: 80.77%] [G loss: 1.603652] [Time: 0.250054]\n",
            "58-4 [D loss: 0.769477, acc.: 53.85%] [G loss: 1.421739] [Time: 0.243474]\n",
            "58-5 [D loss: 0.590249, acc.: 59.62%] [G loss: 1.632705] [Time: 0.246716]\n",
            "58-6 [D loss: 0.560149, acc.: 65.38%] [G loss: 1.543594] [Time: 0.246241]\n",
            "58-7 [D loss: 0.660928, acc.: 57.69%] [G loss: 1.388773] [Time: 0.245921]\n",
            "58-8 [D loss: 0.641400, acc.: 65.38%] [G loss: 1.472816] [Time: 0.245502]\n",
            "58 (test) [D loss: 0.975948, acc.: 50.00%] [G loss: 1.679645] [Time: 0.078136]\n",
            "59-0 [D loss: 0.805340, acc.: 50.00%] [G loss: 1.467396] [Time: 0.251052]\n",
            "59-1 [D loss: 0.690705, acc.: 53.85%] [G loss: 1.269279] [Time: 0.246676]\n",
            "59-2 [D loss: 0.703976, acc.: 50.00%] [G loss: 1.409499] [Time: 0.246987]\n",
            "59-3 [D loss: 0.614318, acc.: 65.38%] [G loss: 1.261208] [Time: 0.248116]\n",
            "59-4 [D loss: 0.684173, acc.: 67.31%] [G loss: 1.279634] [Time: 0.247796]\n",
            "59-5 [D loss: 0.495349, acc.: 84.62%] [G loss: 1.685682] [Time: 0.245278]\n",
            "59-6 [D loss: 0.439645, acc.: 88.46%] [G loss: 1.480456] [Time: 0.246131]\n",
            "59-7 [D loss: 0.435412, acc.: 78.85%] [G loss: 1.414547] [Time: 0.248806]\n",
            "59-8 [D loss: 0.521536, acc.: 75.00%] [G loss: 1.191083] [Time: 0.244117]\n",
            "59 (test) [D loss: 0.828813, acc.: 50.00%] [G loss: 1.398788] [Time: 0.076811]\n",
            "60-0 [D loss: 0.728713, acc.: 61.54%] [G loss: 1.426956] [Time: 0.249813]\n",
            "60-1 [D loss: 0.644538, acc.: 63.46%] [G loss: 1.336136] [Time: 0.244151]\n",
            "60-2 [D loss: 0.562271, acc.: 75.00%] [G loss: 1.577236] [Time: 0.251333]\n",
            "60-3 [D loss: 0.652638, acc.: 63.46%] [G loss: 1.293372] [Time: 0.248302]\n",
            "60-4 [D loss: 0.670395, acc.: 61.54%] [G loss: 1.739919] [Time: 0.245945]\n",
            "60-5 [D loss: 0.600624, acc.: 73.08%] [G loss: 1.434555] [Time: 0.251409]\n",
            "60-6 [D loss: 0.548270, acc.: 65.38%] [G loss: 1.528149] [Time: 0.249589]\n",
            "60-7 [D loss: 0.510362, acc.: 73.08%] [G loss: 1.491193] [Time: 0.247353]\n",
            "60-8 [D loss: 0.608270, acc.: 63.46%] [G loss: 1.295611] [Time: 0.245461]\n",
            "60 (test) [D loss: 0.727841, acc.: 53.85%] [G loss: 1.043025] [Time: 0.075856]\n",
            "61-0 [D loss: 0.681897, acc.: 53.85%] [G loss: 1.343770] [Time: 0.246361]\n",
            "61-1 [D loss: 0.771156, acc.: 50.00%] [G loss: 1.421560] [Time: 0.248003]\n",
            "61-2 [D loss: 0.719587, acc.: 50.00%] [G loss: 1.363415] [Time: 0.253543]\n",
            "61-3 [D loss: 0.660258, acc.: 59.62%] [G loss: 1.400731] [Time: 0.245422]\n",
            "61-4 [D loss: 0.658684, acc.: 53.85%] [G loss: 1.250101] [Time: 0.246455]\n",
            "61-5 [D loss: 0.674833, acc.: 55.77%] [G loss: 1.255541] [Time: 0.249350]\n",
            "61-6 [D loss: 0.647617, acc.: 65.38%] [G loss: 1.261974] [Time: 0.246264]\n",
            "61-7 [D loss: 0.523835, acc.: 71.15%] [G loss: 1.377758] [Time: 0.246566]\n",
            "61-8 [D loss: 0.607218, acc.: 63.46%] [G loss: 1.324675] [Time: 0.248817]\n",
            "61 (test) [D loss: 0.934286, acc.: 50.00%] [G loss: 1.628722] [Time: 0.078401]\n",
            "62-0 [D loss: 0.536211, acc.: 76.92%] [G loss: 1.300511] [Time: 0.249501]\n",
            "62-1 [D loss: 0.582874, acc.: 67.31%] [G loss: 1.081458] [Time: 0.247585]\n",
            "62-2 [D loss: 0.655778, acc.: 59.62%] [G loss: 1.233608] [Time: 0.246662]\n",
            "62-3 [D loss: 0.625666, acc.: 63.46%] [G loss: 1.412884] [Time: 0.244127]\n",
            "62-4 [D loss: 0.806659, acc.: 48.08%] [G loss: 1.209074] [Time: 0.249719]\n",
            "62-5 [D loss: 0.690750, acc.: 63.46%] [G loss: 1.628927] [Time: 0.245827]\n",
            "62-6 [D loss: 0.656805, acc.: 57.69%] [G loss: 1.369572] [Time: 0.252680]\n",
            "62-7 [D loss: 0.729253, acc.: 57.69%] [G loss: 1.430543] [Time: 0.246512]\n",
            "62-8 [D loss: 0.788887, acc.: 48.08%] [G loss: 1.329058] [Time: 0.248597]\n",
            "62 (test) [D loss: 0.848989, acc.: 50.00%] [G loss: 1.400728] [Time: 0.076258]\n",
            "63-0 [D loss: 0.710123, acc.: 51.92%] [G loss: 1.627827] [Time: 0.247613]\n",
            "63-1 [D loss: 0.787302, acc.: 46.15%] [G loss: 1.295848] [Time: 0.247926]\n",
            "63-2 [D loss: 0.779054, acc.: 57.69%] [G loss: 1.362816] [Time: 0.248071]\n",
            "63-3 [D loss: 0.838858, acc.: 51.92%] [G loss: 1.256189] [Time: 0.247396]\n",
            "63-4 [D loss: 0.668664, acc.: 65.38%] [G loss: 1.223923] [Time: 0.245223]\n",
            "63-5 [D loss: 0.625678, acc.: 69.23%] [G loss: 1.296017] [Time: 0.249930]\n",
            "63-6 [D loss: 0.740350, acc.: 50.00%] [G loss: 1.263524] [Time: 0.251348]\n",
            "63-7 [D loss: 0.535849, acc.: 69.23%] [G loss: 1.423831] [Time: 0.248049]\n",
            "63-8 [D loss: 0.809900, acc.: 53.85%] [G loss: 1.258469] [Time: 0.245420]\n",
            "63 (test) [D loss: 0.826905, acc.: 50.00%] [G loss: 1.316307] [Time: 0.077672]\n",
            "64-0 [D loss: 0.656507, acc.: 59.62%] [G loss: 1.550123] [Time: 0.248710]\n",
            "64-1 [D loss: 0.698766, acc.: 50.00%] [G loss: 1.480794] [Time: 0.249456]\n",
            "64-2 [D loss: 0.702223, acc.: 46.15%] [G loss: 1.178737] [Time: 0.245624]\n",
            "64-3 [D loss: 0.676293, acc.: 61.54%] [G loss: 1.590707] [Time: 0.250280]\n",
            "64-4 [D loss: 0.715947, acc.: 50.00%] [G loss: 1.334281] [Time: 0.253435]\n",
            "64-5 [D loss: 0.750619, acc.: 46.15%] [G loss: 1.541856] [Time: 0.247259]\n",
            "64-6 [D loss: 0.820758, acc.: 51.92%] [G loss: 1.231071] [Time: 0.247169]\n",
            "64-7 [D loss: 0.636021, acc.: 63.46%] [G loss: 1.366381] [Time: 0.247250]\n",
            "64-8 [D loss: 0.806235, acc.: 50.00%] [G loss: 1.308298] [Time: 0.249247]\n",
            "64 (test) [D loss: 0.757650, acc.: 51.92%] [G loss: 1.118519] [Time: 0.076602]\n",
            "65-0 [D loss: 0.741354, acc.: 48.08%] [G loss: 1.444136] [Time: 0.244935]\n",
            "65-1 [D loss: 0.627850, acc.: 55.77%] [G loss: 1.819401] [Time: 0.245986]\n",
            "65-2 [D loss: 0.804687, acc.: 38.46%] [G loss: 1.253100] [Time: 0.248096]\n",
            "65-3 [D loss: 0.822550, acc.: 48.08%] [G loss: 1.539224] [Time: 0.250193]\n",
            "65-4 [D loss: 0.840426, acc.: 50.00%] [G loss: 1.442723] [Time: 0.243924]\n",
            "65-5 [D loss: 0.713257, acc.: 57.69%] [G loss: 1.386516] [Time: 0.244651]\n",
            "65-6 [D loss: 0.535210, acc.: 75.00%] [G loss: 1.453735] [Time: 0.249907]\n",
            "65-7 [D loss: 0.750631, acc.: 51.92%] [G loss: 1.231417] [Time: 0.249163]\n",
            "65-8 [D loss: 0.586601, acc.: 65.38%] [G loss: 1.346842] [Time: 0.247508]\n",
            "65 (test) [D loss: 0.996921, acc.: 50.00%] [G loss: 1.753046] [Time: 0.076392]\n",
            "66-0 [D loss: 0.762663, acc.: 50.00%] [G loss: 1.358710] [Time: 0.247457]\n",
            "66-1 [D loss: 0.671378, acc.: 55.77%] [G loss: 1.315624] [Time: 0.247144]\n",
            "66-2 [D loss: 0.672513, acc.: 63.46%] [G loss: 1.136860] [Time: 0.246099]\n",
            "66-3 [D loss: 0.606923, acc.: 71.15%] [G loss: 1.484764] [Time: 0.244099]\n",
            "66-4 [D loss: 0.679152, acc.: 53.85%] [G loss: 1.670141] [Time: 0.247750]\n",
            "66-5 [D loss: 0.659165, acc.: 50.00%] [G loss: 1.455955] [Time: 0.245134]\n",
            "66-6 [D loss: 0.743296, acc.: 57.69%] [G loss: 1.215388] [Time: 0.247568]\n",
            "66-7 [D loss: 0.714455, acc.: 53.85%] [G loss: 1.274296] [Time: 0.247499]\n",
            "66-8 [D loss: 0.661551, acc.: 57.69%] [G loss: 1.419514] [Time: 0.246273]\n",
            "66 (test) [D loss: 1.005007, acc.: 50.00%] [G loss: 1.775129] [Time: 0.078138]\n",
            "67-0 [D loss: 0.792132, acc.: 51.92%] [G loss: 1.298877] [Time: 0.249246]\n",
            "67-1 [D loss: 0.602333, acc.: 67.31%] [G loss: 1.403626] [Time: 0.248912]\n",
            "67-2 [D loss: 0.796826, acc.: 42.31%] [G loss: 1.144353] [Time: 0.246563]\n",
            "67-3 [D loss: 0.853387, acc.: 53.85%] [G loss: 1.354839] [Time: 0.246747]\n",
            "67-4 [D loss: 0.753831, acc.: 48.08%] [G loss: 1.495555] [Time: 0.249905]\n",
            "67-5 [D loss: 0.557091, acc.: 67.31%] [G loss: 1.785557] [Time: 0.243765]\n",
            "67-6 [D loss: 0.677839, acc.: 57.69%] [G loss: 1.366101] [Time: 0.246682]\n",
            "67-7 [D loss: 0.745794, acc.: 65.38%] [G loss: 1.422700] [Time: 0.246889]\n",
            "67-8 [D loss: 0.587023, acc.: 65.38%] [G loss: 1.534798] [Time: 0.251205]\n",
            "67 (test) [D loss: 0.996586, acc.: 50.00%] [G loss: 1.776916] [Time: 0.076670]\n",
            "68-0 [D loss: 0.668476, acc.: 63.46%] [G loss: 1.115403] [Time: 0.247548]\n",
            "68-1 [D loss: 0.658430, acc.: 59.62%] [G loss: 1.535912] [Time: 0.248421]\n",
            "68-2 [D loss: 0.771053, acc.: 50.00%] [G loss: 1.195762] [Time: 0.247950]\n",
            "68-3 [D loss: 0.647169, acc.: 61.54%] [G loss: 1.236861] [Time: 0.247436]\n",
            "68-4 [D loss: 0.610979, acc.: 65.38%] [G loss: 1.289839] [Time: 0.246808]\n",
            "68-5 [D loss: 0.516472, acc.: 75.00%] [G loss: 1.523114] [Time: 0.244838]\n",
            "68-6 [D loss: 0.668807, acc.: 61.54%] [G loss: 1.303958] [Time: 0.245238]\n",
            "68-7 [D loss: 0.775025, acc.: 53.85%] [G loss: 1.448214] [Time: 0.246854]\n",
            "68-8 [D loss: 0.753790, acc.: 48.08%] [G loss: 1.258666] [Time: 0.246114]\n",
            "68 (test) [D loss: 0.891607, acc.: 50.00%] [G loss: 1.529798] [Time: 0.076635]\n",
            "69-0 [D loss: 0.756852, acc.: 53.85%] [G loss: 1.524650] [Time: 0.245110]\n",
            "69-1 [D loss: 0.613732, acc.: 69.23%] [G loss: 1.371481] [Time: 0.247296]\n",
            "69-2 [D loss: 0.737365, acc.: 48.08%] [G loss: 1.277241] [Time: 0.246389]\n",
            "69-3 [D loss: 0.662989, acc.: 59.62%] [G loss: 1.291941] [Time: 0.245895]\n",
            "69-4 [D loss: 0.623619, acc.: 61.54%] [G loss: 1.522271] [Time: 0.246392]\n",
            "69-5 [D loss: 0.495811, acc.: 80.77%] [G loss: 1.394261] [Time: 0.245827]\n",
            "69-6 [D loss: 0.769589, acc.: 55.77%] [G loss: 1.099112] [Time: 0.247179]\n",
            "69-7 [D loss: 0.670652, acc.: 57.69%] [G loss: 1.285136] [Time: 0.244553]\n",
            "69-8 [D loss: 0.711474, acc.: 55.77%] [G loss: 1.387336] [Time: 0.248873]\n",
            "69 (test) [D loss: 0.873320, acc.: 50.00%] [G loss: 1.466608] [Time: 0.078782]\n",
            "70-0 [D loss: 0.717155, acc.: 50.00%] [G loss: 1.357759] [Time: 0.250012]\n",
            "70-1 [D loss: 0.641330, acc.: 61.54%] [G loss: 1.277639] [Time: 0.249495]\n",
            "70-2 [D loss: 0.650632, acc.: 57.69%] [G loss: 1.315509] [Time: 0.247069]\n",
            "70-3 [D loss: 0.804449, acc.: 53.85%] [G loss: 1.429751] [Time: 0.247516]\n",
            "70-4 [D loss: 0.721735, acc.: 61.54%] [G loss: 1.267287] [Time: 0.245629]\n",
            "70-5 [D loss: 0.708656, acc.: 67.31%] [G loss: 1.468477] [Time: 0.248936]\n",
            "70-6 [D loss: 0.722465, acc.: 53.85%] [G loss: 1.119260] [Time: 0.248698]\n",
            "70-7 [D loss: 0.575152, acc.: 75.00%] [G loss: 1.474360] [Time: 0.244804]\n",
            "70-8 [D loss: 0.857323, acc.: 51.92%] [G loss: 1.032549] [Time: 0.247298]\n",
            "70 (test) [D loss: 0.864747, acc.: 50.00%] [G loss: 1.455655] [Time: 0.078229]\n",
            "71-0 [D loss: 0.606061, acc.: 63.46%] [G loss: 1.272338] [Time: 0.252501]\n",
            "71-1 [D loss: 0.592007, acc.: 71.15%] [G loss: 1.602518] [Time: 0.247334]\n",
            "71-2 [D loss: 0.660552, acc.: 51.92%] [G loss: 1.468009] [Time: 0.245383]\n",
            "71-3 [D loss: 0.623447, acc.: 63.46%] [G loss: 1.465219] [Time: 0.251000]\n",
            "71-4 [D loss: 0.663662, acc.: 63.46%] [G loss: 1.438362] [Time: 0.248896]\n",
            "71-5 [D loss: 0.515621, acc.: 71.15%] [G loss: 1.454454] [Time: 0.246345]\n",
            "71-6 [D loss: 0.760773, acc.: 46.15%] [G loss: 1.787619] [Time: 0.244196]\n",
            "71-7 [D loss: 0.605567, acc.: 67.31%] [G loss: 1.396366] [Time: 0.249638]\n",
            "71-8 [D loss: 0.793982, acc.: 48.08%] [G loss: 1.373051] [Time: 0.245769]\n",
            "71 (test) [D loss: 0.895854, acc.: 50.00%] [G loss: 1.484416] [Time: 0.077805]\n",
            "72-0 [D loss: 0.780896, acc.: 48.08%] [G loss: 1.307151] [Time: 0.245534]\n",
            "72-1 [D loss: 0.718356, acc.: 61.54%] [G loss: 1.467289] [Time: 0.255488]\n",
            "72-2 [D loss: 0.658781, acc.: 53.85%] [G loss: 1.326238] [Time: 0.247315]\n",
            "72-3 [D loss: 0.769079, acc.: 40.38%] [G loss: 1.311949] [Time: 0.248905]\n",
            "72-4 [D loss: 0.921260, acc.: 46.15%] [G loss: 1.703014] [Time: 0.244333]\n",
            "72-5 [D loss: 0.709915, acc.: 61.54%] [G loss: 1.844452] [Time: 0.248312]\n",
            "72-6 [D loss: 0.678297, acc.: 53.85%] [G loss: 1.495767] [Time: 0.249053]\n",
            "72-7 [D loss: 0.745215, acc.: 55.77%] [G loss: 1.734119] [Time: 0.245018]\n",
            "72-8 [D loss: 0.670320, acc.: 65.38%] [G loss: 1.300846] [Time: 0.245863]\n",
            "72 (test) [D loss: 0.950478, acc.: 50.00%] [G loss: 1.614625] [Time: 0.081627]\n",
            "73-0 [D loss: 0.693058, acc.: 63.46%] [G loss: 1.487813] [Time: 0.248586]\n",
            "73-1 [D loss: 0.679220, acc.: 59.62%] [G loss: 1.326072] [Time: 0.244233]\n",
            "73-2 [D loss: 0.618776, acc.: 71.15%] [G loss: 1.219692] [Time: 0.245396]\n",
            "73-3 [D loss: 0.670299, acc.: 67.31%] [G loss: 1.424426] [Time: 0.248553]\n",
            "73-4 [D loss: 0.538324, acc.: 71.15%] [G loss: 1.923115] [Time: 0.248939]\n",
            "73-5 [D loss: 0.622315, acc.: 75.00%] [G loss: 1.659919] [Time: 0.243436]\n",
            "73-6 [D loss: 0.525069, acc.: 69.23%] [G loss: 1.436630] [Time: 0.246521]\n",
            "73-7 [D loss: 0.522885, acc.: 73.08%] [G loss: 1.821139] [Time: 0.246752]\n",
            "73-8 [D loss: 0.688286, acc.: 53.85%] [G loss: 1.402541] [Time: 0.247516]\n",
            "73 (test) [D loss: 0.912444, acc.: 50.00%] [G loss: 1.539078] [Time: 0.076395]\n",
            "74-0 [D loss: 0.549166, acc.: 75.00%] [G loss: 1.699887] [Time: 0.248704]\n",
            "74-1 [D loss: 0.702740, acc.: 59.62%] [G loss: 1.682910] [Time: 0.248328]\n",
            "74-2 [D loss: 0.804870, acc.: 46.15%] [G loss: 1.341121] [Time: 0.245172]\n",
            "74-3 [D loss: 0.843355, acc.: 46.15%] [G loss: 1.451568] [Time: 0.244504]\n",
            "74-4 [D loss: 0.736046, acc.: 50.00%] [G loss: 1.699643] [Time: 0.245959]\n",
            "74-5 [D loss: 0.583301, acc.: 65.38%] [G loss: 1.666631] [Time: 0.245135]\n",
            "74-6 [D loss: 0.565987, acc.: 76.92%] [G loss: 1.547930] [Time: 0.247477]\n",
            "74-7 [D loss: 0.617839, acc.: 71.15%] [G loss: 1.577444] [Time: 0.255225]\n",
            "74-8 [D loss: 0.718245, acc.: 59.62%] [G loss: 1.579610] [Time: 0.247729]\n",
            "74 (test) [D loss: 0.931784, acc.: 50.00%] [G loss: 1.594157] [Time: 0.079498]\n",
            "75-0 [D loss: 0.660897, acc.: 63.46%] [G loss: 1.306540] [Time: 0.250050]\n",
            "75-1 [D loss: 0.597270, acc.: 67.31%] [G loss: 1.500180] [Time: 0.247121]\n",
            "75-2 [D loss: 0.599899, acc.: 59.62%] [G loss: 1.241585] [Time: 0.254284]\n",
            "75-3 [D loss: 0.612388, acc.: 67.31%] [G loss: 1.157867] [Time: 0.244957]\n",
            "75-4 [D loss: 0.573419, acc.: 67.31%] [G loss: 1.401508] [Time: 0.250582]\n",
            "75-5 [D loss: 0.430574, acc.: 82.69%] [G loss: 0.953761] [Time: 0.246895]\n",
            "75-6 [D loss: 0.397228, acc.: 90.38%] [G loss: 0.767748] [Time: 0.245995]\n",
            "75-7 [D loss: 0.519443, acc.: 76.92%] [G loss: 0.935123] [Time: 0.245561]\n",
            "75-8 [D loss: 0.528577, acc.: 71.15%] [G loss: 1.193951] [Time: 0.245595]\n",
            "75 (test) [D loss: 0.875308, acc.: 50.00%] [G loss: 1.542958] [Time: 0.079336]\n",
            "76-0 [D loss: 0.771446, acc.: 51.92%] [G loss: 1.147254] [Time: 0.251385]\n",
            "76-1 [D loss: 0.591724, acc.: 69.23%] [G loss: 1.392275] [Time: 0.247910]\n",
            "76-2 [D loss: 0.737222, acc.: 55.77%] [G loss: 1.148103] [Time: 0.251720]\n",
            "76-3 [D loss: 0.708059, acc.: 51.92%] [G loss: 1.372205] [Time: 0.244680]\n",
            "76-4 [D loss: 0.763567, acc.: 51.92%] [G loss: 1.860359] [Time: 0.248082]\n",
            "76-5 [D loss: 0.711451, acc.: 57.69%] [G loss: 1.478038] [Time: 0.246313]\n",
            "76-6 [D loss: 0.662972, acc.: 59.62%] [G loss: 1.395693] [Time: 0.248443]\n",
            "76-7 [D loss: 0.668881, acc.: 61.54%] [G loss: 1.851680] [Time: 0.248961]\n",
            "76-8 [D loss: 0.699409, acc.: 59.62%] [G loss: 1.337699] [Time: 0.247200]\n",
            "76 (test) [D loss: 0.859021, acc.: 50.00%] [G loss: 1.463383] [Time: 0.077970]\n",
            "77-0 [D loss: 0.830088, acc.: 44.23%] [G loss: 1.548464] [Time: 0.252492]\n",
            "77-1 [D loss: 0.594249, acc.: 71.15%] [G loss: 1.621889] [Time: 0.249500]\n",
            "77-2 [D loss: 0.625627, acc.: 65.38%] [G loss: 1.330394] [Time: 0.248486]\n",
            "77-3 [D loss: 0.646460, acc.: 61.54%] [G loss: 1.194061] [Time: 0.247075]\n",
            "77-4 [D loss: 0.785517, acc.: 51.92%] [G loss: 1.533830] [Time: 0.246907]\n",
            "77-5 [D loss: 0.470445, acc.: 80.77%] [G loss: 1.588243] [Time: 0.247172]\n",
            "77-6 [D loss: 0.688470, acc.: 65.38%] [G loss: 1.570600] [Time: 0.246913]\n",
            "77-7 [D loss: 0.544854, acc.: 76.92%] [G loss: 1.560339] [Time: 0.248804]\n",
            "77-8 [D loss: 0.615991, acc.: 63.46%] [G loss: 1.764931] [Time: 0.244312]\n",
            "77 (test) [D loss: 0.912856, acc.: 50.00%] [G loss: 1.604505] [Time: 0.078641]\n",
            "78-0 [D loss: 0.647680, acc.: 59.62%] [G loss: 1.534877] [Time: 0.249074]\n",
            "78-1 [D loss: 0.668340, acc.: 61.54%] [G loss: 1.693139] [Time: 0.245343]\n",
            "78-2 [D loss: 0.681184, acc.: 55.77%] [G loss: 1.394431] [Time: 0.246318]\n",
            "78-3 [D loss: 0.699900, acc.: 57.69%] [G loss: 1.452025] [Time: 0.244498]\n",
            "78-4 [D loss: 0.580619, acc.: 67.31%] [G loss: 1.756307] [Time: 0.255049]\n",
            "78-5 [D loss: 0.548179, acc.: 75.00%] [G loss: 1.719755] [Time: 0.246850]\n",
            "78-6 [D loss: 0.500462, acc.: 73.08%] [G loss: 1.465353] [Time: 0.245893]\n",
            "78-7 [D loss: 0.528605, acc.: 73.08%] [G loss: 1.682652] [Time: 0.250814]\n",
            "78-8 [D loss: 0.498901, acc.: 75.00%] [G loss: 1.574403] [Time: 0.247923]\n",
            "78 (test) [D loss: 1.013511, acc.: 50.00%] [G loss: 1.821423] [Time: 0.077884]\n",
            "79-0 [D loss: 0.648619, acc.: 57.69%] [G loss: 1.393326] [Time: 0.249808]\n",
            "79-1 [D loss: 0.661355, acc.: 55.77%] [G loss: 1.460413] [Time: 0.242444]\n",
            "79-2 [D loss: 0.539622, acc.: 69.23%] [G loss: 1.499540] [Time: 0.249313]\n",
            "79-3 [D loss: 0.660248, acc.: 61.54%] [G loss: 1.400322] [Time: 0.247419]\n",
            "79-4 [D loss: 0.536932, acc.: 73.08%] [G loss: 1.652102] [Time: 0.246458]\n",
            "79-5 [D loss: 0.464260, acc.: 82.69%] [G loss: 1.674989] [Time: 0.245822]\n",
            "79-6 [D loss: 0.628155, acc.: 63.46%] [G loss: 1.555810] [Time: 0.245888]\n",
            "79-7 [D loss: 0.479883, acc.: 80.77%] [G loss: 1.689438] [Time: 0.250293]\n",
            "79-8 [D loss: 0.602546, acc.: 75.00%] [G loss: 1.431604] [Time: 0.250600]\n",
            "79 (test) [D loss: 1.016467, acc.: 50.00%] [G loss: 1.771043] [Time: 0.076911]\n",
            "80-0 [D loss: 0.745813, acc.: 53.85%] [G loss: 1.393066] [Time: 0.247055]\n",
            "80-1 [D loss: 0.557779, acc.: 67.31%] [G loss: 1.443344] [Time: 0.251943]\n",
            "80-2 [D loss: 0.789966, acc.: 46.15%] [G loss: 1.123124] [Time: 0.247560]\n",
            "80-3 [D loss: 0.651015, acc.: 71.15%] [G loss: 0.998247] [Time: 0.247949]\n",
            "80-4 [D loss: 0.535540, acc.: 67.31%] [G loss: 1.347045] [Time: 0.248092]\n",
            "80-5 [D loss: 0.419897, acc.: 82.69%] [G loss: 1.774718] [Time: 0.249435]\n",
            "80-6 [D loss: 0.631750, acc.: 63.46%] [G loss: 1.134150] [Time: 0.248839]\n",
            "80-7 [D loss: 0.442288, acc.: 73.08%] [G loss: 1.480421] [Time: 0.248344]\n",
            "80-8 [D loss: 0.484013, acc.: 82.69%] [G loss: 1.275997] [Time: 0.248116]\n",
            "80 (test) [D loss: 0.955470, acc.: 50.00%] [G loss: 1.658222] [Time: 0.077267]\n",
            "81-0 [D loss: 0.598717, acc.: 63.46%] [G loss: 1.618184] [Time: 0.253263]\n",
            "81-1 [D loss: 0.588092, acc.: 71.15%] [G loss: 1.544146] [Time: 0.243204]\n",
            "81-2 [D loss: 0.663013, acc.: 55.77%] [G loss: 1.366452] [Time: 0.247497]\n",
            "81-3 [D loss: 0.587907, acc.: 65.38%] [G loss: 1.332496] [Time: 0.246878]\n",
            "81-4 [D loss: 0.619394, acc.: 65.38%] [G loss: 1.520929] [Time: 0.249074]\n",
            "81-5 [D loss: 0.419700, acc.: 84.62%] [G loss: 1.626184] [Time: 0.244099]\n",
            "81-6 [D loss: 0.595031, acc.: 55.77%] [G loss: 1.285677] [Time: 0.246336]\n",
            "81-7 [D loss: 0.550063, acc.: 69.23%] [G loss: 1.680277] [Time: 0.245263]\n",
            "81-8 [D loss: 0.565146, acc.: 69.23%] [G loss: 1.405577] [Time: 0.249916]\n",
            "81 (test) [D loss: 1.038491, acc.: 50.00%] [G loss: 1.837050] [Time: 0.076344]\n",
            "82-0 [D loss: 0.503261, acc.: 78.85%] [G loss: 1.662512] [Time: 0.247390]\n",
            "82-1 [D loss: 0.624864, acc.: 67.31%] [G loss: 1.355198] [Time: 0.248895]\n",
            "82-2 [D loss: 0.715832, acc.: 51.92%] [G loss: 1.418512] [Time: 0.249281]\n",
            "82-3 [D loss: 0.534807, acc.: 69.23%] [G loss: 1.717092] [Time: 0.246551]\n",
            "82-4 [D loss: 0.535945, acc.: 71.15%] [G loss: 1.681385] [Time: 0.246924]\n",
            "82-5 [D loss: 0.517092, acc.: 76.92%] [G loss: 1.642186] [Time: 0.246673]\n",
            "82-6 [D loss: 0.690436, acc.: 63.46%] [G loss: 1.503295] [Time: 0.248534]\n",
            "82-7 [D loss: 0.528747, acc.: 80.77%] [G loss: 1.819406] [Time: 0.247962]\n",
            "82-8 [D loss: 0.643618, acc.: 65.38%] [G loss: 1.467135] [Time: 0.247493]\n",
            "82 (test) [D loss: 1.018459, acc.: 50.00%] [G loss: 1.759296] [Time: 0.076790]\n",
            "83-0 [D loss: 0.539920, acc.: 75.00%] [G loss: 1.495182] [Time: 0.246979]\n",
            "83-1 [D loss: 0.583710, acc.: 67.31%] [G loss: 1.596323] [Time: 0.251295]\n",
            "83-2 [D loss: 0.623929, acc.: 61.54%] [G loss: 1.422200] [Time: 0.246692]\n",
            "83-3 [D loss: 0.704342, acc.: 65.38%] [G loss: 1.632093] [Time: 0.243873]\n",
            "83-4 [D loss: 0.509123, acc.: 75.00%] [G loss: 1.733107] [Time: 0.249204]\n",
            "83-5 [D loss: 0.584250, acc.: 73.08%] [G loss: 1.497244] [Time: 0.246033]\n",
            "83-6 [D loss: 0.648253, acc.: 63.46%] [G loss: 1.569617] [Time: 0.248574]\n",
            "83-7 [D loss: 0.593135, acc.: 71.15%] [G loss: 1.620472] [Time: 0.247602]\n",
            "83-8 [D loss: 0.650083, acc.: 59.62%] [G loss: 1.556170] [Time: 0.249698]\n",
            "83 (test) [D loss: 0.968669, acc.: 50.00%] [G loss: 1.670443] [Time: 0.077093]\n",
            "84-0 [D loss: 0.503938, acc.: 76.92%] [G loss: 1.691048] [Time: 0.246092]\n",
            "84-1 [D loss: 0.490681, acc.: 78.85%] [G loss: 1.432625] [Time: 0.246376]\n",
            "84-2 [D loss: 0.394964, acc.: 90.38%] [G loss: 1.384988] [Time: 0.249404]\n",
            "84-3 [D loss: 0.573582, acc.: 75.00%] [G loss: 1.523560] [Time: 0.247882]\n",
            "84-4 [D loss: 0.526532, acc.: 75.00%] [G loss: 1.794978] [Time: 0.246598]\n",
            "84-5 [D loss: 0.464721, acc.: 86.54%] [G loss: 1.795699] [Time: 0.247590]\n",
            "84-6 [D loss: 0.629935, acc.: 69.23%] [G loss: 1.505633] [Time: 0.246707]\n",
            "84-7 [D loss: 0.411056, acc.: 84.62%] [G loss: 1.518658] [Time: 0.245891]\n",
            "84-8 [D loss: 0.498125, acc.: 73.08%] [G loss: 1.685573] [Time: 0.246492]\n",
            "84 (test) [D loss: 0.875808, acc.: 50.00%] [G loss: 1.511922] [Time: 0.079498]\n",
            "85-0 [D loss: 0.479813, acc.: 80.77%] [G loss: 1.871713] [Time: 0.245831]\n",
            "85-1 [D loss: 0.496764, acc.: 75.00%] [G loss: 1.445082] [Time: 0.246016]\n",
            "85-2 [D loss: 0.663510, acc.: 53.85%] [G loss: 1.434310] [Time: 0.246838]\n",
            "85-3 [D loss: 0.577822, acc.: 71.15%] [G loss: 1.258092] [Time: 0.248553]\n",
            "85-4 [D loss: 0.536656, acc.: 75.00%] [G loss: 1.769267] [Time: 0.247856]\n",
            "85-5 [D loss: 0.493752, acc.: 78.85%] [G loss: 1.436134] [Time: 0.244721]\n",
            "85-6 [D loss: 0.602931, acc.: 67.31%] [G loss: 1.581107] [Time: 0.246700]\n",
            "85-7 [D loss: 0.477428, acc.: 76.92%] [G loss: 1.481407] [Time: 0.247517]\n",
            "85-8 [D loss: 0.663016, acc.: 55.77%] [G loss: 1.477120] [Time: 0.250934]\n",
            "85 (test) [D loss: 1.057293, acc.: 50.00%] [G loss: 1.910494] [Time: 0.080042]\n",
            "86-0 [D loss: 0.502516, acc.: 78.85%] [G loss: 1.705404] [Time: 0.251526]\n",
            "86-1 [D loss: 0.676486, acc.: 59.62%] [G loss: 1.433343] [Time: 0.244533]\n",
            "86-2 [D loss: 0.725314, acc.: 51.92%] [G loss: 1.384033] [Time: 0.245981]\n",
            "86-3 [D loss: 0.514152, acc.: 80.77%] [G loss: 1.527107] [Time: 0.248111]\n",
            "86-4 [D loss: 0.577077, acc.: 73.08%] [G loss: 1.649929] [Time: 0.250612]\n",
            "86-5 [D loss: 0.538521, acc.: 71.15%] [G loss: 1.758565] [Time: 0.246401]\n",
            "86-6 [D loss: 0.445553, acc.: 78.85%] [G loss: 1.612871] [Time: 0.249215]\n",
            "86-7 [D loss: 0.566701, acc.: 63.46%] [G loss: 1.728953] [Time: 0.243057]\n",
            "86-8 [D loss: 0.580112, acc.: 67.31%] [G loss: 1.285166] [Time: 0.247083]\n",
            "86 (test) [D loss: 0.983206, acc.: 50.00%] [G loss: 1.727049] [Time: 0.076438]\n",
            "87-0 [D loss: 0.453608, acc.: 76.92%] [G loss: 1.448070] [Time: 0.250564]\n",
            "87-1 [D loss: 0.698065, acc.: 51.92%] [G loss: 1.403367] [Time: 0.242179]\n",
            "87-2 [D loss: 0.706162, acc.: 57.69%] [G loss: 1.473952] [Time: 0.250618]\n",
            "87-3 [D loss: 0.703733, acc.: 59.62%] [G loss: 1.422331] [Time: 0.250484]\n",
            "87-4 [D loss: 0.554767, acc.: 71.15%] [G loss: 1.564754] [Time: 0.247489]\n",
            "87-5 [D loss: 0.527711, acc.: 76.92%] [G loss: 1.623095] [Time: 0.246443]\n",
            "87-6 [D loss: 0.569857, acc.: 69.23%] [G loss: 1.807658] [Time: 0.249459]\n",
            "87-7 [D loss: 0.601808, acc.: 73.08%] [G loss: 1.587242] [Time: 0.247318]\n",
            "87-8 [D loss: 0.724723, acc.: 61.54%] [G loss: 1.389969] [Time: 0.245866]\n",
            "87 (test) [D loss: 0.992033, acc.: 50.00%] [G loss: 1.742483] [Time: 0.077273]\n",
            "88-0 [D loss: 0.555395, acc.: 69.23%] [G loss: 1.432687] [Time: 0.248237]\n",
            "88-1 [D loss: 0.671052, acc.: 57.69%] [G loss: 1.768117] [Time: 0.253512]\n",
            "88-2 [D loss: 0.713918, acc.: 55.77%] [G loss: 1.316387] [Time: 0.247235]\n",
            "88-3 [D loss: 0.570638, acc.: 67.31%] [G loss: 1.444132] [Time: 0.246011]\n",
            "88-4 [D loss: 0.671634, acc.: 65.38%] [G loss: 1.543873] [Time: 0.248897]\n",
            "88-5 [D loss: 0.666620, acc.: 65.38%] [G loss: 1.525857] [Time: 0.245111]\n",
            "88-6 [D loss: 0.575086, acc.: 61.54%] [G loss: 1.516258] [Time: 0.246059]\n",
            "88-7 [D loss: 0.458835, acc.: 78.85%] [G loss: 1.756336] [Time: 0.249134]\n",
            "88-8 [D loss: 0.664135, acc.: 53.85%] [G loss: 1.327260] [Time: 0.249054]\n",
            "88 (test) [D loss: 1.056804, acc.: 50.00%] [G loss: 1.893843] [Time: 0.077342]\n",
            "89-0 [D loss: 0.545861, acc.: 69.23%] [G loss: 1.532814] [Time: 0.245613]\n",
            "89-1 [D loss: 0.666562, acc.: 57.69%] [G loss: 1.430838] [Time: 0.250405]\n",
            "89-2 [D loss: 0.929858, acc.: 36.54%] [G loss: 1.183323] [Time: 0.244604]\n",
            "89-3 [D loss: 0.607449, acc.: 71.15%] [G loss: 1.795845] [Time: 0.248278]\n",
            "89-4 [D loss: 0.648306, acc.: 61.54%] [G loss: 1.699137] [Time: 0.246241]\n",
            "89-5 [D loss: 0.555970, acc.: 69.23%] [G loss: 1.568108] [Time: 0.246866]\n",
            "89-6 [D loss: 0.603139, acc.: 67.31%] [G loss: 1.542041] [Time: 0.248364]\n",
            "89-7 [D loss: 0.550882, acc.: 75.00%] [G loss: 1.666259] [Time: 0.246828]\n",
            "89-8 [D loss: 0.505468, acc.: 73.08%] [G loss: 1.552798] [Time: 0.245715]\n",
            "89 (test) [D loss: 1.013298, acc.: 50.00%] [G loss: 1.832717] [Time: 0.077926]\n",
            "90-0 [D loss: 0.533247, acc.: 73.08%] [G loss: 1.914345] [Time: 0.248090]\n",
            "90-1 [D loss: 0.513960, acc.: 71.15%] [G loss: 1.738270] [Time: 0.250824]\n",
            "90-2 [D loss: 0.765824, acc.: 53.85%] [G loss: 1.373298] [Time: 0.245537]\n",
            "90-3 [D loss: 0.637832, acc.: 63.46%] [G loss: 1.514374] [Time: 0.245365]\n",
            "90-4 [D loss: 0.664693, acc.: 57.69%] [G loss: 1.677098] [Time: 0.245713]\n",
            "90-5 [D loss: 0.420060, acc.: 84.62%] [G loss: 1.810786] [Time: 0.244459]\n",
            "90-6 [D loss: 0.556772, acc.: 71.15%] [G loss: 1.499698] [Time: 0.249276]\n",
            "90-7 [D loss: 0.460840, acc.: 75.00%] [G loss: 1.699185] [Time: 0.245665]\n",
            "90-8 [D loss: 0.477089, acc.: 88.46%] [G loss: 1.608713] [Time: 0.248064]\n",
            "90 (test) [D loss: 1.000465, acc.: 50.00%] [G loss: 1.799236] [Time: 0.080025]\n",
            "91-0 [D loss: 0.560898, acc.: 73.08%] [G loss: 1.384415] [Time: 0.246454]\n",
            "91-1 [D loss: 0.584679, acc.: 71.15%] [G loss: 1.671775] [Time: 0.250043]\n",
            "91-2 [D loss: 0.715110, acc.: 51.92%] [G loss: 1.400736] [Time: 0.245121]\n",
            "91-3 [D loss: 0.630872, acc.: 61.54%] [G loss: 1.723426] [Time: 0.244325]\n",
            "91-4 [D loss: 0.609435, acc.: 55.77%] [G loss: 1.782387] [Time: 0.247984]\n",
            "91-5 [D loss: 0.622757, acc.: 63.46%] [G loss: 1.598917] [Time: 0.246727]\n",
            "91-6 [D loss: 0.632362, acc.: 63.46%] [G loss: 1.431429] [Time: 0.244463]\n",
            "91-7 [D loss: 0.528015, acc.: 76.92%] [G loss: 1.443594] [Time: 0.249759]\n",
            "91-8 [D loss: 0.556790, acc.: 67.31%] [G loss: 1.311700] [Time: 0.245342]\n",
            "91 (test) [D loss: 0.986970, acc.: 50.00%] [G loss: 1.771830] [Time: 0.078798]\n",
            "92-0 [D loss: 0.655489, acc.: 61.54%] [G loss: 1.389296] [Time: 0.248202]\n",
            "92-1 [D loss: 0.698498, acc.: 48.08%] [G loss: 1.508070] [Time: 0.245859]\n",
            "92-2 [D loss: 0.818417, acc.: 44.23%] [G loss: 1.180280] [Time: 0.246045]\n",
            "92-3 [D loss: 0.734485, acc.: 57.69%] [G loss: 1.539405] [Time: 0.246216]\n",
            "92-4 [D loss: 0.759436, acc.: 51.92%] [G loss: 1.587010] [Time: 0.249753]\n",
            "92-5 [D loss: 0.569004, acc.: 69.23%] [G loss: 1.410304] [Time: 0.247572]\n",
            "92-6 [D loss: 0.690065, acc.: 61.54%] [G loss: 1.375020] [Time: 0.242462]\n",
            "92-7 [D loss: 0.467288, acc.: 69.23%] [G loss: 1.689529] [Time: 0.248724]\n",
            "92-8 [D loss: 0.612092, acc.: 76.92%] [G loss: 1.494305] [Time: 0.246792]\n",
            "92 (test) [D loss: 1.111229, acc.: 50.00%] [G loss: 2.083714] [Time: 0.082796]\n",
            "93-0 [D loss: 0.514272, acc.: 80.77%] [G loss: 1.411394] [Time: 0.247439]\n",
            "93-1 [D loss: 0.592917, acc.: 69.23%] [G loss: 1.605460] [Time: 0.249506]\n",
            "93-2 [D loss: 0.763733, acc.: 48.08%] [G loss: 1.402820] [Time: 0.246670]\n",
            "93-3 [D loss: 0.668814, acc.: 61.54%] [G loss: 1.492850] [Time: 0.247420]\n",
            "93-4 [D loss: 0.662296, acc.: 55.77%] [G loss: 1.718005] [Time: 0.245060]\n",
            "93-5 [D loss: 0.573821, acc.: 71.15%] [G loss: 1.490355] [Time: 0.247037]\n",
            "93-6 [D loss: 0.495405, acc.: 76.92%] [G loss: 1.571964] [Time: 0.245645]\n",
            "93-7 [D loss: 0.469394, acc.: 75.00%] [G loss: 1.647740] [Time: 0.247289]\n",
            "93-8 [D loss: 0.713413, acc.: 53.85%] [G loss: 1.451006] [Time: 0.248015]\n",
            "93 (test) [D loss: 0.932089, acc.: 50.00%] [G loss: 1.641635] [Time: 0.075213]\n",
            "94-0 [D loss: 0.627618, acc.: 63.46%] [G loss: 1.449064] [Time: 0.245283]\n",
            "94-1 [D loss: 0.568443, acc.: 73.08%] [G loss: 1.396126] [Time: 0.249033]\n",
            "94-2 [D loss: 0.901477, acc.: 38.46%] [G loss: 0.999886] [Time: 0.250134]\n",
            "94-3 [D loss: 0.727387, acc.: 48.08%] [G loss: 1.385156] [Time: 0.249089]\n",
            "94-4 [D loss: 0.457026, acc.: 84.62%] [G loss: 1.501886] [Time: 0.245828]\n",
            "94-5 [D loss: 0.580334, acc.: 73.08%] [G loss: 1.462653] [Time: 0.247990]\n",
            "94-6 [D loss: 0.594684, acc.: 73.08%] [G loss: 1.749838] [Time: 0.250953]\n",
            "94-7 [D loss: 0.489949, acc.: 75.00%] [G loss: 2.002226] [Time: 0.247767]\n",
            "94-8 [D loss: 0.584710, acc.: 63.46%] [G loss: 1.546293] [Time: 0.247623]\n",
            "94 (test) [D loss: 0.936602, acc.: 50.00%] [G loss: 1.668661] [Time: 0.078086]\n",
            "95-0 [D loss: 0.778330, acc.: 61.54%] [G loss: 1.394938] [Time: 0.247130]\n",
            "95-1 [D loss: 0.589614, acc.: 59.62%] [G loss: 1.502559] [Time: 0.247567]\n",
            "95-2 [D loss: 0.657677, acc.: 71.15%] [G loss: 1.658800] [Time: 0.249984]\n",
            "95-3 [D loss: 0.730743, acc.: 53.85%] [G loss: 1.734205] [Time: 0.249913]\n",
            "95-4 [D loss: 0.612044, acc.: 67.31%] [G loss: 1.696647] [Time: 0.245748]\n",
            "95-5 [D loss: 0.515104, acc.: 76.92%] [G loss: 1.427900] [Time: 0.245314]\n",
            "95-6 [D loss: 0.566184, acc.: 67.31%] [G loss: 1.493993] [Time: 0.247848]\n",
            "95-7 [D loss: 0.428851, acc.: 80.77%] [G loss: 1.780973] [Time: 0.249135]\n",
            "95-8 [D loss: 0.603293, acc.: 65.38%] [G loss: 1.216327] [Time: 0.244949]\n",
            "95 (test) [D loss: 1.035566, acc.: 50.00%] [G loss: 1.845786] [Time: 0.076610]\n",
            "96-0 [D loss: 0.540254, acc.: 75.00%] [G loss: 1.794618] [Time: 0.247634]\n",
            "96-1 [D loss: 0.573674, acc.: 65.38%] [G loss: 1.185293] [Time: 0.242149]\n",
            "96-2 [D loss: 0.851158, acc.: 38.46%] [G loss: 1.221700] [Time: 0.246792]\n",
            "96-3 [D loss: 0.676191, acc.: 63.46%] [G loss: 1.588064] [Time: 0.243145]\n",
            "96-4 [D loss: 0.654996, acc.: 57.69%] [G loss: 1.590120] [Time: 0.245258]\n",
            "96-5 [D loss: 0.550578, acc.: 67.31%] [G loss: 1.298262] [Time: 0.244884]\n",
            "96-6 [D loss: 0.627711, acc.: 65.38%] [G loss: 1.439865] [Time: 0.245182]\n",
            "96-7 [D loss: 0.511468, acc.: 71.15%] [G loss: 1.799108] [Time: 0.245207]\n",
            "96-8 [D loss: 0.568630, acc.: 69.23%] [G loss: 1.600833] [Time: 0.377664]\n",
            "96 (test) [D loss: 1.030990, acc.: 50.00%] [G loss: 1.885177] [Time: 0.076615]\n",
            "97-0 [D loss: 0.576587, acc.: 65.38%] [G loss: 1.443979] [Time: 0.243148]\n",
            "97-1 [D loss: 0.559977, acc.: 67.31%] [G loss: 1.481926] [Time: 0.245732]\n",
            "97-2 [D loss: 0.678082, acc.: 65.38%] [G loss: 1.325901] [Time: 0.247104]\n",
            "97-3 [D loss: 0.663702, acc.: 57.69%] [G loss: 1.325701] [Time: 0.246917]\n",
            "97-4 [D loss: 0.537751, acc.: 73.08%] [G loss: 1.785951] [Time: 0.253772]\n",
            "97-5 [D loss: 0.609766, acc.: 67.31%] [G loss: 1.580632] [Time: 0.247369]\n",
            "97-6 [D loss: 0.589041, acc.: 75.00%] [G loss: 1.621598] [Time: 0.245977]\n",
            "97-7 [D loss: 0.495259, acc.: 76.92%] [G loss: 1.574724] [Time: 0.247838]\n",
            "97-8 [D loss: 0.576607, acc.: 63.46%] [G loss: 1.517779] [Time: 0.247627]\n",
            "97 (test) [D loss: 1.027236, acc.: 50.00%] [G loss: 1.848097] [Time: 0.079586]\n",
            "98-0 [D loss: 0.494395, acc.: 84.62%] [G loss: 1.714852] [Time: 0.246979]\n",
            "98-1 [D loss: 0.557799, acc.: 75.00%] [G loss: 1.260743] [Time: 0.243320]\n",
            "98-2 [D loss: 0.785448, acc.: 51.92%] [G loss: 1.115407] [Time: 0.250909]\n",
            "98-3 [D loss: 0.692371, acc.: 57.69%] [G loss: 1.380376] [Time: 0.248413]\n",
            "98-4 [D loss: 0.573171, acc.: 69.23%] [G loss: 1.689224] [Time: 0.244407]\n",
            "98-5 [D loss: 0.629775, acc.: 61.54%] [G loss: 1.522237] [Time: 0.246594]\n",
            "98-6 [D loss: 0.674319, acc.: 63.46%] [G loss: 1.642060] [Time: 0.250380]\n",
            "98-7 [D loss: 0.485831, acc.: 78.85%] [G loss: 1.636194] [Time: 0.246408]\n",
            "98-8 [D loss: 0.480375, acc.: 75.00%] [G loss: 1.360912] [Time: 0.245528]\n",
            "98 (test) [D loss: 0.965951, acc.: 50.00%] [G loss: 1.680602] [Time: 0.077350]\n",
            "99-0 [D loss: 0.476707, acc.: 73.08%] [G loss: 1.379626] [Time: 0.249118]\n",
            "99-1 [D loss: 0.681181, acc.: 57.69%] [G loss: 1.386635] [Time: 0.250447]\n",
            "99-2 [D loss: 0.674408, acc.: 57.69%] [G loss: 1.354070] [Time: 0.246880]\n",
            "99-3 [D loss: 0.803592, acc.: 48.08%] [G loss: 1.222292] [Time: 0.245991]\n",
            "99-4 [D loss: 0.515549, acc.: 67.31%] [G loss: 1.590407] [Time: 0.246617]\n",
            "99-5 [D loss: 0.592431, acc.: 71.15%] [G loss: 1.476131] [Time: 0.247777]\n",
            "99-6 [D loss: 0.525782, acc.: 73.08%] [G loss: 1.637721] [Time: 0.249128]\n",
            "99-7 [D loss: 0.466207, acc.: 82.69%] [G loss: 1.666007] [Time: 0.246436]\n",
            "99-8 [D loss: 0.463679, acc.: 75.00%] [G loss: 1.307539] [Time: 0.250921]\n",
            "99 (test) [D loss: 0.990296, acc.: 50.00%] [G loss: 1.734322] [Time: 0.076978]\n",
            "100-0 [D loss: 0.597753, acc.: 61.54%] [G loss: 1.309579] [Time: 0.249205]\n",
            "100-1 [D loss: 0.491746, acc.: 82.69%] [G loss: 1.472549] [Time: 0.244256]\n",
            "100-2 [D loss: 0.772275, acc.: 46.15%] [G loss: 1.261462] [Time: 0.246680]\n",
            "100-3 [D loss: 0.784149, acc.: 48.08%] [G loss: 1.297879] [Time: 0.243639]\n",
            "100-4 [D loss: 0.606689, acc.: 61.54%] [G loss: 1.662054] [Time: 0.249650]\n",
            "100-5 [D loss: 0.720993, acc.: 63.46%] [G loss: 1.534442] [Time: 0.246590]\n",
            "100-6 [D loss: 0.740739, acc.: 51.92%] [G loss: 1.449180] [Time: 0.247258]\n",
            "100-7 [D loss: 0.543865, acc.: 75.00%] [G loss: 1.457897] [Time: 0.247045]\n",
            "100-8 [D loss: 0.596537, acc.: 71.15%] [G loss: 1.484206] [Time: 0.250419]\n",
            "100 (test) [D loss: 1.094462, acc.: 50.00%] [G loss: 2.009158] [Time: 0.077837]\n",
            "101-0 [D loss: 0.464856, acc.: 82.69%] [G loss: 1.609302] [Time: 0.245461]\n",
            "101-1 [D loss: 0.623067, acc.: 63.46%] [G loss: 1.364494] [Time: 0.245003]\n",
            "101-2 [D loss: 0.723038, acc.: 50.00%] [G loss: 1.443646] [Time: 0.251386]\n",
            "101-3 [D loss: 0.862794, acc.: 40.38%] [G loss: 1.293720] [Time: 0.250516]\n",
            "101-4 [D loss: 0.624914, acc.: 59.62%] [G loss: 1.724925] [Time: 0.247912]\n",
            "101-5 [D loss: 0.662259, acc.: 65.38%] [G loss: 1.344517] [Time: 0.248252]\n",
            "101-6 [D loss: 0.666643, acc.: 57.69%] [G loss: 1.470498] [Time: 0.245142]\n",
            "101-7 [D loss: 0.545676, acc.: 69.23%] [G loss: 1.527787] [Time: 0.247542]\n",
            "101-8 [D loss: 0.656194, acc.: 57.69%] [G loss: 1.357226] [Time: 0.246105]\n",
            "101 (test) [D loss: 1.075963, acc.: 50.00%] [G loss: 1.957230] [Time: 0.078063]\n",
            "102-0 [D loss: 0.631358, acc.: 57.69%] [G loss: 1.793278] [Time: 0.246822]\n",
            "102-1 [D loss: 0.612733, acc.: 75.00%] [G loss: 1.411348] [Time: 0.248733]\n",
            "102-2 [D loss: 0.666566, acc.: 61.54%] [G loss: 1.454998] [Time: 0.245997]\n",
            "102-3 [D loss: 0.875252, acc.: 40.38%] [G loss: 1.361594] [Time: 0.249073]\n",
            "102-4 [D loss: 0.576211, acc.: 69.23%] [G loss: 1.571914] [Time: 0.248316]\n",
            "102-5 [D loss: 0.627154, acc.: 65.38%] [G loss: 1.492917] [Time: 0.246754]\n",
            "102-6 [D loss: 0.650574, acc.: 67.31%] [G loss: 1.446586] [Time: 0.246525]\n",
            "102-7 [D loss: 0.509376, acc.: 73.08%] [G loss: 1.584558] [Time: 0.246979]\n",
            "102-8 [D loss: 0.697092, acc.: 61.54%] [G loss: 1.445976] [Time: 0.247975]\n",
            "102 (test) [D loss: 1.083574, acc.: 50.00%] [G loss: 2.006038] [Time: 0.078068]\n",
            "103-0 [D loss: 0.505497, acc.: 78.85%] [G loss: 1.747568] [Time: 0.248776]\n",
            "103-1 [D loss: 0.548222, acc.: 71.15%] [G loss: 1.221864] [Time: 0.250576]\n",
            "103-2 [D loss: 0.709520, acc.: 51.92%] [G loss: 1.163190] [Time: 0.248430]\n",
            "103-3 [D loss: 0.876818, acc.: 42.31%] [G loss: 1.224763] [Time: 0.249846]\n",
            "103-4 [D loss: 0.598396, acc.: 69.23%] [G loss: 1.326267] [Time: 0.247552]\n",
            "103-5 [D loss: 0.739502, acc.: 63.46%] [G loss: 1.620606] [Time: 0.249143]\n",
            "103-6 [D loss: 0.685414, acc.: 55.77%] [G loss: 1.707833] [Time: 0.249452]\n",
            "103-7 [D loss: 0.615282, acc.: 69.23%] [G loss: 1.683080] [Time: 0.245872]\n",
            "103-8 [D loss: 0.583209, acc.: 67.31%] [G loss: 1.270758] [Time: 0.255020]\n",
            "103 (test) [D loss: 1.078278, acc.: 50.00%] [G loss: 1.969845] [Time: 0.081557]\n",
            "104-0 [D loss: 0.473371, acc.: 82.69%] [G loss: 1.458835] [Time: 0.246747]\n",
            "104-1 [D loss: 0.657355, acc.: 65.38%] [G loss: 1.108297] [Time: 0.244359]\n",
            "104-2 [D loss: 0.698124, acc.: 50.00%] [G loss: 1.343734] [Time: 0.247524]\n",
            "104-3 [D loss: 0.883137, acc.: 32.69%] [G loss: 1.391278] [Time: 0.248209]\n",
            "104-4 [D loss: 0.625965, acc.: 67.31%] [G loss: 1.456672] [Time: 0.247062]\n",
            "104-5 [D loss: 0.597932, acc.: 67.31%] [G loss: 1.073801] [Time: 0.248999]\n",
            "104-6 [D loss: 0.790332, acc.: 51.92%] [G loss: 1.230168] [Time: 0.247047]\n",
            "104-7 [D loss: 0.602404, acc.: 67.31%] [G loss: 1.699459] [Time: 0.251612]\n",
            "104-8 [D loss: 0.613252, acc.: 69.23%] [G loss: 1.623524] [Time: 0.246011]\n",
            "104 (test) [D loss: 1.116992, acc.: 50.00%] [G loss: 2.061126] [Time: 0.076113]\n",
            "105-0 [D loss: 0.780906, acc.: 63.46%] [G loss: 1.422364] [Time: 0.253234]\n",
            "105-1 [D loss: 0.589545, acc.: 65.38%] [G loss: 1.411214] [Time: 0.243256]\n",
            "105-2 [D loss: 0.663818, acc.: 59.62%] [G loss: 1.382199] [Time: 0.247203]\n",
            "105-3 [D loss: 0.653071, acc.: 63.46%] [G loss: 1.242974] [Time: 0.246176]\n",
            "105-4 [D loss: 0.583206, acc.: 69.23%] [G loss: 1.517511] [Time: 0.243413]\n",
            "105-5 [D loss: 0.711275, acc.: 57.69%] [G loss: 1.295969] [Time: 0.255789]\n",
            "105-6 [D loss: 0.672794, acc.: 57.69%] [G loss: 1.651060] [Time: 0.244061]\n",
            "105-7 [D loss: 0.610222, acc.: 57.69%] [G loss: 1.553222] [Time: 0.245936]\n",
            "105-8 [D loss: 0.601692, acc.: 67.31%] [G loss: 1.367742] [Time: 0.246390]\n",
            "105 (test) [D loss: 1.141215, acc.: 50.00%] [G loss: 2.087001] [Time: 0.078823]\n",
            "106-0 [D loss: 0.464900, acc.: 78.85%] [G loss: 1.693158] [Time: 0.245269]\n",
            "106-1 [D loss: 0.717925, acc.: 48.08%] [G loss: 1.396595] [Time: 0.249840]\n",
            "106-2 [D loss: 0.724743, acc.: 53.85%] [G loss: 1.369579] [Time: 0.245897]\n",
            "106-3 [D loss: 0.823275, acc.: 40.38%] [G loss: 1.300998] [Time: 0.247249]\n",
            "106-4 [D loss: 0.617159, acc.: 65.38%] [G loss: 1.443300] [Time: 0.247399]\n",
            "106-5 [D loss: 0.815916, acc.: 46.15%] [G loss: 1.364438] [Time: 0.246274]\n",
            "106-6 [D loss: 0.571741, acc.: 61.54%] [G loss: 1.620136] [Time: 0.244420]\n",
            "106-7 [D loss: 0.785241, acc.: 55.77%] [G loss: 1.303313] [Time: 0.257973]\n",
            "106-8 [D loss: 0.592157, acc.: 65.38%] [G loss: 1.550173] [Time: 0.248057]\n",
            "106 (test) [D loss: 1.129002, acc.: 50.00%] [G loss: 2.082470] [Time: 0.077106]\n",
            "107-0 [D loss: 0.503577, acc.: 73.08%] [G loss: 1.513966] [Time: 0.248689]\n",
            "107-1 [D loss: 0.612535, acc.: 67.31%] [G loss: 1.259748] [Time: 0.243502]\n",
            "107-2 [D loss: 0.618561, acc.: 71.15%] [G loss: 1.469514] [Time: 0.249781]\n",
            "107-3 [D loss: 0.769259, acc.: 53.85%] [G loss: 1.336889] [Time: 0.247306]\n",
            "107-4 [D loss: 0.578248, acc.: 61.54%] [G loss: 1.449168] [Time: 0.248207]\n",
            "107-5 [D loss: 0.713529, acc.: 55.77%] [G loss: 1.768720] [Time: 0.245927]\n",
            "107-6 [D loss: 0.681289, acc.: 57.69%] [G loss: 1.362177] [Time: 0.245399]\n",
            "107-7 [D loss: 0.641604, acc.: 59.62%] [G loss: 1.384751] [Time: 0.249549]\n",
            "107-8 [D loss: 0.650537, acc.: 63.46%] [G loss: 1.154690] [Time: 0.249940]\n",
            "107 (test) [D loss: 1.163926, acc.: 50.00%] [G loss: 2.173424] [Time: 0.075015]\n",
            "108-0 [D loss: 0.512486, acc.: 82.69%] [G loss: 1.506554] [Time: 0.247188]\n",
            "108-1 [D loss: 0.616477, acc.: 57.69%] [G loss: 1.215702] [Time: 0.247139]\n",
            "108-2 [D loss: 0.671041, acc.: 63.46%] [G loss: 1.307769] [Time: 0.250080]\n",
            "108-3 [D loss: 0.731042, acc.: 59.62%] [G loss: 1.554625] [Time: 0.244990]\n",
            "108-4 [D loss: 0.635746, acc.: 61.54%] [G loss: 1.719138] [Time: 0.247986]\n",
            "108-5 [D loss: 0.637410, acc.: 61.54%] [G loss: 1.596421] [Time: 0.249560]\n",
            "108-6 [D loss: 0.513944, acc.: 76.92%] [G loss: 1.531833] [Time: 0.245195]\n",
            "108-7 [D loss: 0.683652, acc.: 53.85%] [G loss: 1.500655] [Time: 0.249922]\n",
            "108-8 [D loss: 0.609625, acc.: 65.38%] [G loss: 1.455389] [Time: 0.250065]\n",
            "108 (test) [D loss: 1.164867, acc.: 50.00%] [G loss: 2.164474] [Time: 0.076468]\n",
            "109-0 [D loss: 0.654918, acc.: 67.31%] [G loss: 1.465889] [Time: 0.247786]\n",
            "109-1 [D loss: 0.607872, acc.: 63.46%] [G loss: 1.421509] [Time: 0.247823]\n",
            "109-2 [D loss: 0.776481, acc.: 46.15%] [G loss: 1.259909] [Time: 0.245316]\n",
            "109-3 [D loss: 0.790949, acc.: 57.69%] [G loss: 1.410307] [Time: 0.249589]\n",
            "109-4 [D loss: 0.594782, acc.: 67.31%] [G loss: 1.425930] [Time: 0.247362]\n",
            "109-5 [D loss: 0.670149, acc.: 53.85%] [G loss: 1.307684] [Time: 0.246214]\n",
            "109-6 [D loss: 0.523766, acc.: 73.08%] [G loss: 1.363631] [Time: 0.247066]\n",
            "109-7 [D loss: 0.539722, acc.: 73.08%] [G loss: 1.300242] [Time: 0.251294]\n",
            "109-8 [D loss: 0.718758, acc.: 53.85%] [G loss: 1.319848] [Time: 0.245949]\n",
            "109 (test) [D loss: 1.166825, acc.: 50.00%] [G loss: 2.191454] [Time: 0.076862]\n",
            "110-0 [D loss: 0.553681, acc.: 71.15%] [G loss: 1.700160] [Time: 0.245670]\n",
            "110-1 [D loss: 0.637836, acc.: 65.38%] [G loss: 1.352032] [Time: 0.248427]\n",
            "110-2 [D loss: 0.649930, acc.: 63.46%] [G loss: 1.383199] [Time: 0.249438]\n",
            "110-3 [D loss: 0.916325, acc.: 40.38%] [G loss: 1.271384] [Time: 0.244554]\n",
            "110-4 [D loss: 0.603908, acc.: 71.15%] [G loss: 1.618601] [Time: 0.246450]\n",
            "110-5 [D loss: 0.717617, acc.: 50.00%] [G loss: 1.660615] [Time: 0.247585]\n",
            "110-6 [D loss: 0.573949, acc.: 63.46%] [G loss: 1.899644] [Time: 0.249709]\n",
            "110-7 [D loss: 0.630597, acc.: 63.46%] [G loss: 1.445658] [Time: 0.246149]\n",
            "110-8 [D loss: 0.696349, acc.: 57.69%] [G loss: 1.540670] [Time: 0.243037]\n",
            "110 (test) [D loss: 1.099903, acc.: 50.00%] [G loss: 2.022667] [Time: 0.077060]\n",
            "111-0 [D loss: 0.669253, acc.: 59.62%] [G loss: 1.508996] [Time: 0.249392]\n",
            "111-1 [D loss: 0.529714, acc.: 73.08%] [G loss: 1.326073] [Time: 0.246831]\n",
            "111-2 [D loss: 0.715165, acc.: 51.92%] [G loss: 1.256805] [Time: 0.246225]\n",
            "111-3 [D loss: 0.826661, acc.: 44.23%] [G loss: 1.468130] [Time: 0.247314]\n",
            "111-4 [D loss: 0.589283, acc.: 63.46%] [G loss: 2.012839] [Time: 0.248469]\n",
            "111-5 [D loss: 0.727925, acc.: 61.54%] [G loss: 1.631122] [Time: 0.246591]\n",
            "111-6 [D loss: 0.584193, acc.: 69.23%] [G loss: 1.507687] [Time: 0.246395]\n",
            "111-7 [D loss: 0.593278, acc.: 63.46%] [G loss: 1.271741] [Time: 0.248955]\n",
            "111-8 [D loss: 0.541528, acc.: 67.31%] [G loss: 1.323549] [Time: 0.247134]\n",
            "111 (test) [D loss: 1.067199, acc.: 50.00%] [G loss: 1.962397] [Time: 0.075677]\n",
            "112-0 [D loss: 0.486118, acc.: 86.54%] [G loss: 1.514996] [Time: 0.248312]\n",
            "112-1 [D loss: 0.562775, acc.: 65.38%] [G loss: 1.525080] [Time: 0.245612]\n",
            "112-2 [D loss: 0.627255, acc.: 63.46%] [G loss: 1.477815] [Time: 0.246183]\n",
            "112-3 [D loss: 0.766170, acc.: 48.08%] [G loss: 1.469368] [Time: 0.250577]\n",
            "112-4 [D loss: 0.575587, acc.: 71.15%] [G loss: 1.605502] [Time: 0.246755]\n",
            "112-5 [D loss: 0.561069, acc.: 73.08%] [G loss: 1.542437] [Time: 0.247846]\n",
            "112-6 [D loss: 0.546485, acc.: 75.00%] [G loss: 1.338485] [Time: 0.251199]\n",
            "112-7 [D loss: 0.588658, acc.: 71.15%] [G loss: 1.353370] [Time: 0.248419]\n",
            "112-8 [D loss: 0.586882, acc.: 61.54%] [G loss: 1.353965] [Time: 0.247772]\n",
            "112 (test) [D loss: 0.958866, acc.: 50.00%] [G loss: 1.683068] [Time: 0.078478]\n",
            "113-0 [D loss: 0.510337, acc.: 78.85%] [G loss: 1.715062] [Time: 0.247419]\n",
            "113-1 [D loss: 0.552062, acc.: 69.23%] [G loss: 1.450300] [Time: 0.248091]\n",
            "113-2 [D loss: 0.750983, acc.: 50.00%] [G loss: 1.426249] [Time: 0.243927]\n",
            "113-3 [D loss: 0.703907, acc.: 57.69%] [G loss: 1.245085] [Time: 0.250003]\n",
            "113-4 [D loss: 0.520898, acc.: 73.08%] [G loss: 1.529280] [Time: 0.245555]\n",
            "113-5 [D loss: 0.642432, acc.: 63.46%] [G loss: 1.384972] [Time: 0.248748]\n",
            "113-6 [D loss: 0.539796, acc.: 76.92%] [G loss: 1.706444] [Time: 0.245284]\n",
            "113-7 [D loss: 0.527879, acc.: 80.77%] [G loss: 1.457114] [Time: 0.244598]\n",
            "113-8 [D loss: 0.584587, acc.: 71.15%] [G loss: 1.377553] [Time: 0.248212]\n",
            "113 (test) [D loss: 1.061680, acc.: 50.00%] [G loss: 1.900805] [Time: 0.077830]\n",
            "114-0 [D loss: 0.515504, acc.: 73.08%] [G loss: 1.451403] [Time: 0.248156]\n",
            "114-1 [D loss: 0.609642, acc.: 63.46%] [G loss: 1.146457] [Time: 0.243824]\n",
            "114-2 [D loss: 0.588730, acc.: 71.15%] [G loss: 1.238801] [Time: 0.248703]\n",
            "114-3 [D loss: 0.568363, acc.: 75.00%] [G loss: 1.380481] [Time: 0.250017]\n",
            "114-4 [D loss: 0.580165, acc.: 71.15%] [G loss: 2.057001] [Time: 0.247421]\n",
            "114-5 [D loss: 0.696817, acc.: 61.54%] [G loss: 1.414913] [Time: 0.246616]\n",
            "114-6 [D loss: 0.508900, acc.: 76.92%] [G loss: 1.775458] [Time: 0.247489]\n",
            "114-7 [D loss: 0.670133, acc.: 61.54%] [G loss: 1.470854] [Time: 0.247586]\n",
            "114-8 [D loss: 0.566332, acc.: 61.54%] [G loss: 1.447813] [Time: 0.250363]\n",
            "114 (test) [D loss: 1.163038, acc.: 50.00%] [G loss: 2.126916] [Time: 0.076817]\n",
            "115-0 [D loss: 0.508175, acc.: 73.08%] [G loss: 1.467032] [Time: 0.250252]\n",
            "115-1 [D loss: 0.642642, acc.: 55.77%] [G loss: 1.525506] [Time: 0.246186]\n",
            "115-2 [D loss: 0.641911, acc.: 59.62%] [G loss: 1.328489] [Time: 0.252775]\n",
            "115-3 [D loss: 0.728220, acc.: 53.85%] [G loss: 1.217348] [Time: 0.247592]\n",
            "115-4 [D loss: 0.619315, acc.: 69.23%] [G loss: 1.405811] [Time: 0.248884]\n",
            "115-5 [D loss: 0.531079, acc.: 75.00%] [G loss: 1.566067] [Time: 0.243401]\n",
            "115-6 [D loss: 0.574959, acc.: 63.46%] [G loss: 1.471459] [Time: 0.246813]\n",
            "115-7 [D loss: 0.599107, acc.: 61.54%] [G loss: 1.503337] [Time: 0.246108]\n",
            "115-8 [D loss: 0.601952, acc.: 67.31%] [G loss: 1.735095] [Time: 0.248698]\n",
            "115 (test) [D loss: 1.040742, acc.: 50.00%] [G loss: 1.851019] [Time: 0.078120]\n",
            "116-0 [D loss: 0.493475, acc.: 82.69%] [G loss: 1.794903] [Time: 0.246619]\n",
            "116-1 [D loss: 0.597595, acc.: 65.38%] [G loss: 1.273747] [Time: 0.247898]\n",
            "116-2 [D loss: 0.688532, acc.: 65.38%] [G loss: 1.424525] [Time: 0.247305]\n",
            "116-3 [D loss: 0.702255, acc.: 59.62%] [G loss: 1.528625] [Time: 0.245356]\n",
            "116-4 [D loss: 0.564302, acc.: 67.31%] [G loss: 1.406654] [Time: 0.247430]\n",
            "116-5 [D loss: 0.706609, acc.: 48.08%] [G loss: 1.618203] [Time: 0.244629]\n",
            "116-6 [D loss: 0.525761, acc.: 76.92%] [G loss: 1.603021] [Time: 0.244746]\n",
            "116-7 [D loss: 0.548928, acc.: 71.15%] [G loss: 1.706707] [Time: 0.247001]\n",
            "116-8 [D loss: 0.609799, acc.: 63.46%] [G loss: 1.532404] [Time: 0.244058]\n",
            "116 (test) [D loss: 1.156575, acc.: 50.00%] [G loss: 2.154849] [Time: 0.075878]\n",
            "117-0 [D loss: 0.449556, acc.: 82.69%] [G loss: 1.673987] [Time: 0.245725]\n",
            "117-1 [D loss: 0.549609, acc.: 61.54%] [G loss: 1.578458] [Time: 0.249945]\n",
            "117-2 [D loss: 0.663371, acc.: 55.77%] [G loss: 1.124061] [Time: 0.248018]\n",
            "117-3 [D loss: 0.711832, acc.: 50.00%] [G loss: 1.410065] [Time: 0.251024]\n",
            "117-4 [D loss: 0.478100, acc.: 76.92%] [G loss: 1.802471] [Time: 0.245689]\n",
            "117-5 [D loss: 0.619943, acc.: 75.00%] [G loss: 1.687474] [Time: 0.255377]\n",
            "117-6 [D loss: 0.537380, acc.: 71.15%] [G loss: 1.672916] [Time: 0.245447]\n",
            "117-7 [D loss: 0.556604, acc.: 67.31%] [G loss: 1.749137] [Time: 0.248083]\n",
            "117-8 [D loss: 0.685410, acc.: 57.69%] [G loss: 1.394427] [Time: 0.246979]\n",
            "117 (test) [D loss: 0.975625, acc.: 50.00%] [G loss: 1.702575] [Time: 0.081754]\n",
            "118-0 [D loss: 0.626151, acc.: 53.85%] [G loss: 1.608491] [Time: 0.250221]\n",
            "118-1 [D loss: 0.600526, acc.: 61.54%] [G loss: 1.626149] [Time: 0.246538]\n",
            "118-2 [D loss: 0.689093, acc.: 57.69%] [G loss: 1.242913] [Time: 0.247128]\n",
            "118-3 [D loss: 0.772427, acc.: 46.15%] [G loss: 1.074414] [Time: 0.247643]\n",
            "118-4 [D loss: 0.559958, acc.: 71.15%] [G loss: 1.570094] [Time: 0.246581]\n",
            "118-5 [D loss: 0.541258, acc.: 67.31%] [G loss: 1.599925] [Time: 0.247919]\n",
            "118-6 [D loss: 0.458383, acc.: 80.77%] [G loss: 1.649362] [Time: 0.245748]\n",
            "118-7 [D loss: 0.568015, acc.: 73.08%] [G loss: 1.394080] [Time: 0.249110]\n",
            "118-8 [D loss: 0.571752, acc.: 67.31%] [G loss: 1.464023] [Time: 0.247792]\n",
            "118 (test) [D loss: 1.044270, acc.: 50.00%] [G loss: 1.866147] [Time: 0.076895]\n",
            "119-0 [D loss: 0.561876, acc.: 75.00%] [G loss: 1.557610] [Time: 0.253599]\n",
            "119-1 [D loss: 0.484144, acc.: 73.08%] [G loss: 1.406738] [Time: 0.247485]\n",
            "119-2 [D loss: 0.734376, acc.: 50.00%] [G loss: 1.190782] [Time: 0.244920]\n",
            "119-3 [D loss: 0.692548, acc.: 59.62%] [G loss: 1.332227] [Time: 0.249940]\n",
            "119-4 [D loss: 0.562863, acc.: 73.08%] [G loss: 1.705323] [Time: 0.250702]\n",
            "119-5 [D loss: 0.769848, acc.: 55.77%] [G loss: 1.526567] [Time: 0.248781]\n",
            "119-6 [D loss: 0.600024, acc.: 65.38%] [G loss: 1.559783] [Time: 0.250525]\n",
            "119-7 [D loss: 0.516791, acc.: 69.23%] [G loss: 1.601231] [Time: 0.249674]\n",
            "119-8 [D loss: 0.600464, acc.: 69.23%] [G loss: 1.443761] [Time: 0.245960]\n",
            "119 (test) [D loss: 1.160419, acc.: 50.00%] [G loss: 2.156099] [Time: 0.077318]\n",
            "120-0 [D loss: 0.527281, acc.: 71.15%] [G loss: 1.860693] [Time: 0.251122]\n",
            "120-1 [D loss: 0.514574, acc.: 75.00%] [G loss: 1.663948] [Time: 0.248457]\n",
            "120-2 [D loss: 0.684913, acc.: 50.00%] [G loss: 1.370536] [Time: 0.247017]\n",
            "120-3 [D loss: 0.867285, acc.: 46.15%] [G loss: 1.232669] [Time: 0.244359]\n",
            "120-4 [D loss: 0.570338, acc.: 71.15%] [G loss: 1.898978] [Time: 0.248038]\n",
            "120-5 [D loss: 0.545156, acc.: 73.08%] [G loss: 1.782164] [Time: 0.246879]\n",
            "120-6 [D loss: 0.549445, acc.: 71.15%] [G loss: 1.737310] [Time: 0.248759]\n",
            "120-7 [D loss: 0.636127, acc.: 61.54%] [G loss: 1.557741] [Time: 0.245366]\n",
            "120-8 [D loss: 0.620132, acc.: 67.31%] [G loss: 1.560894] [Time: 0.247421]\n",
            "120 (test) [D loss: 1.107694, acc.: 50.00%] [G loss: 2.020352] [Time: 0.077609]\n",
            "121-0 [D loss: 0.679244, acc.: 59.62%] [G loss: 1.556171] [Time: 0.247291]\n",
            "121-1 [D loss: 0.546285, acc.: 76.92%] [G loss: 1.373612] [Time: 0.248753]\n",
            "121-2 [D loss: 0.731918, acc.: 50.00%] [G loss: 1.538007] [Time: 0.245432]\n",
            "121-3 [D loss: 0.654683, acc.: 71.15%] [G loss: 1.536102] [Time: 0.249539]\n",
            "121-4 [D loss: 0.495284, acc.: 73.08%] [G loss: 1.593103] [Time: 0.249310]\n",
            "121-5 [D loss: 0.621712, acc.: 67.31%] [G loss: 1.369777] [Time: 0.243719]\n",
            "121-6 [D loss: 0.586638, acc.: 65.38%] [G loss: 1.375723] [Time: 0.247278]\n",
            "121-7 [D loss: 0.577151, acc.: 73.08%] [G loss: 1.388454] [Time: 0.247022]\n",
            "121-8 [D loss: 0.715352, acc.: 53.85%] [G loss: 1.400262] [Time: 0.253025]\n",
            "121 (test) [D loss: 1.100319, acc.: 50.00%] [G loss: 2.003011] [Time: 0.077399]\n",
            "122-0 [D loss: 0.484896, acc.: 84.62%] [G loss: 1.402260] [Time: 0.248904]\n",
            "122-1 [D loss: 0.646720, acc.: 61.54%] [G loss: 1.428674] [Time: 0.246875]\n",
            "122-2 [D loss: 0.593554, acc.: 71.15%] [G loss: 1.357480] [Time: 0.246208]\n",
            "122-3 [D loss: 0.619693, acc.: 61.54%] [G loss: 1.292638] [Time: 0.249595]\n",
            "122-4 [D loss: 0.526477, acc.: 76.92%] [G loss: 1.307429] [Time: 0.246981]\n",
            "122-5 [D loss: 0.628329, acc.: 63.46%] [G loss: 1.402542] [Time: 0.250049]\n",
            "122-6 [D loss: 0.630676, acc.: 71.15%] [G loss: 1.399310] [Time: 0.249617]\n",
            "122-7 [D loss: 0.615787, acc.: 67.31%] [G loss: 1.620714] [Time: 0.248888]\n",
            "122-8 [D loss: 0.626394, acc.: 65.38%] [G loss: 1.550900] [Time: 0.250309]\n",
            "122 (test) [D loss: 1.026084, acc.: 50.00%] [G loss: 1.838580] [Time: 0.077104]\n",
            "123-0 [D loss: 0.655035, acc.: 65.38%] [G loss: 1.670475] [Time: 0.247836]\n",
            "123-1 [D loss: 0.671086, acc.: 61.54%] [G loss: 1.377727] [Time: 0.249439]\n",
            "123-2 [D loss: 0.676319, acc.: 59.62%] [G loss: 1.362012] [Time: 0.248351]\n",
            "123-3 [D loss: 0.745770, acc.: 61.54%] [G loss: 1.365770] [Time: 0.246765]\n",
            "123-4 [D loss: 0.617786, acc.: 67.31%] [G loss: 1.425289] [Time: 0.249693]\n",
            "123-5 [D loss: 0.612887, acc.: 67.31%] [G loss: 1.802256] [Time: 0.254224]\n",
            "123-6 [D loss: 0.474236, acc.: 84.62%] [G loss: 1.652508] [Time: 0.244371]\n",
            "123-7 [D loss: 0.697542, acc.: 61.54%] [G loss: 1.186211] [Time: 0.248111]\n",
            "123-8 [D loss: 0.675093, acc.: 67.31%] [G loss: 1.645469] [Time: 0.251863]\n",
            "123 (test) [D loss: 0.944498, acc.: 50.00%] [G loss: 1.618268] [Time: 0.077154]\n",
            "124-0 [D loss: 0.561862, acc.: 65.38%] [G loss: 1.665356] [Time: 0.247442]\n",
            "124-1 [D loss: 0.519720, acc.: 71.15%] [G loss: 1.320476] [Time: 0.247907]\n",
            "124-2 [D loss: 0.641235, acc.: 59.62%] [G loss: 1.163193] [Time: 0.244969]\n",
            "124-3 [D loss: 0.634710, acc.: 67.31%] [G loss: 1.342096] [Time: 0.251519]\n",
            "124-4 [D loss: 0.479535, acc.: 76.92%] [G loss: 1.542974] [Time: 0.245121]\n",
            "124-5 [D loss: 0.518967, acc.: 71.15%] [G loss: 1.666471] [Time: 0.248514]\n",
            "124-6 [D loss: 0.697494, acc.: 59.62%] [G loss: 1.210110] [Time: 0.248430]\n",
            "124-7 [D loss: 0.552420, acc.: 71.15%] [G loss: 1.554127] [Time: 0.246109]\n",
            "124-8 [D loss: 0.671693, acc.: 63.46%] [G loss: 1.513638] [Time: 0.247280]\n",
            "124 (test) [D loss: 1.073067, acc.: 50.00%] [G loss: 1.917024] [Time: 0.077437]\n",
            "125-0 [D loss: 0.503674, acc.: 75.00%] [G loss: 1.829301] [Time: 0.253969]\n",
            "125-1 [D loss: 0.619540, acc.: 67.31%] [G loss: 1.630184] [Time: 0.245115]\n",
            "125-2 [D loss: 0.711851, acc.: 55.77%] [G loss: 1.361537] [Time: 0.248816]\n",
            "125-3 [D loss: 0.687790, acc.: 55.77%] [G loss: 1.213536] [Time: 0.246875]\n",
            "125-4 [D loss: 0.547377, acc.: 65.38%] [G loss: 1.525050] [Time: 0.249424]\n",
            "125-5 [D loss: 0.570407, acc.: 69.23%] [G loss: 1.709209] [Time: 0.247919]\n",
            "125-6 [D loss: 0.623328, acc.: 69.23%] [G loss: 1.677214] [Time: 0.248746]\n",
            "125-7 [D loss: 0.668086, acc.: 67.31%] [G loss: 1.567689] [Time: 0.245393]\n",
            "125-8 [D loss: 0.603745, acc.: 69.23%] [G loss: 1.301303] [Time: 0.247184]\n",
            "125 (test) [D loss: 1.019466, acc.: 50.00%] [G loss: 1.786814] [Time: 0.075430]\n",
            "126-0 [D loss: 0.597225, acc.: 67.31%] [G loss: 1.520437] [Time: 0.246321]\n",
            "126-1 [D loss: 0.644176, acc.: 63.46%] [G loss: 1.389540] [Time: 0.249700]\n",
            "126-2 [D loss: 0.722254, acc.: 61.54%] [G loss: 1.345963] [Time: 0.249507]\n",
            "126-3 [D loss: 0.756852, acc.: 48.08%] [G loss: 1.513174] [Time: 0.244413]\n",
            "126-4 [D loss: 0.621505, acc.: 71.15%] [G loss: 1.606553] [Time: 0.249080]\n",
            "126-5 [D loss: 0.499311, acc.: 82.69%] [G loss: 1.410688] [Time: 0.247809]\n",
            "126-6 [D loss: 0.569340, acc.: 63.46%] [G loss: 1.801036] [Time: 0.247871]\n",
            "126-7 [D loss: 0.555506, acc.: 73.08%] [G loss: 1.494606] [Time: 0.243840]\n",
            "126-8 [D loss: 0.597143, acc.: 61.54%] [G loss: 1.383205] [Time: 0.248217]\n",
            "126 (test) [D loss: 1.062514, acc.: 50.00%] [G loss: 1.924213] [Time: 0.076946]\n",
            "127-0 [D loss: 0.517062, acc.: 78.85%] [G loss: 1.510513] [Time: 0.248241]\n",
            "127-1 [D loss: 0.648690, acc.: 59.62%] [G loss: 1.508061] [Time: 0.245854]\n",
            "127-2 [D loss: 0.703603, acc.: 59.62%] [G loss: 1.214520] [Time: 0.251683]\n",
            "127-3 [D loss: 0.740173, acc.: 63.46%] [G loss: 1.394338] [Time: 0.252512]\n",
            "127-4 [D loss: 0.542265, acc.: 75.00%] [G loss: 1.380871] [Time: 0.247877]\n",
            "127-5 [D loss: 0.520124, acc.: 75.00%] [G loss: 1.590112] [Time: 0.246381]\n",
            "127-6 [D loss: 0.599751, acc.: 61.54%] [G loss: 1.411685] [Time: 0.254951]\n",
            "127-7 [D loss: 0.612834, acc.: 65.38%] [G loss: 1.831191] [Time: 0.244087]\n",
            "127-8 [D loss: 0.609476, acc.: 71.15%] [G loss: 1.646533] [Time: 0.252051]\n",
            "127 (test) [D loss: 1.105860, acc.: 50.00%] [G loss: 2.018004] [Time: 0.077190]\n",
            "128-0 [D loss: 0.533522, acc.: 73.08%] [G loss: 1.395056] [Time: 0.247795]\n",
            "128-1 [D loss: 0.677443, acc.: 55.77%] [G loss: 1.389775] [Time: 0.250445]\n",
            "128-2 [D loss: 0.740880, acc.: 55.77%] [G loss: 1.287363] [Time: 0.247256]\n",
            "128-3 [D loss: 0.593659, acc.: 65.38%] [G loss: 1.395716] [Time: 0.249855]\n",
            "128-4 [D loss: 0.585355, acc.: 71.15%] [G loss: 1.458807] [Time: 0.248316]\n",
            "128-5 [D loss: 0.697686, acc.: 59.62%] [G loss: 1.393110] [Time: 0.247553]\n",
            "128-6 [D loss: 0.545622, acc.: 73.08%] [G loss: 1.526955] [Time: 0.251783]\n",
            "128-7 [D loss: 0.583190, acc.: 65.38%] [G loss: 1.594508] [Time: 0.247370]\n",
            "128-8 [D loss: 0.549625, acc.: 73.08%] [G loss: 1.728948] [Time: 0.248066]\n",
            "128 (test) [D loss: 1.118454, acc.: 50.00%] [G loss: 2.034047] [Time: 0.077493]\n",
            "129-0 [D loss: 0.567564, acc.: 63.46%] [G loss: 1.533074] [Time: 0.246710]\n",
            "129-1 [D loss: 0.748581, acc.: 55.77%] [G loss: 1.521777] [Time: 0.249940]\n",
            "129-2 [D loss: 0.789437, acc.: 32.69%] [G loss: 1.315162] [Time: 0.247153]\n",
            "129-3 [D loss: 0.720573, acc.: 50.00%] [G loss: 1.414757] [Time: 0.246201]\n",
            "129-4 [D loss: 0.615200, acc.: 69.23%] [G loss: 1.539734] [Time: 0.246016]\n",
            "129-5 [D loss: 0.599961, acc.: 73.08%] [G loss: 1.303699] [Time: 0.247695]\n",
            "129-6 [D loss: 0.560055, acc.: 71.15%] [G loss: 1.655122] [Time: 0.246633]\n",
            "129-7 [D loss: 0.484696, acc.: 76.92%] [G loss: 1.508919] [Time: 0.249829]\n",
            "129-8 [D loss: 0.652068, acc.: 61.54%] [G loss: 1.681686] [Time: 0.248099]\n",
            "129 (test) [D loss: 1.072053, acc.: 50.00%] [G loss: 1.942039] [Time: 0.079252]\n",
            "130-0 [D loss: 0.487301, acc.: 80.77%] [G loss: 1.443954] [Time: 0.253128]\n",
            "130-1 [D loss: 0.675996, acc.: 53.85%] [G loss: 1.538926] [Time: 0.247661]\n",
            "130-2 [D loss: 0.622143, acc.: 65.38%] [G loss: 1.315573] [Time: 0.247598]\n",
            "130-3 [D loss: 0.681280, acc.: 53.85%] [G loss: 1.356731] [Time: 0.246096]\n",
            "130-4 [D loss: 0.587457, acc.: 71.15%] [G loss: 1.668465] [Time: 0.249693]\n",
            "130-5 [D loss: 0.583314, acc.: 75.00%] [G loss: 1.658138] [Time: 0.246316]\n",
            "130-6 [D loss: 0.532362, acc.: 80.77%] [G loss: 1.734561] [Time: 0.248379]\n",
            "130-7 [D loss: 0.561975, acc.: 65.38%] [G loss: 1.704359] [Time: 0.244280]\n",
            "130-8 [D loss: 0.590919, acc.: 63.46%] [G loss: 1.435858] [Time: 0.245150]\n",
            "130 (test) [D loss: 1.088541, acc.: 50.00%] [G loss: 1.978521] [Time: 0.075749]\n",
            "131-0 [D loss: 0.556610, acc.: 69.23%] [G loss: 1.518697] [Time: 0.248046]\n",
            "131-1 [D loss: 0.503728, acc.: 82.69%] [G loss: 1.510724] [Time: 0.247120]\n",
            "131-2 [D loss: 0.731953, acc.: 51.92%] [G loss: 1.277516] [Time: 0.246785]\n",
            "131-3 [D loss: 0.693685, acc.: 59.62%] [G loss: 1.675065] [Time: 0.246551]\n",
            "131-4 [D loss: 0.528121, acc.: 73.08%] [G loss: 1.585573] [Time: 0.244217]\n",
            "131-5 [D loss: 0.647302, acc.: 65.38%] [G loss: 1.654616] [Time: 0.251539]\n",
            "131-6 [D loss: 0.542183, acc.: 73.08%] [G loss: 1.536353] [Time: 0.243303]\n",
            "131-7 [D loss: 0.596907, acc.: 67.31%] [G loss: 1.719344] [Time: 0.246278]\n",
            "131-8 [D loss: 0.573945, acc.: 69.23%] [G loss: 1.446975] [Time: 0.246979]\n",
            "131 (test) [D loss: 1.161217, acc.: 50.00%] [G loss: 2.101504] [Time: 0.078756]\n",
            "132-0 [D loss: 0.507483, acc.: 73.08%] [G loss: 1.449301] [Time: 0.247837]\n",
            "132-1 [D loss: 0.671484, acc.: 63.46%] [G loss: 1.656587] [Time: 0.244762]\n",
            "132-2 [D loss: 0.746798, acc.: 53.85%] [G loss: 1.303191] [Time: 0.247240]\n",
            "132-3 [D loss: 0.665448, acc.: 65.38%] [G loss: 1.405752] [Time: 0.244995]\n",
            "132-4 [D loss: 0.517676, acc.: 67.31%] [G loss: 1.308281] [Time: 0.245010]\n",
            "132-5 [D loss: 0.606936, acc.: 65.38%] [G loss: 1.493612] [Time: 0.244487]\n",
            "132-6 [D loss: 0.564563, acc.: 73.08%] [G loss: 1.709235] [Time: 0.251305]\n",
            "132-7 [D loss: 0.554118, acc.: 73.08%] [G loss: 1.652428] [Time: 0.248132]\n",
            "132-8 [D loss: 0.628846, acc.: 61.54%] [G loss: 1.502231] [Time: 0.246454]\n",
            "132 (test) [D loss: 1.131350, acc.: 50.00%] [G loss: 2.044721] [Time: 0.075538]\n",
            "133-0 [D loss: 0.547904, acc.: 69.23%] [G loss: 1.524626] [Time: 0.248627]\n",
            "133-1 [D loss: 0.576568, acc.: 75.00%] [G loss: 1.543817] [Time: 0.247628]\n",
            "133-2 [D loss: 0.681191, acc.: 59.62%] [G loss: 1.354515] [Time: 0.246726]\n",
            "133-3 [D loss: 0.629669, acc.: 57.69%] [G loss: 1.469191] [Time: 0.244598]\n",
            "133-4 [D loss: 0.519210, acc.: 75.00%] [G loss: 1.465567] [Time: 0.250692]\n",
            "133-5 [D loss: 0.511040, acc.: 80.77%] [G loss: 1.818604] [Time: 0.247152]\n",
            "133-6 [D loss: 0.580124, acc.: 69.23%] [G loss: 1.770700] [Time: 0.244976]\n",
            "133-7 [D loss: 0.523959, acc.: 75.00%] [G loss: 1.783394] [Time: 0.248956]\n",
            "133-8 [D loss: 0.658928, acc.: 69.23%] [G loss: 1.358879] [Time: 0.246680]\n",
            "133 (test) [D loss: 1.096218, acc.: 50.00%] [G loss: 1.972758] [Time: 0.077601]\n",
            "134-0 [D loss: 0.452410, acc.: 80.77%] [G loss: 1.686506] [Time: 0.249624]\n",
            "134-1 [D loss: 0.598413, acc.: 65.38%] [G loss: 1.320303] [Time: 0.245753]\n",
            "134-2 [D loss: 0.698427, acc.: 55.77%] [G loss: 1.207396] [Time: 0.244378]\n",
            "134-3 [D loss: 0.674197, acc.: 63.46%] [G loss: 1.563616] [Time: 0.249549]\n",
            "134-4 [D loss: 0.507298, acc.: 76.92%] [G loss: 1.675209] [Time: 0.249896]\n",
            "134-5 [D loss: 0.634189, acc.: 65.38%] [G loss: 1.540897] [Time: 0.248283]\n",
            "134-6 [D loss: 0.483493, acc.: 76.92%] [G loss: 1.763831] [Time: 0.250417]\n",
            "134-7 [D loss: 0.492991, acc.: 80.77%] [G loss: 1.533406] [Time: 0.246385]\n",
            "134-8 [D loss: 0.598181, acc.: 59.62%] [G loss: 1.523165] [Time: 0.243786]\n",
            "134 (test) [D loss: 1.103904, acc.: 50.00%] [G loss: 1.978781] [Time: 0.076061]\n",
            "135-0 [D loss: 0.567006, acc.: 75.00%] [G loss: 1.621741] [Time: 0.253418]\n",
            "135-1 [D loss: 0.700816, acc.: 61.54%] [G loss: 1.401998] [Time: 0.249780]\n",
            "135-2 [D loss: 0.716975, acc.: 57.69%] [G loss: 1.442668] [Time: 0.245589]\n",
            "135-3 [D loss: 0.648719, acc.: 61.54%] [G loss: 1.630051] [Time: 0.248762]\n",
            "135-4 [D loss: 0.540290, acc.: 76.92%] [G loss: 1.670502] [Time: 0.249616]\n",
            "135-5 [D loss: 0.684808, acc.: 55.77%] [G loss: 1.604809] [Time: 0.248442]\n",
            "135-6 [D loss: 0.482784, acc.: 80.77%] [G loss: 1.609708] [Time: 0.247599]\n",
            "135-7 [D loss: 0.586499, acc.: 67.31%] [G loss: 1.426243] [Time: 0.247913]\n",
            "135-8 [D loss: 0.690893, acc.: 50.00%] [G loss: 1.516995] [Time: 0.246138]\n",
            "135 (test) [D loss: 1.076283, acc.: 50.00%] [G loss: 1.941017] [Time: 0.077695]\n",
            "136-0 [D loss: 0.349267, acc.: 88.46%] [G loss: 1.726210] [Time: 0.246872]\n",
            "136-1 [D loss: 0.521212, acc.: 71.15%] [G loss: 1.721127] [Time: 0.251213]\n",
            "136-2 [D loss: 0.671854, acc.: 57.69%] [G loss: 1.307741] [Time: 0.245374]\n",
            "136-3 [D loss: 0.618687, acc.: 67.31%] [G loss: 1.387525] [Time: 0.251981]\n",
            "136-4 [D loss: 0.566278, acc.: 69.23%] [G loss: 1.536531] [Time: 0.247236]\n",
            "136-5 [D loss: 0.520781, acc.: 69.23%] [G loss: 1.498275] [Time: 0.249181]\n",
            "136-6 [D loss: 0.381718, acc.: 92.31%] [G loss: 2.074996] [Time: 0.247410]\n",
            "136-7 [D loss: 0.548862, acc.: 76.92%] [G loss: 1.691113] [Time: 0.243447]\n",
            "136-8 [D loss: 0.580038, acc.: 65.38%] [G loss: 1.785206] [Time: 0.247377]\n",
            "136 (test) [D loss: 1.060928, acc.: 50.00%] [G loss: 1.892143] [Time: 0.077080]\n",
            "137-0 [D loss: 0.651802, acc.: 71.15%] [G loss: 1.579883] [Time: 0.250472]\n",
            "137-1 [D loss: 0.564846, acc.: 73.08%] [G loss: 1.613930] [Time: 0.244199]\n",
            "137-2 [D loss: 0.613905, acc.: 71.15%] [G loss: 1.527747] [Time: 0.247058]\n",
            "137-3 [D loss: 0.766539, acc.: 57.69%] [G loss: 1.471199] [Time: 0.246513]\n",
            "137-4 [D loss: 0.595435, acc.: 63.46%] [G loss: 1.510534] [Time: 0.252037]\n",
            "137-5 [D loss: 0.495340, acc.: 82.69%] [G loss: 1.554317] [Time: 0.244758]\n",
            "137-6 [D loss: 0.493728, acc.: 75.00%] [G loss: 1.723913] [Time: 0.251759]\n",
            "137-7 [D loss: 0.557963, acc.: 69.23%] [G loss: 1.605262] [Time: 0.249018]\n",
            "137-8 [D loss: 0.577044, acc.: 71.15%] [G loss: 1.743647] [Time: 0.244035]\n",
            "137 (test) [D loss: 1.116284, acc.: 50.00%] [G loss: 2.008847] [Time: 0.077042]\n",
            "138-0 [D loss: 0.705109, acc.: 63.46%] [G loss: 1.584746] [Time: 0.254498]\n",
            "138-1 [D loss: 0.520562, acc.: 75.00%] [G loss: 1.555944] [Time: 0.250309]\n",
            "138-2 [D loss: 0.538753, acc.: 76.92%] [G loss: 1.642183] [Time: 0.246965]\n",
            "138-3 [D loss: 0.604971, acc.: 59.62%] [G loss: 1.227417] [Time: 0.247762]\n",
            "138-4 [D loss: 0.438849, acc.: 78.85%] [G loss: 1.481977] [Time: 0.244951]\n",
            "138-5 [D loss: 0.520527, acc.: 82.69%] [G loss: 1.623716] [Time: 0.250087]\n",
            "138-6 [D loss: 0.498772, acc.: 73.08%] [G loss: 1.733045] [Time: 0.245966]\n",
            "138-7 [D loss: 0.526402, acc.: 75.00%] [G loss: 1.889911] [Time: 0.244551]\n",
            "138-8 [D loss: 0.525960, acc.: 76.92%] [G loss: 1.511800] [Time: 0.245692]\n",
            "138 (test) [D loss: 1.279686, acc.: 50.00%] [G loss: 2.378153] [Time: 0.077575]\n",
            "139-0 [D loss: 0.602866, acc.: 65.38%] [G loss: 1.713799] [Time: 0.250856]\n",
            "139-1 [D loss: 0.458801, acc.: 80.77%] [G loss: 1.637564] [Time: 0.250608]\n",
            "139-2 [D loss: 0.630998, acc.: 59.62%] [G loss: 1.482958] [Time: 0.245414]\n",
            "139-3 [D loss: 0.665020, acc.: 67.31%] [G loss: 1.505563] [Time: 0.247551]\n",
            "139-4 [D loss: 0.511433, acc.: 73.08%] [G loss: 1.612119] [Time: 0.248046]\n",
            "139-5 [D loss: 0.521964, acc.: 75.00%] [G loss: 1.426481] [Time: 0.245772]\n",
            "139-6 [D loss: 0.467915, acc.: 78.85%] [G loss: 1.542997] [Time: 0.247652]\n",
            "139-7 [D loss: 0.491200, acc.: 73.08%] [G loss: 1.556904] [Time: 0.253377]\n",
            "139-8 [D loss: 0.620444, acc.: 65.38%] [G loss: 1.451557] [Time: 0.247081]\n",
            "139 (test) [D loss: 1.304447, acc.: 50.00%] [G loss: 2.438225] [Time: 0.076348]\n",
            "140-0 [D loss: 0.543560, acc.: 71.15%] [G loss: 1.810401] [Time: 0.250140]\n",
            "140-1 [D loss: 0.555286, acc.: 65.38%] [G loss: 1.608667] [Time: 0.245418]\n",
            "140-2 [D loss: 0.839948, acc.: 36.54%] [G loss: 1.234749] [Time: 0.244512]\n",
            "140-3 [D loss: 0.701870, acc.: 61.54%] [G loss: 1.687261] [Time: 0.249357]\n",
            "140-4 [D loss: 0.453377, acc.: 80.77%] [G loss: 1.739862] [Time: 0.246982]\n",
            "140-5 [D loss: 0.649095, acc.: 63.46%] [G loss: 1.554082] [Time: 0.248283]\n",
            "140-6 [D loss: 0.575769, acc.: 67.31%] [G loss: 1.806333] [Time: 0.247253]\n",
            "140-7 [D loss: 0.481809, acc.: 75.00%] [G loss: 1.717860] [Time: 0.246915]\n",
            "140-8 [D loss: 0.654754, acc.: 63.46%] [G loss: 1.495672] [Time: 0.245796]\n",
            "140 (test) [D loss: 1.235872, acc.: 50.00%] [G loss: 2.307888] [Time: 0.078689]\n",
            "141-0 [D loss: 0.546570, acc.: 75.00%] [G loss: 1.695835] [Time: 0.247686]\n",
            "141-1 [D loss: 0.516846, acc.: 75.00%] [G loss: 1.486006] [Time: 0.245325]\n",
            "141-2 [D loss: 0.652833, acc.: 59.62%] [G loss: 1.428260] [Time: 0.245758]\n",
            "141-3 [D loss: 0.659082, acc.: 57.69%] [G loss: 1.692883] [Time: 0.250463]\n",
            "141-4 [D loss: 0.563620, acc.: 69.23%] [G loss: 1.627426] [Time: 0.248685]\n",
            "141-5 [D loss: 0.511864, acc.: 73.08%] [G loss: 1.646964] [Time: 0.248420]\n",
            "141-6 [D loss: 0.506955, acc.: 71.15%] [G loss: 1.584428] [Time: 0.245563]\n",
            "141-7 [D loss: 0.496274, acc.: 76.92%] [G loss: 1.711406] [Time: 0.246376]\n",
            "141-8 [D loss: 0.561478, acc.: 65.38%] [G loss: 1.707428] [Time: 0.247414]\n",
            "141 (test) [D loss: 1.263221, acc.: 50.00%] [G loss: 2.358141] [Time: 0.076471]\n",
            "142-0 [D loss: 0.554044, acc.: 76.92%] [G loss: 1.364302] [Time: 0.250141]\n",
            "142-1 [D loss: 0.470224, acc.: 80.77%] [G loss: 1.387526] [Time: 0.246267]\n",
            "142-2 [D loss: 0.667718, acc.: 61.54%] [G loss: 1.387368] [Time: 0.248007]\n",
            "142-3 [D loss: 0.640805, acc.: 69.23%] [G loss: 1.319874] [Time: 0.249623]\n",
            "142-4 [D loss: 0.474682, acc.: 75.00%] [G loss: 1.717100] [Time: 0.245557]\n",
            "142-5 [D loss: 0.559541, acc.: 69.23%] [G loss: 1.499594] [Time: 0.249726]\n",
            "142-6 [D loss: 0.500029, acc.: 76.92%] [G loss: 1.657526] [Time: 0.245395]\n",
            "142-7 [D loss: 0.582576, acc.: 67.31%] [G loss: 1.620270] [Time: 0.250410]\n",
            "142-8 [D loss: 0.607652, acc.: 61.54%] [G loss: 1.407937] [Time: 0.246693]\n",
            "142 (test) [D loss: 1.095249, acc.: 50.00%] [G loss: 1.982722] [Time: 0.078071]\n",
            "143-0 [D loss: 0.498831, acc.: 75.00%] [G loss: 1.610408] [Time: 0.247734]\n",
            "143-1 [D loss: 0.573339, acc.: 63.46%] [G loss: 1.208913] [Time: 0.250527]\n",
            "143-2 [D loss: 0.637167, acc.: 59.62%] [G loss: 1.518707] [Time: 0.246170]\n",
            "143-3 [D loss: 0.701592, acc.: 51.92%] [G loss: 1.422605] [Time: 0.248709]\n",
            "143-4 [D loss: 0.466584, acc.: 75.00%] [G loss: 1.573550] [Time: 0.245810]\n",
            "143-5 [D loss: 0.574533, acc.: 67.31%] [G loss: 2.017471] [Time: 0.250116]\n",
            "143-6 [D loss: 0.534783, acc.: 69.23%] [G loss: 1.432878] [Time: 0.248720]\n",
            "143-7 [D loss: 0.457924, acc.: 78.85%] [G loss: 1.648235] [Time: 0.249176]\n",
            "143-8 [D loss: 0.608532, acc.: 63.46%] [G loss: 1.401889] [Time: 0.245098]\n",
            "143 (test) [D loss: 1.195263, acc.: 50.00%] [G loss: 2.184987] [Time: 0.077620]\n",
            "144-0 [D loss: 0.528340, acc.: 71.15%] [G loss: 1.562979] [Time: 0.249319]\n",
            "144-1 [D loss: 0.533768, acc.: 75.00%] [G loss: 1.537907] [Time: 0.249993]\n",
            "144-2 [D loss: 0.695910, acc.: 53.85%] [G loss: 1.467749] [Time: 0.249316]\n",
            "144-3 [D loss: 0.722304, acc.: 50.00%] [G loss: 1.434511] [Time: 0.248081]\n",
            "144-4 [D loss: 0.480323, acc.: 71.15%] [G loss: 1.791072] [Time: 0.247844]\n",
            "144-5 [D loss: 0.499008, acc.: 75.00%] [G loss: 1.856349] [Time: 0.245697]\n",
            "144-6 [D loss: 0.438521, acc.: 86.54%] [G loss: 1.607533] [Time: 0.243921]\n",
            "144-7 [D loss: 0.541230, acc.: 73.08%] [G loss: 1.535761] [Time: 0.241853]\n",
            "144-8 [D loss: 0.462861, acc.: 78.85%] [G loss: 1.819652] [Time: 0.248081]\n",
            "144 (test) [D loss: 1.214234, acc.: 50.00%] [G loss: 2.240336] [Time: 0.075864]\n",
            "145-0 [D loss: 0.505168, acc.: 76.92%] [G loss: 1.740295] [Time: 0.249630]\n",
            "145-1 [D loss: 0.631655, acc.: 67.31%] [G loss: 1.644582] [Time: 0.245694]\n",
            "145-2 [D loss: 0.671266, acc.: 59.62%] [G loss: 1.530555] [Time: 0.247607]\n",
            "145-3 [D loss: 0.668409, acc.: 55.77%] [G loss: 1.393406] [Time: 0.253172]\n",
            "145-4 [D loss: 0.455519, acc.: 82.69%] [G loss: 1.519919] [Time: 0.248081]\n",
            "145-5 [D loss: 0.591063, acc.: 61.54%] [G loss: 1.494230] [Time: 0.249595]\n",
            "145-6 [D loss: 0.480380, acc.: 75.00%] [G loss: 1.500390] [Time: 0.244368]\n",
            "145-7 [D loss: 0.582899, acc.: 69.23%] [G loss: 1.535470] [Time: 0.245644]\n",
            "145-8 [D loss: 0.555753, acc.: 65.38%] [G loss: 1.444268] [Time: 0.247451]\n",
            "145 (test) [D loss: 1.221225, acc.: 50.00%] [G loss: 2.243111] [Time: 0.077122]\n",
            "146-0 [D loss: 0.578235, acc.: 71.15%] [G loss: 1.641860] [Time: 0.247305]\n",
            "146-1 [D loss: 0.610428, acc.: 71.15%] [G loss: 1.490674] [Time: 0.247249]\n",
            "146-2 [D loss: 0.658169, acc.: 61.54%] [G loss: 1.117049] [Time: 0.244088]\n",
            "146-3 [D loss: 0.618874, acc.: 61.54%] [G loss: 1.843819] [Time: 0.246517]\n",
            "146-4 [D loss: 0.580799, acc.: 67.31%] [G loss: 1.489053] [Time: 0.249300]\n",
            "146-5 [D loss: 0.649182, acc.: 65.38%] [G loss: 1.626852] [Time: 0.249290]\n",
            "146-6 [D loss: 0.554826, acc.: 82.69%] [G loss: 1.942382] [Time: 0.250191]\n",
            "146-7 [D loss: 0.556644, acc.: 73.08%] [G loss: 1.547215] [Time: 0.246693]\n",
            "146-8 [D loss: 0.521208, acc.: 75.00%] [G loss: 1.594962] [Time: 0.248187]\n",
            "146 (test) [D loss: 1.242103, acc.: 50.00%] [G loss: 2.316716] [Time: 0.077436]\n",
            "147-0 [D loss: 0.464673, acc.: 75.00%] [G loss: 1.956959] [Time: 0.245546]\n",
            "147-1 [D loss: 0.468992, acc.: 80.77%] [G loss: 1.666119] [Time: 0.247287]\n",
            "147-2 [D loss: 0.747077, acc.: 59.62%] [G loss: 1.487406] [Time: 0.247023]\n",
            "147-3 [D loss: 0.738947, acc.: 57.69%] [G loss: 1.437401] [Time: 0.247186]\n",
            "147-4 [D loss: 0.478217, acc.: 78.85%] [G loss: 1.517219] [Time: 0.248287]\n",
            "147-5 [D loss: 0.476083, acc.: 78.85%] [G loss: 1.814932] [Time: 0.244380]\n",
            "147-6 [D loss: 0.641824, acc.: 61.54%] [G loss: 1.722155] [Time: 0.246241]\n",
            "147-7 [D loss: 0.475221, acc.: 75.00%] [G loss: 1.740292] [Time: 0.248175]\n",
            "147-8 [D loss: 0.628518, acc.: 57.69%] [G loss: 1.539799] [Time: 0.245734]\n",
            "147 (test) [D loss: 1.212155, acc.: 50.00%] [G loss: 2.239649] [Time: 0.077697]\n",
            "148-0 [D loss: 0.446986, acc.: 78.85%] [G loss: 1.673503] [Time: 0.252296]\n",
            "148-1 [D loss: 0.603790, acc.: 65.38%] [G loss: 1.579667] [Time: 0.247947]\n",
            "148-2 [D loss: 0.717419, acc.: 53.85%] [G loss: 1.323401] [Time: 0.247471]\n",
            "148-3 [D loss: 0.528354, acc.: 71.15%] [G loss: 1.944172] [Time: 0.250018]\n",
            "148-4 [D loss: 0.490595, acc.: 75.00%] [G loss: 1.753429] [Time: 0.247741]\n",
            "148-5 [D loss: 0.572300, acc.: 75.00%] [G loss: 1.641323] [Time: 0.253412]\n",
            "148-6 [D loss: 0.477250, acc.: 80.77%] [G loss: 1.797205] [Time: 0.247473]\n",
            "148-7 [D loss: 0.519253, acc.: 69.23%] [G loss: 1.813374] [Time: 0.247132]\n",
            "148-8 [D loss: 0.530643, acc.: 67.31%] [G loss: 1.475701] [Time: 0.253673]\n",
            "148 (test) [D loss: 1.253156, acc.: 50.00%] [G loss: 2.332663] [Time: 0.077790]\n",
            "149-0 [D loss: 0.474608, acc.: 82.69%] [G loss: 1.440241] [Time: 0.245723]\n",
            "149-1 [D loss: 0.597075, acc.: 65.38%] [G loss: 1.586219] [Time: 0.250452]\n",
            "149-2 [D loss: 0.669808, acc.: 57.69%] [G loss: 1.511461] [Time: 0.249286]\n",
            "149-3 [D loss: 0.736634, acc.: 59.62%] [G loss: 1.511616] [Time: 0.246658]\n",
            "149-4 [D loss: 0.502816, acc.: 78.85%] [G loss: 1.898055] [Time: 0.247405]\n",
            "149-5 [D loss: 0.538287, acc.: 75.00%] [G loss: 1.520876] [Time: 0.248220]\n",
            "149-6 [D loss: 0.563778, acc.: 67.31%] [G loss: 1.560213] [Time: 0.249226]\n",
            "149-7 [D loss: 0.553292, acc.: 73.08%] [G loss: 1.740553] [Time: 0.249108]\n",
            "149-8 [D loss: 0.635189, acc.: 59.62%] [G loss: 1.783173] [Time: 0.247883]\n",
            "149 (test) [D loss: 1.184282, acc.: 50.00%] [G loss: 2.168548] [Time: 0.077657]\n",
            "150-0 [D loss: 0.466990, acc.: 78.85%] [G loss: 1.549194] [Time: 0.251447]\n",
            "150-1 [D loss: 0.730877, acc.: 55.77%] [G loss: 1.503799] [Time: 0.244685]\n",
            "150-2 [D loss: 0.748527, acc.: 53.85%] [G loss: 1.479949] [Time: 0.247483]\n",
            "150-3 [D loss: 0.527780, acc.: 71.15%] [G loss: 1.626989] [Time: 0.247951]\n",
            "150-4 [D loss: 0.566397, acc.: 67.31%] [G loss: 1.659998] [Time: 0.247171]\n",
            "150-5 [D loss: 0.545070, acc.: 73.08%] [G loss: 1.642359] [Time: 0.245311]\n",
            "150-6 [D loss: 0.565279, acc.: 65.38%] [G loss: 1.452840] [Time: 0.247034]\n",
            "150-7 [D loss: 0.682425, acc.: 53.85%] [G loss: 1.597890] [Time: 0.246238]\n",
            "150-8 [D loss: 0.546597, acc.: 73.08%] [G loss: 1.605278] [Time: 0.244954]\n",
            "150 (test) [D loss: 1.200529, acc.: 50.00%] [G loss: 2.228366] [Time: 0.077810]\n",
            "151-0 [D loss: 0.582775, acc.: 67.31%] [G loss: 1.341910] [Time: 0.245736]\n",
            "151-1 [D loss: 0.577807, acc.: 59.62%] [G loss: 1.803191] [Time: 0.241327]\n",
            "151-2 [D loss: 0.624233, acc.: 63.46%] [G loss: 1.436706] [Time: 0.247294]\n",
            "151-3 [D loss: 0.649749, acc.: 67.31%] [G loss: 1.341992] [Time: 0.247496]\n",
            "151-4 [D loss: 0.461044, acc.: 78.85%] [G loss: 2.069091] [Time: 0.245686]\n",
            "151-5 [D loss: 0.540899, acc.: 76.92%] [G loss: 1.766069] [Time: 0.248038]\n",
            "151-6 [D loss: 0.581227, acc.: 67.31%] [G loss: 1.701932] [Time: 0.248142]\n",
            "151-7 [D loss: 0.596153, acc.: 75.00%] [G loss: 1.639539] [Time: 0.246208]\n",
            "151-8 [D loss: 0.642937, acc.: 57.69%] [G loss: 1.416453] [Time: 0.244162]\n",
            "151 (test) [D loss: 1.157230, acc.: 50.00%] [G loss: 2.124689] [Time: 0.078641]\n",
            "152-0 [D loss: 0.471706, acc.: 80.77%] [G loss: 1.558954] [Time: 0.247894]\n",
            "152-1 [D loss: 0.621608, acc.: 67.31%] [G loss: 1.421932] [Time: 0.252112]\n",
            "152-2 [D loss: 0.656904, acc.: 67.31%] [G loss: 1.617973] [Time: 0.243333]\n",
            "152-3 [D loss: 0.635998, acc.: 67.31%] [G loss: 1.481807] [Time: 0.246777]\n",
            "152-4 [D loss: 0.498952, acc.: 80.77%] [G loss: 1.605152] [Time: 0.249168]\n",
            "152-5 [D loss: 0.601975, acc.: 59.62%] [G loss: 1.416784] [Time: 0.248492]\n",
            "152-6 [D loss: 0.707360, acc.: 65.38%] [G loss: 1.545393] [Time: 0.250614]\n",
            "152-7 [D loss: 0.619855, acc.: 69.23%] [G loss: 1.589664] [Time: 0.246452]\n",
            "152-8 [D loss: 0.542435, acc.: 71.15%] [G loss: 1.757774] [Time: 0.249123]\n",
            "152 (test) [D loss: 1.355547, acc.: 50.00%] [G loss: 2.561721] [Time: 0.075895]\n",
            "153-0 [D loss: 0.485725, acc.: 69.23%] [G loss: 1.934132] [Time: 0.249102]\n",
            "153-1 [D loss: 0.656132, acc.: 59.62%] [G loss: 1.499847] [Time: 0.247638]\n",
            "153-2 [D loss: 0.798559, acc.: 48.08%] [G loss: 1.472898] [Time: 0.250239]\n",
            "153-3 [D loss: 0.558944, acc.: 63.46%] [G loss: 1.595140] [Time: 0.249637]\n",
            "153-4 [D loss: 0.561575, acc.: 65.38%] [G loss: 1.483365] [Time: 0.242937]\n",
            "153-5 [D loss: 0.641320, acc.: 65.38%] [G loss: 1.637253] [Time: 0.245738]\n",
            "153-6 [D loss: 0.659594, acc.: 57.69%] [G loss: 1.436422] [Time: 0.245907]\n",
            "153-7 [D loss: 0.718699, acc.: 51.92%] [G loss: 1.637501] [Time: 0.248731]\n",
            "153-8 [D loss: 0.539928, acc.: 67.31%] [G loss: 1.678225] [Time: 0.249150]\n",
            "153 (test) [D loss: 1.150891, acc.: 50.00%] [G loss: 2.112481] [Time: 0.075795]\n",
            "154-0 [D loss: 0.447135, acc.: 82.69%] [G loss: 1.637325] [Time: 0.248712]\n",
            "154-1 [D loss: 0.546989, acc.: 63.46%] [G loss: 1.466049] [Time: 0.249199]\n",
            "154-2 [D loss: 0.586390, acc.: 65.38%] [G loss: 1.504156] [Time: 0.247519]\n",
            "154-3 [D loss: 0.617803, acc.: 57.69%] [G loss: 1.675374] [Time: 0.245690]\n",
            "154-4 [D loss: 0.560480, acc.: 71.15%] [G loss: 1.540913] [Time: 0.254004]\n",
            "154-5 [D loss: 0.658466, acc.: 61.54%] [G loss: 1.384670] [Time: 0.247717]\n",
            "154-6 [D loss: 0.686809, acc.: 59.62%] [G loss: 1.851447] [Time: 0.247841]\n",
            "154-7 [D loss: 0.661838, acc.: 67.31%] [G loss: 1.717427] [Time: 0.250552]\n",
            "154-8 [D loss: 0.512050, acc.: 76.92%] [G loss: 1.843634] [Time: 0.246348]\n",
            "154 (test) [D loss: 1.163937, acc.: 50.00%] [G loss: 2.145679] [Time: 0.079612]\n",
            "155-0 [D loss: 0.603233, acc.: 57.69%] [G loss: 1.763346] [Time: 0.252553]\n",
            "155-1 [D loss: 0.599351, acc.: 67.31%] [G loss: 1.582199] [Time: 0.245181]\n",
            "155-2 [D loss: 0.645480, acc.: 65.38%] [G loss: 1.524940] [Time: 0.253359]\n",
            "155-3 [D loss: 0.594432, acc.: 75.00%] [G loss: 1.407205] [Time: 0.245739]\n",
            "155-4 [D loss: 0.580901, acc.: 55.77%] [G loss: 1.426861] [Time: 0.246462]\n",
            "155-5 [D loss: 0.600377, acc.: 67.31%] [G loss: 1.561803] [Time: 0.244205]\n",
            "155-6 [D loss: 0.598235, acc.: 61.54%] [G loss: 1.449991] [Time: 0.250401]\n",
            "155-7 [D loss: 0.721293, acc.: 57.69%] [G loss: 1.665306] [Time: 0.247219]\n",
            "155-8 [D loss: 0.512643, acc.: 75.00%] [G loss: 1.716293] [Time: 0.252540]\n",
            "155 (test) [D loss: 1.093968, acc.: 50.00%] [G loss: 1.974892] [Time: 0.085071]\n",
            "156-0 [D loss: 0.527605, acc.: 71.15%] [G loss: 1.821779] [Time: 0.250120]\n",
            "156-1 [D loss: 0.588932, acc.: 65.38%] [G loss: 1.547638] [Time: 0.248788]\n",
            "156-2 [D loss: 0.718930, acc.: 59.62%] [G loss: 1.682937] [Time: 0.246683]\n",
            "156-3 [D loss: 0.629839, acc.: 67.31%] [G loss: 1.626525] [Time: 0.244256]\n",
            "156-4 [D loss: 0.502597, acc.: 73.08%] [G loss: 1.706078] [Time: 0.248905]\n",
            "156-5 [D loss: 0.607042, acc.: 67.31%] [G loss: 1.566160] [Time: 0.245058]\n",
            "156-6 [D loss: 0.571745, acc.: 65.38%] [G loss: 1.530432] [Time: 0.245835]\n",
            "156-7 [D loss: 0.587678, acc.: 69.23%] [G loss: 1.621651] [Time: 0.247725]\n",
            "156-8 [D loss: 0.539384, acc.: 73.08%] [G loss: 1.638849] [Time: 0.243300]\n",
            "156 (test) [D loss: 1.206025, acc.: 50.00%] [G loss: 2.245857] [Time: 0.078247]\n",
            "157-0 [D loss: 0.489547, acc.: 75.00%] [G loss: 1.561344] [Time: 0.248574]\n",
            "157-1 [D loss: 0.539010, acc.: 69.23%] [G loss: 1.631322] [Time: 0.245125]\n",
            "157-2 [D loss: 0.583777, acc.: 71.15%] [G loss: 1.297630] [Time: 0.252038]\n",
            "157-3 [D loss: 0.636783, acc.: 63.46%] [G loss: 1.528817] [Time: 0.246554]\n",
            "157-4 [D loss: 0.434285, acc.: 88.46%] [G loss: 1.753066] [Time: 0.244554]\n",
            "157-5 [D loss: 0.624734, acc.: 65.38%] [G loss: 1.784118] [Time: 0.246977]\n",
            "157-6 [D loss: 0.584569, acc.: 63.46%] [G loss: 1.263370] [Time: 0.246680]\n",
            "157-7 [D loss: 0.634075, acc.: 65.38%] [G loss: 1.486074] [Time: 0.247498]\n",
            "157-8 [D loss: 0.506472, acc.: 73.08%] [G loss: 1.588189] [Time: 0.249146]\n",
            "157 (test) [D loss: 1.276373, acc.: 50.00%] [G loss: 2.398554] [Time: 0.078070]\n",
            "158-0 [D loss: 0.446154, acc.: 75.00%] [G loss: 1.737338] [Time: 0.252466]\n",
            "158-1 [D loss: 0.632981, acc.: 61.54%] [G loss: 1.494343] [Time: 0.246606]\n",
            "158-2 [D loss: 0.668358, acc.: 63.46%] [G loss: 1.361698] [Time: 0.246392]\n",
            "158-3 [D loss: 0.737291, acc.: 51.92%] [G loss: 1.670271] [Time: 0.245990]\n",
            "158-4 [D loss: 0.528470, acc.: 73.08%] [G loss: 1.910114] [Time: 0.245030]\n",
            "158-5 [D loss: 0.621376, acc.: 65.38%] [G loss: 1.523076] [Time: 0.248199]\n",
            "158-6 [D loss: 0.650861, acc.: 67.31%] [G loss: 1.649084] [Time: 0.245283]\n",
            "158-7 [D loss: 0.642778, acc.: 63.46%] [G loss: 1.550135] [Time: 0.245489]\n",
            "158-8 [D loss: 0.476344, acc.: 75.00%] [G loss: 1.944273] [Time: 0.247891]\n",
            "158 (test) [D loss: 1.268924, acc.: 50.00%] [G loss: 2.375478] [Time: 0.076520]\n",
            "159-0 [D loss: 0.524278, acc.: 71.15%] [G loss: 1.660587] [Time: 0.249851]\n",
            "159-1 [D loss: 0.617594, acc.: 61.54%] [G loss: 1.745628] [Time: 0.245155]\n",
            "159-2 [D loss: 0.634084, acc.: 69.23%] [G loss: 1.382198] [Time: 0.250060]\n",
            "159-3 [D loss: 0.636674, acc.: 67.31%] [G loss: 1.431180] [Time: 0.244828]\n",
            "159-4 [D loss: 0.451072, acc.: 84.62%] [G loss: 1.841265] [Time: 0.246983]\n",
            "159-5 [D loss: 0.641332, acc.: 65.38%] [G loss: 1.393576] [Time: 0.252601]\n",
            "159-6 [D loss: 0.583406, acc.: 67.31%] [G loss: 1.497249] [Time: 0.245267]\n",
            "159-7 [D loss: 0.622483, acc.: 55.77%] [G loss: 1.501839] [Time: 0.246332]\n",
            "159-8 [D loss: 0.552178, acc.: 75.00%] [G loss: 1.655599] [Time: 0.245934]\n",
            "159 (test) [D loss: 1.207821, acc.: 50.00%] [G loss: 2.229921] [Time: 0.079088]\n",
            "160-0 [D loss: 0.412293, acc.: 84.62%] [G loss: 1.815728] [Time: 0.252365]\n",
            "160-1 [D loss: 0.693476, acc.: 53.85%] [G loss: 1.418425] [Time: 0.245856]\n",
            "160-2 [D loss: 0.663096, acc.: 67.31%] [G loss: 1.288978] [Time: 0.246176]\n",
            "160-3 [D loss: 0.582846, acc.: 67.31%] [G loss: 1.695206] [Time: 0.247329]\n",
            "160-4 [D loss: 0.427321, acc.: 84.62%] [G loss: 1.794963] [Time: 0.251193]\n",
            "160-5 [D loss: 0.568998, acc.: 73.08%] [G loss: 1.650172] [Time: 0.249634]\n",
            "160-6 [D loss: 0.564970, acc.: 65.38%] [G loss: 1.415915] [Time: 0.245666]\n",
            "160-7 [D loss: 0.704000, acc.: 55.77%] [G loss: 1.822154] [Time: 0.247820]\n",
            "160-8 [D loss: 0.484636, acc.: 75.00%] [G loss: 1.629236] [Time: 0.247724]\n",
            "160 (test) [D loss: 1.245986, acc.: 50.00%] [G loss: 2.313303] [Time: 0.076541]\n",
            "161-0 [D loss: 0.539093, acc.: 65.38%] [G loss: 1.674245] [Time: 0.250166]\n",
            "161-1 [D loss: 0.733981, acc.: 51.92%] [G loss: 1.466989] [Time: 0.246525]\n",
            "161-2 [D loss: 0.632018, acc.: 57.69%] [G loss: 1.558312] [Time: 0.248882]\n",
            "161-3 [D loss: 0.689201, acc.: 53.85%] [G loss: 1.320794] [Time: 0.245961]\n",
            "161-4 [D loss: 0.530080, acc.: 73.08%] [G loss: 1.691440] [Time: 0.246818]\n",
            "161-5 [D loss: 0.654178, acc.: 55.77%] [G loss: 1.570938] [Time: 0.245563]\n",
            "161-6 [D loss: 0.553074, acc.: 73.08%] [G loss: 1.614043] [Time: 0.249127]\n",
            "161-7 [D loss: 0.638072, acc.: 65.38%] [G loss: 1.427545] [Time: 0.249808]\n",
            "161-8 [D loss: 0.525099, acc.: 71.15%] [G loss: 1.746409] [Time: 0.248348]\n",
            "161 (test) [D loss: 1.275299, acc.: 50.00%] [G loss: 2.391042] [Time: 0.079192]\n",
            "162-0 [D loss: 0.418371, acc.: 82.69%] [G loss: 2.001568] [Time: 0.251189]\n",
            "162-1 [D loss: 0.515239, acc.: 71.15%] [G loss: 1.370449] [Time: 0.245502]\n",
            "162-2 [D loss: 0.715072, acc.: 65.38%] [G loss: 1.482640] [Time: 0.249460]\n",
            "162-3 [D loss: 0.619814, acc.: 65.38%] [G loss: 1.697605] [Time: 0.246297]\n",
            "162-4 [D loss: 0.506300, acc.: 75.00%] [G loss: 1.978141] [Time: 0.250927]\n",
            "162-5 [D loss: 0.584293, acc.: 69.23%] [G loss: 1.879627] [Time: 0.249608]\n",
            "162-6 [D loss: 0.656333, acc.: 63.46%] [G loss: 1.700643] [Time: 0.245118]\n",
            "162-7 [D loss: 0.606561, acc.: 65.38%] [G loss: 1.398274] [Time: 0.249257]\n",
            "162-8 [D loss: 0.467422, acc.: 80.77%] [G loss: 1.780112] [Time: 0.244958]\n",
            "162 (test) [D loss: 1.285575, acc.: 50.00%] [G loss: 2.398397] [Time: 0.077684]\n",
            "163-0 [D loss: 0.469792, acc.: 80.77%] [G loss: 1.574960] [Time: 0.248995]\n",
            "163-1 [D loss: 0.673813, acc.: 57.69%] [G loss: 1.363625] [Time: 0.245920]\n",
            "163-2 [D loss: 0.681485, acc.: 53.85%] [G loss: 1.490206] [Time: 0.249869]\n",
            "163-3 [D loss: 0.566568, acc.: 63.46%] [G loss: 1.541875] [Time: 0.246884]\n",
            "163-4 [D loss: 0.448463, acc.: 82.69%] [G loss: 1.583897] [Time: 0.248683]\n",
            "163-5 [D loss: 0.656515, acc.: 57.69%] [G loss: 1.443258] [Time: 0.245562]\n",
            "163-6 [D loss: 0.525015, acc.: 73.08%] [G loss: 1.615330] [Time: 0.244756]\n",
            "163-7 [D loss: 0.582829, acc.: 69.23%] [G loss: 1.607712] [Time: 0.246616]\n",
            "163-8 [D loss: 0.558775, acc.: 67.31%] [G loss: 1.713498] [Time: 0.248468]\n",
            "163 (test) [D loss: 1.262929, acc.: 50.00%] [G loss: 2.367114] [Time: 0.076186]\n",
            "164-0 [D loss: 0.399038, acc.: 86.54%] [G loss: 1.779579] [Time: 0.247726]\n",
            "164-1 [D loss: 0.700631, acc.: 59.62%] [G loss: 1.656260] [Time: 0.246076]\n",
            "164-2 [D loss: 0.679142, acc.: 55.77%] [G loss: 1.222789] [Time: 0.249229]\n",
            "164-3 [D loss: 0.571855, acc.: 67.31%] [G loss: 1.516079] [Time: 0.247344]\n",
            "164-4 [D loss: 0.553477, acc.: 65.38%] [G loss: 1.650844] [Time: 0.247714]\n",
            "164-5 [D loss: 0.619435, acc.: 69.23%] [G loss: 1.583455] [Time: 0.250068]\n",
            "164-6 [D loss: 0.524202, acc.: 71.15%] [G loss: 1.789466] [Time: 0.246739]\n",
            "164-7 [D loss: 0.583799, acc.: 69.23%] [G loss: 1.662223] [Time: 0.247098]\n",
            "164-8 [D loss: 0.446146, acc.: 84.62%] [G loss: 1.686365] [Time: 0.244710]\n",
            "164 (test) [D loss: 1.267476, acc.: 50.00%] [G loss: 2.357322] [Time: 0.078437]\n",
            "165-0 [D loss: 0.536651, acc.: 71.15%] [G loss: 1.717323] [Time: 0.251060]\n",
            "165-1 [D loss: 0.605856, acc.: 71.15%] [G loss: 1.172837] [Time: 0.246188]\n",
            "165-2 [D loss: 0.633899, acc.: 67.31%] [G loss: 1.369109] [Time: 0.246029]\n",
            "165-3 [D loss: 0.512878, acc.: 78.85%] [G loss: 1.703789] [Time: 0.246282]\n",
            "165-4 [D loss: 0.418768, acc.: 82.69%] [G loss: 1.936711] [Time: 0.250811]\n",
            "165-5 [D loss: 0.620336, acc.: 75.00%] [G loss: 1.271320] [Time: 0.245324]\n",
            "165-6 [D loss: 0.560057, acc.: 73.08%] [G loss: 1.608336] [Time: 0.248823]\n",
            "165-7 [D loss: 0.507137, acc.: 73.08%] [G loss: 1.609479] [Time: 0.246012]\n",
            "165-8 [D loss: 0.541671, acc.: 71.15%] [G loss: 1.601965] [Time: 0.246433]\n",
            "165 (test) [D loss: 1.180994, acc.: 50.00%] [G loss: 2.162927] [Time: 0.079649]\n",
            "166-0 [D loss: 0.442337, acc.: 88.46%] [G loss: 1.625141] [Time: 0.248816]\n",
            "166-1 [D loss: 0.684183, acc.: 57.69%] [G loss: 1.359677] [Time: 0.247646]\n",
            "166-2 [D loss: 0.653031, acc.: 61.54%] [G loss: 1.601351] [Time: 0.246690]\n",
            "166-3 [D loss: 0.525848, acc.: 71.15%] [G loss: 1.427378] [Time: 0.247525]\n",
            "166-4 [D loss: 0.503475, acc.: 76.92%] [G loss: 1.513554] [Time: 0.246767]\n",
            "166-5 [D loss: 0.470820, acc.: 78.85%] [G loss: 1.594094] [Time: 0.245914]\n",
            "166-6 [D loss: 0.669812, acc.: 59.62%] [G loss: 1.561594] [Time: 0.248879]\n",
            "166-7 [D loss: 0.624585, acc.: 63.46%] [G loss: 1.576021] [Time: 0.247657]\n",
            "166-8 [D loss: 0.471552, acc.: 80.77%] [G loss: 1.659585] [Time: 0.246957]\n",
            "166 (test) [D loss: 1.277180, acc.: 50.00%] [G loss: 2.389872] [Time: 0.078329]\n",
            "167-0 [D loss: 0.501348, acc.: 75.00%] [G loss: 1.738727] [Time: 0.250731]\n",
            "167-1 [D loss: 0.572439, acc.: 69.23%] [G loss: 1.496752] [Time: 0.247731]\n",
            "167-2 [D loss: 0.604524, acc.: 65.38%] [G loss: 1.477172] [Time: 0.246234]\n",
            "167-3 [D loss: 0.585292, acc.: 61.54%] [G loss: 1.424456] [Time: 0.247114]\n",
            "167-4 [D loss: 0.529056, acc.: 75.00%] [G loss: 1.682967] [Time: 0.247069]\n",
            "167-5 [D loss: 0.624493, acc.: 57.69%] [G loss: 1.568627] [Time: 0.251345]\n",
            "167-6 [D loss: 0.625629, acc.: 67.31%] [G loss: 1.750069] [Time: 0.247162]\n",
            "167-7 [D loss: 0.590194, acc.: 63.46%] [G loss: 1.845552] [Time: 0.245396]\n",
            "167-8 [D loss: 0.596034, acc.: 61.54%] [G loss: 1.942009] [Time: 0.251505]\n",
            "167 (test) [D loss: 1.245295, acc.: 50.00%] [G loss: 2.333232] [Time: 0.078227]\n",
            "168-0 [D loss: 0.477586, acc.: 75.00%] [G loss: 1.727590] [Time: 0.245200]\n",
            "168-1 [D loss: 0.685042, acc.: 59.62%] [G loss: 1.247596] [Time: 0.242456]\n",
            "168-2 [D loss: 0.551561, acc.: 73.08%] [G loss: 1.465676] [Time: 0.250075]\n",
            "168-3 [D loss: 0.638266, acc.: 65.38%] [G loss: 1.361195] [Time: 0.253482]\n",
            "168-4 [D loss: 0.447432, acc.: 80.77%] [G loss: 1.874563] [Time: 0.248937]\n",
            "168-5 [D loss: 0.414758, acc.: 84.62%] [G loss: 1.713698] [Time: 0.250211]\n",
            "168-6 [D loss: 0.656354, acc.: 50.00%] [G loss: 1.193119] [Time: 0.248565]\n",
            "168-7 [D loss: 0.541247, acc.: 73.08%] [G loss: 1.663154] [Time: 0.246161]\n",
            "168-8 [D loss: 0.468288, acc.: 78.85%] [G loss: 1.650213] [Time: 0.243594]\n",
            "168 (test) [D loss: 1.241169, acc.: 50.00%] [G loss: 2.296092] [Time: 0.076735]\n",
            "169-0 [D loss: 0.430598, acc.: 80.77%] [G loss: 1.551457] [Time: 0.250032]\n",
            "169-1 [D loss: 0.545140, acc.: 75.00%] [G loss: 1.637768] [Time: 0.248398]\n",
            "169-2 [D loss: 0.492090, acc.: 75.00%] [G loss: 1.726121] [Time: 0.245533]\n",
            "169-3 [D loss: 0.617590, acc.: 61.54%] [G loss: 1.402376] [Time: 0.244587]\n",
            "169-4 [D loss: 0.445428, acc.: 80.77%] [G loss: 1.833917] [Time: 0.245294]\n",
            "169-5 [D loss: 0.557486, acc.: 78.85%] [G loss: 1.713343] [Time: 0.248039]\n",
            "169-6 [D loss: 0.599570, acc.: 59.62%] [G loss: 1.882351] [Time: 0.246601]\n",
            "169-7 [D loss: 0.535205, acc.: 69.23%] [G loss: 1.686768] [Time: 0.244558]\n",
            "169-8 [D loss: 0.538952, acc.: 75.00%] [G loss: 1.593672] [Time: 0.246525]\n",
            "169 (test) [D loss: 1.174450, acc.: 50.00%] [G loss: 2.160684] [Time: 0.079126]\n",
            "170-0 [D loss: 0.436134, acc.: 75.00%] [G loss: 1.819198] [Time: 0.248388]\n",
            "170-1 [D loss: 0.591368, acc.: 61.54%] [G loss: 1.484240] [Time: 0.245429]\n",
            "170-2 [D loss: 0.815431, acc.: 50.00%] [G loss: 1.321553] [Time: 0.246502]\n",
            "170-3 [D loss: 0.539118, acc.: 69.23%] [G loss: 1.665786] [Time: 0.244141]\n",
            "170-4 [D loss: 0.484996, acc.: 73.08%] [G loss: 1.904072] [Time: 0.246662]\n",
            "170-5 [D loss: 0.620301, acc.: 65.38%] [G loss: 1.474020] [Time: 0.247498]\n",
            "170-6 [D loss: 0.572842, acc.: 71.15%] [G loss: 1.658961] [Time: 0.246032]\n",
            "170-7 [D loss: 0.674854, acc.: 69.23%] [G loss: 1.740087] [Time: 0.244697]\n",
            "170-8 [D loss: 0.452989, acc.: 84.62%] [G loss: 1.851510] [Time: 0.247202]\n",
            "170 (test) [D loss: 1.191915, acc.: 50.00%] [G loss: 2.204685] [Time: 0.076315]\n",
            "171-0 [D loss: 0.468129, acc.: 76.92%] [G loss: 1.730272] [Time: 0.247095]\n",
            "171-1 [D loss: 0.492315, acc.: 76.92%] [G loss: 1.603315] [Time: 0.247823]\n",
            "171-2 [D loss: 0.668371, acc.: 69.23%] [G loss: 1.349484] [Time: 0.249958]\n",
            "171-3 [D loss: 0.511183, acc.: 69.23%] [G loss: 1.654104] [Time: 0.247364]\n",
            "171-4 [D loss: 0.495239, acc.: 80.77%] [G loss: 1.921065] [Time: 0.246229]\n",
            "171-5 [D loss: 0.618468, acc.: 71.15%] [G loss: 1.651870] [Time: 0.249443]\n",
            "171-6 [D loss: 0.615278, acc.: 61.54%] [G loss: 1.514263] [Time: 0.245953]\n",
            "171-7 [D loss: 0.612961, acc.: 61.54%] [G loss: 1.520480] [Time: 0.244597]\n",
            "171-8 [D loss: 0.541791, acc.: 71.15%] [G loss: 1.837009] [Time: 0.249396]\n",
            "171 (test) [D loss: 1.226907, acc.: 50.00%] [G loss: 2.274082] [Time: 0.076040]\n",
            "172-0 [D loss: 0.425160, acc.: 76.92%] [G loss: 2.012642] [Time: 0.245010]\n",
            "172-1 [D loss: 0.716300, acc.: 55.77%] [G loss: 1.402430] [Time: 0.246468]\n",
            "172-2 [D loss: 0.605649, acc.: 65.38%] [G loss: 1.411616] [Time: 0.246357]\n",
            "172-3 [D loss: 0.594987, acc.: 67.31%] [G loss: 1.389459] [Time: 0.245331]\n",
            "172-4 [D loss: 0.386236, acc.: 86.54%] [G loss: 2.000888] [Time: 0.245867]\n",
            "172-5 [D loss: 0.564651, acc.: 73.08%] [G loss: 1.646452] [Time: 0.245103]\n",
            "172-6 [D loss: 0.614989, acc.: 63.46%] [G loss: 1.638212] [Time: 0.250818]\n",
            "172-7 [D loss: 0.646480, acc.: 61.54%] [G loss: 1.782668] [Time: 0.246544]\n",
            "172-8 [D loss: 0.424884, acc.: 82.69%] [G loss: 1.807771] [Time: 0.253250]\n",
            "172 (test) [D loss: 1.247664, acc.: 50.00%] [G loss: 2.294929] [Time: 0.074162]\n",
            "173-0 [D loss: 0.353818, acc.: 94.23%] [G loss: 1.951210] [Time: 0.245487]\n",
            "173-1 [D loss: 0.625007, acc.: 69.23%] [G loss: 1.499989] [Time: 0.249836]\n",
            "173-2 [D loss: 0.562713, acc.: 63.46%] [G loss: 1.508686] [Time: 0.243556]\n",
            "173-3 [D loss: 0.544340, acc.: 73.08%] [G loss: 1.430171] [Time: 0.246382]\n",
            "173-4 [D loss: 0.484054, acc.: 78.85%] [G loss: 1.636541] [Time: 0.250010]\n",
            "173-5 [D loss: 0.555915, acc.: 73.08%] [G loss: 1.606045] [Time: 0.245455]\n",
            "173-6 [D loss: 0.579692, acc.: 61.54%] [G loss: 1.411541] [Time: 0.245565]\n",
            "173-7 [D loss: 0.578276, acc.: 69.23%] [G loss: 1.524212] [Time: 0.247937]\n",
            "173-8 [D loss: 0.509096, acc.: 75.00%] [G loss: 1.885447] [Time: 0.248022]\n",
            "173 (test) [D loss: 1.190580, acc.: 50.00%] [G loss: 2.194695] [Time: 0.075910]\n",
            "174-0 [D loss: 0.432370, acc.: 84.62%] [G loss: 1.793379] [Time: 0.246026]\n",
            "174-1 [D loss: 0.602542, acc.: 73.08%] [G loss: 1.426245] [Time: 0.244325]\n",
            "174-2 [D loss: 0.630276, acc.: 57.69%] [G loss: 1.468062] [Time: 0.246113]\n",
            "174-3 [D loss: 0.521028, acc.: 76.92%] [G loss: 1.749704] [Time: 0.245673]\n",
            "174-4 [D loss: 0.447012, acc.: 80.77%] [G loss: 1.751302] [Time: 0.245843]\n",
            "174-5 [D loss: 0.684178, acc.: 57.69%] [G loss: 1.445062] [Time: 0.247051]\n",
            "174-6 [D loss: 0.515860, acc.: 76.92%] [G loss: 1.666512] [Time: 0.246210]\n",
            "174-7 [D loss: 0.647565, acc.: 59.62%] [G loss: 1.595036] [Time: 0.249128]\n",
            "174-8 [D loss: 0.488296, acc.: 78.85%] [G loss: 1.685148] [Time: 0.245856]\n",
            "174 (test) [D loss: 1.208661, acc.: 50.00%] [G loss: 2.248633] [Time: 0.079159]\n",
            "175-0 [D loss: 0.491483, acc.: 80.77%] [G loss: 1.528545] [Time: 0.249089]\n",
            "175-1 [D loss: 0.610559, acc.: 73.08%] [G loss: 1.809688] [Time: 0.244917]\n",
            "175-2 [D loss: 0.610391, acc.: 67.31%] [G loss: 1.348315] [Time: 0.248008]\n",
            "175-3 [D loss: 0.536655, acc.: 71.15%] [G loss: 1.733840] [Time: 0.249404]\n",
            "175-4 [D loss: 0.409897, acc.: 84.62%] [G loss: 1.512253] [Time: 0.245931]\n",
            "175-5 [D loss: 0.531979, acc.: 75.00%] [G loss: 1.494024] [Time: 0.254469]\n",
            "175-6 [D loss: 0.567546, acc.: 67.31%] [G loss: 1.788133] [Time: 0.248873]\n",
            "175-7 [D loss: 0.525748, acc.: 75.00%] [G loss: 1.843469] [Time: 0.246540]\n",
            "175-8 [D loss: 0.531412, acc.: 73.08%] [G loss: 1.922980] [Time: 0.250267]\n",
            "175 (test) [D loss: 1.228672, acc.: 50.00%] [G loss: 2.281634] [Time: 0.082006]\n",
            "176-0 [D loss: 0.431244, acc.: 84.62%] [G loss: 1.898937] [Time: 0.245002]\n",
            "176-1 [D loss: 0.619074, acc.: 63.46%] [G loss: 1.566470] [Time: 0.247494]\n",
            "176-2 [D loss: 0.642721, acc.: 61.54%] [G loss: 1.499761] [Time: 0.248399]\n",
            "176-3 [D loss: 0.508050, acc.: 76.92%] [G loss: 1.649903] [Time: 0.248993]\n",
            "176-4 [D loss: 0.420133, acc.: 80.77%] [G loss: 1.822430] [Time: 0.250256]\n",
            "176-5 [D loss: 0.582771, acc.: 69.23%] [G loss: 1.630438] [Time: 0.243681]\n",
            "176-6 [D loss: 0.648602, acc.: 63.46%] [G loss: 1.767883] [Time: 0.246709]\n",
            "176-7 [D loss: 0.650210, acc.: 65.38%] [G loss: 1.523163] [Time: 0.247056]\n",
            "176-8 [D loss: 0.474127, acc.: 76.92%] [G loss: 1.789210] [Time: 0.246985]\n",
            "176 (test) [D loss: 1.246994, acc.: 50.00%] [G loss: 2.322612] [Time: 0.074888]\n",
            "177-0 [D loss: 0.439829, acc.: 82.69%] [G loss: 1.830573] [Time: 0.248402]\n",
            "177-1 [D loss: 0.532890, acc.: 73.08%] [G loss: 1.667944] [Time: 0.245988]\n",
            "177-2 [D loss: 0.549267, acc.: 71.15%] [G loss: 1.242048] [Time: 0.248122]\n",
            "177-3 [D loss: 0.508163, acc.: 73.08%] [G loss: 1.578591] [Time: 0.247730]\n",
            "177-4 [D loss: 0.435612, acc.: 84.62%] [G loss: 2.115609] [Time: 0.247112]\n",
            "177-5 [D loss: 0.581847, acc.: 75.00%] [G loss: 1.611795] [Time: 0.248471]\n",
            "177-6 [D loss: 0.531268, acc.: 75.00%] [G loss: 1.570768] [Time: 0.248264]\n",
            "177-7 [D loss: 0.616441, acc.: 63.46%] [G loss: 1.605959] [Time: 0.245319]\n",
            "177-8 [D loss: 0.466382, acc.: 78.85%] [G loss: 1.787245] [Time: 0.243908]\n",
            "177 (test) [D loss: 1.209402, acc.: 50.00%] [G loss: 2.234204] [Time: 0.078500]\n",
            "178-0 [D loss: 0.396897, acc.: 88.46%] [G loss: 1.737953] [Time: 0.250711]\n",
            "178-1 [D loss: 0.522977, acc.: 76.92%] [G loss: 1.464325] [Time: 0.247158]\n",
            "178-2 [D loss: 0.612162, acc.: 71.15%] [G loss: 1.505085] [Time: 0.244408]\n",
            "178-3 [D loss: 0.634631, acc.: 61.54%] [G loss: 1.768713] [Time: 0.252612]\n",
            "178-4 [D loss: 0.496937, acc.: 73.08%] [G loss: 1.785424] [Time: 0.247555]\n",
            "178-5 [D loss: 0.635159, acc.: 55.77%] [G loss: 1.826374] [Time: 0.249427]\n",
            "178-6 [D loss: 0.602196, acc.: 63.46%] [G loss: 1.554345] [Time: 0.246855]\n",
            "178-7 [D loss: 0.504356, acc.: 75.00%] [G loss: 1.487366] [Time: 0.244609]\n",
            "178-8 [D loss: 0.438702, acc.: 80.77%] [G loss: 1.638846] [Time: 0.247952]\n",
            "178 (test) [D loss: 1.232901, acc.: 50.00%] [G loss: 2.283154] [Time: 0.076545]\n",
            "179-0 [D loss: 0.449810, acc.: 80.77%] [G loss: 1.776370] [Time: 0.249404]\n",
            "179-1 [D loss: 0.704931, acc.: 59.62%] [G loss: 1.301947] [Time: 0.251120]\n",
            "179-2 [D loss: 0.672465, acc.: 55.77%] [G loss: 1.396111] [Time: 0.247165]\n",
            "179-3 [D loss: 0.553841, acc.: 75.00%] [G loss: 1.501313] [Time: 0.249042]\n",
            "179-4 [D loss: 0.486395, acc.: 80.77%] [G loss: 1.686761] [Time: 0.244936]\n",
            "179-5 [D loss: 0.599711, acc.: 69.23%] [G loss: 1.701746] [Time: 0.248327]\n",
            "179-6 [D loss: 0.542347, acc.: 67.31%] [G loss: 1.662580] [Time: 0.248579]\n",
            "179-7 [D loss: 0.546392, acc.: 71.15%] [G loss: 1.676484] [Time: 0.247725]\n",
            "179-8 [D loss: 0.482266, acc.: 78.85%] [G loss: 1.744855] [Time: 0.244263]\n",
            "179 (test) [D loss: 1.307491, acc.: 50.00%] [G loss: 2.456245] [Time: 0.076514]\n",
            "180-0 [D loss: 0.496380, acc.: 76.92%] [G loss: 1.709875] [Time: 0.245314]\n",
            "180-1 [D loss: 0.615915, acc.: 61.54%] [G loss: 1.654897] [Time: 0.246856]\n",
            "180-2 [D loss: 0.713187, acc.: 51.92%] [G loss: 1.312479] [Time: 0.248762]\n",
            "180-3 [D loss: 0.508547, acc.: 76.92%] [G loss: 1.688784] [Time: 0.249665]\n",
            "180-4 [D loss: 0.402072, acc.: 82.69%] [G loss: 1.883592] [Time: 0.246396]\n",
            "180-5 [D loss: 0.626172, acc.: 65.38%] [G loss: 1.350671] [Time: 0.250009]\n",
            "180-6 [D loss: 0.547768, acc.: 75.00%] [G loss: 1.802933] [Time: 0.244106]\n",
            "180-7 [D loss: 0.500100, acc.: 73.08%] [G loss: 1.583592] [Time: 0.246080]\n",
            "180-8 [D loss: 0.565574, acc.: 71.15%] [G loss: 1.794280] [Time: 0.251103]\n",
            "180 (test) [D loss: 1.224151, acc.: 50.00%] [G loss: 2.262160] [Time: 0.076926]\n",
            "181-0 [D loss: 0.455422, acc.: 80.77%] [G loss: 1.787667] [Time: 0.249853]\n",
            "181-1 [D loss: 0.671132, acc.: 69.23%] [G loss: 1.660959] [Time: 0.246152]\n",
            "181-2 [D loss: 0.590884, acc.: 71.15%] [G loss: 1.214948] [Time: 0.246351]\n",
            "181-3 [D loss: 0.487524, acc.: 75.00%] [G loss: 1.571749] [Time: 0.244799]\n",
            "181-4 [D loss: 0.359054, acc.: 86.54%] [G loss: 1.746350] [Time: 0.248107]\n",
            "181-5 [D loss: 0.515299, acc.: 75.00%] [G loss: 1.634593] [Time: 0.246948]\n",
            "181-6 [D loss: 0.545962, acc.: 71.15%] [G loss: 1.728399] [Time: 0.250087]\n",
            "181-7 [D loss: 0.575007, acc.: 65.38%] [G loss: 1.767368] [Time: 0.248161]\n",
            "181-8 [D loss: 0.441967, acc.: 76.92%] [G loss: 1.801567] [Time: 0.245472]\n",
            "181 (test) [D loss: 1.309947, acc.: 50.00%] [G loss: 2.454491] [Time: 0.076055]\n",
            "182-0 [D loss: 0.407422, acc.: 82.69%] [G loss: 1.979524] [Time: 0.245316]\n",
            "182-1 [D loss: 0.467325, acc.: 75.00%] [G loss: 1.343581] [Time: 0.243973]\n",
            "182-2 [D loss: 0.699898, acc.: 51.92%] [G loss: 1.252275] [Time: 0.252234]\n",
            "182-3 [D loss: 0.509942, acc.: 73.08%] [G loss: 1.880165] [Time: 0.245795]\n",
            "182-4 [D loss: 0.553732, acc.: 67.31%] [G loss: 2.085093] [Time: 0.248236]\n",
            "182-5 [D loss: 0.632012, acc.: 61.54%] [G loss: 1.418989] [Time: 0.249537]\n",
            "182-6 [D loss: 0.664840, acc.: 55.77%] [G loss: 1.595388] [Time: 0.252394]\n",
            "182-7 [D loss: 0.593179, acc.: 69.23%] [G loss: 1.894464] [Time: 0.244105]\n",
            "182-8 [D loss: 0.438903, acc.: 78.85%] [G loss: 1.865620] [Time: 0.247823]\n",
            "182 (test) [D loss: 1.302110, acc.: 50.00%] [G loss: 2.437744] [Time: 0.076770]\n",
            "183-0 [D loss: 0.515295, acc.: 80.77%] [G loss: 1.493407] [Time: 0.248178]\n",
            "183-1 [D loss: 0.488278, acc.: 78.85%] [G loss: 1.753004] [Time: 0.250779]\n",
            "183-2 [D loss: 0.688389, acc.: 61.54%] [G loss: 1.373253] [Time: 0.243513]\n",
            "183-3 [D loss: 0.575665, acc.: 71.15%] [G loss: 1.565818] [Time: 0.248919]\n",
            "183-4 [D loss: 0.403395, acc.: 82.69%] [G loss: 1.803576] [Time: 0.246375]\n",
            "183-5 [D loss: 0.488493, acc.: 76.92%] [G loss: 1.621262] [Time: 0.245881]\n",
            "183-6 [D loss: 0.548876, acc.: 67.31%] [G loss: 1.505973] [Time: 0.245256]\n",
            "183-7 [D loss: 0.516202, acc.: 76.92%] [G loss: 1.687152] [Time: 0.246182]\n",
            "183-8 [D loss: 0.568439, acc.: 80.77%] [G loss: 1.469494] [Time: 0.247179]\n",
            "183 (test) [D loss: 1.301891, acc.: 50.00%] [G loss: 2.444416] [Time: 0.076669]\n",
            "184-0 [D loss: 0.404971, acc.: 84.62%] [G loss: 1.658724] [Time: 0.247262]\n",
            "184-1 [D loss: 0.573819, acc.: 67.31%] [G loss: 1.749753] [Time: 0.249060]\n",
            "184-2 [D loss: 0.597266, acc.: 65.38%] [G loss: 1.760411] [Time: 0.249060]\n",
            "184-3 [D loss: 0.671201, acc.: 55.77%] [G loss: 1.650429] [Time: 0.246992]\n",
            "184-4 [D loss: 0.361719, acc.: 86.54%] [G loss: 1.998137] [Time: 0.244643]\n",
            "184-5 [D loss: 0.616897, acc.: 69.23%] [G loss: 1.402514] [Time: 0.246855]\n",
            "184-6 [D loss: 0.550207, acc.: 75.00%] [G loss: 1.649980] [Time: 0.249265]\n",
            "184-7 [D loss: 0.545878, acc.: 76.92%] [G loss: 1.555178] [Time: 0.244067]\n",
            "184-8 [D loss: 0.456326, acc.: 78.85%] [G loss: 1.814848] [Time: 0.243911]\n",
            "184 (test) [D loss: 1.319245, acc.: 50.00%] [G loss: 2.477540] [Time: 0.076330]\n",
            "185-0 [D loss: 0.491757, acc.: 76.92%] [G loss: 1.604984] [Time: 0.248211]\n",
            "185-1 [D loss: 0.586812, acc.: 63.46%] [G loss: 1.604152] [Time: 0.248018]\n",
            "185-2 [D loss: 0.603750, acc.: 55.77%] [G loss: 1.439874] [Time: 0.246801]\n",
            "185-3 [D loss: 0.556791, acc.: 65.38%] [G loss: 1.831023] [Time: 0.245565]\n",
            "185-4 [D loss: 0.436238, acc.: 82.69%] [G loss: 1.831524] [Time: 0.246130]\n",
            "185-5 [D loss: 0.500685, acc.: 76.92%] [G loss: 1.428692] [Time: 0.250222]\n",
            "185-6 [D loss: 0.644299, acc.: 57.69%] [G loss: 1.754833] [Time: 0.243670]\n",
            "185-7 [D loss: 0.555779, acc.: 65.38%] [G loss: 1.697016] [Time: 0.249073]\n",
            "185-8 [D loss: 0.424240, acc.: 86.54%] [G loss: 1.620483] [Time: 0.247001]\n",
            "185 (test) [D loss: 1.261957, acc.: 50.00%] [G loss: 2.347783] [Time: 0.076493]\n",
            "186-0 [D loss: 0.534060, acc.: 69.23%] [G loss: 1.772443] [Time: 0.248947]\n",
            "186-1 [D loss: 0.597959, acc.: 67.31%] [G loss: 1.298342] [Time: 0.248067]\n",
            "186-2 [D loss: 0.667157, acc.: 57.69%] [G loss: 1.583619] [Time: 0.250213]\n",
            "186-3 [D loss: 0.559887, acc.: 69.23%] [G loss: 1.799429] [Time: 0.246122]\n",
            "186-4 [D loss: 0.347591, acc.: 86.54%] [G loss: 1.759401] [Time: 0.246687]\n",
            "186-5 [D loss: 0.599080, acc.: 59.62%] [G loss: 1.430357] [Time: 0.246050]\n",
            "186-6 [D loss: 0.575653, acc.: 65.38%] [G loss: 1.462028] [Time: 0.249995]\n",
            "186-7 [D loss: 0.432528, acc.: 84.62%] [G loss: 1.830511] [Time: 0.248984]\n",
            "186-8 [D loss: 0.436776, acc.: 78.85%] [G loss: 1.947331] [Time: 0.245542]\n",
            "186 (test) [D loss: 1.341036, acc.: 50.00%] [G loss: 2.512571] [Time: 0.075884]\n",
            "187-0 [D loss: 0.531370, acc.: 76.92%] [G loss: 1.456553] [Time: 0.249938]\n",
            "187-1 [D loss: 0.702813, acc.: 59.62%] [G loss: 1.549378] [Time: 0.245811]\n",
            "187-2 [D loss: 0.621992, acc.: 59.62%] [G loss: 1.577291] [Time: 0.244305]\n",
            "187-3 [D loss: 0.556350, acc.: 73.08%] [G loss: 1.712579] [Time: 0.245148]\n",
            "187-4 [D loss: 0.471917, acc.: 78.85%] [G loss: 1.935757] [Time: 0.250125]\n",
            "187-5 [D loss: 0.637451, acc.: 67.31%] [G loss: 1.806824] [Time: 0.246455]\n",
            "187-6 [D loss: 0.501514, acc.: 78.85%] [G loss: 1.741739] [Time: 0.247430]\n",
            "187-7 [D loss: 0.498965, acc.: 76.92%] [G loss: 1.520556] [Time: 0.244730]\n",
            "187-8 [D loss: 0.465700, acc.: 76.92%] [G loss: 1.880976] [Time: 0.248253]\n",
            "187 (test) [D loss: 1.325347, acc.: 50.00%] [G loss: 2.483697] [Time: 0.075185]\n",
            "188-0 [D loss: 0.351372, acc.: 92.31%] [G loss: 1.747326] [Time: 0.248685]\n",
            "188-1 [D loss: 0.634719, acc.: 59.62%] [G loss: 1.395980] [Time: 0.243122]\n",
            "188-2 [D loss: 0.573443, acc.: 67.31%] [G loss: 1.642824] [Time: 0.247485]\n",
            "188-3 [D loss: 0.466486, acc.: 86.54%] [G loss: 1.689963] [Time: 0.242544]\n",
            "188-4 [D loss: 0.333311, acc.: 94.23%] [G loss: 1.689470] [Time: 0.244986]\n",
            "188-5 [D loss: 0.605945, acc.: 65.38%] [G loss: 1.729318] [Time: 0.246644]\n",
            "188-6 [D loss: 0.639821, acc.: 61.54%] [G loss: 1.551889] [Time: 0.244777]\n",
            "188-7 [D loss: 0.602519, acc.: 61.54%] [G loss: 1.581501] [Time: 0.246385]\n",
            "188-8 [D loss: 0.469768, acc.: 78.85%] [G loss: 1.673091] [Time: 0.247114]\n",
            "188 (test) [D loss: 1.321284, acc.: 50.00%] [G loss: 2.488135] [Time: 0.076855]\n",
            "189-0 [D loss: 0.423631, acc.: 82.69%] [G loss: 1.541512] [Time: 0.248961]\n",
            "189-1 [D loss: 0.555929, acc.: 76.92%] [G loss: 1.505946] [Time: 0.245772]\n",
            "189-2 [D loss: 0.632224, acc.: 63.46%] [G loss: 1.439143] [Time: 0.244738]\n",
            "189-3 [D loss: 0.470237, acc.: 71.15%] [G loss: 1.619676] [Time: 0.246642]\n",
            "189-4 [D loss: 0.423555, acc.: 82.69%] [G loss: 1.779711] [Time: 0.244889]\n",
            "189-5 [D loss: 0.522525, acc.: 69.23%] [G loss: 1.596605] [Time: 0.247354]\n",
            "189-6 [D loss: 0.568355, acc.: 69.23%] [G loss: 1.397393] [Time: 0.246197]\n",
            "189-7 [D loss: 0.504903, acc.: 76.92%] [G loss: 1.778772] [Time: 0.245332]\n",
            "189-8 [D loss: 0.427947, acc.: 88.46%] [G loss: 1.768490] [Time: 0.245786]\n",
            "189 (test) [D loss: 1.304865, acc.: 50.00%] [G loss: 2.438792] [Time: 0.076640]\n",
            "190-0 [D loss: 0.467080, acc.: 75.00%] [G loss: 1.761466] [Time: 0.247338]\n",
            "190-1 [D loss: 0.501647, acc.: 80.77%] [G loss: 1.451755] [Time: 0.242655]\n",
            "190-2 [D loss: 0.593600, acc.: 73.08%] [G loss: 1.483386] [Time: 0.245941]\n",
            "190-3 [D loss: 0.485040, acc.: 76.92%] [G loss: 1.821889] [Time: 0.250394]\n",
            "190-4 [D loss: 0.427655, acc.: 84.62%] [G loss: 1.860772] [Time: 0.244005]\n",
            "190-5 [D loss: 0.573475, acc.: 71.15%] [G loss: 1.525645] [Time: 0.246896]\n",
            "190-6 [D loss: 0.642591, acc.: 57.69%] [G loss: 1.339231] [Time: 0.244272]\n",
            "190-7 [D loss: 0.515484, acc.: 73.08%] [G loss: 1.615983] [Time: 0.242058]\n",
            "190-8 [D loss: 0.359873, acc.: 92.31%] [G loss: 1.719829] [Time: 0.245087]\n",
            "190 (test) [D loss: 1.363055, acc.: 50.00%] [G loss: 2.578122] [Time: 0.077494]\n",
            "191-0 [D loss: 0.437699, acc.: 82.69%] [G loss: 1.825145] [Time: 0.243443]\n",
            "191-1 [D loss: 0.646075, acc.: 63.46%] [G loss: 1.504581] [Time: 0.249327]\n",
            "191-2 [D loss: 0.652922, acc.: 65.38%] [G loss: 1.499220] [Time: 0.244983]\n",
            "191-3 [D loss: 0.521292, acc.: 76.92%] [G loss: 1.505733] [Time: 0.248409]\n",
            "191-4 [D loss: 0.368102, acc.: 90.38%] [G loss: 1.666595] [Time: 0.243985]\n",
            "191-5 [D loss: 0.607254, acc.: 69.23%] [G loss: 1.639302] [Time: 0.246262]\n",
            "191-6 [D loss: 0.627169, acc.: 65.38%] [G loss: 1.606995] [Time: 0.246117]\n",
            "191-7 [D loss: 0.489305, acc.: 76.92%] [G loss: 1.501115] [Time: 0.246414]\n",
            "191-8 [D loss: 0.410239, acc.: 88.46%] [G loss: 1.884068] [Time: 0.244093]\n",
            "191 (test) [D loss: 1.287741, acc.: 50.00%] [G loss: 2.401663] [Time: 0.076494]\n",
            "192-0 [D loss: 0.395457, acc.: 86.54%] [G loss: 1.713992] [Time: 0.246846]\n",
            "192-1 [D loss: 0.514558, acc.: 76.92%] [G loss: 1.448098] [Time: 0.242991]\n",
            "192-2 [D loss: 0.552513, acc.: 71.15%] [G loss: 1.690192] [Time: 0.244478]\n",
            "192-3 [D loss: 0.483642, acc.: 76.92%] [G loss: 1.769409] [Time: 0.244621]\n",
            "192-4 [D loss: 0.472627, acc.: 76.92%] [G loss: 1.586873] [Time: 0.244939]\n",
            "192-5 [D loss: 0.573607, acc.: 71.15%] [G loss: 1.650467] [Time: 0.245579]\n",
            "192-6 [D loss: 0.533450, acc.: 73.08%] [G loss: 1.612745] [Time: 0.246106]\n",
            "192-7 [D loss: 0.612199, acc.: 65.38%] [G loss: 1.444234] [Time: 0.250473]\n",
            "192-8 [D loss: 0.455299, acc.: 75.00%] [G loss: 1.704194] [Time: 0.245115]\n",
            "192 (test) [D loss: 1.305009, acc.: 50.00%] [G loss: 2.433498] [Time: 0.075952]\n",
            "193-0 [D loss: 0.449427, acc.: 80.77%] [G loss: 2.096750] [Time: 0.247472]\n",
            "193-1 [D loss: 0.510944, acc.: 80.77%] [G loss: 1.615578] [Time: 0.247231]\n",
            "193-2 [D loss: 0.505950, acc.: 75.00%] [G loss: 1.400026] [Time: 0.247094]\n",
            "193-3 [D loss: 0.593906, acc.: 71.15%] [G loss: 1.696810] [Time: 0.244274]\n",
            "193-4 [D loss: 0.384596, acc.: 86.54%] [G loss: 1.581367] [Time: 0.246924]\n",
            "193-5 [D loss: 0.765237, acc.: 50.00%] [G loss: 1.220488] [Time: 0.246470]\n",
            "193-6 [D loss: 0.613039, acc.: 63.46%] [G loss: 1.531000] [Time: 0.243738]\n",
            "193-7 [D loss: 0.490472, acc.: 73.08%] [G loss: 1.781676] [Time: 0.245140]\n",
            "193-8 [D loss: 0.426164, acc.: 78.85%] [G loss: 1.332761] [Time: 0.245882]\n",
            "193 (test) [D loss: 1.324436, acc.: 50.00%] [G loss: 2.466394] [Time: 0.077763]\n",
            "194-0 [D loss: 0.467884, acc.: 80.77%] [G loss: 1.585627] [Time: 0.248946]\n",
            "194-1 [D loss: 0.580267, acc.: 73.08%] [G loss: 1.559633] [Time: 0.244143]\n",
            "194-2 [D loss: 0.503273, acc.: 80.77%] [G loss: 1.808710] [Time: 0.244177]\n",
            "194-3 [D loss: 0.576877, acc.: 67.31%] [G loss: 1.792846] [Time: 0.245278]\n",
            "194-4 [D loss: 0.490202, acc.: 78.85%] [G loss: 1.892480] [Time: 0.245579]\n",
            "194-5 [D loss: 0.495704, acc.: 69.23%] [G loss: 1.535207] [Time: 0.246562]\n",
            "194-6 [D loss: 0.637221, acc.: 69.23%] [G loss: 1.408481] [Time: 0.244828]\n",
            "194-7 [D loss: 0.453977, acc.: 82.69%] [G loss: 1.847356] [Time: 0.247346]\n",
            "194-8 [D loss: 0.460110, acc.: 84.62%] [G loss: 1.752695] [Time: 0.243549]\n",
            "194 (test) [D loss: 1.363746, acc.: 50.00%] [G loss: 2.561208] [Time: 0.079575]\n",
            "195-0 [D loss: 0.521250, acc.: 71.15%] [G loss: 1.515692] [Time: 0.245926]\n",
            "195-1 [D loss: 0.563058, acc.: 75.00%] [G loss: 1.453898] [Time: 0.251513]\n",
            "195-2 [D loss: 0.482221, acc.: 76.92%] [G loss: 1.536533] [Time: 0.244977]\n",
            "195-3 [D loss: 0.598210, acc.: 67.31%] [G loss: 1.510149] [Time: 0.244962]\n",
            "195-4 [D loss: 0.372973, acc.: 86.54%] [G loss: 1.900344] [Time: 0.247204]\n",
            "195-5 [D loss: 0.650785, acc.: 57.69%] [G loss: 1.729679] [Time: 0.247098]\n",
            "195-6 [D loss: 0.575400, acc.: 69.23%] [G loss: 1.723545] [Time: 0.243336]\n",
            "195-7 [D loss: 0.515945, acc.: 75.00%] [G loss: 1.882453] [Time: 0.244857]\n",
            "195-8 [D loss: 0.456654, acc.: 80.77%] [G loss: 1.544078] [Time: 0.247126]\n",
            "195 (test) [D loss: 1.292878, acc.: 50.00%] [G loss: 2.415924] [Time: 0.077875]\n",
            "196-0 [D loss: 0.404762, acc.: 86.54%] [G loss: 2.094941] [Time: 0.249157]\n",
            "196-1 [D loss: 0.617383, acc.: 63.46%] [G loss: 1.255977] [Time: 0.245669]\n",
            "196-2 [D loss: 0.528048, acc.: 73.08%] [G loss: 1.465652] [Time: 0.245883]\n",
            "196-3 [D loss: 0.513859, acc.: 75.00%] [G loss: 1.821789] [Time: 0.249098]\n",
            "196-4 [D loss: 0.476110, acc.: 78.85%] [G loss: 1.677281] [Time: 0.242858]\n",
            "196-5 [D loss: 0.608359, acc.: 69.23%] [G loss: 1.679651] [Time: 0.246108]\n",
            "196-6 [D loss: 0.603816, acc.: 59.62%] [G loss: 1.672623] [Time: 0.246283]\n",
            "196-7 [D loss: 0.497494, acc.: 71.15%] [G loss: 1.838576] [Time: 0.249514]\n",
            "196-8 [D loss: 0.533848, acc.: 71.15%] [G loss: 1.809183] [Time: 0.245064]\n",
            "196 (test) [D loss: 1.383214, acc.: 50.00%] [G loss: 2.617943] [Time: 0.075947]\n",
            "197-0 [D loss: 0.283092, acc.: 94.23%] [G loss: 2.083545] [Time: 0.246967]\n",
            "197-1 [D loss: 0.782616, acc.: 59.62%] [G loss: 1.361701] [Time: 0.246743]\n",
            "197-2 [D loss: 0.513374, acc.: 71.15%] [G loss: 1.503776] [Time: 0.247592]\n",
            "197-3 [D loss: 0.504660, acc.: 73.08%] [G loss: 1.787018] [Time: 0.246118]\n",
            "197-4 [D loss: 0.468141, acc.: 80.77%] [G loss: 2.051780] [Time: 0.243556]\n",
            "197-5 [D loss: 0.601238, acc.: 57.69%] [G loss: 1.771356] [Time: 0.245368]\n",
            "197-6 [D loss: 0.550111, acc.: 71.15%] [G loss: 1.667585] [Time: 0.246728]\n",
            "197-7 [D loss: 0.431495, acc.: 76.92%] [G loss: 1.714550] [Time: 0.245566]\n",
            "197-8 [D loss: 0.431149, acc.: 82.69%] [G loss: 1.804196] [Time: 0.247772]\n",
            "197 (test) [D loss: 1.352372, acc.: 50.00%] [G loss: 2.544696] [Time: 0.081265]\n",
            "198-0 [D loss: 0.451454, acc.: 78.85%] [G loss: 1.825382] [Time: 0.245412]\n",
            "198-1 [D loss: 0.566565, acc.: 71.15%] [G loss: 1.571944] [Time: 0.247738]\n",
            "198-2 [D loss: 0.574746, acc.: 69.23%] [G loss: 1.770427] [Time: 0.242441]\n",
            "198-3 [D loss: 0.561200, acc.: 69.23%] [G loss: 1.835497] [Time: 0.247804]\n",
            "198-4 [D loss: 0.446139, acc.: 84.62%] [G loss: 1.684851] [Time: 0.242597]\n",
            "198-5 [D loss: 0.462124, acc.: 82.69%] [G loss: 1.533451] [Time: 0.246925]\n",
            "198-6 [D loss: 0.552191, acc.: 69.23%] [G loss: 1.556403] [Time: 0.244173]\n",
            "198-7 [D loss: 0.429255, acc.: 82.69%] [G loss: 1.682947] [Time: 0.244054]\n",
            "198-8 [D loss: 0.462660, acc.: 78.85%] [G loss: 1.641382] [Time: 0.245157]\n",
            "198 (test) [D loss: 1.321448, acc.: 50.00%] [G loss: 2.465622] [Time: 0.077483]\n",
            "199-0 [D loss: 0.414418, acc.: 80.77%] [G loss: 1.819400] [Time: 0.245579]\n",
            "199-1 [D loss: 0.501557, acc.: 75.00%] [G loss: 1.417128] [Time: 0.244854]\n",
            "199-2 [D loss: 0.629376, acc.: 67.31%] [G loss: 1.651858] [Time: 0.245106]\n",
            "199-3 [D loss: 0.538704, acc.: 73.08%] [G loss: 1.956197] [Time: 0.243386]\n",
            "199-4 [D loss: 0.452059, acc.: 78.85%] [G loss: 1.709064] [Time: 0.246140]\n",
            "199-5 [D loss: 0.554330, acc.: 76.92%] [G loss: 1.764160] [Time: 0.245355]\n",
            "199-6 [D loss: 0.655324, acc.: 53.85%] [G loss: 1.784990] [Time: 0.246762]\n",
            "199-7 [D loss: 0.427513, acc.: 80.77%] [G loss: 1.896011] [Time: 0.248184]\n",
            "199-8 [D loss: 0.434975, acc.: 80.77%] [G loss: 1.590351] [Time: 0.245647]\n",
            "199 (test) [D loss: 1.339288, acc.: 50.00%] [G loss: 2.504829] [Time: 0.075668]\n",
            "200-0 [D loss: 0.325590, acc.: 92.31%] [G loss: 2.044170] [Time: 0.246300]\n",
            "200-1 [D loss: 0.639520, acc.: 59.62%] [G loss: 1.547414] [Time: 0.244325]\n",
            "200-2 [D loss: 0.474262, acc.: 80.77%] [G loss: 1.595998] [Time: 0.245535]\n",
            "200-3 [D loss: 0.479213, acc.: 73.08%] [G loss: 1.895784] [Time: 0.244220]\n",
            "200-4 [D loss: 0.431595, acc.: 78.85%] [G loss: 1.798987] [Time: 0.243100]\n",
            "200-5 [D loss: 0.570232, acc.: 75.00%] [G loss: 1.553819] [Time: 0.245344]\n",
            "200-6 [D loss: 0.600173, acc.: 75.00%] [G loss: 1.486729] [Time: 0.244764]\n",
            "200-7 [D loss: 0.667011, acc.: 67.31%] [G loss: 1.692121] [Time: 0.251943]\n",
            "200-8 [D loss: 0.454160, acc.: 78.85%] [G loss: 1.997794] [Time: 0.244034]\n",
            "200 (test) [D loss: 1.333840, acc.: 50.00%] [G loss: 2.483455] [Time: 0.076268]\n",
            "201-0 [D loss: 0.428428, acc.: 86.54%] [G loss: 1.612176] [Time: 0.246231]\n",
            "201-1 [D loss: 0.596866, acc.: 73.08%] [G loss: 1.426304] [Time: 0.243775]\n",
            "201-2 [D loss: 0.656025, acc.: 61.54%] [G loss: 1.499920] [Time: 0.244731]\n",
            "201-3 [D loss: 0.562974, acc.: 67.31%] [G loss: 1.516899] [Time: 0.250044]\n",
            "201-4 [D loss: 0.424508, acc.: 80.77%] [G loss: 1.772461] [Time: 0.246627]\n",
            "201-5 [D loss: 0.514726, acc.: 71.15%] [G loss: 1.694521] [Time: 0.248646]\n",
            "201-6 [D loss: 0.610935, acc.: 73.08%] [G loss: 1.666000] [Time: 0.244635]\n",
            "201-7 [D loss: 0.586818, acc.: 69.23%] [G loss: 1.794542] [Time: 0.251273]\n",
            "201-8 [D loss: 0.589383, acc.: 69.23%] [G loss: 1.899469] [Time: 0.245457]\n",
            "201 (test) [D loss: 1.322210, acc.: 50.00%] [G loss: 2.459819] [Time: 0.076995]\n",
            "202-0 [D loss: 0.370751, acc.: 88.46%] [G loss: 2.072702] [Time: 0.248172]\n",
            "202-1 [D loss: 0.613684, acc.: 63.46%] [G loss: 1.359149] [Time: 0.250780]\n",
            "202-2 [D loss: 0.519537, acc.: 76.92%] [G loss: 1.738129] [Time: 0.249656]\n",
            "202-3 [D loss: 0.513884, acc.: 76.92%] [G loss: 1.951478] [Time: 0.245507]\n",
            "202-4 [D loss: 0.371376, acc.: 92.31%] [G loss: 1.664433] [Time: 0.247223]\n",
            "202-5 [D loss: 0.494197, acc.: 78.85%] [G loss: 1.668839] [Time: 0.243528]\n",
            "202-6 [D loss: 0.792701, acc.: 55.77%] [G loss: 1.654245] [Time: 0.255682]\n",
            "202-7 [D loss: 0.594830, acc.: 71.15%] [G loss: 1.754419] [Time: 0.246452]\n",
            "202-8 [D loss: 0.502155, acc.: 76.92%] [G loss: 1.885865] [Time: 0.247243]\n",
            "202 (test) [D loss: 1.391387, acc.: 50.00%] [G loss: 2.606553] [Time: 0.076625]\n",
            "203-0 [D loss: 0.424375, acc.: 88.46%] [G loss: 1.958809] [Time: 0.246432]\n",
            "203-1 [D loss: 0.551483, acc.: 69.23%] [G loss: 1.489240] [Time: 0.244592]\n",
            "203-2 [D loss: 0.569440, acc.: 63.46%] [G loss: 1.558424] [Time: 0.243948]\n",
            "203-3 [D loss: 0.397409, acc.: 84.62%] [G loss: 1.762543] [Time: 0.245370]\n",
            "203-4 [D loss: 0.410882, acc.: 80.77%] [G loss: 1.928473] [Time: 0.251928]\n",
            "203-5 [D loss: 0.519298, acc.: 69.23%] [G loss: 1.561798] [Time: 0.244920]\n",
            "203-6 [D loss: 0.676635, acc.: 59.62%] [G loss: 1.506399] [Time: 0.243201]\n",
            "203-7 [D loss: 0.465888, acc.: 82.69%] [G loss: 1.999532] [Time: 0.245492]\n",
            "203-8 [D loss: 0.529625, acc.: 76.92%] [G loss: 1.584775] [Time: 0.248094]\n",
            "203 (test) [D loss: 1.390368, acc.: 50.00%] [G loss: 2.599282] [Time: 0.075072]\n",
            "204-0 [D loss: 0.435013, acc.: 88.46%] [G loss: 1.813922] [Time: 0.249087]\n",
            "204-1 [D loss: 0.584837, acc.: 61.54%] [G loss: 1.392256] [Time: 0.244193]\n",
            "204-2 [D loss: 0.589575, acc.: 63.46%] [G loss: 1.774768] [Time: 0.246675]\n",
            "204-3 [D loss: 0.438824, acc.: 82.69%] [G loss: 2.007524] [Time: 0.245537]\n",
            "204-4 [D loss: 0.396168, acc.: 80.77%] [G loss: 1.847022] [Time: 0.244541]\n",
            "204-5 [D loss: 0.487478, acc.: 78.85%] [G loss: 1.678683] [Time: 0.248285]\n",
            "204-6 [D loss: 0.653429, acc.: 55.77%] [G loss: 1.520928] [Time: 0.244964]\n",
            "204-7 [D loss: 0.524042, acc.: 69.23%] [G loss: 1.686654] [Time: 0.242989]\n",
            "204-8 [D loss: 0.500376, acc.: 76.92%] [G loss: 1.923866] [Time: 0.247691]\n",
            "204 (test) [D loss: 1.398832, acc.: 50.00%] [G loss: 2.632359] [Time: 0.078460]\n",
            "205-0 [D loss: 0.436237, acc.: 82.69%] [G loss: 1.899165] [Time: 0.246689]\n",
            "205-1 [D loss: 0.622127, acc.: 65.38%] [G loss: 1.229943] [Time: 0.244135]\n",
            "205-2 [D loss: 0.556378, acc.: 67.31%] [G loss: 1.730956] [Time: 0.243174]\n",
            "205-3 [D loss: 0.504688, acc.: 73.08%] [G loss: 1.786211] [Time: 0.249714]\n",
            "205-4 [D loss: 0.406268, acc.: 84.62%] [G loss: 1.569399] [Time: 0.246562]\n",
            "205-5 [D loss: 0.570585, acc.: 65.38%] [G loss: 1.426851] [Time: 0.242479]\n",
            "205-6 [D loss: 0.533826, acc.: 65.38%] [G loss: 1.428629] [Time: 0.245471]\n",
            "205-7 [D loss: 0.518088, acc.: 80.77%] [G loss: 1.864153] [Time: 0.247230]\n",
            "205-8 [D loss: 0.498793, acc.: 73.08%] [G loss: 1.664282] [Time: 0.241483]\n",
            "205 (test) [D loss: 1.329782, acc.: 50.00%] [G loss: 2.484514] [Time: 0.075545]\n",
            "206-0 [D loss: 0.452507, acc.: 75.00%] [G loss: 1.954272] [Time: 0.244498]\n",
            "206-1 [D loss: 0.657662, acc.: 65.38%] [G loss: 1.489399] [Time: 0.247938]\n",
            "206-2 [D loss: 0.627102, acc.: 65.38%] [G loss: 1.520632] [Time: 0.245295]\n",
            "206-3 [D loss: 0.479941, acc.: 78.85%] [G loss: 1.866292] [Time: 0.247192]\n",
            "206-4 [D loss: 0.429113, acc.: 82.69%] [G loss: 1.908633] [Time: 0.242331]\n",
            "206-5 [D loss: 0.697217, acc.: 59.62%] [G loss: 1.391046] [Time: 0.247082]\n",
            "206-6 [D loss: 0.543649, acc.: 71.15%] [G loss: 1.451136] [Time: 0.244354]\n",
            "206-7 [D loss: 0.542941, acc.: 71.15%] [G loss: 1.477814] [Time: 0.248060]\n",
            "206-8 [D loss: 0.392051, acc.: 84.62%] [G loss: 2.017770] [Time: 0.246650]\n",
            "206 (test) [D loss: 1.460470, acc.: 50.00%] [G loss: 2.771834] [Time: 0.076305]\n",
            "207-0 [D loss: 0.421686, acc.: 80.77%] [G loss: 1.968233] [Time: 0.246717]\n",
            "207-1 [D loss: 0.636743, acc.: 55.77%] [G loss: 1.490657] [Time: 0.244829]\n",
            "207-2 [D loss: 0.491343, acc.: 80.77%] [G loss: 1.515975] [Time: 0.243996]\n",
            "207-3 [D loss: 0.517252, acc.: 69.23%] [G loss: 1.592880] [Time: 0.243075]\n",
            "207-4 [D loss: 0.449611, acc.: 80.77%] [G loss: 2.248515] [Time: 0.248127]\n",
            "207-5 [D loss: 0.550370, acc.: 59.62%] [G loss: 1.772905] [Time: 0.246197]\n",
            "207-6 [D loss: 0.629336, acc.: 63.46%] [G loss: 1.646052] [Time: 0.249536]\n",
            "207-7 [D loss: 0.628633, acc.: 65.38%] [G loss: 1.773033] [Time: 0.246498]\n",
            "207-8 [D loss: 0.505526, acc.: 78.85%] [G loss: 1.977674] [Time: 0.244770]\n",
            "207 (test) [D loss: 1.319896, acc.: 50.00%] [G loss: 2.461434] [Time: 0.078652]\n",
            "208-0 [D loss: 0.381094, acc.: 90.38%] [G loss: 2.060953] [Time: 0.246528]\n",
            "208-1 [D loss: 0.683753, acc.: 61.54%] [G loss: 1.530038] [Time: 0.247210]\n",
            "208-2 [D loss: 0.579019, acc.: 75.00%] [G loss: 1.497787] [Time: 0.244523]\n",
            "208-3 [D loss: 0.505428, acc.: 76.92%] [G loss: 1.638344] [Time: 0.244700]\n",
            "208-4 [D loss: 0.384013, acc.: 88.46%] [G loss: 1.727080] [Time: 0.244904]\n",
            "208-5 [D loss: 0.550589, acc.: 76.92%] [G loss: 1.592461] [Time: 0.244630]\n",
            "208-6 [D loss: 0.526261, acc.: 73.08%] [G loss: 1.865332] [Time: 0.246271]\n",
            "208-7 [D loss: 0.539497, acc.: 67.31%] [G loss: 1.511766] [Time: 0.245601]\n",
            "208-8 [D loss: 0.529452, acc.: 73.08%] [G loss: 1.381809] [Time: 0.243064]\n",
            "208 (test) [D loss: 1.317344, acc.: 50.00%] [G loss: 2.445108] [Time: 0.074884]\n",
            "209-0 [D loss: 0.413705, acc.: 90.38%] [G loss: 1.991132] [Time: 0.243416]\n",
            "209-1 [D loss: 0.687851, acc.: 55.77%] [G loss: 1.417233] [Time: 0.248846]\n",
            "209-2 [D loss: 0.546681, acc.: 76.92%] [G loss: 1.439912] [Time: 0.242997]\n",
            "209-3 [D loss: 0.511874, acc.: 69.23%] [G loss: 1.797154] [Time: 0.247395]\n",
            "209-4 [D loss: 0.416435, acc.: 75.00%] [G loss: 2.024693] [Time: 0.246454]\n",
            "209-5 [D loss: 0.571154, acc.: 69.23%] [G loss: 2.002108] [Time: 0.247938]\n",
            "209-6 [D loss: 0.646753, acc.: 59.62%] [G loss: 1.558562] [Time: 0.243636]\n",
            "209-7 [D loss: 0.638106, acc.: 69.23%] [G loss: 1.865577] [Time: 0.244158]\n",
            "209-8 [D loss: 0.433497, acc.: 82.69%] [G loss: 1.821068] [Time: 0.247759]\n",
            "209 (test) [D loss: 1.345806, acc.: 50.00%] [G loss: 2.517775] [Time: 0.077195]\n",
            "210-0 [D loss: 0.374701, acc.: 86.54%] [G loss: 1.900548] [Time: 0.244868]\n",
            "210-1 [D loss: 0.638952, acc.: 65.38%] [G loss: 1.610843] [Time: 0.246667]\n",
            "210-2 [D loss: 0.570584, acc.: 69.23%] [G loss: 1.679581] [Time: 0.247401]\n",
            "210-3 [D loss: 0.477146, acc.: 76.92%] [G loss: 1.858875] [Time: 0.246123]\n",
            "210-4 [D loss: 0.473316, acc.: 75.00%] [G loss: 1.928252] [Time: 0.243962]\n",
            "210-5 [D loss: 0.584754, acc.: 76.92%] [G loss: 1.778626] [Time: 0.245384]\n",
            "210-6 [D loss: 0.618025, acc.: 63.46%] [G loss: 1.638612] [Time: 0.250212]\n",
            "210-7 [D loss: 0.566912, acc.: 71.15%] [G loss: 1.582552] [Time: 0.243884]\n",
            "210-8 [D loss: 0.419570, acc.: 80.77%] [G loss: 1.670953] [Time: 0.245489]\n",
            "210 (test) [D loss: 1.340254, acc.: 50.00%] [G loss: 2.506902] [Time: 0.076327]\n",
            "211-0 [D loss: 0.330062, acc.: 88.46%] [G loss: 2.039976] [Time: 0.248090]\n",
            "211-1 [D loss: 0.546118, acc.: 75.00%] [G loss: 1.443894] [Time: 0.248673]\n",
            "211-2 [D loss: 0.622495, acc.: 63.46%] [G loss: 1.206439] [Time: 0.243258]\n",
            "211-3 [D loss: 0.412329, acc.: 84.62%] [G loss: 1.798163] [Time: 0.245773]\n",
            "211-4 [D loss: 0.360759, acc.: 90.38%] [G loss: 1.857026] [Time: 0.246214]\n",
            "211-5 [D loss: 0.508878, acc.: 80.77%] [G loss: 1.410285] [Time: 0.244125]\n",
            "211-6 [D loss: 0.556442, acc.: 71.15%] [G loss: 1.733091] [Time: 0.245574]\n",
            "211-7 [D loss: 0.581029, acc.: 67.31%] [G loss: 1.593727] [Time: 0.248218]\n",
            "211-8 [D loss: 0.491612, acc.: 73.08%] [G loss: 1.730014] [Time: 0.245727]\n",
            "211 (test) [D loss: 1.300954, acc.: 50.00%] [G loss: 2.423738] [Time: 0.074404]\n",
            "212-0 [D loss: 0.366895, acc.: 92.31%] [G loss: 2.055976] [Time: 0.245382]\n",
            "212-1 [D loss: 0.585537, acc.: 73.08%] [G loss: 1.710585] [Time: 0.248614]\n",
            "212-2 [D loss: 0.579238, acc.: 65.38%] [G loss: 1.406823] [Time: 0.246611]\n",
            "212-3 [D loss: 0.502781, acc.: 78.85%] [G loss: 2.027537] [Time: 0.243259]\n",
            "212-4 [D loss: 0.501144, acc.: 73.08%] [G loss: 1.986079] [Time: 0.244502]\n",
            "212-5 [D loss: 0.546430, acc.: 69.23%] [G loss: 1.734271] [Time: 0.248516]\n",
            "212-6 [D loss: 0.558591, acc.: 69.23%] [G loss: 1.625298] [Time: 0.244756]\n",
            "212-7 [D loss: 0.446249, acc.: 84.62%] [G loss: 1.706504] [Time: 0.243965]\n",
            "212-8 [D loss: 0.471923, acc.: 84.62%] [G loss: 1.884097] [Time: 0.245778]\n",
            "212 (test) [D loss: 1.293049, acc.: 50.00%] [G loss: 2.385365] [Time: 0.077421]\n",
            "213-0 [D loss: 0.490393, acc.: 76.92%] [G loss: 1.615429] [Time: 0.246572]\n",
            "213-1 [D loss: 0.540142, acc.: 67.31%] [G loss: 1.525475] [Time: 0.248886]\n",
            "213-2 [D loss: 0.543922, acc.: 71.15%] [G loss: 1.653060] [Time: 0.242161]\n",
            "213-3 [D loss: 0.509142, acc.: 71.15%] [G loss: 1.911968] [Time: 0.250709]\n",
            "213-4 [D loss: 0.513526, acc.: 73.08%] [G loss: 1.649373] [Time: 0.246368]\n",
            "213-5 [D loss: 0.494363, acc.: 73.08%] [G loss: 1.595025] [Time: 0.243685]\n",
            "213-6 [D loss: 0.589141, acc.: 67.31%] [G loss: 1.635006] [Time: 0.245725]\n",
            "213-7 [D loss: 0.429055, acc.: 78.85%] [G loss: 1.753518] [Time: 0.248888]\n",
            "213-8 [D loss: 0.487568, acc.: 80.77%] [G loss: 1.599432] [Time: 0.251191]\n",
            "213 (test) [D loss: 1.400757, acc.: 50.00%] [G loss: 2.633783] [Time: 0.076203]\n",
            "214-0 [D loss: 0.407860, acc.: 84.62%] [G loss: 1.959406] [Time: 0.246919]\n",
            "214-1 [D loss: 0.560243, acc.: 69.23%] [G loss: 1.614695] [Time: 0.249739]\n",
            "214-2 [D loss: 0.605411, acc.: 63.46%] [G loss: 1.603531] [Time: 0.248318]\n",
            "214-3 [D loss: 0.417900, acc.: 82.69%] [G loss: 1.838401] [Time: 0.245163]\n",
            "214-4 [D loss: 0.421920, acc.: 82.69%] [G loss: 1.729492] [Time: 0.246184]\n",
            "214-5 [D loss: 0.643605, acc.: 61.54%] [G loss: 1.338509] [Time: 0.249233]\n",
            "214-6 [D loss: 0.437279, acc.: 78.85%] [G loss: 1.848047] [Time: 0.248145]\n",
            "214-7 [D loss: 0.496091, acc.: 75.00%] [G loss: 1.685594] [Time: 0.245165]\n",
            "214-8 [D loss: 0.463912, acc.: 75.00%] [G loss: 1.486080] [Time: 0.246475]\n",
            "214 (test) [D loss: 1.263537, acc.: 50.00%] [G loss: 2.346175] [Time: 0.077140]\n",
            "215-0 [D loss: 0.352780, acc.: 86.54%] [G loss: 1.782353] [Time: 0.250083]\n",
            "215-1 [D loss: 0.609415, acc.: 69.23%] [G loss: 1.498552] [Time: 0.248962]\n",
            "215-2 [D loss: 0.791268, acc.: 55.77%] [G loss: 1.718812] [Time: 0.244715]\n",
            "215-3 [D loss: 0.604274, acc.: 61.54%] [G loss: 1.891250] [Time: 0.248685]\n",
            "215-4 [D loss: 0.397657, acc.: 84.62%] [G loss: 1.805436] [Time: 0.246134]\n",
            "215-5 [D loss: 0.524173, acc.: 82.69%] [G loss: 1.716493] [Time: 0.243907]\n",
            "215-6 [D loss: 0.667965, acc.: 61.54%] [G loss: 1.580501] [Time: 0.248646]\n",
            "215-7 [D loss: 0.450674, acc.: 84.62%] [G loss: 1.813981] [Time: 0.246553]\n",
            "215-8 [D loss: 0.538758, acc.: 73.08%] [G loss: 1.596982] [Time: 0.246559]\n",
            "215 (test) [D loss: 1.379369, acc.: 50.00%] [G loss: 2.589535] [Time: 0.075524]\n",
            "216-0 [D loss: 0.373653, acc.: 80.77%] [G loss: 2.058286] [Time: 0.246548]\n",
            "216-1 [D loss: 0.550165, acc.: 67.31%] [G loss: 1.488740] [Time: 0.246520]\n",
            "216-2 [D loss: 0.588792, acc.: 63.46%] [G loss: 1.626817] [Time: 0.244572]\n",
            "216-3 [D loss: 0.500217, acc.: 73.08%] [G loss: 2.160758] [Time: 0.244868]\n",
            "216-4 [D loss: 0.366595, acc.: 86.54%] [G loss: 1.917721] [Time: 0.246151]\n",
            "216-5 [D loss: 0.544000, acc.: 75.00%] [G loss: 1.461612] [Time: 0.250510]\n",
            "216-6 [D loss: 0.666619, acc.: 55.77%] [G loss: 1.737870] [Time: 0.245367]\n",
            "216-7 [D loss: 0.402879, acc.: 84.62%] [G loss: 1.838254] [Time: 0.245869]\n",
            "216-8 [D loss: 0.531516, acc.: 71.15%] [G loss: 1.766538] [Time: 0.248235]\n",
            "216 (test) [D loss: 1.327563, acc.: 50.00%] [G loss: 2.491007] [Time: 0.077173]\n",
            "217-0 [D loss: 0.399012, acc.: 82.69%] [G loss: 1.838915] [Time: 0.247942]\n",
            "217-1 [D loss: 0.584858, acc.: 73.08%] [G loss: 1.659863] [Time: 0.246840]\n",
            "217-2 [D loss: 0.642552, acc.: 65.38%] [G loss: 1.748101] [Time: 0.244008]\n",
            "217-3 [D loss: 0.498474, acc.: 80.77%] [G loss: 2.007676] [Time: 0.248021]\n",
            "217-4 [D loss: 0.515689, acc.: 69.23%] [G loss: 1.984581] [Time: 0.247651]\n",
            "217-5 [D loss: 0.576131, acc.: 69.23%] [G loss: 1.932279] [Time: 0.243199]\n",
            "217-6 [D loss: 0.464139, acc.: 84.62%] [G loss: 1.727402] [Time: 0.249465]\n",
            "217-7 [D loss: 0.574750, acc.: 61.54%] [G loss: 1.476096] [Time: 0.246405]\n",
            "217-8 [D loss: 0.553175, acc.: 73.08%] [G loss: 1.759608] [Time: 0.251298]\n",
            "217 (test) [D loss: 1.267813, acc.: 50.00%] [G loss: 2.344297] [Time: 0.075799]\n",
            "218-0 [D loss: 0.438470, acc.: 82.69%] [G loss: 2.023288] [Time: 0.249161]\n",
            "218-1 [D loss: 0.617479, acc.: 65.38%] [G loss: 1.759678] [Time: 0.243796]\n",
            "218-2 [D loss: 0.648170, acc.: 59.62%] [G loss: 1.807249] [Time: 0.245317]\n",
            "218-3 [D loss: 0.460376, acc.: 82.69%] [G loss: 2.025197] [Time: 0.244844]\n",
            "218-4 [D loss: 0.533830, acc.: 65.38%] [G loss: 1.705154] [Time: 0.249327]\n",
            "218-5 [D loss: 0.526067, acc.: 75.00%] [G loss: 1.872373] [Time: 0.246675]\n",
            "218-6 [D loss: 0.743553, acc.: 46.15%] [G loss: 1.374104] [Time: 0.245141]\n",
            "218-7 [D loss: 0.566012, acc.: 69.23%] [G loss: 1.959648] [Time: 0.247232]\n",
            "218-8 [D loss: 0.473260, acc.: 80.77%] [G loss: 1.769912] [Time: 0.247466]\n",
            "218 (test) [D loss: 1.452320, acc.: 50.00%] [G loss: 2.744609] [Time: 0.079908]\n",
            "219-0 [D loss: 0.402262, acc.: 84.62%] [G loss: 1.676367] [Time: 0.249386]\n",
            "219-1 [D loss: 0.569201, acc.: 76.92%] [G loss: 1.555775] [Time: 0.249031]\n",
            "219-2 [D loss: 0.706317, acc.: 59.62%] [G loss: 1.421021] [Time: 0.245159]\n",
            "219-3 [D loss: 0.517669, acc.: 69.23%] [G loss: 1.680378] [Time: 0.246331]\n",
            "219-4 [D loss: 0.529300, acc.: 71.15%] [G loss: 1.771444] [Time: 0.242864]\n",
            "219-5 [D loss: 0.607476, acc.: 65.38%] [G loss: 1.789102] [Time: 0.246588]\n",
            "219-6 [D loss: 0.609198, acc.: 53.85%] [G loss: 1.832689] [Time: 0.251679]\n",
            "219-7 [D loss: 0.555022, acc.: 73.08%] [G loss: 1.348639] [Time: 0.244166]\n",
            "219-8 [D loss: 0.524210, acc.: 76.92%] [G loss: 1.608894] [Time: 0.246755]\n",
            "219 (test) [D loss: 1.277618, acc.: 50.00%] [G loss: 2.383100] [Time: 0.082865]\n",
            "220-0 [D loss: 0.286739, acc.: 90.38%] [G loss: 1.862934] [Time: 0.246499]\n",
            "220-1 [D loss: 0.508559, acc.: 78.85%] [G loss: 1.683261] [Time: 0.245043]\n",
            "220-2 [D loss: 0.658123, acc.: 61.54%] [G loss: 1.541866] [Time: 0.246532]\n",
            "220-3 [D loss: 0.430942, acc.: 78.85%] [G loss: 1.976008] [Time: 0.244514]\n",
            "220-4 [D loss: 0.453802, acc.: 78.85%] [G loss: 1.681809] [Time: 0.248001]\n",
            "220-5 [D loss: 0.564692, acc.: 71.15%] [G loss: 1.769248] [Time: 0.245541]\n",
            "220-6 [D loss: 0.644890, acc.: 69.23%] [G loss: 1.733205] [Time: 0.246813]\n",
            "220-7 [D loss: 0.520112, acc.: 73.08%] [G loss: 1.735185] [Time: 0.243331]\n",
            "220-8 [D loss: 0.568230, acc.: 67.31%] [G loss: 1.736365] [Time: 0.247874]\n",
            "220 (test) [D loss: 1.283792, acc.: 50.00%] [G loss: 2.389956] [Time: 0.077888]\n",
            "221-0 [D loss: 0.411226, acc.: 76.92%] [G loss: 2.019179] [Time: 0.247273]\n",
            "221-1 [D loss: 0.586675, acc.: 69.23%] [G loss: 1.435394] [Time: 0.246550]\n",
            "221-2 [D loss: 0.618575, acc.: 65.38%] [G loss: 1.463003] [Time: 0.247327]\n",
            "221-3 [D loss: 0.387031, acc.: 86.54%] [G loss: 2.048273] [Time: 0.252108]\n",
            "221-4 [D loss: 0.565693, acc.: 71.15%] [G loss: 2.012611] [Time: 0.244531]\n",
            "221-5 [D loss: 0.510594, acc.: 69.23%] [G loss: 1.601230] [Time: 0.244447]\n",
            "221-6 [D loss: 0.688853, acc.: 59.62%] [G loss: 1.434723] [Time: 0.248938]\n",
            "221-7 [D loss: 0.493723, acc.: 75.00%] [G loss: 1.856561] [Time: 0.254101]\n",
            "221-8 [D loss: 0.631878, acc.: 59.62%] [G loss: 1.765388] [Time: 0.244932]\n",
            "221 (test) [D loss: 1.358392, acc.: 50.00%] [G loss: 2.548055] [Time: 0.077469]\n",
            "222-0 [D loss: 0.348254, acc.: 86.54%] [G loss: 1.707036] [Time: 0.248573]\n",
            "222-1 [D loss: 0.674760, acc.: 57.69%] [G loss: 1.603365] [Time: 0.249668]\n",
            "222-2 [D loss: 0.638995, acc.: 65.38%] [G loss: 1.730986] [Time: 0.245557]\n",
            "222-3 [D loss: 0.482020, acc.: 71.15%] [G loss: 2.080062] [Time: 0.243239]\n",
            "222-4 [D loss: 0.494936, acc.: 69.23%] [G loss: 1.625852] [Time: 0.245404]\n",
            "222-5 [D loss: 0.646373, acc.: 73.08%] [G loss: 1.523105] [Time: 0.250142]\n",
            "222-6 [D loss: 0.519574, acc.: 73.08%] [G loss: 1.857252] [Time: 0.244946]\n",
            "222-7 [D loss: 0.503117, acc.: 80.77%] [G loss: 1.403944] [Time: 0.242996]\n",
            "222-8 [D loss: 0.509212, acc.: 78.85%] [G loss: 1.801542] [Time: 0.244825]\n",
            "222 (test) [D loss: 1.323857, acc.: 50.00%] [G loss: 2.482445] [Time: 0.074586]\n",
            "223-0 [D loss: 0.337888, acc.: 90.38%] [G loss: 1.760643] [Time: 0.247832]\n",
            "223-1 [D loss: 0.688758, acc.: 55.77%] [G loss: 1.617584] [Time: 0.247709]\n",
            "223-2 [D loss: 0.645479, acc.: 65.38%] [G loss: 1.469058] [Time: 0.245087]\n",
            "223-3 [D loss: 0.512537, acc.: 73.08%] [G loss: 1.874086] [Time: 0.251494]\n",
            "223-4 [D loss: 0.571643, acc.: 67.31%] [G loss: 1.692757] [Time: 0.249028]\n",
            "223-5 [D loss: 0.550698, acc.: 73.08%] [G loss: 1.779628] [Time: 0.244904]\n",
            "223-6 [D loss: 0.456026, acc.: 76.92%] [G loss: 1.513656] [Time: 0.248887]\n",
            "223-7 [D loss: 0.469561, acc.: 86.54%] [G loss: 1.656415] [Time: 0.248010]\n",
            "223-8 [D loss: 0.424070, acc.: 84.62%] [G loss: 1.844213] [Time: 0.243583]\n",
            "223 (test) [D loss: 1.266523, acc.: 50.00%] [G loss: 2.371276] [Time: 0.076833]\n",
            "224-0 [D loss: 0.338632, acc.: 88.46%] [G loss: 1.828893] [Time: 0.244949]\n",
            "224-1 [D loss: 0.473221, acc.: 78.85%] [G loss: 1.771049] [Time: 0.246128]\n",
            "224-2 [D loss: 0.734938, acc.: 55.77%] [G loss: 1.562701] [Time: 0.248662]\n",
            "224-3 [D loss: 0.505243, acc.: 75.00%] [G loss: 2.131895] [Time: 0.246980]\n",
            "224-4 [D loss: 0.587694, acc.: 67.31%] [G loss: 1.625390] [Time: 0.249989]\n",
            "224-5 [D loss: 0.579806, acc.: 71.15%] [G loss: 1.641280] [Time: 0.249544]\n",
            "224-6 [D loss: 0.550603, acc.: 73.08%] [G loss: 1.753541] [Time: 0.245909]\n",
            "224-7 [D loss: 0.567894, acc.: 73.08%] [G loss: 1.862997] [Time: 0.247875]\n",
            "224-8 [D loss: 0.651229, acc.: 57.69%] [G loss: 1.715340] [Time: 0.248091]\n",
            "224 (test) [D loss: 1.353650, acc.: 50.00%] [G loss: 2.548256] [Time: 0.077119]\n",
            "225-0 [D loss: 0.377996, acc.: 84.62%] [G loss: 2.292633] [Time: 0.245759]\n",
            "225-1 [D loss: 0.502667, acc.: 78.85%] [G loss: 1.794620] [Time: 0.245224]\n",
            "225-2 [D loss: 0.657691, acc.: 61.54%] [G loss: 1.750155] [Time: 0.249377]\n",
            "225-3 [D loss: 0.462488, acc.: 78.85%] [G loss: 2.019602] [Time: 0.246784]\n",
            "225-4 [D loss: 0.431369, acc.: 76.92%] [G loss: 1.808811] [Time: 0.250912]\n",
            "225-5 [D loss: 0.488763, acc.: 69.23%] [G loss: 1.863012] [Time: 0.245721]\n",
            "225-6 [D loss: 0.694335, acc.: 57.69%] [G loss: 1.530142] [Time: 0.247545]\n",
            "225-7 [D loss: 0.558535, acc.: 69.23%] [G loss: 1.779097] [Time: 0.248160]\n",
            "225-8 [D loss: 0.408610, acc.: 84.62%] [G loss: 1.993624] [Time: 0.246961]\n",
            "225 (test) [D loss: 1.334844, acc.: 50.00%] [G loss: 2.503466] [Time: 0.076405]\n",
            "226-0 [D loss: 0.355579, acc.: 88.46%] [G loss: 1.972804] [Time: 0.249115]\n",
            "226-1 [D loss: 0.544163, acc.: 71.15%] [G loss: 1.620389] [Time: 0.243906]\n",
            "226-2 [D loss: 0.741952, acc.: 48.08%] [G loss: 1.510893] [Time: 0.249753]\n",
            "226-3 [D loss: 0.404281, acc.: 84.62%] [G loss: 1.928978] [Time: 0.247396]\n",
            "226-4 [D loss: 0.520692, acc.: 73.08%] [G loss: 1.613456] [Time: 0.245274]\n",
            "226-5 [D loss: 0.540908, acc.: 69.23%] [G loss: 1.719398] [Time: 0.250248]\n",
            "226-6 [D loss: 0.608023, acc.: 63.46%] [G loss: 1.808265] [Time: 0.245551]\n",
            "226-7 [D loss: 0.441816, acc.: 86.54%] [G loss: 1.573442] [Time: 0.245124]\n",
            "226-8 [D loss: 0.383880, acc.: 84.62%] [G loss: 1.859301] [Time: 0.245302]\n",
            "226 (test) [D loss: 1.302908, acc.: 50.00%] [G loss: 2.435445] [Time: 0.076781]\n",
            "227-0 [D loss: 0.448693, acc.: 84.62%] [G loss: 1.892529] [Time: 0.248561]\n",
            "227-1 [D loss: 0.565667, acc.: 69.23%] [G loss: 1.612982] [Time: 0.246236]\n",
            "227-2 [D loss: 0.632059, acc.: 65.38%] [G loss: 1.510027] [Time: 0.245130]\n",
            "227-3 [D loss: 0.470374, acc.: 76.92%] [G loss: 2.025409] [Time: 0.250514]\n",
            "227-4 [D loss: 0.533393, acc.: 71.15%] [G loss: 1.550896] [Time: 0.248391]\n",
            "227-5 [D loss: 0.633555, acc.: 61.54%] [G loss: 1.716755] [Time: 0.246877]\n",
            "227-6 [D loss: 0.551425, acc.: 76.92%] [G loss: 1.916845] [Time: 0.249736]\n",
            "227-7 [D loss: 0.551224, acc.: 67.31%] [G loss: 1.710903] [Time: 0.245488]\n",
            "227-8 [D loss: 0.503942, acc.: 69.23%] [G loss: 1.468702] [Time: 0.246258]\n",
            "227 (test) [D loss: 1.349617, acc.: 50.00%] [G loss: 2.545554] [Time: 0.075413]\n",
            "228-0 [D loss: 0.335991, acc.: 92.31%] [G loss: 2.037305] [Time: 0.246932]\n",
            "228-1 [D loss: 0.621749, acc.: 65.38%] [G loss: 1.670652] [Time: 0.247407]\n",
            "228-2 [D loss: 0.571257, acc.: 65.38%] [G loss: 1.631274] [Time: 0.250050]\n",
            "228-3 [D loss: 0.460210, acc.: 76.92%] [G loss: 1.855237] [Time: 0.245291]\n",
            "228-4 [D loss: 0.576689, acc.: 69.23%] [G loss: 1.972519] [Time: 0.246242]\n",
            "228-5 [D loss: 0.556568, acc.: 76.92%] [G loss: 1.611487] [Time: 0.249544]\n",
            "228-6 [D loss: 0.562273, acc.: 71.15%] [G loss: 1.589090] [Time: 0.242869]\n",
            "228-7 [D loss: 0.523105, acc.: 75.00%] [G loss: 1.312240] [Time: 0.244059]\n",
            "228-8 [D loss: 0.460659, acc.: 75.00%] [G loss: 2.023419] [Time: 0.245816]\n",
            "228 (test) [D loss: 1.306198, acc.: 50.00%] [G loss: 2.436768] [Time: 0.078079]\n",
            "229-0 [D loss: 0.324587, acc.: 86.54%] [G loss: 2.058512] [Time: 0.246263]\n",
            "229-1 [D loss: 0.510727, acc.: 73.08%] [G loss: 1.578390] [Time: 0.246055]\n",
            "229-2 [D loss: 0.765464, acc.: 55.77%] [G loss: 1.657300] [Time: 0.245315]\n",
            "229-3 [D loss: 0.493719, acc.: 78.85%] [G loss: 2.161474] [Time: 0.250374]\n",
            "229-4 [D loss: 0.452829, acc.: 84.62%] [G loss: 1.869190] [Time: 0.245695]\n",
            "229-5 [D loss: 0.570077, acc.: 69.23%] [G loss: 1.533493] [Time: 0.243462]\n",
            "229-6 [D loss: 0.681344, acc.: 61.54%] [G loss: 1.606855] [Time: 0.249768]\n",
            "229-7 [D loss: 0.445545, acc.: 84.62%] [G loss: 1.753150] [Time: 0.248321]\n",
            "229-8 [D loss: 0.555192, acc.: 71.15%] [G loss: 1.632670] [Time: 0.243185]\n",
            "229 (test) [D loss: 1.318195, acc.: 50.00%] [G loss: 2.463495] [Time: 0.076041]\n",
            "230-0 [D loss: 0.356921, acc.: 86.54%] [G loss: 1.965386] [Time: 0.247337]\n",
            "230-1 [D loss: 0.438699, acc.: 75.00%] [G loss: 1.460995] [Time: 0.251024]\n",
            "230-2 [D loss: 0.670996, acc.: 59.62%] [G loss: 1.509224] [Time: 0.244490]\n",
            "230-3 [D loss: 0.476712, acc.: 82.69%] [G loss: 2.163838] [Time: 0.247229]\n",
            "230-4 [D loss: 0.574917, acc.: 69.23%] [G loss: 1.485283] [Time: 0.252520]\n",
            "230-5 [D loss: 0.557477, acc.: 71.15%] [G loss: 1.672876] [Time: 0.250376]\n",
            "230-6 [D loss: 0.573783, acc.: 63.46%] [G loss: 1.569023] [Time: 0.249258]\n",
            "230-7 [D loss: 0.497985, acc.: 73.08%] [G loss: 1.549230] [Time: 0.245905]\n",
            "230-8 [D loss: 0.496238, acc.: 78.85%] [G loss: 1.765303] [Time: 0.248090]\n",
            "230 (test) [D loss: 1.339886, acc.: 50.00%] [G loss: 2.495944] [Time: 0.078738]\n",
            "231-0 [D loss: 0.351127, acc.: 92.31%] [G loss: 1.897133] [Time: 0.247316]\n",
            "231-1 [D loss: 0.574509, acc.: 76.92%] [G loss: 1.726313] [Time: 0.245038]\n",
            "231-2 [D loss: 0.657547, acc.: 65.38%] [G loss: 1.582247] [Time: 0.243354]\n",
            "231-3 [D loss: 0.403626, acc.: 82.69%] [G loss: 2.072700] [Time: 0.249147]\n",
            "231-4 [D loss: 0.485272, acc.: 78.85%] [G loss: 1.734040] [Time: 0.247841]\n",
            "231-5 [D loss: 0.590044, acc.: 69.23%] [G loss: 1.415211] [Time: 0.244784]\n",
            "231-6 [D loss: 0.567243, acc.: 73.08%] [G loss: 1.525829] [Time: 0.246675]\n",
            "231-7 [D loss: 0.546716, acc.: 73.08%] [G loss: 1.558789] [Time: 0.248907]\n",
            "231-8 [D loss: 0.511858, acc.: 71.15%] [G loss: 1.976525] [Time: 0.248516]\n",
            "231 (test) [D loss: 1.335564, acc.: 50.00%] [G loss: 2.502907] [Time: 0.075129]\n",
            "232-0 [D loss: 0.300007, acc.: 92.31%] [G loss: 2.253093] [Time: 0.246613]\n",
            "232-1 [D loss: 0.640946, acc.: 61.54%] [G loss: 1.437307] [Time: 0.249380]\n",
            "232-2 [D loss: 0.710220, acc.: 59.62%] [G loss: 1.468559] [Time: 0.246321]\n",
            "232-3 [D loss: 0.422312, acc.: 80.77%] [G loss: 1.783724] [Time: 0.246280]\n",
            "232-4 [D loss: 0.496220, acc.: 78.85%] [G loss: 1.656481] [Time: 0.243894]\n",
            "232-5 [D loss: 0.677218, acc.: 57.69%] [G loss: 1.428302] [Time: 0.245113]\n",
            "232-6 [D loss: 0.512432, acc.: 75.00%] [G loss: 1.553474] [Time: 0.245261]\n",
            "232-7 [D loss: 0.419798, acc.: 88.46%] [G loss: 1.526520] [Time: 0.245149]\n",
            "232-8 [D loss: 0.576909, acc.: 65.38%] [G loss: 1.623537] [Time: 0.245487]\n",
            "232 (test) [D loss: 1.343535, acc.: 50.00%] [G loss: 2.523221] [Time: 0.078735]\n",
            "233-0 [D loss: 0.320711, acc.: 92.31%] [G loss: 2.358042] [Time: 0.247854]\n",
            "233-1 [D loss: 0.562299, acc.: 69.23%] [G loss: 1.500102] [Time: 0.246924]\n",
            "233-2 [D loss: 0.770952, acc.: 61.54%] [G loss: 1.412614] [Time: 0.248581]\n",
            "233-3 [D loss: 0.485813, acc.: 73.08%] [G loss: 2.100965] [Time: 0.249742]\n",
            "233-4 [D loss: 0.571316, acc.: 65.38%] [G loss: 1.773345] [Time: 0.244511]\n",
            "233-5 [D loss: 0.568708, acc.: 75.00%] [G loss: 1.774855] [Time: 0.251714]\n",
            "233-6 [D loss: 0.596303, acc.: 73.08%] [G loss: 1.595419] [Time: 0.250020]\n",
            "233-7 [D loss: 0.520470, acc.: 76.92%] [G loss: 1.556118] [Time: 0.245981]\n",
            "233-8 [D loss: 0.462251, acc.: 84.62%] [G loss: 1.789156] [Time: 0.248093]\n",
            "233 (test) [D loss: 1.366658, acc.: 50.00%] [G loss: 2.576207] [Time: 0.076214]\n",
            "234-0 [D loss: 0.359915, acc.: 88.46%] [G loss: 2.100047] [Time: 0.248350]\n",
            "234-1 [D loss: 0.674042, acc.: 59.62%] [G loss: 1.765488] [Time: 0.248545]\n",
            "234-2 [D loss: 0.720101, acc.: 63.46%] [G loss: 1.584090] [Time: 0.249953]\n",
            "234-3 [D loss: 0.464534, acc.: 76.92%] [G loss: 1.788254] [Time: 0.251288]\n",
            "234-4 [D loss: 0.528904, acc.: 71.15%] [G loss: 1.634691] [Time: 0.246147]\n",
            "234-5 [D loss: 0.571187, acc.: 65.38%] [G loss: 1.513685] [Time: 0.247772]\n",
            "234-6 [D loss: 0.423343, acc.: 78.85%] [G loss: 1.895320] [Time: 0.244804]\n",
            "234-7 [D loss: 0.481027, acc.: 73.08%] [G loss: 1.452086] [Time: 0.246602]\n",
            "234-8 [D loss: 0.447852, acc.: 80.77%] [G loss: 1.645786] [Time: 0.247797]\n",
            "234 (test) [D loss: 1.384962, acc.: 50.00%] [G loss: 2.606626] [Time: 0.079939]\n",
            "235-0 [D loss: 0.443905, acc.: 80.77%] [G loss: 2.085626] [Time: 0.248121]\n",
            "235-1 [D loss: 0.577099, acc.: 75.00%] [G loss: 1.536383] [Time: 0.245939]\n",
            "235-2 [D loss: 0.642522, acc.: 61.54%] [G loss: 1.413514] [Time: 0.248243]\n",
            "235-3 [D loss: 0.658221, acc.: 67.31%] [G loss: 1.578642] [Time: 0.245943]\n",
            "235-4 [D loss: 0.491439, acc.: 75.00%] [G loss: 1.965950] [Time: 0.249701]\n",
            "235-5 [D loss: 0.612290, acc.: 63.46%] [G loss: 1.858306] [Time: 0.247178]\n",
            "235-6 [D loss: 0.602638, acc.: 65.38%] [G loss: 1.806885] [Time: 0.245848]\n",
            "235-7 [D loss: 0.553603, acc.: 71.15%] [G loss: 1.692513] [Time: 0.248708]\n",
            "235-8 [D loss: 0.392726, acc.: 82.69%] [G loss: 1.899169] [Time: 0.256308]\n",
            "235 (test) [D loss: 1.367716, acc.: 50.00%] [G loss: 2.576098] [Time: 0.078032]\n",
            "236-0 [D loss: 0.277640, acc.: 94.23%] [G loss: 1.996785] [Time: 0.249581]\n",
            "236-1 [D loss: 0.563072, acc.: 76.92%] [G loss: 1.700409] [Time: 0.246505]\n",
            "236-2 [D loss: 0.762774, acc.: 50.00%] [G loss: 1.491253] [Time: 0.246622]\n",
            "236-3 [D loss: 0.387691, acc.: 88.46%] [G loss: 2.178852] [Time: 0.245993]\n",
            "236-4 [D loss: 0.488882, acc.: 76.92%] [G loss: 1.499747] [Time: 0.243989]\n",
            "236-5 [D loss: 0.487389, acc.: 78.85%] [G loss: 1.732644] [Time: 0.244438]\n",
            "236-6 [D loss: 0.509303, acc.: 80.77%] [G loss: 1.842181] [Time: 0.249071]\n",
            "236-7 [D loss: 0.437612, acc.: 80.77%] [G loss: 1.869046] [Time: 0.245911]\n",
            "236-8 [D loss: 0.546589, acc.: 67.31%] [G loss: 1.653467] [Time: 0.244546]\n",
            "236 (test) [D loss: 1.402633, acc.: 50.00%] [G loss: 2.650424] [Time: 0.077514]\n",
            "237-0 [D loss: 0.381402, acc.: 86.54%] [G loss: 1.917157] [Time: 0.246975]\n",
            "237-1 [D loss: 0.505742, acc.: 82.69%] [G loss: 1.435014] [Time: 0.248379]\n",
            "237-2 [D loss: 0.873547, acc.: 50.00%] [G loss: 1.375244] [Time: 0.249498]\n",
            "237-3 [D loss: 0.353766, acc.: 84.62%] [G loss: 2.098220] [Time: 0.246165]\n",
            "237-4 [D loss: 0.484259, acc.: 75.00%] [G loss: 1.819332] [Time: 0.250980]\n",
            "237-5 [D loss: 0.627459, acc.: 57.69%] [G loss: 1.659086] [Time: 0.243896]\n",
            "237-6 [D loss: 0.616276, acc.: 67.31%] [G loss: 1.973444] [Time: 0.244655]\n",
            "237-7 [D loss: 0.511292, acc.: 73.08%] [G loss: 1.830205] [Time: 0.248672]\n",
            "237-8 [D loss: 0.479718, acc.: 78.85%] [G loss: 1.924152] [Time: 0.243987]\n",
            "237 (test) [D loss: 1.348974, acc.: 50.00%] [G loss: 2.542309] [Time: 0.076097]\n",
            "238-0 [D loss: 0.387569, acc.: 82.69%] [G loss: 1.838198] [Time: 0.253201]\n",
            "238-1 [D loss: 0.502607, acc.: 75.00%] [G loss: 1.551545] [Time: 0.247476]\n",
            "238-2 [D loss: 0.631674, acc.: 65.38%] [G loss: 1.448346] [Time: 0.251947]\n",
            "238-3 [D loss: 0.437609, acc.: 76.92%] [G loss: 2.089541] [Time: 0.247531]\n",
            "238-4 [D loss: 0.461343, acc.: 78.85%] [G loss: 1.871099] [Time: 0.242213]\n",
            "238-5 [D loss: 0.526874, acc.: 69.23%] [G loss: 1.577145] [Time: 0.248013]\n",
            "238-6 [D loss: 0.608549, acc.: 59.62%] [G loss: 1.600208] [Time: 0.254362]\n",
            "238-7 [D loss: 0.542455, acc.: 65.38%] [G loss: 1.754562] [Time: 0.247276]\n",
            "238-8 [D loss: 0.438837, acc.: 78.85%] [G loss: 1.808729] [Time: 0.247275]\n",
            "238 (test) [D loss: 1.352884, acc.: 50.00%] [G loss: 2.566001] [Time: 0.076175]\n",
            "239-0 [D loss: 0.399239, acc.: 90.38%] [G loss: 2.140428] [Time: 0.247456]\n",
            "239-1 [D loss: 0.563939, acc.: 71.15%] [G loss: 1.389632] [Time: 0.244650]\n",
            "239-2 [D loss: 0.640793, acc.: 67.31%] [G loss: 1.542311] [Time: 0.248483]\n",
            "239-3 [D loss: 0.466487, acc.: 75.00%] [G loss: 1.675110] [Time: 0.245660]\n",
            "239-4 [D loss: 0.536943, acc.: 67.31%] [G loss: 1.424754] [Time: 0.248068]\n",
            "239-5 [D loss: 0.550939, acc.: 73.08%] [G loss: 1.743310] [Time: 0.247011]\n",
            "239-6 [D loss: 0.662606, acc.: 59.62%] [G loss: 1.455362] [Time: 0.243592]\n",
            "239-7 [D loss: 0.565266, acc.: 75.00%] [G loss: 1.582764] [Time: 0.245268]\n",
            "239-8 [D loss: 0.529822, acc.: 80.77%] [G loss: 1.932909] [Time: 0.248049]\n",
            "239 (test) [D loss: 1.358324, acc.: 50.00%] [G loss: 2.577339] [Time: 0.076543]\n",
            "240-0 [D loss: 0.388642, acc.: 86.54%] [G loss: 1.894454] [Time: 0.250452]\n",
            "240-1 [D loss: 0.531879, acc.: 75.00%] [G loss: 1.654680] [Time: 0.247714]\n",
            "240-2 [D loss: 0.731961, acc.: 53.85%] [G loss: 1.398302] [Time: 0.247081]\n",
            "240-3 [D loss: 0.409162, acc.: 86.54%] [G loss: 1.722857] [Time: 0.243632]\n",
            "240-4 [D loss: 0.563214, acc.: 71.15%] [G loss: 1.724436] [Time: 0.248825]\n",
            "240-5 [D loss: 0.544752, acc.: 71.15%] [G loss: 1.828147] [Time: 0.246389]\n",
            "240-6 [D loss: 0.576421, acc.: 59.62%] [G loss: 1.878330] [Time: 0.249233]\n",
            "240-7 [D loss: 0.465978, acc.: 75.00%] [G loss: 1.612079] [Time: 0.245502]\n",
            "240-8 [D loss: 0.501248, acc.: 73.08%] [G loss: 1.897009] [Time: 0.246397]\n",
            "240 (test) [D loss: 1.327516, acc.: 50.00%] [G loss: 2.503966] [Time: 0.076672]\n",
            "241-0 [D loss: 0.372640, acc.: 84.62%] [G loss: 1.724797] [Time: 0.246865]\n",
            "241-1 [D loss: 0.603504, acc.: 76.92%] [G loss: 1.802025] [Time: 0.250863]\n",
            "241-2 [D loss: 0.683954, acc.: 51.92%] [G loss: 1.427574] [Time: 0.249987]\n",
            "241-3 [D loss: 0.385783, acc.: 86.54%] [G loss: 2.093781] [Time: 0.244824]\n",
            "241-4 [D loss: 0.530782, acc.: 69.23%] [G loss: 1.678204] [Time: 0.247281]\n",
            "241-5 [D loss: 0.503196, acc.: 75.00%] [G loss: 1.631710] [Time: 0.244977]\n",
            "241-6 [D loss: 0.479977, acc.: 73.08%] [G loss: 1.636442] [Time: 0.246425]\n",
            "241-7 [D loss: 0.626601, acc.: 53.85%] [G loss: 1.555674] [Time: 0.246309]\n",
            "241-8 [D loss: 0.510845, acc.: 75.00%] [G loss: 1.640206] [Time: 0.247993]\n",
            "241 (test) [D loss: 1.423658, acc.: 50.00%] [G loss: 2.726054] [Time: 0.076836]\n",
            "242-0 [D loss: 0.352012, acc.: 88.46%] [G loss: 1.958053] [Time: 0.248932]\n",
            "242-1 [D loss: 0.522419, acc.: 80.77%] [G loss: 1.741910] [Time: 0.248431]\n",
            "242-2 [D loss: 0.849370, acc.: 46.15%] [G loss: 1.775215] [Time: 0.248400]\n",
            "242-3 [D loss: 0.401836, acc.: 86.54%] [G loss: 2.071727] [Time: 0.247475]\n",
            "242-4 [D loss: 0.677975, acc.: 61.54%] [G loss: 1.445174] [Time: 0.246256]\n",
            "242-5 [D loss: 0.590734, acc.: 69.23%] [G loss: 1.731756] [Time: 0.246693]\n",
            "242-6 [D loss: 0.575301, acc.: 71.15%] [G loss: 1.509653] [Time: 0.248498]\n",
            "242-7 [D loss: 0.639783, acc.: 69.23%] [G loss: 1.586585] [Time: 0.246552]\n",
            "242-8 [D loss: 0.390714, acc.: 80.77%] [G loss: 1.885541] [Time: 0.246844]\n",
            "242 (test) [D loss: 1.356729, acc.: 50.00%] [G loss: 2.576930] [Time: 0.077999]\n",
            "243-0 [D loss: 0.350991, acc.: 88.46%] [G loss: 2.186644] [Time: 0.247661]\n",
            "243-1 [D loss: 0.719002, acc.: 57.69%] [G loss: 1.403398] [Time: 0.246464]\n",
            "243-2 [D loss: 0.677551, acc.: 57.69%] [G loss: 1.501902] [Time: 0.249388]\n",
            "243-3 [D loss: 0.473614, acc.: 76.92%] [G loss: 1.786763] [Time: 0.244108]\n",
            "243-4 [D loss: 0.471988, acc.: 76.92%] [G loss: 1.783714] [Time: 0.249342]\n",
            "243-5 [D loss: 0.652413, acc.: 57.69%] [G loss: 1.450136] [Time: 0.247548]\n",
            "243-6 [D loss: 0.454160, acc.: 82.69%] [G loss: 1.728508] [Time: 0.247744]\n",
            "243-7 [D loss: 0.622568, acc.: 63.46%] [G loss: 1.549468] [Time: 0.244462]\n",
            "243-8 [D loss: 0.465506, acc.: 78.85%] [G loss: 1.774997] [Time: 0.246715]\n",
            "243 (test) [D loss: 1.382614, acc.: 50.00%] [G loss: 2.620710] [Time: 0.075767]\n",
            "244-0 [D loss: 0.350697, acc.: 84.62%] [G loss: 2.145061] [Time: 0.248971]\n",
            "244-1 [D loss: 0.715760, acc.: 53.85%] [G loss: 1.738909] [Time: 0.248095]\n",
            "244-2 [D loss: 0.752391, acc.: 63.46%] [G loss: 1.521790] [Time: 0.249661]\n",
            "244-3 [D loss: 0.548982, acc.: 73.08%] [G loss: 1.676384] [Time: 0.247593]\n",
            "244-4 [D loss: 0.495698, acc.: 73.08%] [G loss: 1.592656] [Time: 0.249709]\n",
            "244-5 [D loss: 0.457589, acc.: 78.85%] [G loss: 1.533112] [Time: 0.251024]\n",
            "244-6 [D loss: 0.499978, acc.: 69.23%] [G loss: 1.767327] [Time: 0.246892]\n",
            "244-7 [D loss: 0.647936, acc.: 59.62%] [G loss: 1.390918] [Time: 0.247441]\n",
            "244-8 [D loss: 0.490472, acc.: 75.00%] [G loss: 1.697806] [Time: 0.249557]\n",
            "244 (test) [D loss: 1.376562, acc.: 50.00%] [G loss: 2.621189] [Time: 0.075974]\n",
            "245-0 [D loss: 0.414264, acc.: 78.85%] [G loss: 2.277671] [Time: 0.250567]\n",
            "245-1 [D loss: 0.522431, acc.: 69.23%] [G loss: 1.723777] [Time: 0.245210]\n",
            "245-2 [D loss: 0.840117, acc.: 50.00%] [G loss: 1.419673] [Time: 0.249133]\n",
            "245-3 [D loss: 0.475538, acc.: 76.92%] [G loss: 1.829167] [Time: 0.249958]\n",
            "245-4 [D loss: 0.601345, acc.: 65.38%] [G loss: 1.583790] [Time: 0.244865]\n",
            "245-5 [D loss: 0.575292, acc.: 69.23%] [G loss: 1.532449] [Time: 0.246708]\n",
            "245-6 [D loss: 0.550306, acc.: 73.08%] [G loss: 1.770561] [Time: 0.247893]\n",
            "245-7 [D loss: 0.580574, acc.: 65.38%] [G loss: 1.661472] [Time: 0.243700]\n",
            "245-8 [D loss: 0.463054, acc.: 76.92%] [G loss: 1.822458] [Time: 0.248680]\n",
            "245 (test) [D loss: 1.453977, acc.: 50.00%] [G loss: 2.767264] [Time: 0.078458]\n",
            "246-0 [D loss: 0.388301, acc.: 86.54%] [G loss: 2.053605] [Time: 0.247940]\n",
            "246-1 [D loss: 0.589308, acc.: 71.15%] [G loss: 1.656990] [Time: 0.245897]\n",
            "246-2 [D loss: 0.614236, acc.: 63.46%] [G loss: 1.332540] [Time: 0.252583]\n",
            "246-3 [D loss: 0.519014, acc.: 63.46%] [G loss: 1.895152] [Time: 0.244203]\n",
            "246-4 [D loss: 0.474406, acc.: 80.77%] [G loss: 1.662331] [Time: 0.247616]\n",
            "246-5 [D loss: 0.592774, acc.: 69.23%] [G loss: 1.678613] [Time: 0.247433]\n",
            "246-6 [D loss: 0.569287, acc.: 71.15%] [G loss: 1.561196] [Time: 0.248760]\n",
            "246-7 [D loss: 0.556177, acc.: 71.15%] [G loss: 1.785298] [Time: 0.246174]\n",
            "246-8 [D loss: 0.482572, acc.: 80.77%] [G loss: 1.834070] [Time: 0.248657]\n",
            "246 (test) [D loss: 1.376765, acc.: 50.00%] [G loss: 2.604412] [Time: 0.076493]\n",
            "247-0 [D loss: 0.366034, acc.: 86.54%] [G loss: 2.286037] [Time: 0.244312]\n",
            "247-1 [D loss: 0.524695, acc.: 78.85%] [G loss: 1.490162] [Time: 0.243736]\n",
            "247-2 [D loss: 0.644245, acc.: 57.69%] [G loss: 1.371176] [Time: 0.244970]\n",
            "247-3 [D loss: 0.441678, acc.: 78.85%] [G loss: 1.819995] [Time: 0.249965]\n",
            "247-4 [D loss: 0.592920, acc.: 67.31%] [G loss: 1.645203] [Time: 0.250930]\n",
            "247-5 [D loss: 0.769168, acc.: 48.08%] [G loss: 2.015220] [Time: 0.245667]\n",
            "247-6 [D loss: 0.560712, acc.: 69.23%] [G loss: 1.795829] [Time: 0.253303]\n",
            "247-7 [D loss: 0.525436, acc.: 71.15%] [G loss: 1.597711] [Time: 0.245404]\n",
            "247-8 [D loss: 0.515366, acc.: 76.92%] [G loss: 1.662103] [Time: 0.246422]\n",
            "247 (test) [D loss: 1.411117, acc.: 50.00%] [G loss: 2.692637] [Time: 0.076866]\n",
            "248-0 [D loss: 0.322531, acc.: 90.38%] [G loss: 2.314186] [Time: 0.248381]\n",
            "248-1 [D loss: 0.647468, acc.: 59.62%] [G loss: 1.717030] [Time: 0.247767]\n",
            "248-2 [D loss: 0.750514, acc.: 50.00%] [G loss: 1.523933] [Time: 0.248920]\n",
            "248-3 [D loss: 0.406101, acc.: 78.85%] [G loss: 2.210942] [Time: 0.244986]\n",
            "248-4 [D loss: 0.448897, acc.: 78.85%] [G loss: 1.744737] [Time: 0.251607]\n",
            "248-5 [D loss: 0.657866, acc.: 65.38%] [G loss: 1.423136] [Time: 0.245138]\n",
            "248-6 [D loss: 0.495418, acc.: 75.00%] [G loss: 1.729991] [Time: 0.244514]\n",
            "248-7 [D loss: 0.583702, acc.: 71.15%] [G loss: 1.607390] [Time: 0.249687]\n",
            "248-8 [D loss: 0.385084, acc.: 86.54%] [G loss: 2.132000] [Time: 0.248723]\n",
            "248 (test) [D loss: 1.472736, acc.: 50.00%] [G loss: 2.808112] [Time: 0.076090]\n",
            "249-0 [D loss: 0.337551, acc.: 92.31%] [G loss: 1.933191] [Time: 0.249911]\n",
            "249-1 [D loss: 0.719437, acc.: 55.77%] [G loss: 1.305092] [Time: 0.246135]\n",
            "249-2 [D loss: 0.587090, acc.: 59.62%] [G loss: 1.570946] [Time: 0.250553]\n",
            "249-3 [D loss: 0.395030, acc.: 82.69%] [G loss: 1.883076] [Time: 0.246142]\n",
            "249-4 [D loss: 0.511419, acc.: 75.00%] [G loss: 1.546624] [Time: 0.248736]\n",
            "249-5 [D loss: 0.588298, acc.: 67.31%] [G loss: 1.447820] [Time: 0.245539]\n",
            "249-6 [D loss: 0.521678, acc.: 75.00%] [G loss: 1.722404] [Time: 0.247243]\n",
            "249-7 [D loss: 0.626263, acc.: 63.46%] [G loss: 1.729723] [Time: 0.249066]\n",
            "249-8 [D loss: 0.365168, acc.: 92.31%] [G loss: 1.814502] [Time: 0.245484]\n",
            "249 (test) [D loss: 1.462816, acc.: 50.00%] [G loss: 2.791080] [Time: 0.075409]\n",
            "250-0 [D loss: 0.390208, acc.: 84.62%] [G loss: 2.076824] [Time: 0.248949]\n",
            "250-1 [D loss: 0.553403, acc.: 69.23%] [G loss: 1.853624] [Time: 0.246664]\n",
            "250-2 [D loss: 0.742864, acc.: 46.15%] [G loss: 1.515461] [Time: 0.248663]\n",
            "250-3 [D loss: 0.403290, acc.: 86.54%] [G loss: 2.040057] [Time: 0.244288]\n",
            "250-4 [D loss: 0.533966, acc.: 69.23%] [G loss: 1.443783] [Time: 0.246882]\n",
            "250-5 [D loss: 0.530339, acc.: 78.85%] [G loss: 1.393179] [Time: 0.248913]\n",
            "250-6 [D loss: 0.548222, acc.: 71.15%] [G loss: 1.414020] [Time: 0.245959]\n",
            "250-7 [D loss: 0.717073, acc.: 63.46%] [G loss: 1.558241] [Time: 0.243593]\n",
            "250-8 [D loss: 0.459317, acc.: 82.69%] [G loss: 2.170197] [Time: 0.246581]\n",
            "250 (test) [D loss: 1.500248, acc.: 50.00%] [G loss: 2.875881] [Time: 0.076923]\n",
            "251-0 [D loss: 0.406148, acc.: 84.62%] [G loss: 2.143984] [Time: 0.246286]\n",
            "251-1 [D loss: 0.667437, acc.: 61.54%] [G loss: 1.444012] [Time: 0.242719]\n",
            "251-2 [D loss: 0.770823, acc.: 55.77%] [G loss: 1.469917] [Time: 0.249891]\n",
            "251-3 [D loss: 0.558271, acc.: 67.31%] [G loss: 1.685657] [Time: 0.249160]\n",
            "251-4 [D loss: 0.569975, acc.: 65.38%] [G loss: 1.527493] [Time: 0.245139]\n",
            "251-5 [D loss: 0.600911, acc.: 76.92%] [G loss: 1.760489] [Time: 0.246809]\n",
            "251-6 [D loss: 0.607080, acc.: 67.31%] [G loss: 1.641513] [Time: 0.244481]\n",
            "251-7 [D loss: 0.564165, acc.: 59.62%] [G loss: 1.617069] [Time: 0.246771]\n",
            "251-8 [D loss: 0.565800, acc.: 69.23%] [G loss: 1.701433] [Time: 0.251818]\n",
            "251 (test) [D loss: 1.467413, acc.: 50.00%] [G loss: 2.809311] [Time: 0.080605]\n",
            "252-0 [D loss: 0.342054, acc.: 90.38%] [G loss: 2.036629] [Time: 0.246386]\n",
            "252-1 [D loss: 0.584071, acc.: 76.92%] [G loss: 1.513526] [Time: 0.247540]\n",
            "252-2 [D loss: 0.715554, acc.: 53.85%] [G loss: 1.249738] [Time: 0.247703]\n",
            "252-3 [D loss: 0.487513, acc.: 65.38%] [G loss: 2.047457] [Time: 0.246291]\n",
            "252-4 [D loss: 0.478484, acc.: 75.00%] [G loss: 1.898891] [Time: 0.246955]\n",
            "252-5 [D loss: 0.644744, acc.: 65.38%] [G loss: 1.469786] [Time: 0.246601]\n",
            "252-6 [D loss: 0.515438, acc.: 76.92%] [G loss: 1.340420] [Time: 0.247726]\n",
            "252-7 [D loss: 0.656326, acc.: 59.62%] [G loss: 1.647713] [Time: 0.254635]\n",
            "252-8 [D loss: 0.451409, acc.: 82.69%] [G loss: 1.943870] [Time: 0.245703]\n",
            "252 (test) [D loss: 1.370364, acc.: 50.00%] [G loss: 2.603556] [Time: 0.078071]\n",
            "253-0 [D loss: 0.382085, acc.: 84.62%] [G loss: 1.789266] [Time: 0.245424]\n",
            "253-1 [D loss: 0.624246, acc.: 61.54%] [G loss: 1.692418] [Time: 0.244808]\n",
            "253-2 [D loss: 0.721924, acc.: 51.92%] [G loss: 1.485903] [Time: 0.247360]\n",
            "253-3 [D loss: 0.460109, acc.: 73.08%] [G loss: 2.180011] [Time: 0.245428]\n",
            "253-4 [D loss: 0.458157, acc.: 78.85%] [G loss: 1.686734] [Time: 0.245045]\n",
            "253-5 [D loss: 0.507362, acc.: 75.00%] [G loss: 1.516886] [Time: 0.249036]\n",
            "253-6 [D loss: 0.624210, acc.: 65.38%] [G loss: 1.830814] [Time: 0.244280]\n",
            "253-7 [D loss: 0.542993, acc.: 65.38%] [G loss: 1.563438] [Time: 0.244517]\n",
            "253-8 [D loss: 0.557339, acc.: 75.00%] [G loss: 1.731277] [Time: 0.246973]\n",
            "253 (test) [D loss: 1.442096, acc.: 50.00%] [G loss: 2.760989] [Time: 0.076577]\n",
            "254-0 [D loss: 0.366666, acc.: 90.38%] [G loss: 2.192963] [Time: 0.248437]\n",
            "254-1 [D loss: 0.625338, acc.: 63.46%] [G loss: 1.471268] [Time: 0.249161]\n",
            "254-2 [D loss: 0.753852, acc.: 50.00%] [G loss: 1.299834] [Time: 0.246328]\n",
            "254-3 [D loss: 0.560674, acc.: 69.23%] [G loss: 2.180693] [Time: 0.246870]\n",
            "254-4 [D loss: 0.453536, acc.: 78.85%] [G loss: 1.621228] [Time: 0.244392]\n",
            "254-5 [D loss: 0.663971, acc.: 59.62%] [G loss: 1.323905] [Time: 0.244598]\n",
            "254-6 [D loss: 0.431535, acc.: 76.92%] [G loss: 1.957304] [Time: 0.247705]\n",
            "254-7 [D loss: 0.718469, acc.: 55.77%] [G loss: 1.721066] [Time: 0.246950]\n",
            "254-8 [D loss: 0.491851, acc.: 76.92%] [G loss: 1.747928] [Time: 0.246725]\n",
            "254 (test) [D loss: 1.501197, acc.: 50.00%] [G loss: 2.871058] [Time: 0.075722]\n",
            "255-0 [D loss: 0.485904, acc.: 69.23%] [G loss: 2.008783] [Time: 0.246439]\n",
            "255-1 [D loss: 0.593516, acc.: 69.23%] [G loss: 1.929233] [Time: 0.248194]\n",
            "255-2 [D loss: 0.685929, acc.: 65.38%] [G loss: 1.522323] [Time: 0.246722]\n",
            "255-3 [D loss: 0.496695, acc.: 75.00%] [G loss: 1.590115] [Time: 0.247381]\n",
            "255-4 [D loss: 0.587349, acc.: 69.23%] [G loss: 1.407979] [Time: 0.243085]\n",
            "255-5 [D loss: 0.568894, acc.: 71.15%] [G loss: 1.778981] [Time: 0.249530]\n",
            "255-6 [D loss: 0.529799, acc.: 73.08%] [G loss: 1.876417] [Time: 0.246441]\n",
            "255-7 [D loss: 0.583049, acc.: 69.23%] [G loss: 1.479762] [Time: 0.243486]\n",
            "255-8 [D loss: 0.404480, acc.: 84.62%] [G loss: 1.447584] [Time: 0.245167]\n",
            "255 (test) [D loss: 1.447942, acc.: 50.00%] [G loss: 2.760379] [Time: 0.075305]\n",
            "256-0 [D loss: 0.267589, acc.: 94.23%] [G loss: 1.950514] [Time: 0.249646]\n",
            "256-1 [D loss: 0.527529, acc.: 76.92%] [G loss: 1.548291] [Time: 0.248733]\n",
            "256-2 [D loss: 0.805392, acc.: 50.00%] [G loss: 1.611118] [Time: 0.244066]\n",
            "256-3 [D loss: 0.423843, acc.: 80.77%] [G loss: 1.771683] [Time: 0.247429]\n",
            "256-4 [D loss: 0.507818, acc.: 71.15%] [G loss: 1.938985] [Time: 0.246111]\n",
            "256-5 [D loss: 0.488684, acc.: 76.92%] [G loss: 1.426195] [Time: 0.249524]\n",
            "256-6 [D loss: 0.592324, acc.: 71.15%] [G loss: 1.672134] [Time: 0.248723]\n",
            "256-7 [D loss: 0.607493, acc.: 69.23%] [G loss: 1.323163] [Time: 0.244404]\n",
            "256-8 [D loss: 0.466669, acc.: 80.77%] [G loss: 1.745534] [Time: 0.246807]\n",
            "256 (test) [D loss: 1.522337, acc.: 50.00%] [G loss: 2.919011] [Time: 0.077403]\n",
            "257-0 [D loss: 0.394515, acc.: 80.77%] [G loss: 1.972147] [Time: 0.244466]\n",
            "257-1 [D loss: 0.642075, acc.: 67.31%] [G loss: 1.546490] [Time: 0.251621]\n",
            "257-2 [D loss: 0.762263, acc.: 55.77%] [G loss: 1.546768] [Time: 0.244589]\n",
            "257-3 [D loss: 0.489849, acc.: 73.08%] [G loss: 2.101308] [Time: 0.245565]\n",
            "257-4 [D loss: 0.609051, acc.: 63.46%] [G loss: 1.820224] [Time: 0.245922]\n",
            "257-5 [D loss: 0.571841, acc.: 67.31%] [G loss: 1.559371] [Time: 0.245319]\n",
            "257-6 [D loss: 0.491087, acc.: 78.85%] [G loss: 1.743070] [Time: 0.245606]\n",
            "257-7 [D loss: 0.571848, acc.: 69.23%] [G loss: 1.611718] [Time: 0.242338]\n",
            "257-8 [D loss: 0.394109, acc.: 82.69%] [G loss: 1.661201] [Time: 0.250698]\n",
            "257 (test) [D loss: 1.442470, acc.: 50.00%] [G loss: 2.762050] [Time: 0.081498]\n",
            "258-0 [D loss: 0.354886, acc.: 82.69%] [G loss: 2.122256] [Time: 0.245456]\n",
            "258-1 [D loss: 0.581680, acc.: 65.38%] [G loss: 1.616584] [Time: 0.247193]\n",
            "258-2 [D loss: 0.784121, acc.: 48.08%] [G loss: 1.431539] [Time: 0.242743]\n",
            "258-3 [D loss: 0.420464, acc.: 82.69%] [G loss: 1.893195] [Time: 0.245389]\n",
            "258-4 [D loss: 0.515655, acc.: 73.08%] [G loss: 1.700114] [Time: 0.244401]\n",
            "258-5 [D loss: 0.633353, acc.: 63.46%] [G loss: 1.511407] [Time: 0.245672]\n",
            "258-6 [D loss: 0.473006, acc.: 80.77%] [G loss: 1.656732] [Time: 0.245249]\n",
            "258-7 [D loss: 0.648031, acc.: 69.23%] [G loss: 1.511604] [Time: 0.246620]\n",
            "258-8 [D loss: 0.451397, acc.: 76.92%] [G loss: 1.640557] [Time: 0.245452]\n",
            "258 (test) [D loss: 1.469750, acc.: 50.00%] [G loss: 2.807668] [Time: 0.077037]\n",
            "259-0 [D loss: 0.283729, acc.: 90.38%] [G loss: 1.915995] [Time: 0.246724]\n",
            "259-1 [D loss: 0.627495, acc.: 63.46%] [G loss: 1.473136] [Time: 0.248452]\n",
            "259-2 [D loss: 0.693461, acc.: 55.77%] [G loss: 1.271529] [Time: 0.243701]\n",
            "259-3 [D loss: 0.464044, acc.: 76.92%] [G loss: 1.929572] [Time: 0.245185]\n",
            "259-4 [D loss: 0.573369, acc.: 67.31%] [G loss: 1.819767] [Time: 0.245692]\n",
            "259-5 [D loss: 0.590362, acc.: 69.23%] [G loss: 1.892751] [Time: 0.247065]\n",
            "259-6 [D loss: 0.487872, acc.: 75.00%] [G loss: 1.656845] [Time: 0.245441]\n",
            "259-7 [D loss: 0.631707, acc.: 63.46%] [G loss: 1.327420] [Time: 0.247078]\n",
            "259-8 [D loss: 0.385699, acc.: 80.77%] [G loss: 2.021517] [Time: 0.246357]\n",
            "259 (test) [D loss: 1.396719, acc.: 50.00%] [G loss: 2.657814] [Time: 0.076859]\n",
            "260-0 [D loss: 0.352464, acc.: 86.54%] [G loss: 1.931479] [Time: 0.243206]\n",
            "260-1 [D loss: 0.613700, acc.: 69.23%] [G loss: 1.829644] [Time: 0.244007]\n",
            "260-2 [D loss: 0.691400, acc.: 55.77%] [G loss: 1.380297] [Time: 0.247672]\n",
            "260-3 [D loss: 0.516045, acc.: 73.08%] [G loss: 2.097999] [Time: 0.242388]\n",
            "260-4 [D loss: 0.479107, acc.: 80.77%] [G loss: 1.881547] [Time: 0.246943]\n",
            "260-5 [D loss: 0.648779, acc.: 61.54%] [G loss: 1.594274] [Time: 0.241413]\n",
            "260-6 [D loss: 0.561188, acc.: 63.46%] [G loss: 1.815625] [Time: 0.246039]\n",
            "260-7 [D loss: 0.524611, acc.: 69.23%] [G loss: 1.894179] [Time: 0.247957]\n",
            "260-8 [D loss: 0.561845, acc.: 71.15%] [G loss: 1.707418] [Time: 0.250094]\n",
            "260 (test) [D loss: 1.453947, acc.: 50.00%] [G loss: 2.771679] [Time: 0.077454]\n",
            "261-0 [D loss: 0.431254, acc.: 84.62%] [G loss: 2.199106] [Time: 0.245960]\n",
            "261-1 [D loss: 0.477891, acc.: 80.77%] [G loss: 1.637580] [Time: 0.240346]\n",
            "261-2 [D loss: 0.855305, acc.: 44.23%] [G loss: 1.535895] [Time: 0.245071]\n",
            "261-3 [D loss: 0.564968, acc.: 69.23%] [G loss: 1.989756] [Time: 0.249368]\n",
            "261-4 [D loss: 0.404358, acc.: 86.54%] [G loss: 1.948698] [Time: 0.246318]\n",
            "261-5 [D loss: 0.614046, acc.: 67.31%] [G loss: 1.954956] [Time: 0.245437]\n",
            "261-6 [D loss: 0.486914, acc.: 78.85%] [G loss: 1.589172] [Time: 0.243435]\n",
            "261-7 [D loss: 0.560507, acc.: 63.46%] [G loss: 1.200716] [Time: 0.245459]\n",
            "261-8 [D loss: 0.469764, acc.: 78.85%] [G loss: 2.111406] [Time: 0.245199]\n",
            "261 (test) [D loss: 1.441161, acc.: 50.00%] [G loss: 2.744981] [Time: 0.080152]\n",
            "262-0 [D loss: 0.358007, acc.: 86.54%] [G loss: 2.098680] [Time: 0.243378]\n",
            "262-1 [D loss: 0.548506, acc.: 73.08%] [G loss: 1.478887] [Time: 0.247186]\n",
            "262-2 [D loss: 0.848325, acc.: 46.15%] [G loss: 1.355369] [Time: 0.243657]\n",
            "262-3 [D loss: 0.499836, acc.: 76.92%] [G loss: 1.916413] [Time: 0.244283]\n",
            "262-4 [D loss: 0.578756, acc.: 67.31%] [G loss: 1.587625] [Time: 0.246121]\n",
            "262-5 [D loss: 0.564860, acc.: 65.38%] [G loss: 1.651035] [Time: 0.247099]\n",
            "262-6 [D loss: 0.554754, acc.: 75.00%] [G loss: 1.681199] [Time: 0.244880]\n",
            "262-7 [D loss: 0.492047, acc.: 84.62%] [G loss: 1.531791] [Time: 0.246633]\n",
            "262-8 [D loss: 0.391197, acc.: 82.69%] [G loss: 1.616676] [Time: 0.249367]\n",
            "262 (test) [D loss: 1.462218, acc.: 50.00%] [G loss: 2.783874] [Time: 0.074703]\n",
            "263-0 [D loss: 0.444839, acc.: 82.69%] [G loss: 1.946900] [Time: 0.246740]\n",
            "263-1 [D loss: 0.518087, acc.: 67.31%] [G loss: 1.422539] [Time: 0.245988]\n",
            "263-2 [D loss: 0.760001, acc.: 57.69%] [G loss: 1.453852] [Time: 0.246280]\n",
            "263-3 [D loss: 0.528744, acc.: 73.08%] [G loss: 2.169219] [Time: 0.247866]\n",
            "263-4 [D loss: 0.523451, acc.: 75.00%] [G loss: 1.662352] [Time: 0.246358]\n",
            "263-5 [D loss: 0.663837, acc.: 69.23%] [G loss: 1.658339] [Time: 0.243556]\n",
            "263-6 [D loss: 0.522191, acc.: 69.23%] [G loss: 1.981686] [Time: 0.247271]\n",
            "263-7 [D loss: 0.598067, acc.: 67.31%] [G loss: 1.267272] [Time: 0.242778]\n",
            "263-8 [D loss: 0.587400, acc.: 69.23%] [G loss: 1.486427] [Time: 0.242031]\n",
            "263 (test) [D loss: 1.452847, acc.: 50.00%] [G loss: 2.767474] [Time: 0.079616]\n",
            "264-0 [D loss: 0.309483, acc.: 82.69%] [G loss: 2.171563] [Time: 0.248745]\n",
            "264-1 [D loss: 0.550233, acc.: 71.15%] [G loss: 1.426227] [Time: 0.244373]\n",
            "264-2 [D loss: 0.710363, acc.: 53.85%] [G loss: 1.228240] [Time: 0.245275]\n",
            "264-3 [D loss: 0.507235, acc.: 78.85%] [G loss: 1.916914] [Time: 0.247499]\n",
            "264-4 [D loss: 0.509293, acc.: 76.92%] [G loss: 1.735792] [Time: 0.247601]\n",
            "264-5 [D loss: 0.615254, acc.: 67.31%] [G loss: 1.475970] [Time: 0.244761]\n",
            "264-6 [D loss: 0.489525, acc.: 73.08%] [G loss: 1.516223] [Time: 0.243146]\n",
            "264-7 [D loss: 0.619657, acc.: 59.62%] [G loss: 1.618437] [Time: 0.247970]\n",
            "264-8 [D loss: 0.393013, acc.: 86.54%] [G loss: 1.721138] [Time: 0.248673]\n",
            "264 (test) [D loss: 1.583844, acc.: 50.00%] [G loss: 3.048034] [Time: 0.078699]\n",
            "265-0 [D loss: 0.295741, acc.: 94.23%] [G loss: 2.114140] [Time: 0.248385]\n",
            "265-1 [D loss: 0.584589, acc.: 65.38%] [G loss: 1.586726] [Time: 0.247965]\n",
            "265-2 [D loss: 0.794485, acc.: 42.31%] [G loss: 1.798039] [Time: 0.247128]\n",
            "265-3 [D loss: 0.644923, acc.: 63.46%] [G loss: 1.712019] [Time: 0.243210]\n",
            "265-4 [D loss: 0.499128, acc.: 78.85%] [G loss: 1.632979] [Time: 0.246068]\n",
            "265-5 [D loss: 0.691148, acc.: 61.54%] [G loss: 1.740081] [Time: 0.244571]\n",
            "265-6 [D loss: 0.543519, acc.: 69.23%] [G loss: 1.542557] [Time: 0.245557]\n",
            "265-7 [D loss: 0.648785, acc.: 59.62%] [G loss: 1.372106] [Time: 0.244584]\n",
            "265-8 [D loss: 0.409511, acc.: 82.69%] [G loss: 1.525380] [Time: 0.245825]\n",
            "265 (test) [D loss: 1.519523, acc.: 50.00%] [G loss: 2.904123] [Time: 0.075063]\n",
            "266-0 [D loss: 0.337180, acc.: 90.38%] [G loss: 1.942474] [Time: 0.249287]\n",
            "266-1 [D loss: 0.486421, acc.: 80.77%] [G loss: 1.386901] [Time: 0.242680]\n",
            "266-2 [D loss: 0.752688, acc.: 48.08%] [G loss: 1.420518] [Time: 0.243507]\n",
            "266-3 [D loss: 0.519120, acc.: 71.15%] [G loss: 1.973747] [Time: 0.250682]\n",
            "266-4 [D loss: 0.576901, acc.: 73.08%] [G loss: 1.986329] [Time: 0.242641]\n",
            "266-5 [D loss: 0.547974, acc.: 69.23%] [G loss: 1.630563] [Time: 0.245589]\n",
            "266-6 [D loss: 0.513758, acc.: 71.15%] [G loss: 1.722023] [Time: 0.246627]\n",
            "266-7 [D loss: 0.593571, acc.: 67.31%] [G loss: 1.413494] [Time: 0.245112]\n",
            "266-8 [D loss: 0.544297, acc.: 71.15%] [G loss: 1.580496] [Time: 0.243958]\n",
            "266 (test) [D loss: 1.497410, acc.: 50.00%] [G loss: 2.862683] [Time: 0.077935]\n",
            "267-0 [D loss: 0.365818, acc.: 86.54%] [G loss: 2.184314] [Time: 0.249424]\n",
            "267-1 [D loss: 0.578751, acc.: 69.23%] [G loss: 1.690738] [Time: 0.251000]\n",
            "267-2 [D loss: 0.776212, acc.: 55.77%] [G loss: 1.635664] [Time: 0.244867]\n",
            "267-3 [D loss: 0.544872, acc.: 65.38%] [G loss: 2.095183] [Time: 0.246371]\n",
            "267-4 [D loss: 0.508196, acc.: 71.15%] [G loss: 1.590001] [Time: 0.250723]\n",
            "267-5 [D loss: 0.654630, acc.: 57.69%] [G loss: 1.772667] [Time: 0.244456]\n",
            "267-6 [D loss: 0.556984, acc.: 73.08%] [G loss: 1.742056] [Time: 0.246814]\n",
            "267-7 [D loss: 0.595796, acc.: 69.23%] [G loss: 1.281266] [Time: 0.246170]\n",
            "267-8 [D loss: 0.431052, acc.: 76.92%] [G loss: 1.757842] [Time: 0.244578]\n",
            "267 (test) [D loss: 1.520684, acc.: 50.00%] [G loss: 2.905442] [Time: 0.077730]\n",
            "268-0 [D loss: 0.314601, acc.: 90.38%] [G loss: 1.827940] [Time: 0.252113]\n",
            "268-1 [D loss: 0.549366, acc.: 71.15%] [G loss: 1.522969] [Time: 0.243545]\n",
            "268-2 [D loss: 0.748473, acc.: 48.08%] [G loss: 1.316886] [Time: 0.245747]\n",
            "268-3 [D loss: 0.411797, acc.: 82.69%] [G loss: 2.119649] [Time: 0.248267]\n",
            "268-4 [D loss: 0.477960, acc.: 78.85%] [G loss: 1.797781] [Time: 0.245268]\n",
            "268-5 [D loss: 0.651319, acc.: 61.54%] [G loss: 1.743731] [Time: 0.245879]\n",
            "268-6 [D loss: 0.467417, acc.: 78.85%] [G loss: 1.830704] [Time: 0.248181]\n",
            "268-7 [D loss: 0.613017, acc.: 65.38%] [G loss: 1.427369] [Time: 0.243275]\n",
            "268-8 [D loss: 0.604863, acc.: 73.08%] [G loss: 1.757100] [Time: 0.244536]\n",
            "268 (test) [D loss: 1.438616, acc.: 50.00%] [G loss: 2.743134] [Time: 0.079459]\n",
            "269-0 [D loss: 0.335470, acc.: 90.38%] [G loss: 2.112592] [Time: 0.245673]\n",
            "269-1 [D loss: 0.489619, acc.: 73.08%] [G loss: 1.535544] [Time: 0.248112]\n",
            "269-2 [D loss: 0.806776, acc.: 46.15%] [G loss: 1.319356] [Time: 0.244263]\n",
            "269-3 [D loss: 0.414361, acc.: 80.77%] [G loss: 2.216400] [Time: 0.243332]\n",
            "269-4 [D loss: 0.627910, acc.: 55.77%] [G loss: 1.570267] [Time: 0.251272]\n",
            "269-5 [D loss: 0.604951, acc.: 65.38%] [G loss: 1.686879] [Time: 0.249135]\n",
            "269-6 [D loss: 0.519274, acc.: 69.23%] [G loss: 1.841105] [Time: 0.247122]\n",
            "269-7 [D loss: 0.678561, acc.: 55.77%] [G loss: 1.707521] [Time: 0.248751]\n",
            "269-8 [D loss: 0.564744, acc.: 75.00%] [G loss: 1.717345] [Time: 0.244756]\n",
            "269 (test) [D loss: 1.521217, acc.: 50.00%] [G loss: 2.909899] [Time: 0.075382]\n",
            "270-0 [D loss: 0.419614, acc.: 78.85%] [G loss: 2.242832] [Time: 0.248631]\n",
            "270-1 [D loss: 0.533362, acc.: 75.00%] [G loss: 1.567621] [Time: 0.247067]\n",
            "270-2 [D loss: 0.729572, acc.: 57.69%] [G loss: 1.306419] [Time: 0.247568]\n",
            "270-3 [D loss: 0.575165, acc.: 67.31%] [G loss: 1.632334] [Time: 0.249419]\n",
            "270-4 [D loss: 0.520266, acc.: 67.31%] [G loss: 1.735384] [Time: 0.246670]\n",
            "270-5 [D loss: 0.724000, acc.: 55.77%] [G loss: 1.443035] [Time: 0.247192]\n",
            "270-6 [D loss: 0.430200, acc.: 82.69%] [G loss: 1.696361] [Time: 0.247146]\n",
            "270-7 [D loss: 0.658008, acc.: 51.92%] [G loss: 1.375132] [Time: 0.245567]\n",
            "270-8 [D loss: 0.533054, acc.: 75.00%] [G loss: 1.620362] [Time: 0.245147]\n",
            "270 (test) [D loss: 1.487028, acc.: 50.00%] [G loss: 2.842245] [Time: 0.078808]\n",
            "271-0 [D loss: 0.260938, acc.: 98.08%] [G loss: 2.125835] [Time: 0.246283]\n",
            "271-1 [D loss: 0.513991, acc.: 71.15%] [G loss: 1.239154] [Time: 0.247369]\n",
            "271-2 [D loss: 0.897590, acc.: 44.23%] [G loss: 1.269182] [Time: 0.245188]\n",
            "271-3 [D loss: 0.373285, acc.: 84.62%] [G loss: 2.093935] [Time: 0.244199]\n",
            "271-4 [D loss: 0.491014, acc.: 73.08%] [G loss: 1.689098] [Time: 0.248979]\n",
            "271-5 [D loss: 0.671343, acc.: 55.77%] [G loss: 1.756148] [Time: 0.248403]\n",
            "271-6 [D loss: 0.490627, acc.: 75.00%] [G loss: 1.915765] [Time: 0.243343]\n",
            "271-7 [D loss: 0.563552, acc.: 67.31%] [G loss: 1.859735] [Time: 0.243165]\n",
            "271-8 [D loss: 0.416359, acc.: 80.77%] [G loss: 1.758179] [Time: 0.249768]\n",
            "271 (test) [D loss: 1.488796, acc.: 50.00%] [G loss: 2.837510] [Time: 0.076559]\n",
            "272-0 [D loss: 0.301603, acc.: 98.08%] [G loss: 1.990334] [Time: 0.247480]\n",
            "272-1 [D loss: 0.450581, acc.: 78.85%] [G loss: 1.620643] [Time: 0.247089]\n",
            "272-2 [D loss: 0.746583, acc.: 53.85%] [G loss: 1.299903] [Time: 0.246026]\n",
            "272-3 [D loss: 0.525513, acc.: 71.15%] [G loss: 1.772560] [Time: 0.251306]\n",
            "272-4 [D loss: 0.500558, acc.: 67.31%] [G loss: 1.873398] [Time: 0.246584]\n",
            "272-5 [D loss: 0.546968, acc.: 71.15%] [G loss: 1.947378] [Time: 0.246671]\n",
            "272-6 [D loss: 0.550906, acc.: 75.00%] [G loss: 1.650627] [Time: 0.243486]\n",
            "272-7 [D loss: 0.669277, acc.: 59.62%] [G loss: 1.296149] [Time: 0.246304]\n",
            "272-8 [D loss: 0.451384, acc.: 78.85%] [G loss: 1.678389] [Time: 0.248402]\n",
            "272 (test) [D loss: 1.526102, acc.: 50.00%] [G loss: 2.914656] [Time: 0.079528]\n",
            "273-0 [D loss: 0.315542, acc.: 90.38%] [G loss: 2.180886] [Time: 0.248956]\n",
            "273-1 [D loss: 0.531552, acc.: 75.00%] [G loss: 1.543912] [Time: 0.249468]\n",
            "273-2 [D loss: 0.845005, acc.: 44.23%] [G loss: 1.395579] [Time: 0.248966]\n",
            "273-3 [D loss: 0.495190, acc.: 78.85%] [G loss: 2.202891] [Time: 0.249030]\n",
            "273-4 [D loss: 0.481394, acc.: 73.08%] [G loss: 1.855474] [Time: 0.245836]\n",
            "273-5 [D loss: 0.569377, acc.: 67.31%] [G loss: 1.791350] [Time: 0.250150]\n",
            "273-6 [D loss: 0.409674, acc.: 84.62%] [G loss: 1.475510] [Time: 0.248590]\n",
            "273-7 [D loss: 0.570062, acc.: 67.31%] [G loss: 1.617114] [Time: 0.245168]\n",
            "273-8 [D loss: 0.527596, acc.: 75.00%] [G loss: 1.937074] [Time: 0.250597]\n",
            "273 (test) [D loss: 1.514509, acc.: 50.00%] [G loss: 2.896215] [Time: 0.081241]\n",
            "274-0 [D loss: 0.311452, acc.: 92.31%] [G loss: 2.070530] [Time: 0.246911]\n",
            "274-1 [D loss: 0.491301, acc.: 75.00%] [G loss: 1.353101] [Time: 0.249755]\n",
            "274-2 [D loss: 0.761179, acc.: 55.77%] [G loss: 1.362791] [Time: 0.246504]\n",
            "274-3 [D loss: 0.406986, acc.: 82.69%] [G loss: 2.201776] [Time: 0.250074]\n",
            "274-4 [D loss: 0.536004, acc.: 75.00%] [G loss: 1.494375] [Time: 0.245112]\n",
            "274-5 [D loss: 0.472970, acc.: 80.77%] [G loss: 1.811189] [Time: 0.246159]\n",
            "274-6 [D loss: 0.426072, acc.: 84.62%] [G loss: 1.861011] [Time: 0.246297]\n",
            "274-7 [D loss: 0.606199, acc.: 67.31%] [G loss: 1.545405] [Time: 0.243263]\n",
            "274-8 [D loss: 0.504743, acc.: 75.00%] [G loss: 1.827289] [Time: 0.251017]\n",
            "274 (test) [D loss: 1.569656, acc.: 50.00%] [G loss: 3.017597] [Time: 0.078345]\n",
            "275-0 [D loss: 0.349474, acc.: 90.38%] [G loss: 1.954135] [Time: 0.243491]\n",
            "275-1 [D loss: 0.479344, acc.: 80.77%] [G loss: 1.598650] [Time: 0.246892]\n",
            "275-2 [D loss: 0.776614, acc.: 53.85%] [G loss: 1.311294] [Time: 0.248535]\n",
            "275-3 [D loss: 0.520489, acc.: 73.08%] [G loss: 1.693028] [Time: 0.250735]\n",
            "275-4 [D loss: 0.554766, acc.: 69.23%] [G loss: 1.719877] [Time: 0.248270]\n",
            "275-5 [D loss: 0.637794, acc.: 61.54%] [G loss: 1.464621] [Time: 0.250099]\n",
            "275-6 [D loss: 0.503713, acc.: 67.31%] [G loss: 1.656939] [Time: 0.247377]\n",
            "275-7 [D loss: 0.587742, acc.: 65.38%] [G loss: 1.671653] [Time: 0.245433]\n",
            "275-8 [D loss: 0.665303, acc.: 59.62%] [G loss: 1.789651] [Time: 0.251166]\n",
            "275 (test) [D loss: 1.476069, acc.: 50.00%] [G loss: 2.802352] [Time: 0.078270]\n",
            "276-0 [D loss: 0.288859, acc.: 96.15%] [G loss: 1.749626] [Time: 0.245874]\n",
            "276-1 [D loss: 0.613872, acc.: 65.38%] [G loss: 1.464949] [Time: 0.248868]\n",
            "276-2 [D loss: 0.748178, acc.: 50.00%] [G loss: 1.449298] [Time: 0.246006]\n",
            "276-3 [D loss: 0.473629, acc.: 76.92%] [G loss: 1.899706] [Time: 0.249233]\n",
            "276-4 [D loss: 0.560451, acc.: 78.85%] [G loss: 1.568016] [Time: 0.244678]\n",
            "276-5 [D loss: 0.606457, acc.: 61.54%] [G loss: 1.623702] [Time: 0.243732]\n",
            "276-6 [D loss: 0.508097, acc.: 73.08%] [G loss: 1.865444] [Time: 0.249034]\n",
            "276-7 [D loss: 0.587077, acc.: 63.46%] [G loss: 1.630642] [Time: 0.247742]\n",
            "276-8 [D loss: 0.480568, acc.: 75.00%] [G loss: 1.663188] [Time: 0.249831]\n",
            "276 (test) [D loss: 1.512383, acc.: 50.00%] [G loss: 2.892100] [Time: 0.076540]\n",
            "277-0 [D loss: 0.301759, acc.: 92.31%] [G loss: 1.571285] [Time: 0.248101]\n",
            "277-1 [D loss: 0.499632, acc.: 80.77%] [G loss: 1.520595] [Time: 0.249428]\n",
            "277-2 [D loss: 0.769298, acc.: 46.15%] [G loss: 1.352303] [Time: 0.248585]\n",
            "277-3 [D loss: 0.562995, acc.: 61.54%] [G loss: 1.825443] [Time: 0.249272]\n",
            "277-4 [D loss: 0.505573, acc.: 75.00%] [G loss: 1.720068] [Time: 0.246551]\n",
            "277-5 [D loss: 0.574257, acc.: 69.23%] [G loss: 1.636484] [Time: 0.246020]\n",
            "277-6 [D loss: 0.603468, acc.: 59.62%] [G loss: 1.643624] [Time: 0.245175]\n",
            "277-7 [D loss: 0.556093, acc.: 75.00%] [G loss: 1.467226] [Time: 0.248916]\n",
            "277-8 [D loss: 0.443617, acc.: 73.08%] [G loss: 1.718409] [Time: 0.247787]\n",
            "277 (test) [D loss: 1.525946, acc.: 50.00%] [G loss: 2.918968] [Time: 0.076013]\n",
            "278-0 [D loss: 0.356705, acc.: 88.46%] [G loss: 1.850944] [Time: 0.244538]\n",
            "278-1 [D loss: 0.659167, acc.: 57.69%] [G loss: 1.426087] [Time: 0.248653]\n",
            "278-2 [D loss: 0.623057, acc.: 57.69%] [G loss: 1.707494] [Time: 0.245606]\n",
            "278-3 [D loss: 0.408916, acc.: 84.62%] [G loss: 1.796712] [Time: 0.245245]\n",
            "278-4 [D loss: 0.611884, acc.: 65.38%] [G loss: 1.798424] [Time: 0.247453]\n",
            "278-5 [D loss: 0.669646, acc.: 63.46%] [G loss: 1.841481] [Time: 0.248100]\n",
            "278-6 [D loss: 0.575016, acc.: 67.31%] [G loss: 1.790981] [Time: 0.244173]\n",
            "278-7 [D loss: 0.561246, acc.: 69.23%] [G loss: 1.514873] [Time: 0.247469]\n",
            "278-8 [D loss: 0.412503, acc.: 82.69%] [G loss: 1.742917] [Time: 0.250578]\n",
            "278 (test) [D loss: 1.574791, acc.: 50.00%] [G loss: 3.025718] [Time: 0.075773]\n",
            "279-0 [D loss: 0.349362, acc.: 84.62%] [G loss: 1.880573] [Time: 0.249153]\n",
            "279-1 [D loss: 0.479713, acc.: 80.77%] [G loss: 1.414880] [Time: 0.246685]\n",
            "279-2 [D loss: 0.799520, acc.: 51.92%] [G loss: 1.436062] [Time: 0.245329]\n",
            "279-3 [D loss: 0.433637, acc.: 73.08%] [G loss: 2.049303] [Time: 0.248510]\n",
            "279-4 [D loss: 0.430978, acc.: 80.77%] [G loss: 1.711930] [Time: 0.247352]\n",
            "279-5 [D loss: 0.590563, acc.: 67.31%] [G loss: 1.741384] [Time: 0.247889]\n",
            "279-6 [D loss: 0.551884, acc.: 73.08%] [G loss: 1.664245] [Time: 0.248483]\n",
            "279-7 [D loss: 0.551426, acc.: 76.92%] [G loss: 1.539681] [Time: 0.245371]\n",
            "279-8 [D loss: 0.431670, acc.: 80.77%] [G loss: 1.793468] [Time: 0.251234]\n",
            "279 (test) [D loss: 1.570766, acc.: 50.00%] [G loss: 3.011088] [Time: 0.077411]\n",
            "280-0 [D loss: 0.366496, acc.: 84.62%] [G loss: 2.096890] [Time: 0.244860]\n",
            "280-1 [D loss: 0.518766, acc.: 78.85%] [G loss: 1.529639] [Time: 0.250163]\n",
            "280-2 [D loss: 0.819690, acc.: 51.92%] [G loss: 1.329696] [Time: 0.243115]\n",
            "280-3 [D loss: 0.388378, acc.: 84.62%] [G loss: 2.055050] [Time: 0.246832]\n",
            "280-4 [D loss: 0.599498, acc.: 69.23%] [G loss: 1.628808] [Time: 0.247606]\n",
            "280-5 [D loss: 0.477801, acc.: 82.69%] [G loss: 1.626109] [Time: 0.247126]\n",
            "280-6 [D loss: 0.559955, acc.: 69.23%] [G loss: 1.920270] [Time: 0.247232]\n",
            "280-7 [D loss: 0.618590, acc.: 59.62%] [G loss: 1.621067] [Time: 0.245788]\n",
            "280-8 [D loss: 0.545658, acc.: 73.08%] [G loss: 1.640388] [Time: 0.249706]\n",
            "280 (test) [D loss: 1.537484, acc.: 50.00%] [G loss: 2.941332] [Time: 0.076102]\n",
            "281-0 [D loss: 0.255958, acc.: 92.31%] [G loss: 1.863984] [Time: 0.249305]\n",
            "281-1 [D loss: 0.518345, acc.: 75.00%] [G loss: 1.480380] [Time: 0.244665]\n",
            "281-2 [D loss: 0.777339, acc.: 50.00%] [G loss: 1.410016] [Time: 0.247319]\n",
            "281-3 [D loss: 0.478604, acc.: 76.92%] [G loss: 2.047660] [Time: 0.247805]\n",
            "281-4 [D loss: 0.515453, acc.: 75.00%] [G loss: 1.756839] [Time: 0.251734]\n",
            "281-5 [D loss: 0.707752, acc.: 59.62%] [G loss: 1.351698] [Time: 0.244893]\n",
            "281-6 [D loss: 0.496613, acc.: 69.23%] [G loss: 1.925829] [Time: 0.249557]\n",
            "281-7 [D loss: 0.581479, acc.: 73.08%] [G loss: 1.442504] [Time: 0.250983]\n",
            "281-8 [D loss: 0.444014, acc.: 78.85%] [G loss: 1.715339] [Time: 0.246439]\n",
            "281 (test) [D loss: 1.523010, acc.: 50.00%] [G loss: 2.909531] [Time: 0.075795]\n",
            "282-0 [D loss: 0.360210, acc.: 88.46%] [G loss: 1.927417] [Time: 0.247842]\n",
            "282-1 [D loss: 0.501995, acc.: 71.15%] [G loss: 1.274376] [Time: 0.251546]\n",
            "282-2 [D loss: 0.909052, acc.: 42.31%] [G loss: 1.251394] [Time: 0.247914]\n",
            "282-3 [D loss: 0.530392, acc.: 73.08%] [G loss: 1.759670] [Time: 0.249922]\n",
            "282-4 [D loss: 0.688996, acc.: 63.46%] [G loss: 1.532565] [Time: 0.246061]\n",
            "282-5 [D loss: 0.555044, acc.: 67.31%] [G loss: 1.683966] [Time: 0.249399]\n",
            "282-6 [D loss: 0.427114, acc.: 84.62%] [G loss: 1.745022] [Time: 0.245419]\n",
            "282-7 [D loss: 0.646611, acc.: 63.46%] [G loss: 1.739873] [Time: 0.250868]\n",
            "282-8 [D loss: 0.418288, acc.: 84.62%] [G loss: 1.974367] [Time: 0.245474]\n",
            "282 (test) [D loss: 1.604017, acc.: 50.00%] [G loss: 3.089331] [Time: 0.077879]\n",
            "283-0 [D loss: 0.331684, acc.: 90.38%] [G loss: 2.288733] [Time: 0.249945]\n",
            "283-1 [D loss: 0.546942, acc.: 71.15%] [G loss: 1.583585] [Time: 0.249898]\n",
            "283-2 [D loss: 0.844096, acc.: 46.15%] [G loss: 1.199516] [Time: 0.246246]\n",
            "283-3 [D loss: 0.431440, acc.: 84.62%] [G loss: 2.118980] [Time: 0.248355]\n",
            "283-4 [D loss: 0.641361, acc.: 65.38%] [G loss: 1.623557] [Time: 0.246748]\n",
            "283-5 [D loss: 0.567390, acc.: 67.31%] [G loss: 1.601867] [Time: 0.244349]\n",
            "283-6 [D loss: 0.491274, acc.: 73.08%] [G loss: 2.002885] [Time: 0.245933]\n",
            "283-7 [D loss: 0.626681, acc.: 48.08%] [G loss: 1.577373] [Time: 0.253469]\n",
            "283-8 [D loss: 0.501507, acc.: 73.08%] [G loss: 1.877412] [Time: 0.245383]\n",
            "283 (test) [D loss: 1.605975, acc.: 50.00%] [G loss: 3.110047] [Time: 0.076799]\n",
            "284-0 [D loss: 0.405956, acc.: 84.62%] [G loss: 2.096614] [Time: 0.251063]\n",
            "284-1 [D loss: 0.665304, acc.: 65.38%] [G loss: 1.586201] [Time: 0.247119]\n",
            "284-2 [D loss: 0.689799, acc.: 48.08%] [G loss: 1.409828] [Time: 0.245274]\n",
            "284-3 [D loss: 0.468862, acc.: 82.69%] [G loss: 1.822781] [Time: 0.246160]\n",
            "284-4 [D loss: 0.532213, acc.: 71.15%] [G loss: 1.761419] [Time: 0.243911]\n",
            "284-5 [D loss: 0.512594, acc.: 76.92%] [G loss: 1.565745] [Time: 0.251951]\n",
            "284-6 [D loss: 0.516382, acc.: 73.08%] [G loss: 1.891238] [Time: 0.245998]\n",
            "284-7 [D loss: 0.658576, acc.: 65.38%] [G loss: 1.422645] [Time: 0.247494]\n",
            "284-8 [D loss: 0.455567, acc.: 78.85%] [G loss: 1.796521] [Time: 0.243865]\n",
            "284 (test) [D loss: 1.564821, acc.: 50.00%] [G loss: 2.995033] [Time: 0.077107]\n",
            "285-0 [D loss: 0.381003, acc.: 84.62%] [G loss: 2.476344] [Time: 0.249593]\n",
            "285-1 [D loss: 0.535528, acc.: 69.23%] [G loss: 1.600635] [Time: 0.244036]\n",
            "285-2 [D loss: 0.829526, acc.: 44.23%] [G loss: 1.301953] [Time: 0.243830]\n",
            "285-3 [D loss: 0.446506, acc.: 75.00%] [G loss: 2.196133] [Time: 0.247293]\n",
            "285-4 [D loss: 0.502751, acc.: 75.00%] [G loss: 1.655543] [Time: 0.246997]\n",
            "285-5 [D loss: 0.577991, acc.: 69.23%] [G loss: 1.562243] [Time: 0.245942]\n",
            "285-6 [D loss: 0.582126, acc.: 69.23%] [G loss: 1.856620] [Time: 0.245321]\n",
            "285-7 [D loss: 0.618751, acc.: 65.38%] [G loss: 1.516673] [Time: 0.246285]\n",
            "285-8 [D loss: 0.426505, acc.: 78.85%] [G loss: 1.735391] [Time: 0.247512]\n",
            "285 (test) [D loss: 1.515850, acc.: 50.00%] [G loss: 2.896409] [Time: 0.077181]\n",
            "286-0 [D loss: 0.334193, acc.: 88.46%] [G loss: 2.061831] [Time: 0.247221]\n",
            "286-1 [D loss: 0.577495, acc.: 73.08%] [G loss: 1.325897] [Time: 0.247043]\n",
            "286-2 [D loss: 0.857368, acc.: 42.31%] [G loss: 1.275394] [Time: 0.247676]\n",
            "286-3 [D loss: 0.493864, acc.: 73.08%] [G loss: 2.242266] [Time: 0.245809]\n",
            "286-4 [D loss: 0.564812, acc.: 71.15%] [G loss: 1.973362] [Time: 0.243532]\n",
            "286-5 [D loss: 0.528413, acc.: 75.00%] [G loss: 1.794415] [Time: 0.247564]\n",
            "286-6 [D loss: 0.707453, acc.: 51.92%] [G loss: 1.416972] [Time: 0.245381]\n",
            "286-7 [D loss: 0.702138, acc.: 65.38%] [G loss: 1.313886] [Time: 0.244296]\n",
            "286-8 [D loss: 0.509038, acc.: 82.69%] [G loss: 1.686386] [Time: 0.254328]\n",
            "286 (test) [D loss: 1.577458, acc.: 50.00%] [G loss: 3.026656] [Time: 0.075847]\n",
            "287-0 [D loss: 0.344176, acc.: 84.62%] [G loss: 2.573500] [Time: 0.244615]\n",
            "287-1 [D loss: 0.624699, acc.: 69.23%] [G loss: 1.313861] [Time: 0.248657]\n",
            "287-2 [D loss: 0.743083, acc.: 57.69%] [G loss: 1.527083] [Time: 0.250929]\n",
            "287-3 [D loss: 0.504921, acc.: 71.15%] [G loss: 1.969519] [Time: 0.247934]\n",
            "287-4 [D loss: 0.474053, acc.: 78.85%] [G loss: 1.842985] [Time: 0.247529]\n",
            "287-5 [D loss: 0.597463, acc.: 67.31%] [G loss: 1.730116] [Time: 0.245537]\n",
            "287-6 [D loss: 0.508453, acc.: 78.85%] [G loss: 1.616572] [Time: 0.246015]\n",
            "287-7 [D loss: 0.622583, acc.: 65.38%] [G loss: 1.544879] [Time: 0.250102]\n",
            "287-8 [D loss: 0.470276, acc.: 78.85%] [G loss: 1.476417] [Time: 0.248026]\n",
            "287 (test) [D loss: 1.527880, acc.: 50.00%] [G loss: 2.919733] [Time: 0.075316]\n",
            "288-0 [D loss: 0.233143, acc.: 98.08%] [G loss: 1.992081] [Time: 0.248068]\n",
            "288-1 [D loss: 0.636873, acc.: 67.31%] [G loss: 1.481140] [Time: 0.247109]\n",
            "288-2 [D loss: 0.898941, acc.: 44.23%] [G loss: 1.311832] [Time: 0.249785]\n",
            "288-3 [D loss: 0.417831, acc.: 82.69%] [G loss: 1.786555] [Time: 0.244136]\n",
            "288-4 [D loss: 0.550127, acc.: 67.31%] [G loss: 1.529295] [Time: 0.246572]\n",
            "288-5 [D loss: 0.506548, acc.: 71.15%] [G loss: 1.489885] [Time: 0.248026]\n",
            "288-6 [D loss: 0.505660, acc.: 78.85%] [G loss: 1.662927] [Time: 0.244045]\n",
            "288-7 [D loss: 0.649399, acc.: 63.46%] [G loss: 1.573382] [Time: 0.246327]\n",
            "288-8 [D loss: 0.363070, acc.: 92.31%] [G loss: 1.613211] [Time: 0.244874]\n",
            "288 (test) [D loss: 1.632208, acc.: 50.00%] [G loss: 3.142194] [Time: 0.077839]\n",
            "289-0 [D loss: 0.269353, acc.: 96.15%] [G loss: 2.077497] [Time: 0.248319]\n",
            "289-1 [D loss: 0.576523, acc.: 69.23%] [G loss: 1.468495] [Time: 0.245525]\n",
            "289-2 [D loss: 0.875327, acc.: 46.15%] [G loss: 1.229847] [Time: 0.244496]\n",
            "289-3 [D loss: 0.517387, acc.: 76.92%] [G loss: 1.616795] [Time: 0.249825]\n",
            "289-4 [D loss: 0.562622, acc.: 71.15%] [G loss: 1.620242] [Time: 0.246072]\n",
            "289-5 [D loss: 0.585532, acc.: 65.38%] [G loss: 1.678805] [Time: 0.249484]\n",
            "289-6 [D loss: 0.437790, acc.: 80.77%] [G loss: 2.077527] [Time: 0.243836]\n",
            "289-7 [D loss: 0.629167, acc.: 59.62%] [G loss: 1.493479] [Time: 0.248171]\n",
            "289-8 [D loss: 0.565108, acc.: 75.00%] [G loss: 1.731326] [Time: 0.246450]\n",
            "289 (test) [D loss: 1.695728, acc.: 50.00%] [G loss: 3.279276] [Time: 0.077140]\n",
            "290-0 [D loss: 0.360443, acc.: 84.62%] [G loss: 2.228970] [Time: 0.247481]\n",
            "290-1 [D loss: 0.562291, acc.: 69.23%] [G loss: 1.386349] [Time: 0.250430]\n",
            "290-2 [D loss: 0.818897, acc.: 51.92%] [G loss: 1.338798] [Time: 0.244832]\n",
            "290-3 [D loss: 0.583812, acc.: 67.31%] [G loss: 2.233835] [Time: 0.246442]\n",
            "290-4 [D loss: 0.551098, acc.: 69.23%] [G loss: 1.626154] [Time: 0.242986]\n",
            "290-5 [D loss: 0.615373, acc.: 65.38%] [G loss: 1.451459] [Time: 0.246928]\n",
            "290-6 [D loss: 0.401872, acc.: 80.77%] [G loss: 1.705230] [Time: 0.244185]\n",
            "290-7 [D loss: 0.659983, acc.: 59.62%] [G loss: 1.336918] [Time: 0.245984]\n",
            "290-8 [D loss: 0.551787, acc.: 73.08%] [G loss: 1.684139] [Time: 0.250795]\n",
            "290 (test) [D loss: 1.622671, acc.: 50.00%] [G loss: 3.127370] [Time: 0.076268]\n",
            "291-0 [D loss: 0.286222, acc.: 90.38%] [G loss: 2.176523] [Time: 0.244859]\n",
            "291-1 [D loss: 0.612405, acc.: 63.46%] [G loss: 1.561261] [Time: 0.245155]\n",
            "291-2 [D loss: 0.711177, acc.: 53.85%] [G loss: 1.585498] [Time: 0.245160]\n",
            "291-3 [D loss: 0.560419, acc.: 69.23%] [G loss: 1.901209] [Time: 0.246618]\n",
            "291-4 [D loss: 0.563179, acc.: 65.38%] [G loss: 1.701174] [Time: 0.248139]\n",
            "291-5 [D loss: 0.775391, acc.: 53.85%] [G loss: 1.546196] [Time: 0.243993]\n",
            "291-6 [D loss: 0.473795, acc.: 73.08%] [G loss: 1.687446] [Time: 0.246920]\n",
            "291-7 [D loss: 0.497323, acc.: 80.77%] [G loss: 1.351026] [Time: 0.245677]\n",
            "291-8 [D loss: 0.535143, acc.: 71.15%] [G loss: 1.692539] [Time: 0.247617]\n",
            "291 (test) [D loss: 1.602092, acc.: 50.00%] [G loss: 3.068872] [Time: 0.075534]\n",
            "292-0 [D loss: 0.304393, acc.: 92.31%] [G loss: 2.282738] [Time: 0.247714]\n",
            "292-1 [D loss: 0.531603, acc.: 78.85%] [G loss: 1.752313] [Time: 0.246315]\n",
            "292-2 [D loss: 0.729747, acc.: 50.00%] [G loss: 1.496221] [Time: 0.246342]\n",
            "292-3 [D loss: 0.486820, acc.: 75.00%] [G loss: 1.888272] [Time: 0.249247]\n",
            "292-4 [D loss: 0.459477, acc.: 78.85%] [G loss: 1.904411] [Time: 0.244679]\n",
            "292-5 [D loss: 0.618437, acc.: 65.38%] [G loss: 1.544263] [Time: 0.245926]\n",
            "292-6 [D loss: 0.513197, acc.: 69.23%] [G loss: 1.808111] [Time: 0.247174]\n",
            "292-7 [D loss: 0.646441, acc.: 61.54%] [G loss: 1.435165] [Time: 0.250745]\n",
            "292-8 [D loss: 0.477227, acc.: 75.00%] [G loss: 1.912007] [Time: 0.247136]\n",
            "292 (test) [D loss: 1.583146, acc.: 50.00%] [G loss: 3.044502] [Time: 0.076238]\n",
            "293-0 [D loss: 0.257723, acc.: 92.31%] [G loss: 2.170696] [Time: 0.249766]\n",
            "293-1 [D loss: 0.517879, acc.: 73.08%] [G loss: 1.578011] [Time: 0.248625]\n",
            "293-2 [D loss: 0.852462, acc.: 38.46%] [G loss: 1.572725] [Time: 0.246458]\n",
            "293-3 [D loss: 0.427223, acc.: 80.77%] [G loss: 2.335336] [Time: 0.247747]\n",
            "293-4 [D loss: 0.505856, acc.: 76.92%] [G loss: 1.707303] [Time: 0.245083]\n",
            "293-5 [D loss: 0.679349, acc.: 63.46%] [G loss: 1.580539] [Time: 0.244628]\n",
            "293-6 [D loss: 0.567957, acc.: 69.23%] [G loss: 1.953199] [Time: 0.246993]\n",
            "293-7 [D loss: 0.648062, acc.: 59.62%] [G loss: 1.436307] [Time: 0.250270]\n",
            "293-8 [D loss: 0.429177, acc.: 80.77%] [G loss: 1.534341] [Time: 0.243415]\n",
            "293 (test) [D loss: 1.658066, acc.: 50.00%] [G loss: 3.199954] [Time: 0.074999]\n",
            "294-0 [D loss: 0.319144, acc.: 94.23%] [G loss: 2.310510] [Time: 0.243711]\n",
            "294-1 [D loss: 0.524502, acc.: 76.92%] [G loss: 1.369978] [Time: 0.247193]\n",
            "294-2 [D loss: 1.029443, acc.: 32.69%] [G loss: 1.106647] [Time: 0.247998]\n",
            "294-3 [D loss: 0.485722, acc.: 73.08%] [G loss: 1.599156] [Time: 0.243968]\n",
            "294-4 [D loss: 0.471526, acc.: 75.00%] [G loss: 1.922398] [Time: 0.248569]\n",
            "294-5 [D loss: 0.630454, acc.: 67.31%] [G loss: 1.591774] [Time: 0.243088]\n",
            "294-6 [D loss: 0.476833, acc.: 76.92%] [G loss: 1.802503] [Time: 0.245302]\n",
            "294-7 [D loss: 0.650469, acc.: 59.62%] [G loss: 1.550651] [Time: 0.244584]\n",
            "294-8 [D loss: 0.509406, acc.: 75.00%] [G loss: 1.669684] [Time: 0.249873]\n",
            "294 (test) [D loss: 1.703677, acc.: 50.00%] [G loss: 3.300199] [Time: 0.074727]\n",
            "295-0 [D loss: 0.270224, acc.: 92.31%] [G loss: 1.962980] [Time: 0.248255]\n",
            "295-1 [D loss: 0.698397, acc.: 53.85%] [G loss: 1.430130] [Time: 0.243694]\n",
            "295-2 [D loss: 0.777550, acc.: 44.23%] [G loss: 1.465755] [Time: 0.246169]\n",
            "295-3 [D loss: 0.497831, acc.: 75.00%] [G loss: 1.759991] [Time: 0.253221]\n",
            "295-4 [D loss: 0.548673, acc.: 76.92%] [G loss: 1.615757] [Time: 0.246565]\n",
            "295-5 [D loss: 0.713857, acc.: 53.85%] [G loss: 1.680862] [Time: 0.244914]\n",
            "295-6 [D loss: 0.471115, acc.: 80.77%] [G loss: 1.750387] [Time: 0.245360]\n",
            "295-7 [D loss: 0.662288, acc.: 59.62%] [G loss: 1.628323] [Time: 0.249650]\n",
            "295-8 [D loss: 0.508616, acc.: 76.92%] [G loss: 1.664359] [Time: 0.243876]\n",
            "295 (test) [D loss: 1.664477, acc.: 50.00%] [G loss: 3.214745] [Time: 0.076913]\n",
            "296-0 [D loss: 0.323847, acc.: 88.46%] [G loss: 2.044332] [Time: 0.248974]\n",
            "296-1 [D loss: 0.614765, acc.: 67.31%] [G loss: 1.704679] [Time: 0.246087]\n",
            "296-2 [D loss: 0.808228, acc.: 50.00%] [G loss: 1.348966] [Time: 0.246566]\n",
            "296-3 [D loss: 0.650403, acc.: 59.62%] [G loss: 1.556897] [Time: 0.248569]\n",
            "296-4 [D loss: 0.528984, acc.: 71.15%] [G loss: 1.953791] [Time: 0.249016]\n",
            "296-5 [D loss: 0.758979, acc.: 55.77%] [G loss: 1.522671] [Time: 0.247555]\n",
            "296-6 [D loss: 0.562684, acc.: 82.69%] [G loss: 1.762041] [Time: 0.246587]\n",
            "296-7 [D loss: 0.631245, acc.: 57.69%] [G loss: 1.458677] [Time: 0.245604]\n",
            "296-8 [D loss: 0.607542, acc.: 69.23%] [G loss: 1.713304] [Time: 0.247570]\n",
            "296 (test) [D loss: 1.619432, acc.: 50.00%] [G loss: 3.132480] [Time: 0.075997]\n",
            "297-0 [D loss: 0.331555, acc.: 86.54%] [G loss: 2.247948] [Time: 0.250658]\n",
            "297-1 [D loss: 0.601664, acc.: 67.31%] [G loss: 1.406546] [Time: 0.252155]\n",
            "297-2 [D loss: 0.754611, acc.: 51.92%] [G loss: 1.167437] [Time: 0.244859]\n",
            "297-3 [D loss: 0.582196, acc.: 71.15%] [G loss: 1.763749] [Time: 0.246892]\n",
            "297-4 [D loss: 0.525355, acc.: 71.15%] [G loss: 1.766263] [Time: 0.250210]\n",
            "297-5 [D loss: 0.617725, acc.: 57.69%] [G loss: 1.523391] [Time: 0.247208]\n",
            "297-6 [D loss: 0.519095, acc.: 73.08%] [G loss: 1.963871] [Time: 0.246726]\n",
            "297-7 [D loss: 0.618559, acc.: 63.46%] [G loss: 1.704494] [Time: 0.245306]\n",
            "297-8 [D loss: 0.542991, acc.: 76.92%] [G loss: 1.718227] [Time: 0.245035]\n",
            "297 (test) [D loss: 1.562837, acc.: 50.00%] [G loss: 3.004366] [Time: 0.075425]\n",
            "298-0 [D loss: 0.331916, acc.: 90.38%] [G loss: 1.884250] [Time: 0.247758]\n",
            "298-1 [D loss: 0.601765, acc.: 67.31%] [G loss: 1.315172] [Time: 0.250751]\n",
            "298-2 [D loss: 0.700308, acc.: 57.69%] [G loss: 1.471999] [Time: 0.246769]\n",
            "298-3 [D loss: 0.518147, acc.: 76.92%] [G loss: 1.801386] [Time: 0.249657]\n",
            "298-4 [D loss: 0.567816, acc.: 73.08%] [G loss: 1.667712] [Time: 0.243043]\n",
            "298-5 [D loss: 0.662774, acc.: 57.69%] [G loss: 1.961469] [Time: 0.246603]\n",
            "298-6 [D loss: 0.591508, acc.: 69.23%] [G loss: 1.646130] [Time: 0.247706]\n",
            "298-7 [D loss: 0.641220, acc.: 57.69%] [G loss: 1.479502] [Time: 0.245068]\n",
            "298-8 [D loss: 0.435307, acc.: 80.77%] [G loss: 1.451313] [Time: 0.248237]\n",
            "298 (test) [D loss: 1.620509, acc.: 50.00%] [G loss: 3.133065] [Time: 0.076765]\n",
            "299-0 [D loss: 0.397973, acc.: 78.85%] [G loss: 1.908626] [Time: 0.249050]\n",
            "299-1 [D loss: 0.624355, acc.: 61.54%] [G loss: 1.635434] [Time: 0.246402]\n",
            "299-2 [D loss: 0.811277, acc.: 50.00%] [G loss: 1.410647] [Time: 0.243526]\n",
            "299-3 [D loss: 0.520815, acc.: 75.00%] [G loss: 1.562260] [Time: 0.243519]\n",
            "299-4 [D loss: 0.578298, acc.: 69.23%] [G loss: 1.488241] [Time: 0.247440]\n",
            "299-5 [D loss: 0.657373, acc.: 67.31%] [G loss: 1.853177] [Time: 0.247698]\n",
            "299-6 [D loss: 0.508083, acc.: 75.00%] [G loss: 1.682710] [Time: 0.248629]\n",
            "299-7 [D loss: 0.688875, acc.: 61.54%] [G loss: 1.344133] [Time: 0.248131]\n",
            "299-8 [D loss: 0.515305, acc.: 80.77%] [G loss: 1.728390] [Time: 0.247712]\n",
            "299 (test) [D loss: 1.618353, acc.: 50.00%] [G loss: 3.129158] [Time: 0.074514]\n",
            "300-0 [D loss: 0.255961, acc.: 94.23%] [G loss: 2.355335] [Time: 0.245912]\n",
            "300-1 [D loss: 0.595990, acc.: 67.31%] [G loss: 1.232903] [Time: 0.248138]\n",
            "300-2 [D loss: 0.789721, acc.: 48.08%] [G loss: 1.402292] [Time: 0.248527]\n",
            "300-3 [D loss: 0.466294, acc.: 73.08%] [G loss: 1.864137] [Time: 0.244758]\n",
            "300-4 [D loss: 0.589152, acc.: 71.15%] [G loss: 1.560245] [Time: 0.246064]\n",
            "300-5 [D loss: 0.587778, acc.: 65.38%] [G loss: 1.577464] [Time: 0.248785]\n",
            "300-6 [D loss: 0.633119, acc.: 57.69%] [G loss: 1.586818] [Time: 0.246112]\n",
            "300-7 [D loss: 0.685672, acc.: 57.69%] [G loss: 1.596291] [Time: 0.247712]\n",
            "300-8 [D loss: 0.520465, acc.: 76.92%] [G loss: 1.812154] [Time: 0.245265]\n",
            "300 (test) [D loss: 1.555589, acc.: 50.00%] [G loss: 2.979011] [Time: 0.078179]\n",
            "301-0 [D loss: 0.313135, acc.: 80.77%] [G loss: 2.463334] [Time: 0.247638]\n",
            "301-1 [D loss: 0.504831, acc.: 76.92%] [G loss: 1.499142] [Time: 0.244204]\n",
            "301-2 [D loss: 0.752289, acc.: 50.00%] [G loss: 1.205690] [Time: 0.251825]\n",
            "301-3 [D loss: 0.530762, acc.: 71.15%] [G loss: 1.911158] [Time: 0.245027]\n",
            "301-4 [D loss: 0.508706, acc.: 73.08%] [G loss: 1.677968] [Time: 0.247474]\n",
            "301-5 [D loss: 0.511078, acc.: 71.15%] [G loss: 1.687183] [Time: 0.253014]\n",
            "301-6 [D loss: 0.506991, acc.: 71.15%] [G loss: 1.416948] [Time: 0.244473]\n",
            "301-7 [D loss: 0.558300, acc.: 71.15%] [G loss: 1.245456] [Time: 0.247257]\n",
            "301-8 [D loss: 0.556737, acc.: 69.23%] [G loss: 1.563428] [Time: 0.243712]\n",
            "301 (test) [D loss: 1.616811, acc.: 50.00%] [G loss: 3.124796] [Time: 0.078263]\n",
            "302-0 [D loss: 0.305873, acc.: 92.31%] [G loss: 2.030595] [Time: 0.251506]\n",
            "302-1 [D loss: 0.542350, acc.: 71.15%] [G loss: 1.487563] [Time: 0.246158]\n",
            "302-2 [D loss: 0.813429, acc.: 48.08%] [G loss: 1.046050] [Time: 0.244836]\n",
            "302-3 [D loss: 0.534211, acc.: 71.15%] [G loss: 1.846534] [Time: 0.249275]\n",
            "302-4 [D loss: 0.545229, acc.: 69.23%] [G loss: 1.663373] [Time: 0.245227]\n",
            "302-5 [D loss: 0.585062, acc.: 65.38%] [G loss: 1.445383] [Time: 0.243301]\n",
            "302-6 [D loss: 0.525111, acc.: 80.77%] [G loss: 1.759280] [Time: 0.244381]\n",
            "302-7 [D loss: 0.682080, acc.: 65.38%] [G loss: 1.314744] [Time: 0.246769]\n",
            "302-8 [D loss: 0.425234, acc.: 82.69%] [G loss: 1.982165] [Time: 0.247654]\n",
            "302 (test) [D loss: 1.636768, acc.: 50.00%] [G loss: 3.152293] [Time: 0.076295]\n",
            "303-0 [D loss: 0.294729, acc.: 94.23%] [G loss: 2.600004] [Time: 0.245264]\n",
            "303-1 [D loss: 0.549677, acc.: 73.08%] [G loss: 1.451815] [Time: 0.247166]\n",
            "303-2 [D loss: 0.837387, acc.: 36.54%] [G loss: 1.212022] [Time: 0.248083]\n",
            "303-3 [D loss: 0.640210, acc.: 59.62%] [G loss: 1.781861] [Time: 0.247757]\n",
            "303-4 [D loss: 0.614183, acc.: 69.23%] [G loss: 1.462779] [Time: 0.248919]\n",
            "303-5 [D loss: 0.659886, acc.: 67.31%] [G loss: 1.330289] [Time: 0.246079]\n",
            "303-6 [D loss: 0.482575, acc.: 67.31%] [G loss: 1.623686] [Time: 0.245472]\n",
            "303-7 [D loss: 0.570627, acc.: 65.38%] [G loss: 1.513122] [Time: 0.249623]\n",
            "303-8 [D loss: 0.543095, acc.: 71.15%] [G loss: 1.477428] [Time: 0.245744]\n",
            "303 (test) [D loss: 1.581554, acc.: 50.00%] [G loss: 3.046073] [Time: 0.076041]\n",
            "304-0 [D loss: 0.274300, acc.: 92.31%] [G loss: 2.272579] [Time: 0.248374]\n",
            "304-1 [D loss: 0.612926, acc.: 69.23%] [G loss: 1.725320] [Time: 0.248452]\n",
            "304-2 [D loss: 0.799700, acc.: 46.15%] [G loss: 1.601296] [Time: 0.249892]\n",
            "304-3 [D loss: 0.555328, acc.: 75.00%] [G loss: 1.726094] [Time: 0.243339]\n",
            "304-4 [D loss: 0.505482, acc.: 71.15%] [G loss: 1.824679] [Time: 0.250379]\n",
            "304-5 [D loss: 0.660387, acc.: 57.69%] [G loss: 1.581305] [Time: 0.249723]\n",
            "304-6 [D loss: 0.498768, acc.: 73.08%] [G loss: 1.705895] [Time: 0.248323]\n",
            "304-7 [D loss: 0.677524, acc.: 55.77%] [G loss: 1.599247] [Time: 0.255330]\n",
            "304-8 [D loss: 0.426264, acc.: 84.62%] [G loss: 1.918527] [Time: 0.243600]\n",
            "304 (test) [D loss: 1.640681, acc.: 50.00%] [G loss: 3.165054] [Time: 0.076693]\n",
            "305-0 [D loss: 0.273503, acc.: 92.31%] [G loss: 2.165249] [Time: 0.248816]\n",
            "305-1 [D loss: 0.676091, acc.: 55.77%] [G loss: 1.496785] [Time: 0.250041]\n",
            "305-2 [D loss: 0.796418, acc.: 44.23%] [G loss: 1.396405] [Time: 0.243726]\n",
            "305-3 [D loss: 0.471758, acc.: 86.54%] [G loss: 1.703556] [Time: 0.246740]\n",
            "305-4 [D loss: 0.532363, acc.: 75.00%] [G loss: 1.687496] [Time: 0.248098]\n",
            "305-5 [D loss: 0.594888, acc.: 63.46%] [G loss: 1.557385] [Time: 0.246664]\n",
            "305-6 [D loss: 0.520835, acc.: 80.77%] [G loss: 1.853954] [Time: 0.244754]\n",
            "305-7 [D loss: 0.621631, acc.: 65.38%] [G loss: 1.424507] [Time: 0.248335]\n",
            "305-8 [D loss: 0.542842, acc.: 69.23%] [G loss: 1.818710] [Time: 0.247807]\n",
            "305 (test) [D loss: 1.653062, acc.: 50.00%] [G loss: 3.194385] [Time: 0.080381]\n",
            "306-0 [D loss: 0.238225, acc.: 96.15%] [G loss: 2.225232] [Time: 0.249898]\n",
            "306-1 [D loss: 0.746192, acc.: 59.62%] [G loss: 1.336605] [Time: 0.246965]\n",
            "306-2 [D loss: 0.616127, acc.: 63.46%] [G loss: 1.530346] [Time: 0.246156]\n",
            "306-3 [D loss: 0.511047, acc.: 80.77%] [G loss: 1.750727] [Time: 0.245738]\n",
            "306-4 [D loss: 0.474894, acc.: 75.00%] [G loss: 1.504521] [Time: 0.246817]\n",
            "306-5 [D loss: 0.653736, acc.: 59.62%] [G loss: 1.606791] [Time: 0.248461]\n",
            "306-6 [D loss: 0.582431, acc.: 65.38%] [G loss: 1.654318] [Time: 0.246727]\n",
            "306-7 [D loss: 0.702426, acc.: 55.77%] [G loss: 1.505248] [Time: 0.243345]\n",
            "306-8 [D loss: 0.592049, acc.: 71.15%] [G loss: 1.543569] [Time: 0.244552]\n",
            "306 (test) [D loss: 1.679664, acc.: 50.00%] [G loss: 3.249162] [Time: 0.078074]\n",
            "307-0 [D loss: 0.263146, acc.: 94.23%] [G loss: 2.310187] [Time: 0.243885]\n",
            "307-1 [D loss: 0.724344, acc.: 57.69%] [G loss: 1.365538] [Time: 0.249837]\n",
            "307-2 [D loss: 0.849828, acc.: 46.15%] [G loss: 1.426497] [Time: 0.244678]\n",
            "307-3 [D loss: 0.563208, acc.: 61.54%] [G loss: 1.630297] [Time: 0.242941]\n",
            "307-4 [D loss: 0.516894, acc.: 69.23%] [G loss: 1.948933] [Time: 0.244710]\n",
            "307-5 [D loss: 0.564424, acc.: 69.23%] [G loss: 1.586903] [Time: 0.252396]\n",
            "307-6 [D loss: 0.441586, acc.: 78.85%] [G loss: 1.637163] [Time: 0.242394]\n",
            "307-7 [D loss: 0.649824, acc.: 59.62%] [G loss: 1.362450] [Time: 0.246796]\n",
            "307-8 [D loss: 0.455470, acc.: 78.85%] [G loss: 1.703802] [Time: 0.245621]\n",
            "307 (test) [D loss: 1.655293, acc.: 50.00%] [G loss: 3.191910] [Time: 0.079138]\n",
            "308-0 [D loss: 0.386369, acc.: 82.69%] [G loss: 1.741044] [Time: 0.245723]\n",
            "308-1 [D loss: 0.722117, acc.: 50.00%] [G loss: 1.485800] [Time: 0.243848]\n",
            "308-2 [D loss: 0.725045, acc.: 57.69%] [G loss: 1.357970] [Time: 0.248166]\n",
            "308-3 [D loss: 0.611755, acc.: 65.38%] [G loss: 1.711341] [Time: 0.249773]\n",
            "308-4 [D loss: 0.570091, acc.: 69.23%] [G loss: 1.475112] [Time: 0.242987]\n",
            "308-5 [D loss: 0.614196, acc.: 69.23%] [G loss: 1.687248] [Time: 0.248079]\n",
            "308-6 [D loss: 0.569688, acc.: 73.08%] [G loss: 1.388608] [Time: 0.244116]\n",
            "308-7 [D loss: 0.673247, acc.: 63.46%] [G loss: 1.292664] [Time: 0.245595]\n",
            "308-8 [D loss: 0.480209, acc.: 80.77%] [G loss: 1.738874] [Time: 0.246701]\n",
            "308 (test) [D loss: 1.626256, acc.: 50.00%] [G loss: 3.140725] [Time: 0.078327]\n",
            "309-0 [D loss: 0.262344, acc.: 94.23%] [G loss: 2.185944] [Time: 0.246286]\n",
            "309-1 [D loss: 0.791169, acc.: 51.92%] [G loss: 1.507734] [Time: 0.244667]\n",
            "309-2 [D loss: 0.759842, acc.: 57.69%] [G loss: 1.362622] [Time: 0.245301]\n",
            "309-3 [D loss: 0.555626, acc.: 69.23%] [G loss: 1.768469] [Time: 0.249900]\n",
            "309-4 [D loss: 0.639640, acc.: 67.31%] [G loss: 1.521023] [Time: 0.246043]\n",
            "309-5 [D loss: 0.467013, acc.: 80.77%] [G loss: 1.548193] [Time: 0.243500]\n",
            "309-6 [D loss: 0.462107, acc.: 76.92%] [G loss: 1.742082] [Time: 0.247282]\n",
            "309-7 [D loss: 0.648919, acc.: 63.46%] [G loss: 1.531360] [Time: 0.247914]\n",
            "309-8 [D loss: 0.514260, acc.: 69.23%] [G loss: 1.588057] [Time: 0.245244]\n",
            "309 (test) [D loss: 1.620398, acc.: 50.00%] [G loss: 3.121249] [Time: 0.075429]\n",
            "310-0 [D loss: 0.282561, acc.: 90.38%] [G loss: 1.942439] [Time: 0.247917]\n",
            "310-1 [D loss: 0.709514, acc.: 46.15%] [G loss: 1.432440] [Time: 0.247337]\n",
            "310-2 [D loss: 0.734523, acc.: 57.69%] [G loss: 1.455359] [Time: 0.243023]\n",
            "310-3 [D loss: 0.535269, acc.: 76.92%] [G loss: 1.695144] [Time: 0.245937]\n",
            "310-4 [D loss: 0.478441, acc.: 75.00%] [G loss: 1.597449] [Time: 0.244691]\n",
            "310-5 [D loss: 0.517027, acc.: 76.92%] [G loss: 1.985748] [Time: 0.245810]\n",
            "310-6 [D loss: 0.556240, acc.: 65.38%] [G loss: 1.624023] [Time: 0.246200]\n",
            "310-7 [D loss: 0.703471, acc.: 61.54%] [G loss: 1.411211] [Time: 0.246752]\n",
            "310-8 [D loss: 0.478658, acc.: 76.92%] [G loss: 1.396768] [Time: 0.244257]\n",
            "310 (test) [D loss: 1.598155, acc.: 50.00%] [G loss: 3.094606] [Time: 0.075300]\n",
            "311-0 [D loss: 0.324693, acc.: 84.62%] [G loss: 2.301255] [Time: 0.250787]\n",
            "311-1 [D loss: 0.596688, acc.: 63.46%] [G loss: 1.641894] [Time: 0.245344]\n",
            "311-2 [D loss: 0.767274, acc.: 53.85%] [G loss: 1.417327] [Time: 0.245204]\n",
            "311-3 [D loss: 0.545843, acc.: 71.15%] [G loss: 1.669557] [Time: 0.248765]\n",
            "311-4 [D loss: 0.568477, acc.: 69.23%] [G loss: 1.741847] [Time: 0.245885]\n",
            "311-5 [D loss: 0.651778, acc.: 48.08%] [G loss: 1.591609] [Time: 0.244621]\n",
            "311-6 [D loss: 0.545515, acc.: 71.15%] [G loss: 1.774406] [Time: 0.245332]\n",
            "311-7 [D loss: 0.712345, acc.: 53.85%] [G loss: 1.451465] [Time: 0.243606]\n",
            "311-8 [D loss: 0.522473, acc.: 78.85%] [G loss: 1.508266] [Time: 0.249897]\n",
            "311 (test) [D loss: 1.582936, acc.: 50.00%] [G loss: 3.041872] [Time: 0.078307]\n",
            "312-0 [D loss: 0.417226, acc.: 86.54%] [G loss: 2.109043] [Time: 0.246862]\n",
            "312-1 [D loss: 0.646649, acc.: 59.62%] [G loss: 1.461011] [Time: 0.242240]\n",
            "312-2 [D loss: 0.729712, acc.: 53.85%] [G loss: 1.388323] [Time: 0.244998]\n",
            "312-3 [D loss: 0.557718, acc.: 71.15%] [G loss: 1.569784] [Time: 0.248461]\n",
            "312-4 [D loss: 0.490685, acc.: 71.15%] [G loss: 1.626554] [Time: 0.244364]\n",
            "312-5 [D loss: 0.605267, acc.: 67.31%] [G loss: 1.716637] [Time: 0.246358]\n",
            "312-6 [D loss: 0.589500, acc.: 69.23%] [G loss: 1.687128] [Time: 0.246111]\n",
            "312-7 [D loss: 0.684675, acc.: 53.85%] [G loss: 1.403962] [Time: 0.247570]\n",
            "312-8 [D loss: 0.535896, acc.: 67.31%] [G loss: 1.578594] [Time: 0.247539]\n",
            "312 (test) [D loss: 1.670056, acc.: 50.00%] [G loss: 3.237154] [Time: 0.076374]\n",
            "313-0 [D loss: 0.264775, acc.: 94.23%] [G loss: 2.062920] [Time: 0.249795]\n",
            "313-1 [D loss: 0.612481, acc.: 71.15%] [G loss: 1.259404] [Time: 0.243649]\n",
            "313-2 [D loss: 0.746675, acc.: 59.62%] [G loss: 1.332200] [Time: 0.243320]\n",
            "313-3 [D loss: 0.481552, acc.: 80.77%] [G loss: 1.750854] [Time: 0.245251]\n",
            "313-4 [D loss: 0.544812, acc.: 63.46%] [G loss: 1.540497] [Time: 0.248858]\n",
            "313-5 [D loss: 0.642489, acc.: 59.62%] [G loss: 1.791892] [Time: 0.244658]\n",
            "313-6 [D loss: 0.433635, acc.: 84.62%] [G loss: 1.641862] [Time: 0.253544]\n",
            "313-7 [D loss: 0.671756, acc.: 59.62%] [G loss: 1.206332] [Time: 0.246637]\n",
            "313-8 [D loss: 0.486516, acc.: 80.77%] [G loss: 1.611441] [Time: 0.246944]\n",
            "313 (test) [D loss: 1.734536, acc.: 50.00%] [G loss: 3.362869] [Time: 0.076657]\n",
            "314-0 [D loss: 0.273725, acc.: 94.23%] [G loss: 2.056437] [Time: 0.250777]\n",
            "314-1 [D loss: 0.684843, acc.: 57.69%] [G loss: 1.335403] [Time: 0.254649]\n",
            "314-2 [D loss: 0.706293, acc.: 51.92%] [G loss: 1.633507] [Time: 0.246284]\n",
            "314-3 [D loss: 0.474170, acc.: 82.69%] [G loss: 1.781364] [Time: 0.242874]\n",
            "314-4 [D loss: 0.502708, acc.: 71.15%] [G loss: 1.474327] [Time: 0.247580]\n",
            "314-5 [D loss: 0.605635, acc.: 71.15%] [G loss: 1.420290] [Time: 0.242728]\n",
            "314-6 [D loss: 0.573014, acc.: 65.38%] [G loss: 1.642560] [Time: 0.245680]\n",
            "314-7 [D loss: 0.678302, acc.: 55.77%] [G loss: 1.441532] [Time: 0.248156]\n",
            "314-8 [D loss: 0.554343, acc.: 69.23%] [G loss: 1.789966] [Time: 0.247013]\n",
            "314 (test) [D loss: 1.666940, acc.: 50.00%] [G loss: 3.233584] [Time: 0.077362]\n",
            "315-0 [D loss: 0.303556, acc.: 88.46%] [G loss: 2.040091] [Time: 0.246914]\n",
            "315-1 [D loss: 0.579884, acc.: 67.31%] [G loss: 1.379781] [Time: 0.246954]\n",
            "315-2 [D loss: 0.723485, acc.: 55.77%] [G loss: 1.204209] [Time: 0.250219]\n",
            "315-3 [D loss: 0.446436, acc.: 86.54%] [G loss: 1.809214] [Time: 0.246149]\n",
            "315-4 [D loss: 0.567358, acc.: 75.00%] [G loss: 1.677153] [Time: 0.246538]\n",
            "315-5 [D loss: 0.541147, acc.: 63.46%] [G loss: 1.573125] [Time: 0.249169]\n",
            "315-6 [D loss: 0.695694, acc.: 51.92%] [G loss: 1.368774] [Time: 0.247413]\n",
            "315-7 [D loss: 0.702416, acc.: 63.46%] [G loss: 1.700320] [Time: 0.246106]\n",
            "315-8 [D loss: 0.538564, acc.: 71.15%] [G loss: 1.707408] [Time: 0.243860]\n",
            "315 (test) [D loss: 1.781048, acc.: 50.00%] [G loss: 3.455119] [Time: 0.076555]\n",
            "316-0 [D loss: 0.307409, acc.: 86.54%] [G loss: 2.274026] [Time: 0.251375]\n",
            "316-1 [D loss: 0.740557, acc.: 61.54%] [G loss: 1.343059] [Time: 0.248995]\n",
            "316-2 [D loss: 0.772200, acc.: 53.85%] [G loss: 1.380042] [Time: 0.244771]\n",
            "316-3 [D loss: 0.522248, acc.: 80.77%] [G loss: 1.867844] [Time: 0.251400]\n",
            "316-4 [D loss: 0.434335, acc.: 82.69%] [G loss: 1.444284] [Time: 0.244795]\n",
            "316-5 [D loss: 0.576275, acc.: 65.38%] [G loss: 1.513732] [Time: 0.245972]\n",
            "316-6 [D loss: 0.505848, acc.: 67.31%] [G loss: 1.543064] [Time: 0.245961]\n",
            "316-7 [D loss: 0.755597, acc.: 57.69%] [G loss: 1.721531] [Time: 0.250047]\n",
            "316-8 [D loss: 0.567788, acc.: 65.38%] [G loss: 1.706387] [Time: 0.246264]\n",
            "316 (test) [D loss: 1.769616, acc.: 50.00%] [G loss: 3.434346] [Time: 0.078143]\n",
            "317-0 [D loss: 0.365623, acc.: 88.46%] [G loss: 2.225075] [Time: 0.245516]\n",
            "317-1 [D loss: 0.570823, acc.: 69.23%] [G loss: 1.656989] [Time: 0.247319]\n",
            "317-2 [D loss: 0.767662, acc.: 42.31%] [G loss: 1.392556] [Time: 0.246108]\n",
            "317-3 [D loss: 0.511433, acc.: 75.00%] [G loss: 2.020089] [Time: 0.252204]\n",
            "317-4 [D loss: 0.490855, acc.: 73.08%] [G loss: 1.917954] [Time: 0.245349]\n",
            "317-5 [D loss: 0.635569, acc.: 61.54%] [G loss: 1.517804] [Time: 0.248492]\n",
            "317-6 [D loss: 0.495881, acc.: 73.08%] [G loss: 1.787352] [Time: 0.247794]\n",
            "317-7 [D loss: 0.697746, acc.: 51.92%] [G loss: 1.585170] [Time: 0.246165]\n",
            "317-8 [D loss: 0.640646, acc.: 63.46%] [G loss: 1.751701] [Time: 0.246272]\n",
            "317 (test) [D loss: 1.702398, acc.: 50.00%] [G loss: 3.310887] [Time: 0.078384]\n",
            "318-0 [D loss: 0.283120, acc.: 92.31%] [G loss: 2.233390] [Time: 0.247111]\n",
            "318-1 [D loss: 0.662315, acc.: 61.54%] [G loss: 1.615382] [Time: 0.245049]\n",
            "318-2 [D loss: 0.767366, acc.: 55.77%] [G loss: 1.048730] [Time: 0.243936]\n",
            "318-3 [D loss: 0.469789, acc.: 76.92%] [G loss: 1.832976] [Time: 0.246264]\n",
            "318-4 [D loss: 0.555700, acc.: 59.62%] [G loss: 1.623976] [Time: 0.247912]\n",
            "318-5 [D loss: 0.586614, acc.: 67.31%] [G loss: 1.909035] [Time: 0.243830]\n",
            "318-6 [D loss: 0.467712, acc.: 71.15%] [G loss: 1.710070] [Time: 0.244523]\n",
            "318-7 [D loss: 0.536045, acc.: 75.00%] [G loss: 1.483271] [Time: 0.245821]\n",
            "318-8 [D loss: 0.519047, acc.: 71.15%] [G loss: 1.843457] [Time: 0.249882]\n",
            "318 (test) [D loss: 1.749153, acc.: 50.00%] [G loss: 3.394333] [Time: 0.077028]\n",
            "319-0 [D loss: 0.281496, acc.: 90.38%] [G loss: 2.006721] [Time: 0.244131]\n",
            "319-1 [D loss: 0.673648, acc.: 55.77%] [G loss: 1.484795] [Time: 0.246405]\n",
            "319-2 [D loss: 0.695951, acc.: 59.62%] [G loss: 1.528912] [Time: 0.249853]\n",
            "319-3 [D loss: 0.493898, acc.: 69.23%] [G loss: 1.782895] [Time: 0.247118]\n",
            "319-4 [D loss: 0.615912, acc.: 63.46%] [G loss: 1.552473] [Time: 0.245464]\n",
            "319-5 [D loss: 0.611352, acc.: 63.46%] [G loss: 1.820488] [Time: 0.248389]\n",
            "319-6 [D loss: 0.638360, acc.: 53.85%] [G loss: 1.614167] [Time: 0.245393]\n",
            "319-7 [D loss: 0.658720, acc.: 59.62%] [G loss: 1.402692] [Time: 0.245951]\n",
            "319-8 [D loss: 0.529015, acc.: 75.00%] [G loss: 1.653235] [Time: 0.244864]\n",
            "319 (test) [D loss: 1.751591, acc.: 50.00%] [G loss: 3.390175] [Time: 0.078706]\n",
            "320-0 [D loss: 0.321831, acc.: 84.62%] [G loss: 1.841754] [Time: 0.253207]\n",
            "320-1 [D loss: 0.563031, acc.: 69.23%] [G loss: 1.578048] [Time: 0.246078]\n",
            "320-2 [D loss: 0.674832, acc.: 61.54%] [G loss: 1.433986] [Time: 0.245784]\n",
            "320-3 [D loss: 0.624793, acc.: 57.69%] [G loss: 1.591909] [Time: 0.245875]\n",
            "320-4 [D loss: 0.592563, acc.: 63.46%] [G loss: 1.605446] [Time: 0.250938]\n",
            "320-5 [D loss: 0.599315, acc.: 67.31%] [G loss: 1.940067] [Time: 0.246336]\n",
            "320-6 [D loss: 0.536952, acc.: 67.31%] [G loss: 1.874985] [Time: 0.247770]\n",
            "320-7 [D loss: 0.755087, acc.: 50.00%] [G loss: 1.448937] [Time: 0.245523]\n",
            "320-8 [D loss: 0.587445, acc.: 69.23%] [G loss: 1.390073] [Time: 0.245663]\n",
            "320 (test) [D loss: 1.669690, acc.: 50.00%] [G loss: 3.223004] [Time: 0.076040]\n",
            "321-0 [D loss: 0.309000, acc.: 88.46%] [G loss: 2.131053] [Time: 0.246832]\n",
            "321-1 [D loss: 0.529468, acc.: 67.31%] [G loss: 1.509881] [Time: 0.247928]\n",
            "321-2 [D loss: 0.797369, acc.: 53.85%] [G loss: 1.415645] [Time: 0.246598]\n",
            "321-3 [D loss: 0.466500, acc.: 73.08%] [G loss: 1.760229] [Time: 0.248710]\n",
            "321-4 [D loss: 0.604383, acc.: 67.31%] [G loss: 1.521919] [Time: 0.243659]\n",
            "321-5 [D loss: 0.624666, acc.: 65.38%] [G loss: 1.714402] [Time: 0.246732]\n",
            "321-6 [D loss: 0.523672, acc.: 80.77%] [G loss: 1.728907] [Time: 0.248600]\n",
            "321-7 [D loss: 0.699015, acc.: 69.23%] [G loss: 1.379970] [Time: 0.243908]\n",
            "321-8 [D loss: 0.514257, acc.: 76.92%] [G loss: 1.412552] [Time: 0.245892]\n",
            "321 (test) [D loss: 1.671236, acc.: 50.00%] [G loss: 3.236041] [Time: 0.078381]\n",
            "322-0 [D loss: 0.308533, acc.: 94.23%] [G loss: 2.290983] [Time: 0.248893]\n",
            "322-1 [D loss: 0.689912, acc.: 51.92%] [G loss: 1.295924] [Time: 0.244635]\n",
            "322-2 [D loss: 0.543044, acc.: 71.15%] [G loss: 1.216540] [Time: 0.247951]\n",
            "322-3 [D loss: 0.545919, acc.: 76.92%] [G loss: 1.787269] [Time: 0.248139]\n",
            "322-4 [D loss: 0.562404, acc.: 71.15%] [G loss: 1.394446] [Time: 0.246455]\n",
            "322-5 [D loss: 0.777965, acc.: 46.15%] [G loss: 1.311988] [Time: 0.245612]\n",
            "322-6 [D loss: 0.432315, acc.: 84.62%] [G loss: 1.648897] [Time: 0.247267]\n",
            "322-7 [D loss: 0.633276, acc.: 57.69%] [G loss: 1.468511] [Time: 0.251115]\n",
            "322-8 [D loss: 0.520455, acc.: 76.92%] [G loss: 1.355450] [Time: 0.245658]\n",
            "322 (test) [D loss: 1.784697, acc.: 50.00%] [G loss: 3.491806] [Time: 0.076346]\n",
            "323-0 [D loss: 0.258359, acc.: 92.31%] [G loss: 2.127114] [Time: 0.248428]\n",
            "323-1 [D loss: 0.623060, acc.: 59.62%] [G loss: 1.514323] [Time: 0.246156]\n",
            "323-2 [D loss: 0.797728, acc.: 48.08%] [G loss: 1.677381] [Time: 0.249969]\n",
            "323-3 [D loss: 0.464203, acc.: 78.85%] [G loss: 1.743356] [Time: 0.245326]\n",
            "323-4 [D loss: 0.478648, acc.: 75.00%] [G loss: 1.513404] [Time: 0.244997]\n",
            "323-5 [D loss: 0.694897, acc.: 55.77%] [G loss: 1.725289] [Time: 0.250167]\n",
            "323-6 [D loss: 0.643774, acc.: 61.54%] [G loss: 1.733107] [Time: 0.245927]\n",
            "323-7 [D loss: 0.666030, acc.: 53.85%] [G loss: 1.506861] [Time: 0.245760]\n",
            "323-8 [D loss: 0.488917, acc.: 75.00%] [G loss: 1.758777] [Time: 0.245287]\n",
            "323 (test) [D loss: 1.732887, acc.: 50.00%] [G loss: 3.360944] [Time: 0.077303]\n",
            "324-0 [D loss: 0.344700, acc.: 90.38%] [G loss: 2.305242] [Time: 0.248074]\n",
            "324-1 [D loss: 0.532257, acc.: 71.15%] [G loss: 1.511521] [Time: 0.246197]\n",
            "324-2 [D loss: 0.839487, acc.: 59.62%] [G loss: 1.376804] [Time: 0.244426]\n",
            "324-3 [D loss: 0.460828, acc.: 84.62%] [G loss: 1.699533] [Time: 0.243434]\n",
            "324-4 [D loss: 0.702233, acc.: 57.69%] [G loss: 1.465631] [Time: 0.247567]\n",
            "324-5 [D loss: 0.592983, acc.: 67.31%] [G loss: 1.696002] [Time: 0.247175]\n",
            "324-6 [D loss: 0.584225, acc.: 67.31%] [G loss: 1.758347] [Time: 0.247528]\n",
            "324-7 [D loss: 0.539046, acc.: 65.38%] [G loss: 1.534578] [Time: 0.248883]\n",
            "324-8 [D loss: 0.491479, acc.: 76.92%] [G loss: 1.456648] [Time: 0.246399]\n",
            "324 (test) [D loss: 1.769067, acc.: 50.00%] [G loss: 3.440706] [Time: 0.076075]\n",
            "325-0 [D loss: 0.293596, acc.: 92.31%] [G loss: 2.014194] [Time: 0.247658]\n",
            "325-1 [D loss: 0.613032, acc.: 69.23%] [G loss: 1.377337] [Time: 0.244702]\n",
            "325-2 [D loss: 0.748617, acc.: 57.69%] [G loss: 1.322508] [Time: 0.245441]\n",
            "325-3 [D loss: 0.530187, acc.: 75.00%] [G loss: 1.571018] [Time: 0.253263]\n",
            "325-4 [D loss: 0.653597, acc.: 67.31%] [G loss: 1.707492] [Time: 0.251337]\n",
            "325-5 [D loss: 0.615725, acc.: 59.62%] [G loss: 1.526572] [Time: 0.250902]\n",
            "325-6 [D loss: 0.517322, acc.: 73.08%] [G loss: 1.787317] [Time: 0.246421]\n",
            "325-7 [D loss: 0.821734, acc.: 51.92%] [G loss: 1.487032] [Time: 0.248452]\n",
            "325-8 [D loss: 0.506810, acc.: 69.23%] [G loss: 1.870541] [Time: 0.244593]\n",
            "325 (test) [D loss: 1.730466, acc.: 50.00%] [G loss: 3.371826] [Time: 0.077516]\n",
            "326-0 [D loss: 0.227811, acc.: 94.23%] [G loss: 2.442900] [Time: 0.247550]\n",
            "326-1 [D loss: 0.712298, acc.: 57.69%] [G loss: 1.389617] [Time: 0.246661]\n",
            "326-2 [D loss: 0.792288, acc.: 53.85%] [G loss: 1.411720] [Time: 0.245552]\n",
            "326-3 [D loss: 0.489488, acc.: 75.00%] [G loss: 1.828987] [Time: 0.246268]\n",
            "326-4 [D loss: 0.595169, acc.: 65.38%] [G loss: 1.877899] [Time: 0.247390]\n",
            "326-5 [D loss: 0.590563, acc.: 71.15%] [G loss: 2.019732] [Time: 0.254804]\n",
            "326-6 [D loss: 0.508514, acc.: 71.15%] [G loss: 1.640828] [Time: 0.247168]\n",
            "326-7 [D loss: 0.697463, acc.: 55.77%] [G loss: 1.159886] [Time: 0.243261]\n",
            "326-8 [D loss: 0.454151, acc.: 78.85%] [G loss: 1.779484] [Time: 0.249593]\n",
            "326 (test) [D loss: 1.769833, acc.: 50.00%] [G loss: 3.430310] [Time: 0.076522]\n",
            "327-0 [D loss: 0.301900, acc.: 88.46%] [G loss: 2.142408] [Time: 0.245879]\n",
            "327-1 [D loss: 0.557191, acc.: 71.15%] [G loss: 1.545696] [Time: 0.246205]\n",
            "327-2 [D loss: 0.731495, acc.: 51.92%] [G loss: 1.316872] [Time: 0.245578]\n",
            "327-3 [D loss: 0.449235, acc.: 76.92%] [G loss: 1.697333] [Time: 0.247381]\n",
            "327-4 [D loss: 0.542087, acc.: 69.23%] [G loss: 1.855779] [Time: 0.244861]\n",
            "327-5 [D loss: 0.515589, acc.: 73.08%] [G loss: 1.564841] [Time: 0.245226]\n",
            "327-6 [D loss: 0.514047, acc.: 76.92%] [G loss: 1.467089] [Time: 0.248062]\n",
            "327-7 [D loss: 0.584633, acc.: 65.38%] [G loss: 1.531062] [Time: 0.244840]\n",
            "327-8 [D loss: 0.555194, acc.: 67.31%] [G loss: 1.878555] [Time: 0.246838]\n",
            "327 (test) [D loss: 1.788638, acc.: 50.00%] [G loss: 3.476155] [Time: 0.078473]\n",
            "328-0 [D loss: 0.376275, acc.: 84.62%] [G loss: 2.031505] [Time: 0.247342]\n",
            "328-1 [D loss: 0.593028, acc.: 67.31%] [G loss: 1.426901] [Time: 0.249880]\n",
            "328-2 [D loss: 0.757059, acc.: 53.85%] [G loss: 1.570296] [Time: 0.244992]\n",
            "328-3 [D loss: 0.520694, acc.: 73.08%] [G loss: 1.414547] [Time: 0.245546]\n",
            "328-4 [D loss: 0.564378, acc.: 76.92%] [G loss: 1.535831] [Time: 0.248021]\n",
            "328-5 [D loss: 0.714957, acc.: 65.38%] [G loss: 1.797262] [Time: 0.244204]\n",
            "328-6 [D loss: 0.457579, acc.: 78.85%] [G loss: 1.966967] [Time: 0.246496]\n",
            "328-7 [D loss: 0.698742, acc.: 55.77%] [G loss: 1.543162] [Time: 0.244519]\n",
            "328-8 [D loss: 0.479458, acc.: 75.00%] [G loss: 1.843109] [Time: 0.244470]\n",
            "328 (test) [D loss: 1.820293, acc.: 50.00%] [G loss: 3.542929] [Time: 0.076506]\n",
            "329-0 [D loss: 0.254753, acc.: 96.15%] [G loss: 2.222519] [Time: 0.248909]\n",
            "329-1 [D loss: 0.738524, acc.: 57.69%] [G loss: 1.290301] [Time: 0.249807]\n",
            "329-2 [D loss: 0.644250, acc.: 65.38%] [G loss: 1.422664] [Time: 0.243256]\n",
            "329-3 [D loss: 0.522915, acc.: 73.08%] [G loss: 1.680124] [Time: 0.247185]\n",
            "329-4 [D loss: 0.550562, acc.: 63.46%] [G loss: 1.597695] [Time: 0.250692]\n",
            "329-5 [D loss: 0.628792, acc.: 67.31%] [G loss: 1.793442] [Time: 0.251543]\n",
            "329-6 [D loss: 0.539421, acc.: 75.00%] [G loss: 1.707750] [Time: 0.254244]\n",
            "329-7 [D loss: 0.677032, acc.: 57.69%] [G loss: 1.275023] [Time: 0.242565]\n",
            "329-8 [D loss: 0.513155, acc.: 75.00%] [G loss: 1.637819] [Time: 0.246525]\n",
            "329 (test) [D loss: 1.736025, acc.: 50.00%] [G loss: 3.366900] [Time: 0.076993]\n",
            "330-0 [D loss: 0.236554, acc.: 96.15%] [G loss: 2.389552] [Time: 0.244066]\n",
            "330-1 [D loss: 0.529996, acc.: 67.31%] [G loss: 1.311020] [Time: 0.247867]\n",
            "330-2 [D loss: 0.831027, acc.: 51.92%] [G loss: 1.445551] [Time: 0.244401]\n",
            "330-3 [D loss: 0.549151, acc.: 69.23%] [G loss: 1.868570] [Time: 0.246635]\n",
            "330-4 [D loss: 0.513220, acc.: 71.15%] [G loss: 1.719315] [Time: 0.246718]\n",
            "330-5 [D loss: 0.547500, acc.: 75.00%] [G loss: 1.695294] [Time: 0.246231]\n",
            "330-6 [D loss: 0.597988, acc.: 67.31%] [G loss: 1.813094] [Time: 0.246980]\n",
            "330-7 [D loss: 0.708685, acc.: 50.00%] [G loss: 1.068896] [Time: 0.245170]\n",
            "330-8 [D loss: 0.511249, acc.: 75.00%] [G loss: 1.880272] [Time: 0.246002]\n",
            "330 (test) [D loss: 1.764781, acc.: 50.00%] [G loss: 3.417210] [Time: 0.075048]\n",
            "331-0 [D loss: 0.288425, acc.: 90.38%] [G loss: 2.362148] [Time: 0.247279]\n",
            "331-1 [D loss: 0.530204, acc.: 76.92%] [G loss: 1.602783] [Time: 0.244964]\n",
            "331-2 [D loss: 0.827687, acc.: 51.92%] [G loss: 1.363209] [Time: 0.244086]\n",
            "331-3 [D loss: 0.684537, acc.: 57.69%] [G loss: 1.819789] [Time: 0.246513]\n",
            "331-4 [D loss: 0.474138, acc.: 76.92%] [G loss: 2.004750] [Time: 0.247229]\n",
            "331-5 [D loss: 0.683196, acc.: 63.46%] [G loss: 1.679553] [Time: 0.248249]\n",
            "331-6 [D loss: 0.522268, acc.: 76.92%] [G loss: 1.267735] [Time: 0.244049]\n",
            "331-7 [D loss: 0.805734, acc.: 42.31%] [G loss: 1.319626] [Time: 0.244156]\n",
            "331-8 [D loss: 0.548213, acc.: 67.31%] [G loss: 1.737511] [Time: 0.248295]\n",
            "331 (test) [D loss: 1.740717, acc.: 50.00%] [G loss: 3.379172] [Time: 0.080404]\n",
            "332-0 [D loss: 0.327911, acc.: 86.54%] [G loss: 2.500559] [Time: 0.246493]\n",
            "332-1 [D loss: 0.585258, acc.: 57.69%] [G loss: 1.257224] [Time: 0.245615]\n",
            "332-2 [D loss: 0.747993, acc.: 50.00%] [G loss: 1.299707] [Time: 0.245051]\n",
            "332-3 [D loss: 0.546824, acc.: 76.92%] [G loss: 1.669258] [Time: 0.248623]\n",
            "332-4 [D loss: 0.497723, acc.: 73.08%] [G loss: 1.402027] [Time: 0.245357]\n",
            "332-5 [D loss: 0.568054, acc.: 69.23%] [G loss: 1.475600] [Time: 0.247214]\n",
            "332-6 [D loss: 0.559216, acc.: 65.38%] [G loss: 1.721749] [Time: 0.242816]\n",
            "332-7 [D loss: 0.736610, acc.: 57.69%] [G loss: 1.367000] [Time: 0.247340]\n",
            "332-8 [D loss: 0.566396, acc.: 59.62%] [G loss: 1.945095] [Time: 0.244192]\n",
            "332 (test) [D loss: 1.732180, acc.: 50.00%] [G loss: 3.363041] [Time: 0.080636]\n",
            "333-0 [D loss: 0.249911, acc.: 96.15%] [G loss: 2.267438] [Time: 0.246812]\n",
            "333-1 [D loss: 0.611777, acc.: 69.23%] [G loss: 1.498555] [Time: 0.247362]\n",
            "333-2 [D loss: 0.763545, acc.: 46.15%] [G loss: 1.561089] [Time: 0.245824]\n",
            "333-3 [D loss: 0.603833, acc.: 65.38%] [G loss: 1.755208] [Time: 0.244651]\n",
            "333-4 [D loss: 0.521687, acc.: 69.23%] [G loss: 1.776230] [Time: 0.245991]\n",
            "333-5 [D loss: 0.579522, acc.: 69.23%] [G loss: 1.724191] [Time: 0.250117]\n",
            "333-6 [D loss: 0.636317, acc.: 59.62%] [G loss: 1.498029] [Time: 0.248296]\n",
            "333-7 [D loss: 0.752164, acc.: 48.08%] [G loss: 1.373628] [Time: 0.247551]\n",
            "333-8 [D loss: 0.500084, acc.: 76.92%] [G loss: 1.977170] [Time: 0.245680]\n",
            "333 (test) [D loss: 1.799324, acc.: 50.00%] [G loss: 3.490966] [Time: 0.081506]\n",
            "334-0 [D loss: 0.347641, acc.: 92.31%] [G loss: 2.177389] [Time: 0.247883]\n",
            "334-1 [D loss: 0.612344, acc.: 67.31%] [G loss: 1.680620] [Time: 0.245512]\n",
            "334-2 [D loss: 0.656069, acc.: 61.54%] [G loss: 1.289690] [Time: 0.243787]\n",
            "334-3 [D loss: 0.690982, acc.: 55.77%] [G loss: 2.085577] [Time: 0.249864]\n",
            "334-4 [D loss: 0.488998, acc.: 78.85%] [G loss: 1.807785] [Time: 0.248720]\n",
            "334-5 [D loss: 0.654989, acc.: 65.38%] [G loss: 1.735406] [Time: 0.247298]\n",
            "334-6 [D loss: 0.637030, acc.: 63.46%] [G loss: 1.505119] [Time: 0.249637]\n",
            "334-7 [D loss: 0.798531, acc.: 53.85%] [G loss: 1.326817] [Time: 0.246524]\n",
            "334-8 [D loss: 0.545251, acc.: 69.23%] [G loss: 1.922600] [Time: 0.251901]\n",
            "334 (test) [D loss: 1.818607, acc.: 50.00%] [G loss: 3.532564] [Time: 0.076351]\n",
            "335-0 [D loss: 0.297029, acc.: 92.31%] [G loss: 2.223764] [Time: 0.244718]\n",
            "335-1 [D loss: 0.570596, acc.: 67.31%] [G loss: 1.368297] [Time: 0.249237]\n",
            "335-2 [D loss: 0.854407, acc.: 48.08%] [G loss: 1.452973] [Time: 0.246735]\n",
            "335-3 [D loss: 0.555209, acc.: 69.23%] [G loss: 1.972475] [Time: 0.246639]\n",
            "335-4 [D loss: 0.487763, acc.: 76.92%] [G loss: 1.655592] [Time: 0.247589]\n",
            "335-5 [D loss: 0.564087, acc.: 69.23%] [G loss: 1.741105] [Time: 0.250864]\n",
            "335-6 [D loss: 0.541544, acc.: 73.08%] [G loss: 1.644368] [Time: 0.246907]\n",
            "335-7 [D loss: 0.665865, acc.: 59.62%] [G loss: 1.407241] [Time: 0.246572]\n",
            "335-8 [D loss: 0.506082, acc.: 78.85%] [G loss: 1.588496] [Time: 0.244655]\n",
            "335 (test) [D loss: 1.794705, acc.: 50.00%] [G loss: 3.500816] [Time: 0.077607]\n",
            "336-0 [D loss: 0.272620, acc.: 92.31%] [G loss: 2.224321] [Time: 0.246918]\n",
            "336-1 [D loss: 0.647273, acc.: 53.85%] [G loss: 1.323601] [Time: 0.247657]\n",
            "336-2 [D loss: 0.734439, acc.: 53.85%] [G loss: 1.359476] [Time: 0.248315]\n",
            "336-3 [D loss: 0.568251, acc.: 73.08%] [G loss: 1.561439] [Time: 0.250271]\n",
            "336-4 [D loss: 0.553178, acc.: 65.38%] [G loss: 1.537979] [Time: 0.245831]\n",
            "336-5 [D loss: 0.578053, acc.: 71.15%] [G loss: 1.870606] [Time: 0.247435]\n",
            "336-6 [D loss: 0.679652, acc.: 59.62%] [G loss: 1.776695] [Time: 0.247711]\n",
            "336-7 [D loss: 0.760321, acc.: 51.92%] [G loss: 1.246216] [Time: 0.243833]\n",
            "336-8 [D loss: 0.478544, acc.: 86.54%] [G loss: 1.728144] [Time: 0.252981]\n",
            "336 (test) [D loss: 1.851144, acc.: 50.00%] [G loss: 3.602839] [Time: 0.076598]\n",
            "337-0 [D loss: 0.286817, acc.: 90.38%] [G loss: 2.040685] [Time: 0.245229]\n",
            "337-1 [D loss: 0.636964, acc.: 59.62%] [G loss: 1.626487] [Time: 0.243476]\n",
            "337-2 [D loss: 0.713225, acc.: 63.46%] [G loss: 1.472882] [Time: 0.244352]\n",
            "337-3 [D loss: 0.744997, acc.: 65.38%] [G loss: 1.689627] [Time: 0.246559]\n",
            "337-4 [D loss: 0.576687, acc.: 69.23%] [G loss: 1.712574] [Time: 0.248353]\n",
            "337-5 [D loss: 0.546421, acc.: 71.15%] [G loss: 1.645754] [Time: 0.246415]\n",
            "337-6 [D loss: 0.592426, acc.: 53.85%] [G loss: 1.401565] [Time: 0.248498]\n",
            "337-7 [D loss: 0.831753, acc.: 50.00%] [G loss: 1.149740] [Time: 0.249714]\n",
            "337-8 [D loss: 0.559444, acc.: 63.46%] [G loss: 1.626224] [Time: 0.243276]\n",
            "337 (test) [D loss: 1.928617, acc.: 50.00%] [G loss: 3.760756] [Time: 0.078323]\n",
            "338-0 [D loss: 0.411969, acc.: 84.62%] [G loss: 2.099365] [Time: 0.247813]\n",
            "338-1 [D loss: 0.503555, acc.: 76.92%] [G loss: 1.369686] [Time: 0.247270]\n",
            "338-2 [D loss: 0.886070, acc.: 42.31%] [G loss: 1.312495] [Time: 0.246240]\n",
            "338-3 [D loss: 0.464891, acc.: 84.62%] [G loss: 1.663967] [Time: 0.247302]\n",
            "338-4 [D loss: 0.592836, acc.: 63.46%] [G loss: 1.619306] [Time: 0.249764]\n",
            "338-5 [D loss: 0.546870, acc.: 76.92%] [G loss: 1.885286] [Time: 0.243667]\n",
            "338-6 [D loss: 0.573477, acc.: 67.31%] [G loss: 1.824718] [Time: 0.246476]\n",
            "338-7 [D loss: 0.775090, acc.: 51.92%] [G loss: 1.168949] [Time: 0.248144]\n",
            "338-8 [D loss: 0.609657, acc.: 63.46%] [G loss: 1.491129] [Time: 0.247473]\n",
            "338 (test) [D loss: 1.759351, acc.: 50.00%] [G loss: 3.410740] [Time: 0.074988]\n",
            "339-0 [D loss: 0.311844, acc.: 90.38%] [G loss: 1.909427] [Time: 0.248733]\n",
            "339-1 [D loss: 0.551261, acc.: 69.23%] [G loss: 1.462414] [Time: 0.244000]\n",
            "339-2 [D loss: 0.725944, acc.: 63.46%] [G loss: 1.409123] [Time: 0.248687]\n",
            "339-3 [D loss: 0.687889, acc.: 59.62%] [G loss: 1.698143] [Time: 0.247928]\n",
            "339-4 [D loss: 0.528855, acc.: 75.00%] [G loss: 1.722597] [Time: 0.244533]\n",
            "339-5 [D loss: 0.458026, acc.: 82.69%] [G loss: 1.851962] [Time: 0.247603]\n",
            "339-6 [D loss: 0.473774, acc.: 75.00%] [G loss: 1.600327] [Time: 0.247706]\n",
            "339-7 [D loss: 0.823609, acc.: 42.31%] [G loss: 1.339844] [Time: 0.245055]\n",
            "339-8 [D loss: 0.571107, acc.: 73.08%] [G loss: 1.972748] [Time: 0.245651]\n",
            "339 (test) [D loss: 1.827664, acc.: 50.00%] [G loss: 3.556162] [Time: 0.077617]\n",
            "340-0 [D loss: 0.413254, acc.: 80.77%] [G loss: 1.993101] [Time: 0.243970]\n",
            "340-1 [D loss: 0.734993, acc.: 57.69%] [G loss: 1.329627] [Time: 0.248696]\n",
            "340-2 [D loss: 0.705448, acc.: 50.00%] [G loss: 1.432681] [Time: 0.243693]\n",
            "340-3 [D loss: 0.497216, acc.: 73.08%] [G loss: 1.709726] [Time: 0.248442]\n",
            "340-4 [D loss: 0.482538, acc.: 73.08%] [G loss: 1.617898] [Time: 0.247167]\n",
            "340-5 [D loss: 0.569378, acc.: 67.31%] [G loss: 1.700638] [Time: 0.241762]\n",
            "340-6 [D loss: 0.555120, acc.: 69.23%] [G loss: 1.491294] [Time: 0.247009]\n",
            "340-7 [D loss: 0.792762, acc.: 48.08%] [G loss: 1.536045] [Time: 0.246915]\n",
            "340-8 [D loss: 0.518188, acc.: 75.00%] [G loss: 1.832211] [Time: 0.244792]\n",
            "340 (test) [D loss: 1.773184, acc.: 50.00%] [G loss: 3.425780] [Time: 0.077432]\n",
            "341-0 [D loss: 0.441187, acc.: 82.69%] [G loss: 1.988974] [Time: 0.252632]\n",
            "341-1 [D loss: 0.641926, acc.: 61.54%] [G loss: 1.544958] [Time: 0.245545]\n",
            "341-2 [D loss: 0.642206, acc.: 65.38%] [G loss: 1.385447] [Time: 0.245528]\n",
            "341-3 [D loss: 0.637381, acc.: 69.23%] [G loss: 1.709872] [Time: 0.246283]\n",
            "341-4 [D loss: 0.574839, acc.: 69.23%] [G loss: 1.621089] [Time: 0.245251]\n",
            "341-5 [D loss: 0.509251, acc.: 80.77%] [G loss: 1.630693] [Time: 0.249426]\n",
            "341-6 [D loss: 0.591784, acc.: 65.38%] [G loss: 1.607257] [Time: 0.248045]\n",
            "341-7 [D loss: 0.744557, acc.: 53.85%] [G loss: 1.206957] [Time: 0.246105]\n",
            "341-8 [D loss: 0.629193, acc.: 61.54%] [G loss: 1.509938] [Time: 0.245992]\n",
            "341 (test) [D loss: 1.884927, acc.: 50.00%] [G loss: 3.674812] [Time: 0.077070]\n",
            "342-0 [D loss: 0.417705, acc.: 82.69%] [G loss: 1.926785] [Time: 0.247872]\n",
            "342-1 [D loss: 0.616130, acc.: 69.23%] [G loss: 1.614532] [Time: 0.244890]\n",
            "342-2 [D loss: 0.704847, acc.: 63.46%] [G loss: 1.539601] [Time: 0.246497]\n",
            "342-3 [D loss: 0.497229, acc.: 65.38%] [G loss: 1.716494] [Time: 0.243968]\n",
            "342-4 [D loss: 0.588602, acc.: 63.46%] [G loss: 1.765073] [Time: 0.248787]\n",
            "342-5 [D loss: 0.440421, acc.: 84.62%] [G loss: 1.756961] [Time: 0.246853]\n",
            "342-6 [D loss: 0.479780, acc.: 80.77%] [G loss: 1.654515] [Time: 0.243098]\n",
            "342-7 [D loss: 0.877760, acc.: 44.23%] [G loss: 1.081157] [Time: 0.247646]\n",
            "342-8 [D loss: 0.454704, acc.: 78.85%] [G loss: 1.639205] [Time: 0.244558]\n",
            "342 (test) [D loss: 1.929041, acc.: 50.00%] [G loss: 3.757234] [Time: 0.075990]\n",
            "343-0 [D loss: 0.499662, acc.: 73.08%] [G loss: 1.670248] [Time: 0.246337]\n",
            "343-1 [D loss: 0.506903, acc.: 75.00%] [G loss: 1.709547] [Time: 0.246699]\n",
            "343-2 [D loss: 0.599713, acc.: 57.69%] [G loss: 1.349043] [Time: 0.245331]\n",
            "343-3 [D loss: 0.561176, acc.: 67.31%] [G loss: 1.556742] [Time: 0.246316]\n",
            "343-4 [D loss: 0.519071, acc.: 73.08%] [G loss: 1.517739] [Time: 0.243447]\n",
            "343-5 [D loss: 0.547013, acc.: 67.31%] [G loss: 1.492778] [Time: 0.245256]\n",
            "343-6 [D loss: 0.509267, acc.: 78.85%] [G loss: 1.488023] [Time: 0.243905]\n",
            "343-7 [D loss: 0.978665, acc.: 32.69%] [G loss: 1.180052] [Time: 0.245164]\n",
            "343-8 [D loss: 0.668521, acc.: 71.15%] [G loss: 1.871228] [Time: 0.248496]\n",
            "343 (test) [D loss: 1.865222, acc.: 50.00%] [G loss: 3.627947] [Time: 0.078253]\n",
            "344-0 [D loss: 0.374333, acc.: 82.69%] [G loss: 2.122490] [Time: 0.243237]\n",
            "344-1 [D loss: 0.588759, acc.: 73.08%] [G loss: 1.589710] [Time: 0.248769]\n",
            "344-2 [D loss: 0.779602, acc.: 50.00%] [G loss: 1.315174] [Time: 0.244421]\n",
            "344-3 [D loss: 0.595113, acc.: 71.15%] [G loss: 1.538264] [Time: 0.250595]\n",
            "344-4 [D loss: 0.517196, acc.: 73.08%] [G loss: 1.410209] [Time: 0.246268]\n",
            "344-5 [D loss: 0.658095, acc.: 67.31%] [G loss: 1.590296] [Time: 0.246489]\n",
            "344-6 [D loss: 0.589757, acc.: 67.31%] [G loss: 1.630201] [Time: 0.245876]\n",
            "344-7 [D loss: 0.824055, acc.: 46.15%] [G loss: 1.207473] [Time: 0.247397]\n",
            "344-8 [D loss: 0.533002, acc.: 69.23%] [G loss: 1.723000] [Time: 0.248443]\n",
            "344 (test) [D loss: 1.841251, acc.: 50.00%] [G loss: 3.573146] [Time: 0.076579]\n",
            "345-0 [D loss: 0.465560, acc.: 78.85%] [G loss: 1.765900] [Time: 0.247239]\n",
            "345-1 [D loss: 0.510002, acc.: 69.23%] [G loss: 1.602720] [Time: 0.249786]\n",
            "345-2 [D loss: 0.689514, acc.: 57.69%] [G loss: 1.446503] [Time: 0.245532]\n",
            "345-3 [D loss: 0.568555, acc.: 69.23%] [G loss: 1.768511] [Time: 0.246831]\n",
            "345-4 [D loss: 0.577421, acc.: 73.08%] [G loss: 1.406417] [Time: 0.246455]\n",
            "345-5 [D loss: 0.652138, acc.: 65.38%] [G loss: 1.785872] [Time: 0.245903]\n",
            "345-6 [D loss: 0.519810, acc.: 69.23%] [G loss: 1.588561] [Time: 0.244754]\n",
            "345-7 [D loss: 0.934768, acc.: 42.31%] [G loss: 1.168055] [Time: 0.244718]\n",
            "345-8 [D loss: 0.563955, acc.: 71.15%] [G loss: 1.740130] [Time: 0.247523]\n",
            "345 (test) [D loss: 1.802272, acc.: 50.00%] [G loss: 3.496287] [Time: 0.078279]\n",
            "346-0 [D loss: 0.338000, acc.: 88.46%] [G loss: 1.866129] [Time: 0.245927]\n",
            "346-1 [D loss: 0.686828, acc.: 55.77%] [G loss: 1.602527] [Time: 0.246417]\n",
            "346-2 [D loss: 0.689223, acc.: 59.62%] [G loss: 1.600950] [Time: 0.254986]\n",
            "346-3 [D loss: 0.623960, acc.: 61.54%] [G loss: 1.601936] [Time: 0.245441]\n",
            "346-4 [D loss: 0.631087, acc.: 67.31%] [G loss: 1.454934] [Time: 0.247917]\n",
            "346-5 [D loss: 0.566305, acc.: 63.46%] [G loss: 1.786714] [Time: 0.250135]\n",
            "346-6 [D loss: 0.729293, acc.: 57.69%] [G loss: 1.589984] [Time: 0.247332]\n",
            "346-7 [D loss: 0.728334, acc.: 51.92%] [G loss: 1.350390] [Time: 0.249366]\n",
            "346-8 [D loss: 0.563919, acc.: 71.15%] [G loss: 1.489089] [Time: 0.245372]\n",
            "346 (test) [D loss: 1.887107, acc.: 50.00%] [G loss: 3.672630] [Time: 0.076455]\n",
            "347-0 [D loss: 0.361486, acc.: 88.46%] [G loss: 1.947067] [Time: 0.246533]\n",
            "347-1 [D loss: 0.637063, acc.: 59.62%] [G loss: 1.450611] [Time: 0.248145]\n",
            "347-2 [D loss: 0.714749, acc.: 57.69%] [G loss: 1.572282] [Time: 0.245328]\n",
            "347-3 [D loss: 0.606475, acc.: 67.31%] [G loss: 1.699636] [Time: 0.247806]\n",
            "347-4 [D loss: 0.643013, acc.: 71.15%] [G loss: 1.879277] [Time: 0.251640]\n",
            "347-5 [D loss: 0.585447, acc.: 69.23%] [G loss: 1.654914] [Time: 0.246044]\n",
            "347-6 [D loss: 0.568102, acc.: 71.15%] [G loss: 1.879450] [Time: 0.246637]\n",
            "347-7 [D loss: 0.811170, acc.: 42.31%] [G loss: 1.298429] [Time: 0.246328]\n",
            "347-8 [D loss: 0.509059, acc.: 76.92%] [G loss: 1.225465] [Time: 0.249214]\n",
            "347 (test) [D loss: 1.949269, acc.: 50.00%] [G loss: 3.810546] [Time: 0.076860]\n",
            "348-0 [D loss: 0.455157, acc.: 76.92%] [G loss: 1.706897] [Time: 0.243763]\n",
            "348-1 [D loss: 0.571766, acc.: 71.15%] [G loss: 1.376683] [Time: 0.248827]\n",
            "348-2 [D loss: 0.552224, acc.: 67.31%] [G loss: 1.401530] [Time: 0.246020]\n",
            "348-3 [D loss: 0.630802, acc.: 67.31%] [G loss: 1.824848] [Time: 0.249540]\n",
            "348-4 [D loss: 0.636306, acc.: 61.54%] [G loss: 1.707937] [Time: 0.248937]\n",
            "348-5 [D loss: 0.503401, acc.: 76.92%] [G loss: 1.563643] [Time: 0.246708]\n",
            "348-6 [D loss: 0.688837, acc.: 51.92%] [G loss: 1.763381] [Time: 0.248333]\n",
            "348-7 [D loss: 0.630175, acc.: 57.69%] [G loss: 1.442374] [Time: 0.247271]\n",
            "348-8 [D loss: 0.637702, acc.: 67.31%] [G loss: 1.470177] [Time: 0.243150]\n",
            "348 (test) [D loss: 1.891842, acc.: 50.00%] [G loss: 3.691553] [Time: 0.080846]\n",
            "349-0 [D loss: 0.347139, acc.: 84.62%] [G loss: 2.146707] [Time: 0.248652]\n",
            "349-1 [D loss: 0.646016, acc.: 65.38%] [G loss: 1.053392] [Time: 0.248025]\n",
            "349-2 [D loss: 0.716343, acc.: 53.85%] [G loss: 1.425548] [Time: 0.251346]\n",
            "349-3 [D loss: 0.586069, acc.: 71.15%] [G loss: 1.532844] [Time: 0.246399]\n",
            "349-4 [D loss: 0.583081, acc.: 67.31%] [G loss: 1.650438] [Time: 0.245781]\n",
            "349-5 [D loss: 0.505247, acc.: 71.15%] [G loss: 1.689941] [Time: 0.250552]\n",
            "349-6 [D loss: 0.601153, acc.: 61.54%] [G loss: 1.600536] [Time: 0.246212]\n",
            "349-7 [D loss: 0.764199, acc.: 42.31%] [G loss: 1.174662] [Time: 0.247465]\n",
            "349-8 [D loss: 0.638552, acc.: 59.62%] [G loss: 1.687618] [Time: 0.248919]\n",
            "349 (test) [D loss: 1.926142, acc.: 50.00%] [G loss: 3.762902] [Time: 0.080600]\n",
            "350-0 [D loss: 0.441439, acc.: 78.85%] [G loss: 1.840270] [Time: 0.244815]\n",
            "350-1 [D loss: 0.598876, acc.: 63.46%] [G loss: 1.473258] [Time: 0.247712]\n",
            "350-2 [D loss: 0.660658, acc.: 67.31%] [G loss: 1.363734] [Time: 0.248240]\n",
            "350-3 [D loss: 0.778442, acc.: 53.85%] [G loss: 1.522587] [Time: 0.245010]\n",
            "350-4 [D loss: 0.532871, acc.: 73.08%] [G loss: 1.528390] [Time: 0.251716]\n",
            "350-5 [D loss: 0.554070, acc.: 71.15%] [G loss: 1.681672] [Time: 0.245028]\n",
            "350-6 [D loss: 0.502844, acc.: 78.85%] [G loss: 1.578498] [Time: 0.244956]\n",
            "350-7 [D loss: 0.704302, acc.: 48.08%] [G loss: 1.102150] [Time: 0.246948]\n",
            "350-8 [D loss: 0.550023, acc.: 71.15%] [G loss: 1.497606] [Time: 0.247452]\n",
            "350 (test) [D loss: 1.926545, acc.: 50.00%] [G loss: 3.768692] [Time: 0.077759]\n",
            "351-0 [D loss: 0.361383, acc.: 86.54%] [G loss: 1.847874] [Time: 0.247566]\n",
            "351-1 [D loss: 0.693138, acc.: 57.69%] [G loss: 1.516057] [Time: 0.241314]\n",
            "351-2 [D loss: 0.624243, acc.: 67.31%] [G loss: 1.254010] [Time: 0.248314]\n",
            "351-3 [D loss: 0.656483, acc.: 63.46%] [G loss: 1.599679] [Time: 0.245047]\n",
            "351-4 [D loss: 0.650665, acc.: 65.38%] [G loss: 1.611775] [Time: 0.246817]\n",
            "351-5 [D loss: 0.528683, acc.: 73.08%] [G loss: 1.824614] [Time: 0.246204]\n",
            "351-6 [D loss: 0.527882, acc.: 73.08%] [G loss: 1.555830] [Time: 0.247820]\n",
            "351-7 [D loss: 0.897420, acc.: 38.46%] [G loss: 1.027803] [Time: 0.245132]\n",
            "351-8 [D loss: 0.683258, acc.: 59.62%] [G loss: 1.578265] [Time: 0.245116]\n",
            "351 (test) [D loss: 1.878636, acc.: 50.00%] [G loss: 3.668026] [Time: 0.079420]\n",
            "352-0 [D loss: 0.316859, acc.: 90.38%] [G loss: 1.654178] [Time: 0.246394]\n",
            "352-1 [D loss: 0.545010, acc.: 65.38%] [G loss: 1.504604] [Time: 0.246613]\n",
            "352-2 [D loss: 0.599944, acc.: 67.31%] [G loss: 1.517410] [Time: 0.250756]\n",
            "352-3 [D loss: 0.737908, acc.: 50.00%] [G loss: 1.558785] [Time: 0.249810]\n",
            "352-4 [D loss: 0.547211, acc.: 75.00%] [G loss: 1.667637] [Time: 0.243957]\n",
            "352-5 [D loss: 0.600891, acc.: 63.46%] [G loss: 1.778345] [Time: 0.246700]\n",
            "352-6 [D loss: 0.616343, acc.: 65.38%] [G loss: 1.644649] [Time: 0.246741]\n",
            "352-7 [D loss: 0.901112, acc.: 40.38%] [G loss: 1.186728] [Time: 0.244844]\n",
            "352-8 [D loss: 0.547724, acc.: 73.08%] [G loss: 1.577694] [Time: 0.246330]\n",
            "352 (test) [D loss: 1.895123, acc.: 50.00%] [G loss: 3.693421] [Time: 0.076771]\n",
            "353-0 [D loss: 0.443970, acc.: 75.00%] [G loss: 1.919079] [Time: 0.247897]\n",
            "353-1 [D loss: 0.582585, acc.: 69.23%] [G loss: 1.169715] [Time: 0.246617]\n",
            "353-2 [D loss: 0.673362, acc.: 59.62%] [G loss: 1.546449] [Time: 0.244611]\n",
            "353-3 [D loss: 0.615489, acc.: 65.38%] [G loss: 1.504167] [Time: 0.246898]\n",
            "353-4 [D loss: 0.510522, acc.: 73.08%] [G loss: 1.191402] [Time: 0.243990]\n",
            "353-5 [D loss: 0.565929, acc.: 71.15%] [G loss: 1.628059] [Time: 0.243300]\n",
            "353-6 [D loss: 0.489102, acc.: 75.00%] [G loss: 1.689517] [Time: 0.247969]\n",
            "353-7 [D loss: 0.868171, acc.: 44.23%] [G loss: 1.109173] [Time: 0.244292]\n",
            "353-8 [D loss: 0.511448, acc.: 73.08%] [G loss: 1.660768] [Time: 0.247705]\n",
            "353 (test) [D loss: 1.968194, acc.: 50.00%] [G loss: 3.843597] [Time: 0.076659]\n",
            "354-0 [D loss: 0.633206, acc.: 67.31%] [G loss: 1.753508] [Time: 0.247142]\n",
            "354-1 [D loss: 0.574645, acc.: 67.31%] [G loss: 1.424089] [Time: 0.251532]\n",
            "354-2 [D loss: 0.660279, acc.: 63.46%] [G loss: 1.248098] [Time: 0.246952]\n",
            "354-3 [D loss: 0.645721, acc.: 61.54%] [G loss: 1.517555] [Time: 0.249032]\n",
            "354-4 [D loss: 0.692172, acc.: 51.92%] [G loss: 1.628290] [Time: 0.248434]\n",
            "354-5 [D loss: 0.507509, acc.: 76.92%] [G loss: 1.818874] [Time: 0.247792]\n",
            "354-6 [D loss: 0.605552, acc.: 67.31%] [G loss: 1.444954] [Time: 0.246005]\n",
            "354-7 [D loss: 1.107632, acc.: 32.69%] [G loss: 1.206379] [Time: 0.247315]\n",
            "354-8 [D loss: 0.562477, acc.: 63.46%] [G loss: 1.648224] [Time: 0.248088]\n",
            "354 (test) [D loss: 1.916674, acc.: 50.00%] [G loss: 3.744389] [Time: 0.076401]\n",
            "355-0 [D loss: 0.435174, acc.: 82.69%] [G loss: 1.679309] [Time: 0.247264]\n",
            "355-1 [D loss: 0.671563, acc.: 53.85%] [G loss: 1.321229] [Time: 0.246225]\n",
            "355-2 [D loss: 0.635221, acc.: 65.38%] [G loss: 1.429303] [Time: 0.244032]\n",
            "355-3 [D loss: 0.710967, acc.: 59.62%] [G loss: 1.879283] [Time: 0.249393]\n",
            "355-4 [D loss: 0.579569, acc.: 65.38%] [G loss: 1.501536] [Time: 0.248354]\n",
            "355-5 [D loss: 0.567595, acc.: 67.31%] [G loss: 1.570601] [Time: 0.249703]\n",
            "355-6 [D loss: 0.544003, acc.: 67.31%] [G loss: 1.433079] [Time: 0.247359]\n",
            "355-7 [D loss: 0.907517, acc.: 34.62%] [G loss: 0.990456] [Time: 0.250548]\n",
            "355-8 [D loss: 0.625119, acc.: 67.31%] [G loss: 1.437086] [Time: 0.250134]\n",
            "355 (test) [D loss: 1.955383, acc.: 50.00%] [G loss: 3.824841] [Time: 0.076923]\n",
            "356-0 [D loss: 0.514205, acc.: 75.00%] [G loss: 1.819475] [Time: 0.249282]\n",
            "356-1 [D loss: 0.703276, acc.: 51.92%] [G loss: 1.468471] [Time: 0.249129]\n",
            "356-2 [D loss: 0.718642, acc.: 51.92%] [G loss: 1.408167] [Time: 0.247623]\n",
            "356-3 [D loss: 0.684400, acc.: 59.62%] [G loss: 1.560300] [Time: 0.247521]\n",
            "356-4 [D loss: 0.547097, acc.: 71.15%] [G loss: 1.570145] [Time: 0.245547]\n",
            "356-5 [D loss: 0.494850, acc.: 73.08%] [G loss: 1.943638] [Time: 0.253030]\n",
            "356-6 [D loss: 0.486263, acc.: 82.69%] [G loss: 1.515121] [Time: 0.244539]\n",
            "356-7 [D loss: 0.920466, acc.: 42.31%] [G loss: 1.125951] [Time: 0.245629]\n",
            "356-8 [D loss: 0.607486, acc.: 65.38%] [G loss: 1.232191] [Time: 0.249205]\n",
            "356 (test) [D loss: 1.998949, acc.: 50.00%] [G loss: 3.922314] [Time: 0.077230]\n",
            "357-0 [D loss: 0.372583, acc.: 84.62%] [G loss: 1.973652] [Time: 0.247687]\n",
            "357-1 [D loss: 0.735719, acc.: 48.08%] [G loss: 1.431166] [Time: 0.247892]\n",
            "357-2 [D loss: 0.537546, acc.: 69.23%] [G loss: 1.609073] [Time: 0.248786]\n",
            "357-3 [D loss: 0.607806, acc.: 61.54%] [G loss: 1.255049] [Time: 0.248860]\n",
            "357-4 [D loss: 0.559414, acc.: 67.31%] [G loss: 1.547610] [Time: 0.246601]\n",
            "357-5 [D loss: 0.540250, acc.: 67.31%] [G loss: 1.836399] [Time: 0.245750]\n",
            "357-6 [D loss: 0.704497, acc.: 48.08%] [G loss: 1.609762] [Time: 0.245987]\n",
            "357-7 [D loss: 0.871121, acc.: 46.15%] [G loss: 1.486743] [Time: 0.253068]\n",
            "357-8 [D loss: 0.671129, acc.: 57.69%] [G loss: 1.581841] [Time: 0.245850]\n",
            "357 (test) [D loss: 1.940291, acc.: 50.00%] [G loss: 3.797306] [Time: 0.076036]\n",
            "358-0 [D loss: 0.431834, acc.: 80.77%] [G loss: 1.814287] [Time: 0.246993]\n",
            "358-1 [D loss: 0.673017, acc.: 57.69%] [G loss: 1.212686] [Time: 0.249695]\n",
            "358-2 [D loss: 0.666267, acc.: 67.31%] [G loss: 1.483990] [Time: 0.247076]\n",
            "358-3 [D loss: 0.664588, acc.: 55.77%] [G loss: 1.811205] [Time: 0.245643]\n",
            "358-4 [D loss: 0.630065, acc.: 61.54%] [G loss: 1.444883] [Time: 0.245729]\n",
            "358-5 [D loss: 0.593223, acc.: 76.92%] [G loss: 1.368675] [Time: 0.247620]\n",
            "358-6 [D loss: 0.461670, acc.: 86.54%] [G loss: 1.772589] [Time: 0.250148]\n",
            "358-7 [D loss: 0.847688, acc.: 51.92%] [G loss: 1.160185] [Time: 0.245142]\n",
            "358-8 [D loss: 0.563677, acc.: 75.00%] [G loss: 1.592693] [Time: 0.242952]\n",
            "358 (test) [D loss: 1.954319, acc.: 50.00%] [G loss: 3.829173] [Time: 0.078516]\n",
            "359-0 [D loss: 0.540493, acc.: 71.15%] [G loss: 1.641705] [Time: 0.252917]\n",
            "359-1 [D loss: 0.753134, acc.: 53.85%] [G loss: 1.047798] [Time: 0.246054]\n",
            "359-2 [D loss: 0.693069, acc.: 55.77%] [G loss: 1.477232] [Time: 0.246671]\n",
            "359-3 [D loss: 0.682153, acc.: 69.23%] [G loss: 1.357928] [Time: 0.245008]\n",
            "359-4 [D loss: 0.535021, acc.: 73.08%] [G loss: 1.851858] [Time: 0.248058]\n",
            "359-5 [D loss: 0.554383, acc.: 65.38%] [G loss: 1.544322] [Time: 0.245364]\n",
            "359-6 [D loss: 0.579954, acc.: 75.00%] [G loss: 1.617771] [Time: 0.244779]\n",
            "359-7 [D loss: 0.894396, acc.: 38.46%] [G loss: 1.151315] [Time: 0.245875]\n",
            "359-8 [D loss: 0.609146, acc.: 65.38%] [G loss: 1.402917] [Time: 0.246284]\n",
            "359 (test) [D loss: 1.990489, acc.: 50.00%] [G loss: 3.891886] [Time: 0.076464]\n",
            "360-0 [D loss: 0.337345, acc.: 90.38%] [G loss: 1.615463] [Time: 0.250921]\n",
            "360-1 [D loss: 0.768487, acc.: 53.85%] [G loss: 1.317653] [Time: 0.248830]\n",
            "360-2 [D loss: 0.765086, acc.: 51.92%] [G loss: 1.479638] [Time: 0.243646]\n",
            "360-3 [D loss: 0.594463, acc.: 65.38%] [G loss: 1.381289] [Time: 0.250997]\n",
            "360-4 [D loss: 0.551951, acc.: 75.00%] [G loss: 1.674862] [Time: 0.246937]\n",
            "360-5 [D loss: 0.542196, acc.: 71.15%] [G loss: 1.568797] [Time: 0.244457]\n",
            "360-6 [D loss: 0.543484, acc.: 71.15%] [G loss: 1.647969] [Time: 0.247957]\n",
            "360-7 [D loss: 0.893034, acc.: 36.54%] [G loss: 1.190960] [Time: 0.245508]\n",
            "360-8 [D loss: 0.618084, acc.: 67.31%] [G loss: 1.703339] [Time: 0.246528]\n",
            "360 (test) [D loss: 2.054045, acc.: 50.00%] [G loss: 4.028605] [Time: 0.075737]\n",
            "361-0 [D loss: 0.446300, acc.: 76.92%] [G loss: 1.906875] [Time: 0.246331]\n",
            "361-1 [D loss: 0.697507, acc.: 63.46%] [G loss: 1.315050] [Time: 0.247602]\n",
            "361-2 [D loss: 0.776438, acc.: 50.00%] [G loss: 1.666934] [Time: 0.246462]\n",
            "361-3 [D loss: 0.690408, acc.: 53.85%] [G loss: 1.550779] [Time: 0.244821]\n",
            "361-4 [D loss: 0.562567, acc.: 67.31%] [G loss: 1.614667] [Time: 0.248118]\n",
            "361-5 [D loss: 0.619575, acc.: 57.69%] [G loss: 1.565306] [Time: 0.245071]\n",
            "361-6 [D loss: 0.548120, acc.: 69.23%] [G loss: 1.388028] [Time: 0.246278]\n",
            "361-7 [D loss: 0.904256, acc.: 38.46%] [G loss: 1.228997] [Time: 0.248467]\n",
            "361-8 [D loss: 0.543438, acc.: 76.92%] [G loss: 1.721798] [Time: 0.249763]\n",
            "361 (test) [D loss: 1.995483, acc.: 50.00%] [G loss: 3.899355] [Time: 0.076184]\n",
            "362-0 [D loss: 0.384973, acc.: 84.62%] [G loss: 1.655775] [Time: 0.244884]\n",
            "362-1 [D loss: 0.726175, acc.: 55.77%] [G loss: 1.345413] [Time: 0.244433]\n",
            "362-2 [D loss: 0.792505, acc.: 50.00%] [G loss: 1.400632] [Time: 0.248507]\n",
            "362-3 [D loss: 0.546998, acc.: 69.23%] [G loss: 1.732037] [Time: 0.244120]\n",
            "362-4 [D loss: 0.570741, acc.: 69.23%] [G loss: 1.652976] [Time: 0.247160]\n",
            "362-5 [D loss: 0.609383, acc.: 67.31%] [G loss: 1.291571] [Time: 0.249454]\n",
            "362-6 [D loss: 0.577904, acc.: 71.15%] [G loss: 1.439075] [Time: 0.249620]\n",
            "362-7 [D loss: 0.869339, acc.: 36.54%] [G loss: 1.147116] [Time: 0.245386]\n",
            "362-8 [D loss: 0.617485, acc.: 75.00%] [G loss: 1.714389] [Time: 0.244610]\n",
            "362 (test) [D loss: 1.974846, acc.: 50.00%] [G loss: 3.854342] [Time: 0.077560]\n",
            "363-0 [D loss: 0.409308, acc.: 84.62%] [G loss: 2.180261] [Time: 0.248254]\n",
            "363-1 [D loss: 0.696134, acc.: 53.85%] [G loss: 1.538066] [Time: 0.246294]\n",
            "363-2 [D loss: 0.756870, acc.: 61.54%] [G loss: 1.474187] [Time: 0.245500]\n",
            "363-3 [D loss: 0.732268, acc.: 57.69%] [G loss: 1.751472] [Time: 0.246819]\n",
            "363-4 [D loss: 0.620060, acc.: 63.46%] [G loss: 1.763525] [Time: 0.251208]\n",
            "363-5 [D loss: 0.510375, acc.: 73.08%] [G loss: 1.593372] [Time: 0.245902]\n",
            "363-6 [D loss: 0.554652, acc.: 69.23%] [G loss: 1.566173] [Time: 0.247605]\n",
            "363-7 [D loss: 0.823397, acc.: 44.23%] [G loss: 1.049092] [Time: 0.247943]\n",
            "363-8 [D loss: 0.609307, acc.: 63.46%] [G loss: 1.593528] [Time: 0.247036]\n",
            "363 (test) [D loss: 1.939579, acc.: 50.00%] [G loss: 3.790830] [Time: 0.078923]\n",
            "364-0 [D loss: 0.417920, acc.: 78.85%] [G loss: 1.813107] [Time: 0.246850]\n",
            "364-1 [D loss: 0.680483, acc.: 50.00%] [G loss: 1.295291] [Time: 0.245252]\n",
            "364-2 [D loss: 0.695064, acc.: 61.54%] [G loss: 1.311878] [Time: 0.245082]\n",
            "364-3 [D loss: 0.557636, acc.: 75.00%] [G loss: 1.372607] [Time: 0.247742]\n",
            "364-4 [D loss: 0.714633, acc.: 55.77%] [G loss: 1.320875] [Time: 0.247216]\n",
            "364-5 [D loss: 0.567078, acc.: 65.38%] [G loss: 1.548604] [Time: 0.244784]\n",
            "364-6 [D loss: 0.566048, acc.: 76.92%] [G loss: 1.554359] [Time: 0.247179]\n",
            "364-7 [D loss: 0.954169, acc.: 32.69%] [G loss: 0.967032] [Time: 0.246675]\n",
            "364-8 [D loss: 0.626250, acc.: 65.38%] [G loss: 1.525754] [Time: 0.248596]\n",
            "364 (test) [D loss: 1.954010, acc.: 50.00%] [G loss: 3.827527] [Time: 0.077469]\n",
            "365-0 [D loss: 0.328456, acc.: 86.54%] [G loss: 2.300921] [Time: 0.245524]\n",
            "365-1 [D loss: 0.715957, acc.: 51.92%] [G loss: 1.465365] [Time: 0.249413]\n",
            "365-2 [D loss: 0.822482, acc.: 51.92%] [G loss: 1.512941] [Time: 0.246030]\n",
            "365-3 [D loss: 0.702705, acc.: 55.77%] [G loss: 1.426110] [Time: 0.245412]\n",
            "365-4 [D loss: 0.705604, acc.: 53.85%] [G loss: 1.559833] [Time: 0.247581]\n",
            "365-5 [D loss: 0.589255, acc.: 63.46%] [G loss: 1.569316] [Time: 0.247820]\n",
            "365-6 [D loss: 0.652323, acc.: 65.38%] [G loss: 1.383559] [Time: 0.246821]\n",
            "365-7 [D loss: 0.853377, acc.: 48.08%] [G loss: 1.066568] [Time: 0.246523]\n",
            "365-8 [D loss: 0.672882, acc.: 63.46%] [G loss: 1.323038] [Time: 0.248747]\n",
            "365 (test) [D loss: 1.929833, acc.: 50.00%] [G loss: 3.770957] [Time: 0.076771]\n",
            "366-0 [D loss: 0.489207, acc.: 73.08%] [G loss: 2.108464] [Time: 0.249949]\n",
            "366-1 [D loss: 0.739757, acc.: 55.77%] [G loss: 1.308365] [Time: 0.247200]\n",
            "366-2 [D loss: 0.730106, acc.: 53.85%] [G loss: 1.254472] [Time: 0.249200]\n",
            "366-3 [D loss: 0.679594, acc.: 65.38%] [G loss: 1.453595] [Time: 0.250029]\n",
            "366-4 [D loss: 0.595943, acc.: 63.46%] [G loss: 1.737032] [Time: 0.247718]\n",
            "366-5 [D loss: 0.596399, acc.: 67.31%] [G loss: 1.495497] [Time: 0.246299]\n",
            "366-6 [D loss: 0.606830, acc.: 65.38%] [G loss: 1.497227] [Time: 0.249516]\n",
            "366-7 [D loss: 0.818923, acc.: 44.23%] [G loss: 1.068248] [Time: 0.246685]\n",
            "366-8 [D loss: 0.497196, acc.: 78.85%] [G loss: 1.795285] [Time: 0.244759]\n",
            "366 (test) [D loss: 2.014606, acc.: 50.00%] [G loss: 3.940848] [Time: 0.076949]\n",
            "367-0 [D loss: 0.380192, acc.: 80.77%] [G loss: 1.989538] [Time: 0.246718]\n",
            "367-1 [D loss: 0.706110, acc.: 57.69%] [G loss: 1.099121] [Time: 0.245114]\n",
            "367-2 [D loss: 0.878328, acc.: 38.46%] [G loss: 1.166950] [Time: 0.242714]\n",
            "367-3 [D loss: 0.609900, acc.: 63.46%] [G loss: 1.651513] [Time: 0.243501]\n",
            "Traceback (most recent call last):\n",
            "  File \"cgan_emoji.py\", line 340, in <module>\n",
            "    train_mode()\n",
            "  File \"cgan_emoji.py\", line 333, in train_mode\n",
            "    dcgan.train(epochs=5000, batch_size=26, save_interval=50)\n",
            "  File \"cgan_emoji.py\", line 196, in train\n",
            "    g_loss = self.combined.train_on_batch([noise, texts], valid)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1449, in train_on_batch\n",
            "    outputs = self.train_function(ins)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2979, in __call__\n",
            "    return self._call(inputs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2937, in _call\n",
            "    fetched = self._callable_fn(*array_vals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1472, in __call__\n",
            "    run_metadata_ptr)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l__mVw3FGCo-",
        "colab_type": "code",
        "outputId": "df9f00fc-3b18-43d8-e4a4-d4da8c1fa17d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7fNAAq6PtqX",
        "colab_type": "code",
        "outputId": "7b75e99b-cc8b-437a-9acd-c897edb5fa04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/My\\ Drive/EmojiGAN"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/EmojiGAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOh6zGBHP3JQ",
        "colab_type": "code",
        "outputId": "1e9c5a18-a3a9-4dec-8f1d-4c98d0e686cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 cgan_emoji.py 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From cgan_emoji.py:26: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From cgan_emoji.py:27: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From cgan_emoji.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-03-12 05:40:04.579484: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-03-12 05:40:04.582275: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1412bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-12 05:40:04.582311: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-03-12 05:40:04.589065: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-03-12 05:40:04.751136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-12 05:40:04.752321: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1412d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-12 05:40:04.752351: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-03-12 05:40:04.753206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-12 05:40:04.754045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-12 05:40:04.767426: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-12 05:40:05.032737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-12 05:40:05.145610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-03-12 05:40:05.186250: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-03-12 05:40:05.449656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-03-12 05:40:05.488084: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-03-12 05:40:05.968780: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-12 05:40:05.969101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-12 05:40:05.970222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-12 05:40:05.971201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-03-12 05:40:05.974680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-12 05:40:05.976562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-12 05:40:05.976595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-03-12 05:40:05.976608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-03-12 05:40:05.980222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-12 05:40:05.981308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-12 05:40:05.982232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "Using colab GPU\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "d_input (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 64)   1792        d_input[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 64)   0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 16, 16, 128)  73856       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 17, 17, 128)  0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 17, 17, 128)  512         zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 17, 17, 128)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 17, 17, 128)  0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 17, 17, 256)  295168      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 17, 17, 256)  1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 17, 17, 256)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 17, 17, 256)  0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "cond_d_input (InputLayer)       (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 9, 9, 512)    1180160     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          30100       cond_d_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 9, 9, 512)    2048        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 1, 100)    0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 9, 9, 512)    0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 9, 9, 100)    0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 9, 9, 612)    0           leaky_re_lu_4[0][0]              \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 9, 9, 512)    2820608     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 9, 9, 512)    2048        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 9, 9, 512)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 9, 9, 512)    0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 41472)        0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            41473       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,448,789\n",
            "Trainable params: 4,445,973\n",
            "Non-trainable params: 2,816\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "cond_g_input (InputLayer)       (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "g_input (InputLayer)            (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 100)          30100       cond_g_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 200)          0           g_input[0][0]                    \n",
            "                                                                 dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 16384)        3293184     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 8, 8, 256)    0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 256)  0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 256)  590080      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 256)  1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 16, 16, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 256)  0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 128)  295040      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 128)  0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 64)   73792       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 64, 64)   256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 64, 64, 3)    1731        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64, 64, 3)    0           conv2d_9[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 4,285,719\n",
            "Trainable params: 4,284,823\n",
            "Non-trainable params: 896\n",
            "__________________________________________________________________________________________________\n",
            "Acquiring images & labels...\n",
            "Traceback (most recent call last):\n",
            "  File \"cgan_emoji.py\", line 340, in <module>\n",
            "    train_mode()\n",
            "  File \"cgan_emoji.py\", line 333, in train_mode\n",
            "    dcgan.train(epochs=50, batch_size=26, save_interval=50)\n",
            "  File \"cgan_emoji.py\", line 147, in train\n",
            "    X_train, Captions, X_test, Captions_test, Labels = load_dataset(self.img_path, self.txt_path, self.img_shape)\n",
            "  File \"/content/drive/My Drive/EmojiGAN/utils/dataset_utils.py\", line 47, in load_dataset\n",
            "    tokenized = sent_tokenize(text)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\", line 94, in sent_tokenize\n",
            "    tokenizer = load('tokenizers/punkt/{0}.pickle'.format(language))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/nltk/data.py\", line 834, in load\n",
            "    opened_resource = _open(resource_url)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/nltk/data.py\", line 952, in _open\n",
            "    return find(path_, path + ['']).open()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/nltk/data.py\", line 673, in find\n",
            "    raise LookupError(resource_not_found)\n",
            "LookupError: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt')\n",
            "  \u001b[0m\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - ''\n",
            "**********************************************************************\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqXtwSohQYp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnDwGsq3RRlQ",
        "colab_type": "code",
        "outputId": "afaf1b11-b9af-40ce-e405-4ad755347020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QioCUlTBRVe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 cgan_emoji.py 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1HkUva3RcT8",
        "colab_type": "code",
        "outputId": "a548b8f0-423e-4f2d-d1e5-c65b111532a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1ltyLPYsLFG",
        "colab_type": "code",
        "outputId": "daae107d-d96d-4646-afe2-c2128c1e3dd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive/My\\ Drive/EmojiGAN"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/EmojiGAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcgHltPsseCL",
        "colab_type": "code",
        "outputId": "f79d6ba9-4fb8-4e23-c98e-190ee67311e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cgan_emoji.py  \u001b[0m\u001b[01;34mimages\u001b[0m/                \u001b[01;34m__pycache__\u001b[0m/  temp.py\n",
            "classifier.py  inception_score.py     \u001b[01;34msample\u001b[0m/       \u001b[01;34mutils\u001b[0m/\n",
            "\u001b[01;34memoji\u001b[0m/         preprocess_dataset.py  \u001b[01;34msaved_model\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8qbAcGcsfcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uuJ4Uw_s7bV",
        "colab_type": "code",
        "outputId": "c013f6cc-640d-40fc-9525-2ecaf7a0a9ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoDyMAqNs_C1",
        "colab_type": "code",
        "outputId": "7d6649a5-8ae5-4be8-bbda-645ae35e731f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 cgan_emoji.py 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "4500-1 [D loss: 0.707799, acc.: 32.69%] [G loss: 0.681063] [Time: 0.150044]\n",
            "4500-2 [D loss: 0.698428, acc.: 38.46%] [G loss: 0.722573] [Time: 0.148399]\n",
            "4500-3 [D loss: 0.682150, acc.: 42.31%] [G loss: 0.757868] [Time: 0.148333]\n",
            "4500-4 [D loss: 0.699047, acc.: 38.46%] [G loss: 0.703469] [Time: 0.151415]\n",
            "4500-5 [D loss: 0.686520, acc.: 46.15%] [G loss: 0.713487] [Time: 0.151501]\n",
            "4500-6 [D loss: 0.688290, acc.: 48.08%] [G loss: 0.715304] [Time: 0.147462]\n",
            "4500-7 [D loss: 0.689700, acc.: 53.85%] [G loss: 0.689263] [Time: 0.148096]\n",
            "4500-8 [D loss: 0.710821, acc.: 46.15%] [G loss: 0.691180] [Time: 0.150654]\n",
            "4500 (test) [D loss: 0.816675, acc.: 48.08%] [G loss: 0.758254] [Time: 0.045691]\n",
            "4501-0 [D loss: 0.688465, acc.: 44.23%] [G loss: 0.742450] [Time: 0.149556]\n",
            "4501-1 [D loss: 0.705850, acc.: 42.31%] [G loss: 0.692351] [Time: 0.151705]\n",
            "4501-2 [D loss: 0.718738, acc.: 42.31%] [G loss: 0.710265] [Time: 0.150429]\n",
            "4501-3 [D loss: 0.671066, acc.: 53.85%] [G loss: 0.729161] [Time: 0.150638]\n",
            "4501-4 [D loss: 0.699443, acc.: 38.46%] [G loss: 0.704744] [Time: 0.150406]\n",
            "4501-5 [D loss: 0.690012, acc.: 44.23%] [G loss: 0.686124] [Time: 0.148300]\n",
            "4501-6 [D loss: 0.689524, acc.: 46.15%] [G loss: 0.705854] [Time: 0.146822]\n",
            "4501-7 [D loss: 0.711433, acc.: 38.46%] [G loss: 0.707047] [Time: 0.151100]\n",
            "4501-8 [D loss: 0.694922, acc.: 40.38%] [G loss: 0.688942] [Time: 0.149062]\n",
            "4501 (test) [D loss: 0.804213, acc.: 48.08%] [G loss: 0.765859] [Time: 0.044149]\n",
            "4502-0 [D loss: 0.680046, acc.: 46.15%] [G loss: 0.731682] [Time: 0.148827]\n",
            "4502-1 [D loss: 0.723384, acc.: 38.46%] [G loss: 0.713913] [Time: 0.149286]\n",
            "4502-2 [D loss: 0.698672, acc.: 38.46%] [G loss: 0.700889] [Time: 0.150861]\n",
            "4502-3 [D loss: 0.664637, acc.: 50.00%] [G loss: 0.751058] [Time: 0.148232]\n",
            "4502-4 [D loss: 0.704120, acc.: 40.38%] [G loss: 0.736417] [Time: 0.148707]\n",
            "4502-5 [D loss: 0.694848, acc.: 44.23%] [G loss: 0.712258] [Time: 0.147178]\n",
            "4502-6 [D loss: 0.695398, acc.: 48.08%] [G loss: 0.723999] [Time: 0.149709]\n",
            "4502-7 [D loss: 0.700766, acc.: 42.31%] [G loss: 0.706461] [Time: 0.147014]\n",
            "4502-8 [D loss: 0.716645, acc.: 42.31%] [G loss: 0.740088] [Time: 0.147880]\n",
            "4502 (test) [D loss: 0.837317, acc.: 50.00%] [G loss: 1.129017] [Time: 0.045333]\n",
            "4503-0 [D loss: 0.685929, acc.: 48.08%] [G loss: 0.755304] [Time: 0.152251]\n",
            "4503-1 [D loss: 0.696470, acc.: 44.23%] [G loss: 0.708780] [Time: 0.152533]\n",
            "4503-2 [D loss: 0.703095, acc.: 38.46%] [G loss: 0.713279] [Time: 0.147782]\n",
            "4503-3 [D loss: 0.679191, acc.: 48.08%] [G loss: 0.741157] [Time: 0.150939]\n",
            "4503-4 [D loss: 0.688520, acc.: 51.92%] [G loss: 0.726793] [Time: 0.147936]\n",
            "4503-5 [D loss: 0.682329, acc.: 48.08%] [G loss: 0.709971] [Time: 0.147935]\n",
            "4503-6 [D loss: 0.681231, acc.: 44.23%] [G loss: 0.714010] [Time: 0.150171]\n",
            "4503-7 [D loss: 0.702935, acc.: 40.38%] [G loss: 0.697686] [Time: 0.150976]\n",
            "4503-8 [D loss: 0.702510, acc.: 38.46%] [G loss: 0.699425] [Time: 0.149444]\n",
            "4503 (test) [D loss: 0.835445, acc.: 50.00%] [G loss: 0.948574] [Time: 0.045312]\n",
            "4504-0 [D loss: 0.690676, acc.: 53.85%] [G loss: 0.741384] [Time: 0.147301]\n",
            "4504-1 [D loss: 0.701262, acc.: 51.92%] [G loss: 0.688365] [Time: 0.147530]\n",
            "4504-2 [D loss: 0.698504, acc.: 40.38%] [G loss: 0.710821] [Time: 0.149107]\n",
            "4504-3 [D loss: 0.673390, acc.: 50.00%] [G loss: 0.737848] [Time: 0.150011]\n",
            "4504-4 [D loss: 0.713167, acc.: 36.54%] [G loss: 0.725697] [Time: 0.148104]\n",
            "4504-5 [D loss: 0.696628, acc.: 40.38%] [G loss: 0.703328] [Time: 0.147655]\n",
            "4504-6 [D loss: 0.702524, acc.: 40.38%] [G loss: 0.699604] [Time: 0.147609]\n",
            "4504-7 [D loss: 0.697718, acc.: 36.54%] [G loss: 0.706638] [Time: 0.148384]\n",
            "4504-8 [D loss: 0.702968, acc.: 44.23%] [G loss: 0.676921] [Time: 0.147290]\n",
            "4504 (test) [D loss: 0.811911, acc.: 48.08%] [G loss: 0.778452] [Time: 0.044569]\n",
            "4505-0 [D loss: 0.679533, acc.: 48.08%] [G loss: 0.734696] [Time: 0.147400]\n",
            "4505-1 [D loss: 0.705871, acc.: 36.54%] [G loss: 0.705699] [Time: 0.149381]\n",
            "4505-2 [D loss: 0.705725, acc.: 40.38%] [G loss: 0.718615] [Time: 0.148777]\n",
            "4505-3 [D loss: 0.673797, acc.: 55.77%] [G loss: 0.707705] [Time: 0.151769]\n",
            "4505-4 [D loss: 0.693985, acc.: 44.23%] [G loss: 0.702961] [Time: 0.152007]\n",
            "4505-5 [D loss: 0.683609, acc.: 48.08%] [G loss: 0.708754] [Time: 0.148501]\n",
            "4505-6 [D loss: 0.700164, acc.: 44.23%] [G loss: 0.709953] [Time: 0.149813]\n",
            "4505-7 [D loss: 0.696823, acc.: 40.38%] [G loss: 0.691939] [Time: 0.149471]\n",
            "4505-8 [D loss: 0.704647, acc.: 40.38%] [G loss: 0.695698] [Time: 0.149495]\n",
            "4505 (test) [D loss: 0.836795, acc.: 50.00%] [G loss: 0.549783] [Time: 0.043731]\n",
            "4506-0 [D loss: 0.678843, acc.: 55.77%] [G loss: 0.709784] [Time: 0.148352]\n",
            "4506-1 [D loss: 0.696427, acc.: 50.00%] [G loss: 0.686686] [Time: 0.150418]\n",
            "4506-2 [D loss: 0.715089, acc.: 40.38%] [G loss: 0.703236] [Time: 0.147133]\n",
            "4506-3 [D loss: 0.663321, acc.: 48.08%] [G loss: 0.722018] [Time: 0.147178]\n",
            "4506-4 [D loss: 0.706897, acc.: 40.38%] [G loss: 0.693504] [Time: 0.149388]\n",
            "4506-5 [D loss: 0.698556, acc.: 26.92%] [G loss: 0.685783] [Time: 0.147815]\n",
            "4506-6 [D loss: 0.699690, acc.: 42.31%] [G loss: 0.715707] [Time: 0.153795]\n",
            "4506-7 [D loss: 0.696667, acc.: 40.38%] [G loss: 0.701403] [Time: 0.150739]\n",
            "4506-8 [D loss: 0.705618, acc.: 36.54%] [G loss: 0.674105] [Time: 0.150856]\n",
            "4506 (test) [D loss: 0.813952, acc.: 50.00%] [G loss: 0.589217] [Time: 0.045230]\n",
            "4507-0 [D loss: 0.682433, acc.: 53.85%] [G loss: 0.703814] [Time: 0.152819]\n",
            "4507-1 [D loss: 0.711451, acc.: 42.31%] [G loss: 0.691897] [Time: 0.151425]\n",
            "4507-2 [D loss: 0.708861, acc.: 40.38%] [G loss: 0.696930] [Time: 0.147681]\n",
            "4507-3 [D loss: 0.664842, acc.: 48.08%] [G loss: 0.742366] [Time: 0.152019]\n",
            "4507-4 [D loss: 0.697681, acc.: 50.00%] [G loss: 0.709751] [Time: 0.150482]\n",
            "4507-5 [D loss: 0.680488, acc.: 50.00%] [G loss: 0.702539] [Time: 0.147714]\n",
            "4507-6 [D loss: 0.702144, acc.: 34.62%] [G loss: 0.706340] [Time: 0.149744]\n",
            "4507-7 [D loss: 0.694746, acc.: 50.00%] [G loss: 0.707853] [Time: 0.151801]\n",
            "4507-8 [D loss: 0.700289, acc.: 46.15%] [G loss: 0.710189] [Time: 0.149053]\n",
            "4507 (test) [D loss: 0.834541, acc.: 48.08%] [G loss: 0.935248] [Time: 0.043773]\n",
            "4508-0 [D loss: 0.676832, acc.: 57.69%] [G loss: 0.748619] [Time: 0.147050]\n",
            "4508-1 [D loss: 0.699385, acc.: 44.23%] [G loss: 0.701206] [Time: 0.151814]\n",
            "4508-2 [D loss: 0.696082, acc.: 46.15%] [G loss: 0.715443] [Time: 0.151707]\n",
            "4508-3 [D loss: 0.667578, acc.: 48.08%] [G loss: 0.734276] [Time: 0.147100]\n",
            "4508-4 [D loss: 0.705711, acc.: 46.15%] [G loss: 0.729657] [Time: 0.150554]\n",
            "4508-5 [D loss: 0.686839, acc.: 42.31%] [G loss: 0.728632] [Time: 0.148876]\n",
            "4508-6 [D loss: 0.701381, acc.: 46.15%] [G loss: 0.720307] [Time: 0.149126]\n",
            "4508-7 [D loss: 0.698366, acc.: 50.00%] [G loss: 0.717920] [Time: 0.150769]\n",
            "4508-8 [D loss: 0.714668, acc.: 28.85%] [G loss: 0.704109] [Time: 0.148531]\n",
            "4508 (test) [D loss: 0.815136, acc.: 50.00%] [G loss: 0.875685] [Time: 0.044207]\n",
            "4509-0 [D loss: 0.695066, acc.: 42.31%] [G loss: 0.737735] [Time: 0.147928]\n",
            "4509-1 [D loss: 0.702770, acc.: 53.85%] [G loss: 0.705391] [Time: 0.152871]\n",
            "4509-2 [D loss: 0.708315, acc.: 44.23%] [G loss: 0.698387] [Time: 0.148202]\n",
            "4509-3 [D loss: 0.682517, acc.: 40.38%] [G loss: 0.731653] [Time: 0.147422]\n",
            "4509-4 [D loss: 0.698247, acc.: 38.46%] [G loss: 0.716987] [Time: 0.146957]\n",
            "4509-5 [D loss: 0.687918, acc.: 44.23%] [G loss: 0.723554] [Time: 0.148730]\n",
            "4509-6 [D loss: 0.708364, acc.: 48.08%] [G loss: 0.696486] [Time: 0.148332]\n",
            "4509-7 [D loss: 0.702143, acc.: 34.62%] [G loss: 0.697936] [Time: 0.151350]\n",
            "4509-8 [D loss: 0.715476, acc.: 34.62%] [G loss: 0.693116] [Time: 0.150149]\n",
            "4509 (test) [D loss: 0.820466, acc.: 48.08%] [G loss: 0.740336] [Time: 0.047244]\n",
            "4510-0 [D loss: 0.690268, acc.: 44.23%] [G loss: 0.740423] [Time: 0.152241]\n",
            "4510-1 [D loss: 0.701654, acc.: 40.38%] [G loss: 0.698049] [Time: 0.154485]\n",
            "4510-2 [D loss: 0.708946, acc.: 40.38%] [G loss: 0.729111] [Time: 0.148185]\n",
            "4510-3 [D loss: 0.680013, acc.: 44.23%] [G loss: 0.759443] [Time: 0.151902]\n",
            "4510-4 [D loss: 0.709864, acc.: 38.46%] [G loss: 0.710104] [Time: 0.149098]\n",
            "4510-5 [D loss: 0.700575, acc.: 42.31%] [G loss: 0.713733] [Time: 0.150865]\n",
            "4510-6 [D loss: 0.716115, acc.: 34.62%] [G loss: 0.710916] [Time: 0.149909]\n",
            "4510-7 [D loss: 0.702068, acc.: 42.31%] [G loss: 0.680860] [Time: 0.146981]\n",
            "4510-8 [D loss: 0.692742, acc.: 46.15%] [G loss: 0.702445] [Time: 0.148828]\n",
            "4510 (test) [D loss: 0.820438, acc.: 48.08%] [G loss: 0.816472] [Time: 0.043692]\n",
            "4511-0 [D loss: 0.683227, acc.: 50.00%] [G loss: 0.731784] [Time: 0.149695]\n",
            "4511-1 [D loss: 0.694092, acc.: 48.08%] [G loss: 0.715941] [Time: 0.150749]\n",
            "4511-2 [D loss: 0.703927, acc.: 40.38%] [G loss: 0.728081] [Time: 0.149614]\n",
            "4511-3 [D loss: 0.672314, acc.: 48.08%] [G loss: 0.722387] [Time: 0.146686]\n",
            "4511-4 [D loss: 0.704011, acc.: 34.62%] [G loss: 0.701989] [Time: 0.149773]\n",
            "4511-5 [D loss: 0.685478, acc.: 50.00%] [G loss: 0.709220] [Time: 0.151471]\n",
            "4511-6 [D loss: 0.699429, acc.: 46.15%] [G loss: 0.708956] [Time: 0.152937]\n",
            "4511-7 [D loss: 0.704161, acc.: 38.46%] [G loss: 0.688030] [Time: 0.152866]\n",
            "4511-8 [D loss: 0.712441, acc.: 51.92%] [G loss: 0.682648] [Time: 0.150615]\n",
            "4511 (test) [D loss: 0.805208, acc.: 48.08%] [G loss: 0.883838] [Time: 0.043185]\n",
            "4512-0 [D loss: 0.696395, acc.: 40.38%] [G loss: 0.729049] [Time: 0.148668]\n",
            "4512-1 [D loss: 0.709115, acc.: 38.46%] [G loss: 0.700578] [Time: 0.150352]\n",
            "4512-2 [D loss: 0.697031, acc.: 44.23%] [G loss: 0.731391] [Time: 0.149085]\n",
            "4512-3 [D loss: 0.678703, acc.: 46.15%] [G loss: 0.721678] [Time: 0.149599]\n",
            "4512-4 [D loss: 0.705423, acc.: 38.46%] [G loss: 0.707612] [Time: 0.151153]\n",
            "4512-5 [D loss: 0.690346, acc.: 42.31%] [G loss: 0.695732] [Time: 0.149204]\n",
            "4512-6 [D loss: 0.692933, acc.: 50.00%] [G loss: 0.712310] [Time: 0.150918]\n",
            "4512-7 [D loss: 0.699759, acc.: 38.46%] [G loss: 0.695065] [Time: 0.151001]\n",
            "4512-8 [D loss: 0.702207, acc.: 36.54%] [G loss: 0.712059] [Time: 0.146956]\n",
            "4512 (test) [D loss: 0.838092, acc.: 48.08%] [G loss: 0.930440] [Time: 0.044818]\n",
            "4513-0 [D loss: 0.696127, acc.: 42.31%] [G loss: 0.738254] [Time: 0.146259]\n",
            "4513-1 [D loss: 0.698441, acc.: 42.31%] [G loss: 0.695953] [Time: 0.148219]\n",
            "4513-2 [D loss: 0.704869, acc.: 48.08%] [G loss: 0.694013] [Time: 0.149396]\n",
            "4513-3 [D loss: 0.675586, acc.: 48.08%] [G loss: 0.725851] [Time: 0.150692]\n",
            "4513-4 [D loss: 0.701534, acc.: 36.54%] [G loss: 0.703926] [Time: 0.149466]\n",
            "4513-5 [D loss: 0.704620, acc.: 42.31%] [G loss: 0.706789] [Time: 0.150999]\n",
            "4513-6 [D loss: 0.701998, acc.: 46.15%] [G loss: 0.706877] [Time: 0.154359]\n",
            "4513-7 [D loss: 0.701339, acc.: 42.31%] [G loss: 0.708618] [Time: 0.156448]\n",
            "4513-8 [D loss: 0.692575, acc.: 42.31%] [G loss: 0.692788] [Time: 0.151064]\n",
            "4513 (test) [D loss: 0.821505, acc.: 50.00%] [G loss: 0.804591] [Time: 0.044484]\n",
            "4514-0 [D loss: 0.685964, acc.: 46.15%] [G loss: 0.736385] [Time: 0.147767]\n",
            "4514-1 [D loss: 0.704419, acc.: 42.31%] [G loss: 0.685788] [Time: 0.150779]\n",
            "4514-2 [D loss: 0.717190, acc.: 40.38%] [G loss: 0.704972] [Time: 0.148565]\n",
            "4514-3 [D loss: 0.689630, acc.: 46.15%] [G loss: 0.726043] [Time: 0.154900]\n",
            "4514-4 [D loss: 0.707467, acc.: 42.31%] [G loss: 0.705448] [Time: 0.151619]\n",
            "4514-5 [D loss: 0.695167, acc.: 51.92%] [G loss: 0.712140] [Time: 0.151374]\n",
            "4514-6 [D loss: 0.700089, acc.: 46.15%] [G loss: 0.721666] [Time: 0.152336]\n",
            "4514-7 [D loss: 0.707708, acc.: 48.08%] [G loss: 0.690784] [Time: 0.150284]\n",
            "4514-8 [D loss: 0.692100, acc.: 48.08%] [G loss: 0.700591] [Time: 0.150989]\n",
            "4514 (test) [D loss: 0.814570, acc.: 48.08%] [G loss: 0.926418] [Time: 0.044033]\n",
            "4515-0 [D loss: 0.683929, acc.: 44.23%] [G loss: 0.695430] [Time: 0.150781]\n",
            "4515-1 [D loss: 0.702878, acc.: 38.46%] [G loss: 0.698303] [Time: 0.152909]\n",
            "4515-2 [D loss: 0.706304, acc.: 36.54%] [G loss: 0.713335] [Time: 0.148165]\n",
            "4515-3 [D loss: 0.671994, acc.: 50.00%] [G loss: 0.702910] [Time: 0.151504]\n",
            "4515-4 [D loss: 0.705474, acc.: 40.38%] [G loss: 0.714747] [Time: 0.151329]\n",
            "4515-5 [D loss: 0.679828, acc.: 50.00%] [G loss: 0.690247] [Time: 0.150552]\n",
            "4515-6 [D loss: 0.688162, acc.: 40.38%] [G loss: 0.709948] [Time: 0.148751]\n",
            "4515-7 [D loss: 0.703960, acc.: 42.31%] [G loss: 0.696009] [Time: 0.154251]\n",
            "4515-8 [D loss: 0.705464, acc.: 50.00%] [G loss: 0.697195] [Time: 0.147768]\n",
            "4515 (test) [D loss: 0.829412, acc.: 48.08%] [G loss: 0.815790] [Time: 0.043660]\n",
            "4516-0 [D loss: 0.687745, acc.: 51.92%] [G loss: 0.736572] [Time: 0.151255]\n",
            "4516-1 [D loss: 0.696789, acc.: 40.38%] [G loss: 0.709445] [Time: 0.150577]\n",
            "4516-2 [D loss: 0.707632, acc.: 38.46%] [G loss: 0.708710] [Time: 0.147280]\n",
            "4516-3 [D loss: 0.669986, acc.: 48.08%] [G loss: 0.724941] [Time: 0.147343]\n",
            "4516-4 [D loss: 0.697148, acc.: 38.46%] [G loss: 0.701567] [Time: 0.154841]\n",
            "4516-5 [D loss: 0.689548, acc.: 44.23%] [G loss: 0.716206] [Time: 0.148289]\n",
            "4516-6 [D loss: 0.687220, acc.: 48.08%] [G loss: 0.701261] [Time: 0.147629]\n",
            "4516-7 [D loss: 0.695614, acc.: 44.23%] [G loss: 0.679582] [Time: 0.147966]\n",
            "4516-8 [D loss: 0.698279, acc.: 42.31%] [G loss: 0.716895] [Time: 0.147139]\n",
            "4516 (test) [D loss: 0.834432, acc.: 48.08%] [G loss: 0.772531] [Time: 0.045027]\n",
            "4517-0 [D loss: 0.689833, acc.: 44.23%] [G loss: 0.754745] [Time: 0.149000]\n",
            "4517-1 [D loss: 0.702263, acc.: 51.92%] [G loss: 0.681503] [Time: 0.148752]\n",
            "4517-2 [D loss: 0.709647, acc.: 46.15%] [G loss: 0.700760] [Time: 0.149012]\n",
            "4517-3 [D loss: 0.675301, acc.: 38.46%] [G loss: 0.741895] [Time: 0.149176]\n",
            "4517-4 [D loss: 0.705505, acc.: 44.23%] [G loss: 0.699023] [Time: 0.150725]\n",
            "4517-5 [D loss: 0.690764, acc.: 40.38%] [G loss: 0.701330] [Time: 0.152674]\n",
            "4517-6 [D loss: 0.689754, acc.: 51.92%] [G loss: 0.704731] [Time: 0.149809]\n",
            "4517-7 [D loss: 0.706788, acc.: 38.46%] [G loss: 0.687312] [Time: 0.151577]\n",
            "4517-8 [D loss: 0.715083, acc.: 34.62%] [G loss: 0.699255] [Time: 0.153101]\n",
            "4517 (test) [D loss: 0.824624, acc.: 48.08%] [G loss: 0.842281] [Time: 0.044811]\n",
            "4518-0 [D loss: 0.672148, acc.: 46.15%] [G loss: 0.744719] [Time: 0.150201]\n",
            "4518-1 [D loss: 0.700626, acc.: 28.85%] [G loss: 0.714751] [Time: 0.147117]\n",
            "4518-2 [D loss: 0.711105, acc.: 32.69%] [G loss: 0.713352] [Time: 0.148648]\n",
            "4518-3 [D loss: 0.670976, acc.: 40.38%] [G loss: 0.722617] [Time: 0.150659]\n",
            "4518-4 [D loss: 0.711348, acc.: 32.69%] [G loss: 0.712272] [Time: 0.151097]\n",
            "4518-5 [D loss: 0.691668, acc.: 40.38%] [G loss: 0.706484] [Time: 0.149408]\n",
            "4518-6 [D loss: 0.691699, acc.: 51.92%] [G loss: 0.714894] [Time: 0.148376]\n",
            "4518-7 [D loss: 0.699410, acc.: 44.23%] [G loss: 0.698153] [Time: 0.148351]\n",
            "4518-8 [D loss: 0.704637, acc.: 42.31%] [G loss: 0.714187] [Time: 0.147383]\n",
            "4518 (test) [D loss: 0.829883, acc.: 50.00%] [G loss: 0.988366] [Time: 0.043862]\n",
            "4519-0 [D loss: 0.675369, acc.: 53.85%] [G loss: 0.739787] [Time: 0.152803]\n",
            "4519-1 [D loss: 0.699017, acc.: 46.15%] [G loss: 0.697608] [Time: 0.149816]\n",
            "4519-2 [D loss: 0.702133, acc.: 30.77%] [G loss: 0.724495] [Time: 0.148702]\n",
            "4519-3 [D loss: 0.678752, acc.: 57.69%] [G loss: 0.742022] [Time: 0.147220]\n",
            "4519-4 [D loss: 0.709476, acc.: 34.62%] [G loss: 0.715840] [Time: 0.148561]\n",
            "4519-5 [D loss: 0.691253, acc.: 44.23%] [G loss: 0.725744] [Time: 0.149672]\n",
            "4519-6 [D loss: 0.694187, acc.: 46.15%] [G loss: 0.713019] [Time: 0.150481]\n",
            "4519-7 [D loss: 0.698500, acc.: 38.46%] [G loss: 0.695382] [Time: 0.150477]\n",
            "4519-8 [D loss: 0.708924, acc.: 40.38%] [G loss: 0.711603] [Time: 0.149731]\n",
            "4519 (test) [D loss: 0.838406, acc.: 48.08%] [G loss: 0.892522] [Time: 0.043818]\n",
            "4520-0 [D loss: 0.663014, acc.: 63.46%] [G loss: 0.726368] [Time: 0.149105]\n",
            "4520-1 [D loss: 0.705959, acc.: 32.69%] [G loss: 0.699708] [Time: 0.151223]\n",
            "4520-2 [D loss: 0.705170, acc.: 40.38%] [G loss: 0.708104] [Time: 0.152493]\n",
            "4520-3 [D loss: 0.671686, acc.: 55.77%] [G loss: 0.726963] [Time: 0.152694]\n",
            "4520-4 [D loss: 0.700619, acc.: 48.08%] [G loss: 0.687039] [Time: 0.147673]\n",
            "4520-5 [D loss: 0.673665, acc.: 57.69%] [G loss: 0.708739] [Time: 0.146618]\n",
            "4520-6 [D loss: 0.685336, acc.: 44.23%] [G loss: 0.712661] [Time: 0.149410]\n",
            "4520-7 [D loss: 0.692951, acc.: 55.77%] [G loss: 0.694416] [Time: 0.147051]\n",
            "4520-8 [D loss: 0.694957, acc.: 42.31%] [G loss: 0.692963] [Time: 0.146801]\n",
            "4520 (test) [D loss: 0.818929, acc.: 48.08%] [G loss: 0.804157] [Time: 0.043152]\n",
            "4521-0 [D loss: 0.682836, acc.: 53.85%] [G loss: 0.727442] [Time: 0.149385]\n",
            "4521-1 [D loss: 0.707092, acc.: 40.38%] [G loss: 0.690560] [Time: 0.147688]\n",
            "4521-2 [D loss: 0.705890, acc.: 34.62%] [G loss: 0.707697] [Time: 0.149743]\n",
            "4521-3 [D loss: 0.670855, acc.: 50.00%] [G loss: 0.730749] [Time: 0.148321]\n",
            "4521-4 [D loss: 0.698257, acc.: 38.46%] [G loss: 0.682459] [Time: 0.148572]\n",
            "4521-5 [D loss: 0.694428, acc.: 46.15%] [G loss: 0.716429] [Time: 0.152277]\n",
            "4521-6 [D loss: 0.694249, acc.: 46.15%] [G loss: 0.702062] [Time: 0.151210]\n",
            "4521-7 [D loss: 0.719264, acc.: 40.38%] [G loss: 0.686501] [Time: 0.149367]\n",
            "4521-8 [D loss: 0.705320, acc.: 46.15%] [G loss: 0.701776] [Time: 0.147789]\n",
            "4521 (test) [D loss: 0.839852, acc.: 48.08%] [G loss: 0.742157] [Time: 0.043880]\n",
            "4522-0 [D loss: 0.670185, acc.: 53.85%] [G loss: 0.733180] [Time: 0.147319]\n",
            "4522-1 [D loss: 0.709951, acc.: 38.46%] [G loss: 0.689047] [Time: 0.147655]\n",
            "4522-2 [D loss: 0.713924, acc.: 34.62%] [G loss: 0.700401] [Time: 0.148589]\n",
            "4522-3 [D loss: 0.672110, acc.: 51.92%] [G loss: 0.739658] [Time: 0.149185]\n",
            "4522-4 [D loss: 0.687537, acc.: 50.00%] [G loss: 0.682045] [Time: 0.150111]\n",
            "4522-5 [D loss: 0.688183, acc.: 44.23%] [G loss: 0.707555] [Time: 0.148243]\n",
            "4522-6 [D loss: 0.699622, acc.: 42.31%] [G loss: 0.702470] [Time: 0.147715]\n",
            "4522-7 [D loss: 0.693610, acc.: 48.08%] [G loss: 0.700409] [Time: 0.151412]\n",
            "4522-8 [D loss: 0.707996, acc.: 46.15%] [G loss: 0.679033] [Time: 0.150475]\n",
            "4522 (test) [D loss: 0.856788, acc.: 51.92%] [G loss: 0.580829] [Time: 0.045040]\n",
            "4523-0 [D loss: 0.676516, acc.: 55.77%] [G loss: 0.715033] [Time: 0.148154]\n",
            "4523-1 [D loss: 0.710207, acc.: 48.08%] [G loss: 0.683380] [Time: 0.151784]\n",
            "4523-2 [D loss: 0.690956, acc.: 50.00%] [G loss: 0.690650] [Time: 0.148000]\n",
            "4523-3 [D loss: 0.668311, acc.: 42.31%] [G loss: 0.723875] [Time: 0.149179]\n",
            "4523-4 [D loss: 0.706469, acc.: 44.23%] [G loss: 0.706052] [Time: 0.149749]\n",
            "4523-5 [D loss: 0.697228, acc.: 32.69%] [G loss: 0.719096] [Time: 0.148728]\n",
            "4523-6 [D loss: 0.696335, acc.: 53.85%] [G loss: 0.723456] [Time: 0.150255]\n",
            "4523-7 [D loss: 0.702651, acc.: 40.38%] [G loss: 0.702346] [Time: 0.151740]\n",
            "4523-8 [D loss: 0.701678, acc.: 48.08%] [G loss: 0.712240] [Time: 0.148101]\n",
            "4523 (test) [D loss: 0.821062, acc.: 48.08%] [G loss: 0.900599] [Time: 0.043872]\n",
            "4524-0 [D loss: 0.684775, acc.: 40.38%] [G loss: 0.753596] [Time: 0.148466]\n",
            "4524-1 [D loss: 0.698242, acc.: 51.92%] [G loss: 0.712146] [Time: 0.149335]\n",
            "4524-2 [D loss: 0.693068, acc.: 42.31%] [G loss: 0.725549] [Time: 0.148933]\n",
            "4524-3 [D loss: 0.661032, acc.: 53.85%] [G loss: 0.717412] [Time: 0.149913]\n",
            "4524-4 [D loss: 0.693062, acc.: 48.08%] [G loss: 0.721407] [Time: 0.150052]\n",
            "4524-5 [D loss: 0.684958, acc.: 46.15%] [G loss: 0.721916] [Time: 0.152381]\n",
            "4524-6 [D loss: 0.695664, acc.: 50.00%] [G loss: 0.729339] [Time: 0.150877]\n",
            "4524-7 [D loss: 0.710050, acc.: 40.38%] [G loss: 0.688705] [Time: 0.149442]\n",
            "4524-8 [D loss: 0.711092, acc.: 34.62%] [G loss: 0.701110] [Time: 0.152012]\n",
            "4524 (test) [D loss: 0.843554, acc.: 48.08%] [G loss: 0.942902] [Time: 0.044549]\n",
            "4525-0 [D loss: 0.692053, acc.: 46.15%] [G loss: 0.722797] [Time: 0.151830]\n",
            "4525-1 [D loss: 0.701038, acc.: 46.15%] [G loss: 0.700490] [Time: 0.148553]\n",
            "4525-2 [D loss: 0.710507, acc.: 40.38%] [G loss: 0.690906] [Time: 0.149209]\n",
            "4525-3 [D loss: 0.680274, acc.: 48.08%] [G loss: 0.759262] [Time: 0.147527]\n",
            "4525-4 [D loss: 0.704683, acc.: 44.23%] [G loss: 0.729787] [Time: 0.149444]\n",
            "4525-5 [D loss: 0.686690, acc.: 46.15%] [G loss: 0.708302] [Time: 0.148342]\n",
            "4525-6 [D loss: 0.689443, acc.: 55.77%] [G loss: 0.724411] [Time: 0.149137]\n",
            "4525-7 [D loss: 0.706487, acc.: 34.62%] [G loss: 0.696621] [Time: 0.150190]\n",
            "4525-8 [D loss: 0.697335, acc.: 50.00%] [G loss: 0.687865] [Time: 0.151605]\n",
            "4525 (test) [D loss: 0.827245, acc.: 51.92%] [G loss: 0.716134] [Time: 0.044863]\n",
            "4526-0 [D loss: 0.668802, acc.: 55.77%] [G loss: 0.721372] [Time: 0.150517]\n",
            "4526-1 [D loss: 0.694368, acc.: 40.38%] [G loss: 0.689444] [Time: 0.150755]\n",
            "4526-2 [D loss: 0.694689, acc.: 46.15%] [G loss: 0.696724] [Time: 0.148521]\n",
            "4526-3 [D loss: 0.672427, acc.: 40.38%] [G loss: 0.717351] [Time: 0.151895]\n",
            "4526-4 [D loss: 0.699522, acc.: 50.00%] [G loss: 0.695794] [Time: 0.150685]\n",
            "4526-5 [D loss: 0.673571, acc.: 55.77%] [G loss: 0.704482] [Time: 0.148430]\n",
            "4526-6 [D loss: 0.705532, acc.: 38.46%] [G loss: 0.710969] [Time: 0.147323]\n",
            "4526-7 [D loss: 0.704149, acc.: 44.23%] [G loss: 0.709537] [Time: 0.149009]\n",
            "4526-8 [D loss: 0.695987, acc.: 42.31%] [G loss: 0.709970] [Time: 0.147559]\n",
            "4526 (test) [D loss: 0.822398, acc.: 50.00%] [G loss: 0.817179] [Time: 0.045397]\n",
            "4527-0 [D loss: 0.675999, acc.: 53.85%] [G loss: 0.723979] [Time: 0.150170]\n",
            "4527-1 [D loss: 0.703685, acc.: 40.38%] [G loss: 0.712558] [Time: 0.148171]\n",
            "4527-2 [D loss: 0.693043, acc.: 40.38%] [G loss: 0.704830] [Time: 0.149403]\n",
            "4527-3 [D loss: 0.668453, acc.: 57.69%] [G loss: 0.734182] [Time: 0.149677]\n",
            "4527-4 [D loss: 0.703693, acc.: 48.08%] [G loss: 0.691780] [Time: 0.149293]\n",
            "4527-5 [D loss: 0.677008, acc.: 46.15%] [G loss: 0.721354] [Time: 0.148003]\n",
            "4527-6 [D loss: 0.694064, acc.: 44.23%] [G loss: 0.720347] [Time: 0.156163]\n",
            "4527-7 [D loss: 0.705112, acc.: 42.31%] [G loss: 0.700387] [Time: 0.147515]\n",
            "4527-8 [D loss: 0.702215, acc.: 36.54%] [G loss: 0.708679] [Time: 0.149209]\n",
            "4527 (test) [D loss: 0.819804, acc.: 50.00%] [G loss: 0.841685] [Time: 0.043218]\n",
            "4528-0 [D loss: 0.680998, acc.: 53.85%] [G loss: 0.742190] [Time: 0.147269]\n",
            "4528-1 [D loss: 0.715651, acc.: 38.46%] [G loss: 0.713435] [Time: 0.148198]\n",
            "4528-2 [D loss: 0.697934, acc.: 42.31%] [G loss: 0.690106] [Time: 0.149698]\n",
            "4528-3 [D loss: 0.668257, acc.: 46.15%] [G loss: 0.720638] [Time: 0.151201]\n",
            "4528-4 [D loss: 0.700939, acc.: 34.62%] [G loss: 0.691869] [Time: 0.148399]\n",
            "4528-5 [D loss: 0.685485, acc.: 36.54%] [G loss: 0.704922] [Time: 0.152465]\n",
            "4528-6 [D loss: 0.699340, acc.: 50.00%] [G loss: 0.713451] [Time: 0.147962]\n",
            "4528-7 [D loss: 0.700940, acc.: 48.08%] [G loss: 0.704019] [Time: 0.148740]\n",
            "4528-8 [D loss: 0.708034, acc.: 32.69%] [G loss: 0.693095] [Time: 0.151628]\n",
            "4528 (test) [D loss: 0.816062, acc.: 48.08%] [G loss: 0.770230] [Time: 0.044590]\n",
            "4529-0 [D loss: 0.672594, acc.: 59.62%] [G loss: 0.749332] [Time: 0.149634]\n",
            "4529-1 [D loss: 0.697333, acc.: 34.62%] [G loss: 0.705906] [Time: 0.148770]\n",
            "4529-2 [D loss: 0.702287, acc.: 40.38%] [G loss: 0.693741] [Time: 0.151250]\n",
            "4529-3 [D loss: 0.695641, acc.: 34.62%] [G loss: 0.741483] [Time: 0.147794]\n",
            "4529-4 [D loss: 0.687867, acc.: 44.23%] [G loss: 0.751996] [Time: 0.147138]\n",
            "4529-5 [D loss: 0.684013, acc.: 44.23%] [G loss: 0.744793] [Time: 0.149035]\n",
            "4529-6 [D loss: 0.688285, acc.: 50.00%] [G loss: 0.726539] [Time: 0.149572]\n",
            "4529-7 [D loss: 0.712370, acc.: 32.69%] [G loss: 0.718586] [Time: 0.147449]\n",
            "4529-8 [D loss: 0.703113, acc.: 38.46%] [G loss: 0.695408] [Time: 0.151459]\n",
            "4529 (test) [D loss: 0.830523, acc.: 48.08%] [G loss: 0.902259] [Time: 0.044708]\n",
            "4530-0 [D loss: 0.673013, acc.: 57.69%] [G loss: 0.748026] [Time: 0.148445]\n",
            "4530-1 [D loss: 0.706745, acc.: 46.15%] [G loss: 0.689977] [Time: 0.150994]\n",
            "4530-2 [D loss: 0.697882, acc.: 44.23%] [G loss: 0.714684] [Time: 0.147038]\n",
            "4530-3 [D loss: 0.675741, acc.: 48.08%] [G loss: 0.743204] [Time: 0.147636]\n",
            "4530-4 [D loss: 0.696605, acc.: 51.92%] [G loss: 0.715982] [Time: 0.147421]\n",
            "4530-5 [D loss: 0.691325, acc.: 44.23%] [G loss: 0.708324] [Time: 0.150192]\n",
            "4530-6 [D loss: 0.703733, acc.: 40.38%] [G loss: 0.727108] [Time: 0.148483]\n",
            "4530-7 [D loss: 0.696818, acc.: 42.31%] [G loss: 0.690707] [Time: 0.147751]\n",
            "4530-8 [D loss: 0.708065, acc.: 38.46%] [G loss: 0.696673] [Time: 0.147912]\n",
            "4530 (test) [D loss: 0.817515, acc.: 48.08%] [G loss: 0.737194] [Time: 0.043873]\n",
            "4531-0 [D loss: 0.684975, acc.: 51.92%] [G loss: 0.749481] [Time: 0.148264]\n",
            "4531-1 [D loss: 0.702670, acc.: 38.46%] [G loss: 0.706700] [Time: 0.150764]\n",
            "4531-2 [D loss: 0.706314, acc.: 38.46%] [G loss: 0.698144] [Time: 0.149224]\n",
            "4531-3 [D loss: 0.670057, acc.: 51.92%] [G loss: 0.719207] [Time: 0.153360]\n",
            "4531-4 [D loss: 0.704880, acc.: 48.08%] [G loss: 0.697905] [Time: 0.147552]\n",
            "4531-5 [D loss: 0.690843, acc.: 42.31%] [G loss: 0.701553] [Time: 0.147732]\n",
            "4531-6 [D loss: 0.696692, acc.: 48.08%] [G loss: 0.713966] [Time: 0.147300]\n",
            "4531-7 [D loss: 0.698755, acc.: 44.23%] [G loss: 0.688468] [Time: 0.148885]\n",
            "4531-8 [D loss: 0.702281, acc.: 38.46%] [G loss: 0.702709] [Time: 0.150799]\n",
            "4531 (test) [D loss: 0.814811, acc.: 46.15%] [G loss: 0.805421] [Time: 0.044051]\n",
            "4532-0 [D loss: 0.676248, acc.: 53.85%] [G loss: 0.734976] [Time: 0.148793]\n",
            "4532-1 [D loss: 0.704814, acc.: 42.31%] [G loss: 0.705989] [Time: 0.150544]\n",
            "4532-2 [D loss: 0.699620, acc.: 44.23%] [G loss: 0.691639] [Time: 0.150315]\n",
            "4532-3 [D loss: 0.673124, acc.: 50.00%] [G loss: 0.727589] [Time: 0.155523]\n",
            "4532-4 [D loss: 0.692398, acc.: 50.00%] [G loss: 0.696473] [Time: 0.148102]\n",
            "4532-5 [D loss: 0.680466, acc.: 51.92%] [G loss: 0.705892] [Time: 0.147464]\n",
            "4532-6 [D loss: 0.694306, acc.: 53.85%] [G loss: 0.690881] [Time: 0.148906]\n",
            "4532-7 [D loss: 0.696749, acc.: 40.38%] [G loss: 0.693041] [Time: 0.150296]\n",
            "4532-8 [D loss: 0.708514, acc.: 34.62%] [G loss: 0.685411] [Time: 0.147340]\n",
            "4532 (test) [D loss: 0.847137, acc.: 46.15%] [G loss: 0.628660] [Time: 0.044646]\n",
            "4533-0 [D loss: 0.688445, acc.: 51.92%] [G loss: 0.750388] [Time: 0.147458]\n",
            "4533-1 [D loss: 0.704792, acc.: 42.31%] [G loss: 0.681500] [Time: 0.148077]\n",
            "4533-2 [D loss: 0.707505, acc.: 36.54%] [G loss: 0.696484] [Time: 0.149971]\n",
            "4533-3 [D loss: 0.664587, acc.: 50.00%] [G loss: 0.734268] [Time: 0.149281]\n",
            "4533-4 [D loss: 0.694386, acc.: 46.15%] [G loss: 0.703474] [Time: 0.150031]\n",
            "4533-5 [D loss: 0.687804, acc.: 36.54%] [G loss: 0.682399] [Time: 0.148548]\n",
            "4533-6 [D loss: 0.687703, acc.: 57.69%] [G loss: 0.700716] [Time: 0.148968]\n",
            "4533-7 [D loss: 0.709197, acc.: 42.31%] [G loss: 0.675240] [Time: 0.152330]\n",
            "4533-8 [D loss: 0.713444, acc.: 40.38%] [G loss: 0.667540] [Time: 0.151814]\n",
            "4533 (test) [D loss: 0.822461, acc.: 46.15%] [G loss: 0.656743] [Time: 0.043954]\n",
            "4534-0 [D loss: 0.677234, acc.: 53.85%] [G loss: 0.743272] [Time: 0.147564]\n",
            "4534-1 [D loss: 0.702895, acc.: 30.77%] [G loss: 0.700663] [Time: 0.153289]\n",
            "4534-2 [D loss: 0.709201, acc.: 26.92%] [G loss: 0.696068] [Time: 0.150172]\n",
            "4534-3 [D loss: 0.680251, acc.: 50.00%] [G loss: 0.729718] [Time: 0.151769]\n",
            "4534-4 [D loss: 0.703460, acc.: 36.54%] [G loss: 0.722198] [Time: 0.152118]\n",
            "4534-5 [D loss: 0.674473, acc.: 53.85%] [G loss: 0.733025] [Time: 0.151083]\n",
            "4534-6 [D loss: 0.692801, acc.: 38.46%] [G loss: 0.709720] [Time: 0.148839]\n",
            "4534-7 [D loss: 0.705869, acc.: 34.62%] [G loss: 0.703696] [Time: 0.147316]\n",
            "4534-8 [D loss: 0.706824, acc.: 44.23%] [G loss: 0.685647] [Time: 0.150015]\n",
            "4534 (test) [D loss: 0.812837, acc.: 46.15%] [G loss: 0.746363] [Time: 0.042972]\n",
            "4535-0 [D loss: 0.680834, acc.: 55.77%] [G loss: 0.713449] [Time: 0.147967]\n",
            "4535-1 [D loss: 0.698577, acc.: 44.23%] [G loss: 0.703262] [Time: 0.147118]\n",
            "4535-2 [D loss: 0.714119, acc.: 32.69%] [G loss: 0.695240] [Time: 0.147400]\n",
            "4535-3 [D loss: 0.679605, acc.: 42.31%] [G loss: 0.712363] [Time: 0.147398]\n",
            "4535-4 [D loss: 0.691319, acc.: 44.23%] [G loss: 0.704509] [Time: 0.149719]\n",
            "4535-5 [D loss: 0.685922, acc.: 40.38%] [G loss: 0.709624] [Time: 0.149693]\n",
            "4535-6 [D loss: 0.686985, acc.: 42.31%] [G loss: 0.706963] [Time: 0.148876]\n",
            "4535-7 [D loss: 0.695699, acc.: 44.23%] [G loss: 0.691899] [Time: 0.149834]\n",
            "4535-8 [D loss: 0.700952, acc.: 40.38%] [G loss: 0.707430] [Time: 0.148239]\n",
            "4535 (test) [D loss: 0.829602, acc.: 46.15%] [G loss: 0.775952] [Time: 0.043855]\n",
            "4536-0 [D loss: 0.678414, acc.: 51.92%] [G loss: 0.753214] [Time: 0.147362]\n",
            "4536-1 [D loss: 0.707319, acc.: 42.31%] [G loss: 0.700360] [Time: 0.148120]\n",
            "4536-2 [D loss: 0.700211, acc.: 44.23%] [G loss: 0.717159] [Time: 0.150452]\n",
            "4536-3 [D loss: 0.696249, acc.: 40.38%] [G loss: 0.732323] [Time: 0.152069]\n",
            "4536-4 [D loss: 0.708154, acc.: 34.62%] [G loss: 0.710395] [Time: 0.147759]\n",
            "4536-5 [D loss: 0.684176, acc.: 50.00%] [G loss: 0.703824] [Time: 0.148944]\n",
            "4536-6 [D loss: 0.707598, acc.: 46.15%] [G loss: 0.706255] [Time: 0.148111]\n",
            "4536-7 [D loss: 0.694840, acc.: 46.15%] [G loss: 0.698751] [Time: 0.148301]\n",
            "4536-8 [D loss: 0.697257, acc.: 36.54%] [G loss: 0.680073] [Time: 0.149968]\n",
            "4536 (test) [D loss: 0.826225, acc.: 46.15%] [G loss: 0.674540] [Time: 0.043937]\n",
            "4537-0 [D loss: 0.673780, acc.: 59.62%] [G loss: 0.711809] [Time: 0.150478]\n",
            "4537-1 [D loss: 0.708533, acc.: 36.54%] [G loss: 0.682348] [Time: 0.147514]\n",
            "4537-2 [D loss: 0.695812, acc.: 34.62%] [G loss: 0.690381] [Time: 0.147207]\n",
            "4537-3 [D loss: 0.682289, acc.: 48.08%] [G loss: 0.695709] [Time: 0.150721]\n",
            "4537-4 [D loss: 0.708607, acc.: 32.69%] [G loss: 0.692216] [Time: 0.147142]\n",
            "4537-5 [D loss: 0.693036, acc.: 40.38%] [G loss: 0.697697] [Time: 0.147893]\n",
            "4537-6 [D loss: 0.693188, acc.: 48.08%] [G loss: 0.707667] [Time: 0.148769]\n",
            "4537-7 [D loss: 0.704950, acc.: 40.38%] [G loss: 0.684723] [Time: 0.147596]\n",
            "4537-8 [D loss: 0.713226, acc.: 38.46%] [G loss: 0.695119] [Time: 0.148846]\n",
            "4537 (test) [D loss: 0.866237, acc.: 48.08%] [G loss: 0.533574] [Time: 0.044486]\n",
            "4538-0 [D loss: 0.684187, acc.: 53.85%] [G loss: 0.721549] [Time: 0.151039]\n",
            "4538-1 [D loss: 0.692145, acc.: 46.15%] [G loss: 0.712556] [Time: 0.151593]\n",
            "4538-2 [D loss: 0.708105, acc.: 32.69%] [G loss: 0.690943] [Time: 0.147458]\n",
            "4538-3 [D loss: 0.673206, acc.: 51.92%] [G loss: 0.743838] [Time: 0.147309]\n",
            "4538-4 [D loss: 0.700480, acc.: 42.31%] [G loss: 0.721632] [Time: 0.147758]\n",
            "4538-5 [D loss: 0.681750, acc.: 53.85%] [G loss: 0.702837] [Time: 0.150210]\n",
            "4538-6 [D loss: 0.686124, acc.: 51.92%] [G loss: 0.711658] [Time: 0.148282]\n",
            "4538-7 [D loss: 0.725717, acc.: 28.85%] [G loss: 0.713243] [Time: 0.148587]\n",
            "4538-8 [D loss: 0.702156, acc.: 40.38%] [G loss: 0.701935] [Time: 0.148703]\n",
            "4538 (test) [D loss: 0.843099, acc.: 46.15%] [G loss: 0.567239] [Time: 0.044588]\n",
            "4539-0 [D loss: 0.667774, acc.: 57.69%] [G loss: 0.748348] [Time: 0.151016]\n",
            "4539-1 [D loss: 0.699462, acc.: 38.46%] [G loss: 0.695411] [Time: 0.148578]\n",
            "4539-2 [D loss: 0.695153, acc.: 40.38%] [G loss: 0.690481] [Time: 0.149393]\n",
            "4539-3 [D loss: 0.666723, acc.: 46.15%] [G loss: 0.721924] [Time: 0.148911]\n",
            "4539-4 [D loss: 0.701563, acc.: 50.00%] [G loss: 0.700328] [Time: 0.148201]\n",
            "4539-5 [D loss: 0.689105, acc.: 46.15%] [G loss: 0.701059] [Time: 0.148261]\n",
            "4539-6 [D loss: 0.697617, acc.: 50.00%] [G loss: 0.715358] [Time: 0.150035]\n",
            "4539-7 [D loss: 0.696224, acc.: 48.08%] [G loss: 0.702361] [Time: 0.146870]\n",
            "4539-8 [D loss: 0.706139, acc.: 38.46%] [G loss: 0.691714] [Time: 0.146815]\n",
            "4539 (test) [D loss: 0.836204, acc.: 46.15%] [G loss: 0.630867] [Time: 0.044661]\n",
            "4540-0 [D loss: 0.666192, acc.: 51.92%] [G loss: 0.759626] [Time: 0.150370]\n",
            "4540-1 [D loss: 0.692958, acc.: 51.92%] [G loss: 0.702555] [Time: 0.147968]\n",
            "4540-2 [D loss: 0.710802, acc.: 38.46%] [G loss: 0.721735] [Time: 0.147876]\n",
            "4540-3 [D loss: 0.668262, acc.: 50.00%] [G loss: 0.721692] [Time: 0.149602]\n",
            "4540-4 [D loss: 0.701896, acc.: 50.00%] [G loss: 0.723836] [Time: 0.148247]\n",
            "4540-5 [D loss: 0.690513, acc.: 40.38%] [G loss: 0.704486] [Time: 0.148775]\n",
            "4540-6 [D loss: 0.699670, acc.: 42.31%] [G loss: 0.715853] [Time: 0.147276]\n",
            "4540-7 [D loss: 0.696171, acc.: 46.15%] [G loss: 0.704995] [Time: 0.151223]\n",
            "4540-8 [D loss: 0.701999, acc.: 32.69%] [G loss: 0.715294] [Time: 0.146922]\n",
            "4540 (test) [D loss: 0.826763, acc.: 48.08%] [G loss: 0.831768] [Time: 0.045302]\n",
            "4541-0 [D loss: 0.682711, acc.: 46.15%] [G loss: 0.764221] [Time: 0.156432]\n",
            "4541-1 [D loss: 0.706386, acc.: 55.77%] [G loss: 0.703094] [Time: 0.150389]\n",
            "4541-2 [D loss: 0.707343, acc.: 44.23%] [G loss: 0.713664] [Time: 0.150496]\n",
            "4541-3 [D loss: 0.671558, acc.: 48.08%] [G loss: 0.710867] [Time: 0.150787]\n",
            "4541-4 [D loss: 0.702098, acc.: 42.31%] [G loss: 0.683577] [Time: 0.149620]\n",
            "4541-5 [D loss: 0.688511, acc.: 44.23%] [G loss: 0.715314] [Time: 0.148045]\n",
            "4541-6 [D loss: 0.692692, acc.: 53.85%] [G loss: 0.716412] [Time: 0.152335]\n",
            "4541-7 [D loss: 0.704150, acc.: 40.38%] [G loss: 0.704826] [Time: 0.149824]\n",
            "4541-8 [D loss: 0.701419, acc.: 51.92%] [G loss: 0.748587] [Time: 0.148949]\n",
            "4541 (test) [D loss: 0.844575, acc.: 48.08%] [G loss: 0.806205] [Time: 0.043521]\n",
            "4542-0 [D loss: 0.674910, acc.: 59.62%] [G loss: 0.761965] [Time: 0.147327]\n",
            "4542-1 [D loss: 0.712951, acc.: 40.38%] [G loss: 0.715566] [Time: 0.147441]\n",
            "4542-2 [D loss: 0.691214, acc.: 48.08%] [G loss: 0.704712] [Time: 0.152548]\n",
            "4542-3 [D loss: 0.670321, acc.: 50.00%] [G loss: 0.742728] [Time: 0.149676]\n",
            "4542-4 [D loss: 0.704940, acc.: 53.85%] [G loss: 0.740203] [Time: 0.148751]\n",
            "4542-5 [D loss: 0.696573, acc.: 32.69%] [G loss: 0.739795] [Time: 0.148653]\n",
            "4542-6 [D loss: 0.708630, acc.: 46.15%] [G loss: 0.717256] [Time: 0.149352]\n",
            "4542-7 [D loss: 0.699276, acc.: 48.08%] [G loss: 0.692484] [Time: 0.147960]\n",
            "4542-8 [D loss: 0.704786, acc.: 48.08%] [G loss: 0.702740] [Time: 0.147131]\n",
            "4542 (test) [D loss: 0.835175, acc.: 48.08%] [G loss: 0.796233] [Time: 0.044986]\n",
            "4543-0 [D loss: 0.683928, acc.: 46.15%] [G loss: 0.744548] [Time: 0.154608]\n",
            "4543-1 [D loss: 0.707079, acc.: 40.38%] [G loss: 0.689190] [Time: 0.148944]\n",
            "4543-2 [D loss: 0.714747, acc.: 30.77%] [G loss: 0.712650] [Time: 0.148825]\n",
            "4543-3 [D loss: 0.670938, acc.: 46.15%] [G loss: 0.761347] [Time: 0.147133]\n",
            "4543-4 [D loss: 0.716087, acc.: 28.85%] [G loss: 0.706678] [Time: 0.149795]\n",
            "4543-5 [D loss: 0.686783, acc.: 36.54%] [G loss: 0.696250] [Time: 0.151610]\n",
            "4543-6 [D loss: 0.703492, acc.: 51.92%] [G loss: 0.733185] [Time: 0.150403]\n",
            "4543-7 [D loss: 0.709765, acc.: 44.23%] [G loss: 0.699067] [Time: 0.147280]\n",
            "4543-8 [D loss: 0.699535, acc.: 34.62%] [G loss: 0.709038] [Time: 0.151309]\n",
            "4543 (test) [D loss: 0.819915, acc.: 48.08%] [G loss: 0.790091] [Time: 0.046249]\n",
            "4544-0 [D loss: 0.702066, acc.: 44.23%] [G loss: 0.736605] [Time: 0.146480]\n",
            "4544-1 [D loss: 0.707728, acc.: 36.54%] [G loss: 0.695319] [Time: 0.147541]\n",
            "4544-2 [D loss: 0.713579, acc.: 40.38%] [G loss: 0.694743] [Time: 0.150468]\n",
            "4544-3 [D loss: 0.673872, acc.: 50.00%] [G loss: 0.713360] [Time: 0.153288]\n",
            "4544-4 [D loss: 0.707956, acc.: 48.08%] [G loss: 0.718814] [Time: 0.146863]\n",
            "4544-5 [D loss: 0.691015, acc.: 42.31%] [G loss: 0.705756] [Time: 0.148088]\n",
            "4544-6 [D loss: 0.701200, acc.: 36.54%] [G loss: 0.730723] [Time: 0.150215]\n",
            "4544-7 [D loss: 0.696105, acc.: 40.38%] [G loss: 0.714303] [Time: 0.148666]\n",
            "4544-8 [D loss: 0.704965, acc.: 46.15%] [G loss: 0.720204] [Time: 0.148801]\n",
            "4544 (test) [D loss: 0.817537, acc.: 50.00%] [G loss: 0.965828] [Time: 0.043655]\n",
            "4545-0 [D loss: 0.668969, acc.: 61.54%] [G loss: 0.758277] [Time: 0.153191]\n",
            "4545-1 [D loss: 0.702138, acc.: 50.00%] [G loss: 0.704014] [Time: 0.148098]\n",
            "4545-2 [D loss: 0.718922, acc.: 38.46%] [G loss: 0.713426] [Time: 0.147840]\n",
            "4545-3 [D loss: 0.688116, acc.: 40.38%] [G loss: 0.708888] [Time: 0.149700]\n",
            "4545-4 [D loss: 0.686891, acc.: 57.69%] [G loss: 0.715210] [Time: 0.152409]\n",
            "4545-5 [D loss: 0.674560, acc.: 48.08%] [G loss: 0.713765] [Time: 0.148597]\n",
            "4545-6 [D loss: 0.692456, acc.: 46.15%] [G loss: 0.706519] [Time: 0.151449]\n",
            "4545-7 [D loss: 0.704168, acc.: 38.46%] [G loss: 0.697356] [Time: 0.152717]\n",
            "4545-8 [D loss: 0.707983, acc.: 25.00%] [G loss: 0.701962] [Time: 0.149880]\n",
            "4545 (test) [D loss: 0.822942, acc.: 46.15%] [G loss: 0.759141] [Time: 0.046653]\n",
            "4546-0 [D loss: 0.674195, acc.: 48.08%] [G loss: 0.710509] [Time: 0.150133]\n",
            "4546-1 [D loss: 0.704448, acc.: 36.54%] [G loss: 0.718825] [Time: 0.150912]\n",
            "4546-2 [D loss: 0.693933, acc.: 42.31%] [G loss: 0.711070] [Time: 0.149710]\n",
            "4546-3 [D loss: 0.679976, acc.: 51.92%] [G loss: 0.747538] [Time: 0.154461]\n",
            "4546-4 [D loss: 0.700930, acc.: 48.08%] [G loss: 0.715103] [Time: 0.149804]\n",
            "4546-5 [D loss: 0.697568, acc.: 42.31%] [G loss: 0.699023] [Time: 0.147660]\n",
            "4546-6 [D loss: 0.681974, acc.: 51.92%] [G loss: 0.707366] [Time: 0.147771]\n",
            "4546-7 [D loss: 0.703354, acc.: 34.62%] [G loss: 0.700640] [Time: 0.152899]\n",
            "4546-8 [D loss: 0.697461, acc.: 46.15%] [G loss: 0.698913] [Time: 0.150126]\n",
            "4546 (test) [D loss: 0.846332, acc.: 46.15%] [G loss: 0.628333] [Time: 0.043392]\n",
            "4547-0 [D loss: 0.681880, acc.: 46.15%] [G loss: 0.743063] [Time: 0.151029]\n",
            "4547-1 [D loss: 0.703209, acc.: 44.23%] [G loss: 0.689571] [Time: 0.148954]\n",
            "4547-2 [D loss: 0.698044, acc.: 40.38%] [G loss: 0.705624] [Time: 0.148397]\n",
            "4547-3 [D loss: 0.681681, acc.: 51.92%] [G loss: 0.731858] [Time: 0.148878]\n",
            "4547-4 [D loss: 0.700789, acc.: 34.62%] [G loss: 0.707526] [Time: 0.148749]\n",
            "4547-5 [D loss: 0.691156, acc.: 40.38%] [G loss: 0.686952] [Time: 0.147880]\n",
            "4547-6 [D loss: 0.697756, acc.: 48.08%] [G loss: 0.713202] [Time: 0.148399]\n",
            "4547-7 [D loss: 0.702895, acc.: 30.77%] [G loss: 0.672060] [Time: 0.150000]\n",
            "4547-8 [D loss: 0.713519, acc.: 40.38%] [G loss: 0.693502] [Time: 0.150776]\n",
            "4547 (test) [D loss: 0.914328, acc.: 50.00%] [G loss: 0.467747] [Time: 0.044655]\n",
            "4548-0 [D loss: 0.665797, acc.: 61.54%] [G loss: 0.721630] [Time: 0.149525]\n",
            "4548-1 [D loss: 0.697170, acc.: 53.85%] [G loss: 0.689812] [Time: 0.150318]\n",
            "4548-2 [D loss: 0.704333, acc.: 40.38%] [G loss: 0.688257] [Time: 0.150434]\n",
            "4548-3 [D loss: 0.686212, acc.: 46.15%] [G loss: 0.711864] [Time: 0.149973]\n",
            "4548-4 [D loss: 0.713476, acc.: 38.46%] [G loss: 0.678108] [Time: 0.147859]\n",
            "4548-5 [D loss: 0.687205, acc.: 40.38%] [G loss: 0.709862] [Time: 0.148457]\n",
            "4548-6 [D loss: 0.692366, acc.: 38.46%] [G loss: 0.703965] [Time: 0.148686]\n",
            "4548-7 [D loss: 0.707776, acc.: 44.23%] [G loss: 0.699904] [Time: 0.150911]\n",
            "4548-8 [D loss: 0.701147, acc.: 48.08%] [G loss: 0.717104] [Time: 0.150590]\n",
            "4548 (test) [D loss: 0.852521, acc.: 48.08%] [G loss: 0.841393] [Time: 0.045017]\n",
            "4549-0 [D loss: 0.686240, acc.: 51.92%] [G loss: 0.775618] [Time: 0.148259]\n",
            "4549-1 [D loss: 0.708487, acc.: 36.54%] [G loss: 0.711302] [Time: 0.148049]\n",
            "4549-2 [D loss: 0.697948, acc.: 44.23%] [G loss: 0.721784] [Time: 0.149574]\n",
            "4549-3 [D loss: 0.681173, acc.: 36.54%] [G loss: 0.750323] [Time: 0.150783]\n",
            "4549-4 [D loss: 0.710026, acc.: 42.31%] [G loss: 0.745167] [Time: 0.147689]\n",
            "4549-5 [D loss: 0.685311, acc.: 46.15%] [G loss: 0.711813] [Time: 0.147500]\n",
            "4549-6 [D loss: 0.689839, acc.: 51.92%] [G loss: 0.705875] [Time: 0.149972]\n",
            "4549-7 [D loss: 0.699751, acc.: 38.46%] [G loss: 0.706667] [Time: 0.149435]\n",
            "4549-8 [D loss: 0.699036, acc.: 51.92%] [G loss: 0.718986] [Time: 0.147882]\n",
            "4549 (test) [D loss: 0.877114, acc.: 50.00%] [G loss: 1.203091] [Time: 0.045018]\n",
            "4550-0 [D loss: 0.693825, acc.: 55.77%] [G loss: 0.726849] [Time: 0.154634]\n",
            "4550-1 [D loss: 0.692676, acc.: 46.15%] [G loss: 0.707821] [Time: 0.147645]\n",
            "4550-2 [D loss: 0.706427, acc.: 42.31%] [G loss: 0.712460] [Time: 0.146945]\n",
            "4550-3 [D loss: 0.666534, acc.: 42.31%] [G loss: 0.727504] [Time: 0.147345]\n",
            "4550-4 [D loss: 0.705610, acc.: 32.69%] [G loss: 0.727885] [Time: 0.148604]\n",
            "4550-5 [D loss: 0.698948, acc.: 42.31%] [G loss: 0.726657] [Time: 0.149836]\n",
            "4550-6 [D loss: 0.703962, acc.: 44.23%] [G loss: 0.707214] [Time: 0.153475]\n",
            "4550-7 [D loss: 0.699314, acc.: 50.00%] [G loss: 0.687553] [Time: 0.149373]\n",
            "4550-8 [D loss: 0.707440, acc.: 40.38%] [G loss: 0.686179] [Time: 0.149864]\n",
            "4550 (test) [D loss: 0.868590, acc.: 50.00%] [G loss: 1.036734] [Time: 0.043229]\n",
            "4551-0 [D loss: 0.677410, acc.: 46.15%] [G loss: 0.716927] [Time: 0.147847]\n",
            "4551-1 [D loss: 0.697628, acc.: 42.31%] [G loss: 0.696739] [Time: 0.149372]\n",
            "4551-2 [D loss: 0.711341, acc.: 44.23%] [G loss: 0.713657] [Time: 0.148269]\n",
            "4551-3 [D loss: 0.679488, acc.: 53.85%] [G loss: 0.732102] [Time: 0.148033]\n",
            "4551-4 [D loss: 0.710110, acc.: 51.92%] [G loss: 0.716470] [Time: 0.147697]\n",
            "4551-5 [D loss: 0.680998, acc.: 44.23%] [G loss: 0.718031] [Time: 0.150861]\n",
            "4551-6 [D loss: 0.697566, acc.: 46.15%] [G loss: 0.730229] [Time: 0.152606]\n",
            "4551-7 [D loss: 0.702497, acc.: 48.08%] [G loss: 0.686362] [Time: 0.149684]\n",
            "4551-8 [D loss: 0.712689, acc.: 51.92%] [G loss: 0.706955] [Time: 0.151942]\n",
            "4551 (test) [D loss: 0.868796, acc.: 50.00%] [G loss: 1.151309] [Time: 0.044356]\n",
            "4552-0 [D loss: 0.673153, acc.: 44.23%] [G loss: 0.773857] [Time: 0.149736]\n",
            "4552-1 [D loss: 0.712451, acc.: 34.62%] [G loss: 0.720649] [Time: 0.147096]\n",
            "4552-2 [D loss: 0.706653, acc.: 42.31%] [G loss: 0.707946] [Time: 0.152164]\n",
            "4552-3 [D loss: 0.683000, acc.: 40.38%] [G loss: 0.733394] [Time: 0.148461]\n",
            "4552-4 [D loss: 0.699375, acc.: 48.08%] [G loss: 0.697633] [Time: 0.147773]\n",
            "4552-5 [D loss: 0.675804, acc.: 50.00%] [G loss: 0.690243] [Time: 0.151394]\n",
            "4552-6 [D loss: 0.696804, acc.: 44.23%] [G loss: 0.710925] [Time: 0.150642]\n",
            "4552-7 [D loss: 0.704883, acc.: 42.31%] [G loss: 0.700133] [Time: 0.147985]\n",
            "4552-8 [D loss: 0.717471, acc.: 44.23%] [G loss: 0.678521] [Time: 0.151037]\n",
            "4552 (test) [D loss: 0.843035, acc.: 50.00%] [G loss: 0.677095] [Time: 0.045230]\n",
            "4553-0 [D loss: 0.671850, acc.: 59.62%] [G loss: 0.729666] [Time: 0.151113]\n",
            "4553-1 [D loss: 0.699130, acc.: 51.92%] [G loss: 0.700004] [Time: 0.148712]\n",
            "4553-2 [D loss: 0.713589, acc.: 40.38%] [G loss: 0.699643] [Time: 0.148898]\n",
            "4553-3 [D loss: 0.675295, acc.: 46.15%] [G loss: 0.723934] [Time: 0.147007]\n",
            "4553-4 [D loss: 0.698263, acc.: 48.08%] [G loss: 0.706149] [Time: 0.148088]\n",
            "4553-5 [D loss: 0.688716, acc.: 40.38%] [G loss: 0.687346] [Time: 0.150794]\n",
            "4553-6 [D loss: 0.692552, acc.: 48.08%] [G loss: 0.708104] [Time: 0.148629]\n",
            "4553-7 [D loss: 0.699179, acc.: 50.00%] [G loss: 0.700711] [Time: 0.151187]\n",
            "4553-8 [D loss: 0.703605, acc.: 36.54%] [G loss: 0.704770] [Time: 0.148270]\n",
            "4553 (test) [D loss: 0.853961, acc.: 46.15%] [G loss: 0.640034] [Time: 0.044906]\n",
            "4554-0 [D loss: 0.684335, acc.: 42.31%] [G loss: 0.732092] [Time: 0.148697]\n",
            "4554-1 [D loss: 0.698392, acc.: 50.00%] [G loss: 0.701432] [Time: 0.149140]\n",
            "4554-2 [D loss: 0.716945, acc.: 25.00%] [G loss: 0.693336] [Time: 0.149505]\n",
            "4554-3 [D loss: 0.678784, acc.: 51.92%] [G loss: 0.709403] [Time: 0.150058]\n",
            "4554-4 [D loss: 0.702802, acc.: 44.23%] [G loss: 0.702581] [Time: 0.150443]\n",
            "4554-5 [D loss: 0.684338, acc.: 46.15%] [G loss: 0.713580] [Time: 0.149648]\n",
            "4554-6 [D loss: 0.698978, acc.: 48.08%] [G loss: 0.716823] [Time: 0.146654]\n",
            "4554-7 [D loss: 0.697174, acc.: 36.54%] [G loss: 0.701881] [Time: 0.150167]\n",
            "4554-8 [D loss: 0.707686, acc.: 42.31%] [G loss: 0.688394] [Time: 0.150748]\n",
            "4554 (test) [D loss: 0.860295, acc.: 46.15%] [G loss: 0.585212] [Time: 0.043156]\n",
            "4555-0 [D loss: 0.682186, acc.: 53.85%] [G loss: 0.742311] [Time: 0.148053]\n",
            "4555-1 [D loss: 0.691294, acc.: 48.08%] [G loss: 0.696551] [Time: 0.152223]\n",
            "4555-2 [D loss: 0.697335, acc.: 38.46%] [G loss: 0.686419] [Time: 0.149903]\n",
            "4555-3 [D loss: 0.691638, acc.: 40.38%] [G loss: 0.732004] [Time: 0.148316]\n",
            "4555-4 [D loss: 0.713394, acc.: 36.54%] [G loss: 0.700246] [Time: 0.150615]\n",
            "4555-5 [D loss: 0.689692, acc.: 38.46%] [G loss: 0.718032] [Time: 0.151145]\n",
            "4555-6 [D loss: 0.706114, acc.: 44.23%] [G loss: 0.724976] [Time: 0.149433]\n",
            "4555-7 [D loss: 0.696259, acc.: 48.08%] [G loss: 0.700810] [Time: 0.147582]\n",
            "4555-8 [D loss: 0.697717, acc.: 44.23%] [G loss: 0.706576] [Time: 0.148077]\n",
            "4555 (test) [D loss: 0.840049, acc.: 48.08%] [G loss: 0.768630] [Time: 0.043419]\n",
            "4556-0 [D loss: 0.686607, acc.: 44.23%] [G loss: 0.754005] [Time: 0.147272]\n",
            "4556-1 [D loss: 0.704515, acc.: 40.38%] [G loss: 0.684578] [Time: 0.151191]\n",
            "4556-2 [D loss: 0.713404, acc.: 34.62%] [G loss: 0.716027] [Time: 0.153656]\n",
            "4556-3 [D loss: 0.679195, acc.: 48.08%] [G loss: 0.735198] [Time: 0.148473]\n",
            "4556-4 [D loss: 0.693805, acc.: 38.46%] [G loss: 0.716802] [Time: 0.150750]\n",
            "4556-5 [D loss: 0.683354, acc.: 42.31%] [G loss: 0.707086] [Time: 0.149675]\n",
            "4556-6 [D loss: 0.691583, acc.: 40.38%] [G loss: 0.711803] [Time: 0.147763]\n",
            "4556-7 [D loss: 0.700595, acc.: 42.31%] [G loss: 0.702950] [Time: 0.150504]\n",
            "4556-8 [D loss: 0.704570, acc.: 40.38%] [G loss: 0.703953] [Time: 0.149610]\n",
            "4556 (test) [D loss: 0.852946, acc.: 50.00%] [G loss: 1.046823] [Time: 0.044717]\n",
            "4557-0 [D loss: 0.666380, acc.: 55.77%] [G loss: 0.755253] [Time: 0.151162]\n",
            "4557-1 [D loss: 0.703718, acc.: 38.46%] [G loss: 0.707875] [Time: 0.147494]\n",
            "4557-2 [D loss: 0.707421, acc.: 48.08%] [G loss: 0.734229] [Time: 0.149939]\n",
            "4557-3 [D loss: 0.683172, acc.: 50.00%] [G loss: 0.730738] [Time: 0.147982]\n",
            "4557-4 [D loss: 0.700693, acc.: 40.38%] [G loss: 0.697364] [Time: 0.153253]\n",
            "4557-5 [D loss: 0.686450, acc.: 36.54%] [G loss: 0.701646] [Time: 0.153294]\n",
            "4557-6 [D loss: 0.702755, acc.: 36.54%] [G loss: 0.734405] [Time: 0.163855]\n",
            "4557-7 [D loss: 0.692060, acc.: 51.92%] [G loss: 0.706230] [Time: 0.151404]\n",
            "4557-8 [D loss: 0.702798, acc.: 40.38%] [G loss: 0.693380] [Time: 0.156035]\n",
            "4557 (test) [D loss: 0.858477, acc.: 50.00%] [G loss: 0.970635] [Time: 0.046218]\n",
            "4558-0 [D loss: 0.685813, acc.: 53.85%] [G loss: 0.765037] [Time: 0.149917]\n",
            "4558-1 [D loss: 0.694970, acc.: 46.15%] [G loss: 0.703767] [Time: 0.149476]\n",
            "4558-2 [D loss: 0.713517, acc.: 38.46%] [G loss: 0.694602] [Time: 0.147520]\n",
            "4558-3 [D loss: 0.677748, acc.: 55.77%] [G loss: 0.725290] [Time: 0.148564]\n",
            "4558-4 [D loss: 0.711489, acc.: 36.54%] [G loss: 0.722164] [Time: 0.149868]\n",
            "4558-5 [D loss: 0.682393, acc.: 40.38%] [G loss: 0.723973] [Time: 0.147113]\n",
            "4558-6 [D loss: 0.703863, acc.: 44.23%] [G loss: 0.706928] [Time: 0.149838]\n",
            "4558-7 [D loss: 0.711122, acc.: 40.38%] [G loss: 0.690424] [Time: 0.149800]\n",
            "4558-8 [D loss: 0.691900, acc.: 48.08%] [G loss: 0.722046] [Time: 0.150286]\n",
            "4558 (test) [D loss: 0.866168, acc.: 48.08%] [G loss: 0.740084] [Time: 0.044832]\n",
            "4559-0 [D loss: 0.676550, acc.: 53.85%] [G loss: 0.763642] [Time: 0.151257]\n",
            "4559-1 [D loss: 0.690612, acc.: 44.23%] [G loss: 0.703344] [Time: 0.150905]\n",
            "4559-2 [D loss: 0.698450, acc.: 46.15%] [G loss: 0.715712] [Time: 0.148072]\n",
            "4559-3 [D loss: 0.674333, acc.: 50.00%] [G loss: 0.724660] [Time: 0.150065]\n",
            "4559-4 [D loss: 0.703296, acc.: 46.15%] [G loss: 0.721054] [Time: 0.149786]\n",
            "4559-5 [D loss: 0.681126, acc.: 50.00%] [G loss: 0.701466] [Time: 0.149698]\n",
            "4559-6 [D loss: 0.706548, acc.: 32.69%] [G loss: 0.714641] [Time: 0.148270]\n",
            "4559-7 [D loss: 0.706089, acc.: 30.77%] [G loss: 0.705469] [Time: 0.151639]\n",
            "4559-8 [D loss: 0.714430, acc.: 46.15%] [G loss: 0.681941] [Time: 0.148197]\n",
            "4559 (test) [D loss: 0.826031, acc.: 50.00%] [G loss: 0.859574] [Time: 0.044533]\n",
            "4560-0 [D loss: 0.664746, acc.: 61.54%] [G loss: 0.753875] [Time: 0.150001]\n",
            "4560-1 [D loss: 0.701802, acc.: 38.46%] [G loss: 0.707864] [Time: 0.153350]\n",
            "4560-2 [D loss: 0.701463, acc.: 42.31%] [G loss: 0.704889] [Time: 0.149159]\n",
            "4560-3 [D loss: 0.664935, acc.: 50.00%] [G loss: 0.731173] [Time: 0.148422]\n",
            "4560-4 [D loss: 0.714894, acc.: 30.77%] [G loss: 0.691685] [Time: 0.151583]\n",
            "4560-5 [D loss: 0.681727, acc.: 42.31%] [G loss: 0.692630] [Time: 0.147752]\n",
            "4560-6 [D loss: 0.697626, acc.: 42.31%] [G loss: 0.700540] [Time: 0.151325]\n",
            "4560-7 [D loss: 0.709716, acc.: 40.38%] [G loss: 0.677569] [Time: 0.148056]\n",
            "4560-8 [D loss: 0.701742, acc.: 38.46%] [G loss: 0.698337] [Time: 0.147342]\n",
            "4560 (test) [D loss: 0.876037, acc.: 46.15%] [G loss: 0.582989] [Time: 0.044101]\n",
            "4561-0 [D loss: 0.664433, acc.: 50.00%] [G loss: 0.729069] [Time: 0.148215]\n",
            "4561-1 [D loss: 0.706437, acc.: 40.38%] [G loss: 0.672535] [Time: 0.148370]\n",
            "4561-2 [D loss: 0.712677, acc.: 32.69%] [G loss: 0.688521] [Time: 0.149044]\n",
            "4561-3 [D loss: 0.671117, acc.: 48.08%] [G loss: 0.724997] [Time: 0.149788]\n",
            "4561-4 [D loss: 0.697240, acc.: 44.23%] [G loss: 0.697398] [Time: 0.149371]\n",
            "4561-5 [D loss: 0.685691, acc.: 40.38%] [G loss: 0.706595] [Time: 0.148800]\n",
            "4561-6 [D loss: 0.700030, acc.: 42.31%] [G loss: 0.707695] [Time: 0.147964]\n",
            "4561-7 [D loss: 0.705286, acc.: 40.38%] [G loss: 0.690138] [Time: 0.148964]\n",
            "4561-8 [D loss: 0.696844, acc.: 40.38%] [G loss: 0.701162] [Time: 0.150156]\n",
            "4561 (test) [D loss: 0.867215, acc.: 44.23%] [G loss: 0.645930] [Time: 0.044441]\n",
            "4562-0 [D loss: 0.684128, acc.: 51.92%] [G loss: 0.712782] [Time: 0.148117]\n",
            "4562-1 [D loss: 0.705092, acc.: 40.38%] [G loss: 0.684214] [Time: 0.153095]\n",
            "4562-2 [D loss: 0.711503, acc.: 40.38%] [G loss: 0.688866] [Time: 0.150110]\n",
            "4562-3 [D loss: 0.671813, acc.: 46.15%] [G loss: 0.722515] [Time: 0.148635]\n",
            "4562-4 [D loss: 0.692104, acc.: 51.92%] [G loss: 0.708887] [Time: 0.150832]\n",
            "4562-5 [D loss: 0.688913, acc.: 32.69%] [G loss: 0.713300] [Time: 0.151058]\n",
            "4562-6 [D loss: 0.695684, acc.: 40.38%] [G loss: 0.722957] [Time: 0.149236]\n",
            "4562-7 [D loss: 0.703685, acc.: 42.31%] [G loss: 0.703857] [Time: 0.150064]\n",
            "4562-8 [D loss: 0.717263, acc.: 36.54%] [G loss: 0.722599] [Time: 0.147284]\n",
            "4562 (test) [D loss: 0.842124, acc.: 50.00%] [G loss: 0.964910] [Time: 0.044639]\n",
            "4563-0 [D loss: 0.685679, acc.: 63.46%] [G loss: 0.763373] [Time: 0.148261]\n",
            "4563-1 [D loss: 0.705884, acc.: 36.54%] [G loss: 0.705771] [Time: 0.149772]\n",
            "4563-2 [D loss: 0.704455, acc.: 38.46%] [G loss: 0.723346] [Time: 0.148773]\n",
            "4563-3 [D loss: 0.671296, acc.: 50.00%] [G loss: 0.750588] [Time: 0.147693]\n",
            "4563-4 [D loss: 0.707164, acc.: 38.46%] [G loss: 0.720368] [Time: 0.147547]\n",
            "4563-5 [D loss: 0.684197, acc.: 44.23%] [G loss: 0.706523] [Time: 0.150425]\n",
            "4563-6 [D loss: 0.692229, acc.: 38.46%] [G loss: 0.706923] [Time: 0.153422]\n",
            "4563-7 [D loss: 0.695027, acc.: 57.69%] [G loss: 0.700361] [Time: 0.149530]\n",
            "4563-8 [D loss: 0.698802, acc.: 44.23%] [G loss: 0.695503] [Time: 0.146826]\n",
            "4563 (test) [D loss: 0.860037, acc.: 48.08%] [G loss: 0.728612] [Time: 0.044933]\n",
            "4564-0 [D loss: 0.680655, acc.: 51.92%] [G loss: 0.742363] [Time: 0.146815]\n",
            "4564-1 [D loss: 0.697292, acc.: 42.31%] [G loss: 0.688506] [Time: 0.148550]\n",
            "4564-2 [D loss: 0.705786, acc.: 36.54%] [G loss: 0.696536] [Time: 0.147791]\n",
            "4564-3 [D loss: 0.671930, acc.: 53.85%] [G loss: 0.722292] [Time: 0.148736]\n",
            "4564-4 [D loss: 0.705329, acc.: 32.69%] [G loss: 0.682620] [Time: 0.148350]\n",
            "4564-5 [D loss: 0.689185, acc.: 40.38%] [G loss: 0.694744] [Time: 0.149430]\n",
            "4564-6 [D loss: 0.692483, acc.: 34.62%] [G loss: 0.697681] [Time: 0.149513]\n",
            "4564-7 [D loss: 0.703151, acc.: 46.15%] [G loss: 0.708203] [Time: 0.149884]\n",
            "4564-8 [D loss: 0.689541, acc.: 51.92%] [G loss: 0.701708] [Time: 0.149621]\n",
            "4564 (test) [D loss: 0.840733, acc.: 48.08%] [G loss: 0.731313] [Time: 0.043302]\n",
            "4565-0 [D loss: 0.694688, acc.: 50.00%] [G loss: 0.734526] [Time: 0.148133]\n",
            "4565-1 [D loss: 0.700818, acc.: 50.00%] [G loss: 0.691058] [Time: 0.151428]\n",
            "4565-2 [D loss: 0.707588, acc.: 46.15%] [G loss: 0.703604] [Time: 0.150283]\n",
            "4565-3 [D loss: 0.676766, acc.: 53.85%] [G loss: 0.710043] [Time: 0.147300]\n",
            "4565-4 [D loss: 0.707070, acc.: 32.69%] [G loss: 0.713197] [Time: 0.147673]\n",
            "4565-5 [D loss: 0.685614, acc.: 36.54%] [G loss: 0.711681] [Time: 0.150794]\n",
            "4565-6 [D loss: 0.702314, acc.: 42.31%] [G loss: 0.705113] [Time: 0.150031]\n",
            "4565-7 [D loss: 0.702364, acc.: 46.15%] [G loss: 0.696961] [Time: 0.148877]\n",
            "4565-8 [D loss: 0.705239, acc.: 44.23%] [G loss: 0.694739] [Time: 0.149115]\n",
            "4565 (test) [D loss: 0.835643, acc.: 48.08%] [G loss: 0.863386] [Time: 0.045917]\n",
            "4566-0 [D loss: 0.674799, acc.: 53.85%] [G loss: 0.730597] [Time: 0.147854]\n",
            "4566-1 [D loss: 0.696072, acc.: 50.00%] [G loss: 0.708797] [Time: 0.147830]\n",
            "4566-2 [D loss: 0.709692, acc.: 46.15%] [G loss: 0.713403] [Time: 0.148012]\n",
            "4566-3 [D loss: 0.674459, acc.: 46.15%] [G loss: 0.727250] [Time: 0.148184]\n",
            "4566-4 [D loss: 0.696816, acc.: 40.38%] [G loss: 0.711447] [Time: 0.147240]\n",
            "4566-5 [D loss: 0.698936, acc.: 32.69%] [G loss: 0.703381] [Time: 0.149031]\n",
            "4566-6 [D loss: 0.699644, acc.: 48.08%] [G loss: 0.707717] [Time: 0.149534]\n",
            "4566-7 [D loss: 0.705310, acc.: 36.54%] [G loss: 0.694441] [Time: 0.148568]\n",
            "4566-8 [D loss: 0.702284, acc.: 42.31%] [G loss: 0.690028] [Time: 0.148104]\n",
            "4566 (test) [D loss: 0.852476, acc.: 50.00%] [G loss: 0.825095] [Time: 0.045431]\n",
            "4567-0 [D loss: 0.672083, acc.: 61.54%] [G loss: 0.726194] [Time: 0.149685]\n",
            "4567-1 [D loss: 0.697726, acc.: 38.46%] [G loss: 0.695792] [Time: 0.150473]\n",
            "4567-2 [D loss: 0.713903, acc.: 30.77%] [G loss: 0.698760] [Time: 0.149744]\n",
            "4567-3 [D loss: 0.662346, acc.: 63.46%] [G loss: 0.728725] [Time: 0.149660]\n",
            "4567-4 [D loss: 0.698960, acc.: 36.54%] [G loss: 0.711344] [Time: 0.147156]\n",
            "4567-5 [D loss: 0.698984, acc.: 40.38%] [G loss: 0.690769] [Time: 0.146795]\n",
            "4567-6 [D loss: 0.691324, acc.: 51.92%] [G loss: 0.703463] [Time: 0.149900]\n",
            "4567-7 [D loss: 0.706499, acc.: 46.15%] [G loss: 0.699460] [Time: 0.148287]\n",
            "4567-8 [D loss: 0.710024, acc.: 38.46%] [G loss: 0.682705] [Time: 0.147611]\n",
            "4567 (test) [D loss: 0.851323, acc.: 48.08%] [G loss: 0.734740] [Time: 0.044823]\n",
            "4568-0 [D loss: 0.683119, acc.: 48.08%] [G loss: 0.726537] [Time: 0.151533]\n",
            "4568-1 [D loss: 0.712269, acc.: 40.38%] [G loss: 0.697978] [Time: 0.149118]\n",
            "4568-2 [D loss: 0.722058, acc.: 28.85%] [G loss: 0.698188] [Time: 0.150444]\n",
            "4568-3 [D loss: 0.675468, acc.: 50.00%] [G loss: 0.726826] [Time: 0.148175]\n",
            "4568-4 [D loss: 0.700659, acc.: 44.23%] [G loss: 0.697920] [Time: 0.152324]\n",
            "4568-5 [D loss: 0.686581, acc.: 44.23%] [G loss: 0.698145] [Time: 0.150486]\n",
            "4568-6 [D loss: 0.686494, acc.: 46.15%] [G loss: 0.700040] [Time: 0.147763]\n",
            "4568-7 [D loss: 0.705281, acc.: 38.46%] [G loss: 0.684285] [Time: 0.154040]\n",
            "4568-8 [D loss: 0.713033, acc.: 48.08%] [G loss: 0.697712] [Time: 0.150685]\n",
            "4568 (test) [D loss: 0.837851, acc.: 50.00%] [G loss: 0.836502] [Time: 0.044229]\n",
            "4569-0 [D loss: 0.661170, acc.: 55.77%] [G loss: 0.736948] [Time: 0.151087]\n",
            "4569-1 [D loss: 0.706856, acc.: 46.15%] [G loss: 0.682518] [Time: 0.148522]\n",
            "4569-2 [D loss: 0.721805, acc.: 32.69%] [G loss: 0.706631] [Time: 0.147270]\n",
            "4569-3 [D loss: 0.674001, acc.: 44.23%] [G loss: 0.723843] [Time: 0.147581]\n",
            "4569-4 [D loss: 0.705623, acc.: 36.54%] [G loss: 0.711331] [Time: 0.148250]\n",
            "4569-5 [D loss: 0.680424, acc.: 46.15%] [G loss: 0.712602] [Time: 0.154134]\n",
            "4569-6 [D loss: 0.688820, acc.: 53.85%] [G loss: 0.703727] [Time: 0.148646]\n",
            "4569-7 [D loss: 0.697844, acc.: 46.15%] [G loss: 0.698933] [Time: 0.147840]\n",
            "4569-8 [D loss: 0.709015, acc.: 26.92%] [G loss: 0.689251] [Time: 0.147725]\n",
            "4569 (test) [D loss: 0.834866, acc.: 50.00%] [G loss: 0.887351] [Time: 0.043087]\n",
            "4570-0 [D loss: 0.667105, acc.: 61.54%] [G loss: 0.748869] [Time: 0.148498]\n",
            "4570-1 [D loss: 0.708726, acc.: 38.46%] [G loss: 0.698727] [Time: 0.148829]\n",
            "4570-2 [D loss: 0.697352, acc.: 38.46%] [G loss: 0.727949] [Time: 0.148736]\n",
            "4570-3 [D loss: 0.674736, acc.: 51.92%] [G loss: 0.714153] [Time: 0.151708]\n",
            "4570-4 [D loss: 0.701908, acc.: 38.46%] [G loss: 0.716664] [Time: 0.149347]\n",
            "4570-5 [D loss: 0.708352, acc.: 34.62%] [G loss: 0.704584] [Time: 0.147976]\n",
            "4570-6 [D loss: 0.684901, acc.: 51.92%] [G loss: 0.712297] [Time: 0.149972]\n",
            "4570-7 [D loss: 0.708072, acc.: 40.38%] [G loss: 0.696567] [Time: 0.151238]\n",
            "4570-8 [D loss: 0.712156, acc.: 46.15%] [G loss: 0.704076] [Time: 0.148556]\n",
            "4570 (test) [D loss: 0.829225, acc.: 50.00%] [G loss: 0.863149] [Time: 0.043376]\n",
            "4571-0 [D loss: 0.684215, acc.: 38.46%] [G loss: 0.739044] [Time: 0.149067]\n",
            "4571-1 [D loss: 0.710636, acc.: 32.69%] [G loss: 0.684126] [Time: 0.153594]\n",
            "4571-2 [D loss: 0.699494, acc.: 42.31%] [G loss: 0.694399] [Time: 0.150794]\n",
            "4571-3 [D loss: 0.674222, acc.: 53.85%] [G loss: 0.736060] [Time: 0.151363]\n",
            "4571-4 [D loss: 0.702861, acc.: 38.46%] [G loss: 0.692010] [Time: 0.152627]\n",
            "4571-5 [D loss: 0.688473, acc.: 38.46%] [G loss: 0.698270] [Time: 0.148041]\n",
            "4571-6 [D loss: 0.703677, acc.: 44.23%] [G loss: 0.715186] [Time: 0.148133]\n",
            "4571-7 [D loss: 0.702609, acc.: 46.15%] [G loss: 0.681913] [Time: 0.148753]\n",
            "4571-8 [D loss: 0.690065, acc.: 46.15%] [G loss: 0.689216] [Time: 0.149424]\n",
            "4571 (test) [D loss: 0.867216, acc.: 46.15%] [G loss: 0.695885] [Time: 0.043809]\n",
            "4572-0 [D loss: 0.682654, acc.: 55.77%] [G loss: 0.743470] [Time: 0.148544]\n",
            "4572-1 [D loss: 0.701217, acc.: 38.46%] [G loss: 0.690852] [Time: 0.148353]\n",
            "4572-2 [D loss: 0.697791, acc.: 44.23%] [G loss: 0.678422] [Time: 0.148794]\n",
            "4572-3 [D loss: 0.680102, acc.: 48.08%] [G loss: 0.746139] [Time: 0.147200]\n",
            "4572-4 [D loss: 0.691561, acc.: 50.00%] [G loss: 0.709753] [Time: 0.147502]\n",
            "4572-5 [D loss: 0.699046, acc.: 51.92%] [G loss: 0.716997] [Time: 0.147517]\n",
            "4572-6 [D loss: 0.697821, acc.: 38.46%] [G loss: 0.706730] [Time: 0.148537]\n",
            "4572-7 [D loss: 0.700737, acc.: 46.15%] [G loss: 0.699497] [Time: 0.149644]\n",
            "4572-8 [D loss: 0.710921, acc.: 42.31%] [G loss: 0.698879] [Time: 0.149516]\n",
            "4572 (test) [D loss: 0.847830, acc.: 51.92%] [G loss: 0.986421] [Time: 0.045195]\n",
            "4573-0 [D loss: 0.682668, acc.: 50.00%] [G loss: 0.790668] [Time: 0.150321]\n",
            "4573-1 [D loss: 0.699472, acc.: 34.62%] [G loss: 0.700881] [Time: 0.149369]\n",
            "4573-2 [D loss: 0.705346, acc.: 36.54%] [G loss: 0.709772] [Time: 0.147879]\n",
            "4573-3 [D loss: 0.676294, acc.: 36.54%] [G loss: 0.735904] [Time: 0.148067]\n",
            "4573-4 [D loss: 0.695848, acc.: 46.15%] [G loss: 0.710271] [Time: 0.147726]\n",
            "4573-5 [D loss: 0.684321, acc.: 48.08%] [G loss: 0.724693] [Time: 0.147226]\n",
            "4573-6 [D loss: 0.708118, acc.: 42.31%] [G loss: 0.704139] [Time: 0.146760]\n",
            "4573-7 [D loss: 0.696560, acc.: 53.85%] [G loss: 0.723452] [Time: 0.148916]\n",
            "4573-8 [D loss: 0.691899, acc.: 40.38%] [G loss: 0.697078] [Time: 0.149772]\n",
            "4573 (test) [D loss: 0.857061, acc.: 53.85%] [G loss: 0.782642] [Time: 0.045064]\n",
            "4574-0 [D loss: 0.682291, acc.: 67.31%] [G loss: 0.737013] [Time: 0.149672]\n",
            "4574-1 [D loss: 0.707141, acc.: 42.31%] [G loss: 0.696343] [Time: 0.148950]\n",
            "4574-2 [D loss: 0.689381, acc.: 46.15%] [G loss: 0.710423] [Time: 0.148701]\n",
            "4574-3 [D loss: 0.671101, acc.: 40.38%] [G loss: 0.719952] [Time: 0.148529]\n",
            "4574-4 [D loss: 0.700914, acc.: 38.46%] [G loss: 0.707765] [Time: 0.148845]\n",
            "4574-5 [D loss: 0.677822, acc.: 46.15%] [G loss: 0.697011] [Time: 0.150366]\n",
            "4574-6 [D loss: 0.699316, acc.: 38.46%] [G loss: 0.720379] [Time: 0.150328]\n",
            "4574-7 [D loss: 0.699612, acc.: 40.38%] [G loss: 0.690608] [Time: 0.150494]\n",
            "4574-8 [D loss: 0.705775, acc.: 46.15%] [G loss: 0.689764] [Time: 0.150315]\n",
            "4574 (test) [D loss: 0.867809, acc.: 48.08%] [G loss: 0.675231] [Time: 0.045059]\n",
            "4575-0 [D loss: 0.668454, acc.: 63.46%] [G loss: 0.718981] [Time: 0.147797]\n",
            "4575-1 [D loss: 0.715244, acc.: 34.62%] [G loss: 0.692623] [Time: 0.148536]\n",
            "4575-2 [D loss: 0.693614, acc.: 48.08%] [G loss: 0.725034] [Time: 0.149988]\n",
            "4575-3 [D loss: 0.683720, acc.: 42.31%] [G loss: 0.716412] [Time: 0.151649]\n",
            "4575-4 [D loss: 0.710424, acc.: 34.62%] [G loss: 0.712640] [Time: 0.151699]\n",
            "4575-5 [D loss: 0.687329, acc.: 30.77%] [G loss: 0.721566] [Time: 0.148631]\n",
            "4575-6 [D loss: 0.700140, acc.: 44.23%] [G loss: 0.699685] [Time: 0.151740]\n",
            "4575-7 [D loss: 0.700381, acc.: 42.31%] [G loss: 0.708728] [Time: 0.149822]\n",
            "4575-8 [D loss: 0.708210, acc.: 44.23%] [G loss: 0.694670] [Time: 0.147935]\n",
            "4575 (test) [D loss: 0.847982, acc.: 46.15%] [G loss: 0.741588] [Time: 0.043784]\n",
            "4576-0 [D loss: 0.674101, acc.: 51.92%] [G loss: 0.737128] [Time: 0.148202]\n",
            "4576-1 [D loss: 0.713414, acc.: 42.31%] [G loss: 0.697130] [Time: 0.148263]\n",
            "4576-2 [D loss: 0.700697, acc.: 51.92%] [G loss: 0.692866] [Time: 0.149998]\n",
            "4576-3 [D loss: 0.698196, acc.: 40.38%] [G loss: 0.726971] [Time: 0.151084]\n",
            "4576-4 [D loss: 0.716729, acc.: 34.62%] [G loss: 0.706070] [Time: 0.147679]\n",
            "4576-5 [D loss: 0.681242, acc.: 53.85%] [G loss: 0.703988] [Time: 0.148780]\n",
            "4576-6 [D loss: 0.694445, acc.: 42.31%] [G loss: 0.714484] [Time: 0.147440]\n",
            "4576-7 [D loss: 0.700112, acc.: 36.54%] [G loss: 0.702769] [Time: 0.148495]\n",
            "4576-8 [D loss: 0.705523, acc.: 38.46%] [G loss: 0.703785] [Time: 0.150307]\n",
            "4576 (test) [D loss: 0.859977, acc.: 50.00%] [G loss: 0.691554] [Time: 0.044988]\n",
            "4577-0 [D loss: 0.691582, acc.: 44.23%] [G loss: 0.746759] [Time: 0.148827]\n",
            "4577-1 [D loss: 0.705480, acc.: 36.54%] [G loss: 0.687770] [Time: 0.150046]\n",
            "4577-2 [D loss: 0.698186, acc.: 38.46%] [G loss: 0.729663] [Time: 0.147695]\n",
            "4577-3 [D loss: 0.681617, acc.: 42.31%] [G loss: 0.717369] [Time: 0.148498]\n",
            "4577-4 [D loss: 0.707757, acc.: 38.46%] [G loss: 0.713232] [Time: 0.154309]\n",
            "4577-5 [D loss: 0.690476, acc.: 42.31%] [G loss: 0.675099] [Time: 0.150093]\n",
            "4577-6 [D loss: 0.688290, acc.: 44.23%] [G loss: 0.697870] [Time: 0.149813]\n",
            "4577-7 [D loss: 0.702960, acc.: 48.08%] [G loss: 0.694085] [Time: 0.149929]\n",
            "4577-8 [D loss: 0.709871, acc.: 32.69%] [G loss: 0.682011] [Time: 0.148078]\n",
            "4577 (test) [D loss: 0.855713, acc.: 48.08%] [G loss: 0.672087] [Time: 0.044249]\n",
            "4578-0 [D loss: 0.680705, acc.: 50.00%] [G loss: 0.735774] [Time: 0.149821]\n",
            "4578-1 [D loss: 0.704589, acc.: 40.38%] [G loss: 0.687569] [Time: 0.147605]\n",
            "4578-2 [D loss: 0.695024, acc.: 48.08%] [G loss: 0.690316] [Time: 0.149531]\n",
            "4578-3 [D loss: 0.678113, acc.: 51.92%] [G loss: 0.747540] [Time: 0.149836]\n",
            "4578-4 [D loss: 0.697085, acc.: 46.15%] [G loss: 0.698424] [Time: 0.149194]\n",
            "4578-5 [D loss: 0.698846, acc.: 34.62%] [G loss: 0.693156] [Time: 0.150660]\n",
            "4578-6 [D loss: 0.703871, acc.: 42.31%] [G loss: 0.700323] [Time: 0.150348]\n",
            "4578-7 [D loss: 0.704966, acc.: 40.38%] [G loss: 0.717585] [Time: 0.152867]\n",
            "4578-8 [D loss: 0.706722, acc.: 32.69%] [G loss: 0.689430] [Time: 0.151142]\n",
            "4578 (test) [D loss: 0.848976, acc.: 46.15%] [G loss: 0.761080] [Time: 0.047074]\n",
            "4579-0 [D loss: 0.671044, acc.: 63.46%] [G loss: 0.749695] [Time: 0.149684]\n",
            "4579-1 [D loss: 0.705180, acc.: 42.31%] [G loss: 0.706850] [Time: 0.150058]\n",
            "4579-2 [D loss: 0.712654, acc.: 40.38%] [G loss: 0.730513] [Time: 0.152649]\n",
            "4579-3 [D loss: 0.682593, acc.: 40.38%] [G loss: 0.740885] [Time: 0.150494]\n",
            "4579-4 [D loss: 0.721689, acc.: 26.92%] [G loss: 0.727295] [Time: 0.149774]\n",
            "4579-5 [D loss: 0.680406, acc.: 46.15%] [G loss: 0.739323] [Time: 0.149857]\n",
            "4579-6 [D loss: 0.707350, acc.: 46.15%] [G loss: 0.706495] [Time: 0.148556]\n",
            "4579-7 [D loss: 0.701615, acc.: 51.92%] [G loss: 0.715005] [Time: 0.150741]\n",
            "4579-8 [D loss: 0.706324, acc.: 46.15%] [G loss: 0.706929] [Time: 0.148592]\n",
            "4579 (test) [D loss: 0.841624, acc.: 50.00%] [G loss: 0.931513] [Time: 0.044345]\n",
            "4580-0 [D loss: 0.677665, acc.: 46.15%] [G loss: 0.743604] [Time: 0.150587]\n",
            "4580-1 [D loss: 0.705212, acc.: 40.38%] [G loss: 0.706857] [Time: 0.147329]\n",
            "4580-2 [D loss: 0.710090, acc.: 42.31%] [G loss: 0.711627] [Time: 0.148061]\n",
            "4580-3 [D loss: 0.673402, acc.: 42.31%] [G loss: 0.743430] [Time: 0.147199]\n",
            "4580-4 [D loss: 0.700616, acc.: 51.92%] [G loss: 0.711835] [Time: 0.149889]\n",
            "4580-5 [D loss: 0.684470, acc.: 38.46%] [G loss: 0.713814] [Time: 0.149395]\n",
            "4580-6 [D loss: 0.695661, acc.: 42.31%] [G loss: 0.713849] [Time: 0.149798]\n",
            "4580-7 [D loss: 0.694848, acc.: 53.85%] [G loss: 0.691938] [Time: 0.148685]\n",
            "4580-8 [D loss: 0.702777, acc.: 42.31%] [G loss: 0.695209] [Time: 0.148846]\n",
            "4580 (test) [D loss: 0.848483, acc.: 48.08%] [G loss: 0.789344] [Time: 0.043871]\n",
            "4581-0 [D loss: 0.676618, acc.: 59.62%] [G loss: 0.753125] [Time: 0.148000]\n",
            "4581-1 [D loss: 0.697801, acc.: 48.08%] [G loss: 0.680403] [Time: 0.147794]\n",
            "4581-2 [D loss: 0.708210, acc.: 36.54%] [G loss: 0.710988] [Time: 0.148269]\n",
            "4581-3 [D loss: 0.674728, acc.: 44.23%] [G loss: 0.726478] [Time: 0.148005]\n",
            "4581-4 [D loss: 0.695570, acc.: 48.08%] [G loss: 0.731010] [Time: 0.150997]\n",
            "4581-5 [D loss: 0.691508, acc.: 30.77%] [G loss: 0.710852] [Time: 0.148553]\n",
            "4581-6 [D loss: 0.694486, acc.: 48.08%] [G loss: 0.724136] [Time: 0.148455]\n",
            "4581-7 [D loss: 0.694482, acc.: 48.08%] [G loss: 0.712853] [Time: 0.148394]\n",
            "4581-8 [D loss: 0.702035, acc.: 46.15%] [G loss: 0.709315] [Time: 0.146808]\n",
            "4581 (test) [D loss: 0.839583, acc.: 44.23%] [G loss: 0.818353] [Time: 0.043381]\n",
            "4582-0 [D loss: 0.678881, acc.: 48.08%] [G loss: 0.750742] [Time: 0.149354]\n",
            "4582-1 [D loss: 0.700397, acc.: 34.62%] [G loss: 0.685471] [Time: 0.152653]\n",
            "4582-2 [D loss: 0.700539, acc.: 48.08%] [G loss: 0.709439] [Time: 0.149696]\n",
            "4582-3 [D loss: 0.681590, acc.: 46.15%] [G loss: 0.729921] [Time: 0.148835]\n",
            "4582-4 [D loss: 0.719253, acc.: 32.69%] [G loss: 0.705627] [Time: 0.148297]\n",
            "4582-5 [D loss: 0.685979, acc.: 40.38%] [G loss: 0.703356] [Time: 0.148971]\n",
            "4582-6 [D loss: 0.682879, acc.: 50.00%] [G loss: 0.714985] [Time: 0.147239]\n",
            "4582-7 [D loss: 0.707384, acc.: 48.08%] [G loss: 0.696115] [Time: 0.148567]\n",
            "4582-8 [D loss: 0.707938, acc.: 40.38%] [G loss: 0.685882] [Time: 0.149880]\n",
            "4582 (test) [D loss: 0.883000, acc.: 48.08%] [G loss: 0.551740] [Time: 0.043643]\n",
            "4583-0 [D loss: 0.685107, acc.: 55.77%] [G loss: 0.727945] [Time: 0.148319]\n",
            "4583-1 [D loss: 0.697986, acc.: 50.00%] [G loss: 0.685231] [Time: 0.148937]\n",
            "4583-2 [D loss: 0.703845, acc.: 34.62%] [G loss: 0.705160] [Time: 0.149849]\n",
            "4583-3 [D loss: 0.679616, acc.: 48.08%] [G loss: 0.724150] [Time: 0.147673]\n",
            "4583-4 [D loss: 0.702419, acc.: 50.00%] [G loss: 0.717327] [Time: 0.148818]\n",
            "4583-5 [D loss: 0.668470, acc.: 50.00%] [G loss: 0.718825] [Time: 0.148804]\n",
            "4583-6 [D loss: 0.696115, acc.: 48.08%] [G loss: 0.726828] [Time: 0.146850]\n",
            "4583-7 [D loss: 0.683697, acc.: 53.85%] [G loss: 0.694747] [Time: 0.148980]\n",
            "4583-8 [D loss: 0.705685, acc.: 34.62%] [G loss: 0.685473] [Time: 0.150102]\n",
            "4583 (test) [D loss: 0.877367, acc.: 48.08%] [G loss: 0.603811] [Time: 0.043607]\n",
            "4584-0 [D loss: 0.675328, acc.: 51.92%] [G loss: 0.766158] [Time: 0.147116]\n",
            "4584-1 [D loss: 0.699725, acc.: 50.00%] [G loss: 0.680571] [Time: 0.148313]\n",
            "4584-2 [D loss: 0.699787, acc.: 44.23%] [G loss: 0.692294] [Time: 0.148416]\n",
            "4584-3 [D loss: 0.678882, acc.: 44.23%] [G loss: 0.737773] [Time: 0.147897]\n",
            "4584-4 [D loss: 0.712909, acc.: 42.31%] [G loss: 0.727481] [Time: 0.149672]\n",
            "4584-5 [D loss: 0.683712, acc.: 46.15%] [G loss: 0.716254] [Time: 0.149617]\n",
            "4584-6 [D loss: 0.695714, acc.: 38.46%] [G loss: 0.693816] [Time: 0.147591]\n",
            "4584-7 [D loss: 0.701319, acc.: 38.46%] [G loss: 0.697806] [Time: 0.148977]\n",
            "4584-8 [D loss: 0.702558, acc.: 51.92%] [G loss: 0.712027] [Time: 0.148782]\n",
            "4584 (test) [D loss: 0.880147, acc.: 50.00%] [G loss: 0.618694] [Time: 0.046103]\n",
            "4585-0 [D loss: 0.688019, acc.: 48.08%] [G loss: 0.726929] [Time: 0.151414]\n",
            "4585-1 [D loss: 0.687528, acc.: 48.08%] [G loss: 0.692962] [Time: 0.151362]\n",
            "4585-2 [D loss: 0.710493, acc.: 50.00%] [G loss: 0.685947] [Time: 0.149571]\n",
            "4585-3 [D loss: 0.668993, acc.: 42.31%] [G loss: 0.742522] [Time: 0.148278]\n",
            "4585-4 [D loss: 0.705907, acc.: 46.15%] [G loss: 0.696734] [Time: 0.147699]\n",
            "4585-5 [D loss: 0.693740, acc.: 38.46%] [G loss: 0.700010] [Time: 0.150090]\n",
            "4585-6 [D loss: 0.694157, acc.: 48.08%] [G loss: 0.701678] [Time: 0.148765]\n",
            "4585-7 [D loss: 0.695792, acc.: 48.08%] [G loss: 0.701510] [Time: 0.149492]\n",
            "4585-8 [D loss: 0.701478, acc.: 46.15%] [G loss: 0.678998] [Time: 0.147561]\n",
            "4585 (test) [D loss: 0.886315, acc.: 50.00%] [G loss: 0.581486] [Time: 0.044178]\n",
            "4586-0 [D loss: 0.672013, acc.: 65.38%] [G loss: 0.736974] [Time: 0.149304]\n",
            "4586-1 [D loss: 0.701377, acc.: 46.15%] [G loss: 0.695451] [Time: 0.149382]\n",
            "4586-2 [D loss: 0.706027, acc.: 34.62%] [G loss: 0.691469] [Time: 0.151285]\n",
            "4586-3 [D loss: 0.678716, acc.: 51.92%] [G loss: 0.744585] [Time: 0.150377]\n",
            "4586-4 [D loss: 0.713533, acc.: 46.15%] [G loss: 0.737514] [Time: 0.148321]\n",
            "4586-5 [D loss: 0.677996, acc.: 48.08%] [G loss: 0.712286] [Time: 0.148663]\n",
            "4586-6 [D loss: 0.692079, acc.: 48.08%] [G loss: 0.729250] [Time: 0.147778]\n",
            "4586-7 [D loss: 0.686651, acc.: 51.92%] [G loss: 0.724123] [Time: 0.151932]\n",
            "4586-8 [D loss: 0.700744, acc.: 40.38%] [G loss: 0.712620] [Time: 0.149323]\n",
            "4586 (test) [D loss: 0.845251, acc.: 50.00%] [G loss: 0.979344] [Time: 0.045117]\n",
            "4587-0 [D loss: 0.689415, acc.: 50.00%] [G loss: 0.766232] [Time: 0.153255]\n",
            "4587-1 [D loss: 0.713641, acc.: 44.23%] [G loss: 0.716758] [Time: 0.151620]\n",
            "4587-2 [D loss: 0.708171, acc.: 42.31%] [G loss: 0.713796] [Time: 0.148900]\n",
            "4587-3 [D loss: 0.695593, acc.: 42.31%] [G loss: 0.737783] [Time: 0.148079]\n",
            "4587-4 [D loss: 0.701004, acc.: 40.38%] [G loss: 0.732432] [Time: 0.150934]\n",
            "4587-5 [D loss: 0.701568, acc.: 48.08%] [G loss: 0.715689] [Time: 0.147096]\n",
            "4587-6 [D loss: 0.697799, acc.: 48.08%] [G loss: 0.709521] [Time: 0.147614]\n",
            "4587-7 [D loss: 0.704987, acc.: 44.23%] [G loss: 0.704739] [Time: 0.147680]\n",
            "4587-8 [D loss: 0.695033, acc.: 46.15%] [G loss: 0.684822] [Time: 0.147149]\n",
            "4587 (test) [D loss: 0.855348, acc.: 53.85%] [G loss: 0.769175] [Time: 0.045061]\n",
            "4588-0 [D loss: 0.669033, acc.: 53.85%] [G loss: 0.725168] [Time: 0.150165]\n",
            "4588-1 [D loss: 0.700455, acc.: 42.31%] [G loss: 0.701858] [Time: 0.151992]\n",
            "4588-2 [D loss: 0.702176, acc.: 34.62%] [G loss: 0.705220] [Time: 0.148690]\n",
            "4588-3 [D loss: 0.679786, acc.: 55.77%] [G loss: 0.742362] [Time: 0.147852]\n",
            "4588-4 [D loss: 0.707667, acc.: 44.23%] [G loss: 0.714382] [Time: 0.148207]\n",
            "4588-5 [D loss: 0.680805, acc.: 50.00%] [G loss: 0.687001] [Time: 0.146945]\n",
            "4588-6 [D loss: 0.702615, acc.: 50.00%] [G loss: 0.728307] [Time: 0.151944]\n",
            "4588-7 [D loss: 0.697055, acc.: 46.15%] [G loss: 0.694849] [Time: 0.147372]\n",
            "4588-8 [D loss: 0.698626, acc.: 46.15%] [G loss: 0.699718] [Time: 0.148135]\n",
            "4588 (test) [D loss: 0.845033, acc.: 48.08%] [G loss: 0.765723] [Time: 0.043831]\n",
            "4589-0 [D loss: 0.677651, acc.: 53.85%] [G loss: 0.715385] [Time: 0.148359]\n",
            "4589-1 [D loss: 0.707899, acc.: 34.62%] [G loss: 0.707294] [Time: 0.150206]\n",
            "4589-2 [D loss: 0.710363, acc.: 38.46%] [G loss: 0.699884] [Time: 0.150510]\n",
            "4589-3 [D loss: 0.670139, acc.: 53.85%] [G loss: 0.726248] [Time: 0.148226]\n",
            "4589-4 [D loss: 0.693451, acc.: 34.62%] [G loss: 0.708554] [Time: 0.149711]\n",
            "4589-5 [D loss: 0.682001, acc.: 40.38%] [G loss: 0.689621] [Time: 0.148073]\n",
            "4589-6 [D loss: 0.693002, acc.: 51.92%] [G loss: 0.729097] [Time: 0.148254]\n",
            "4589-7 [D loss: 0.707263, acc.: 40.38%] [G loss: 0.690805] [Time: 0.147818]\n",
            "4589-8 [D loss: 0.706722, acc.: 42.31%] [G loss: 0.702301] [Time: 0.148003]\n",
            "4589 (test) [D loss: 0.889166, acc.: 50.00%] [G loss: 0.573058] [Time: 0.044593]\n",
            "4590-0 [D loss: 0.711553, acc.: 50.00%] [G loss: 0.710190] [Time: 0.147904]\n",
            "4590-1 [D loss: 0.694055, acc.: 44.23%] [G loss: 0.696388] [Time: 0.149758]\n",
            "4590-2 [D loss: 0.723545, acc.: 46.15%] [G loss: 0.688641] [Time: 0.147202]\n",
            "4590-3 [D loss: 0.676788, acc.: 42.31%] [G loss: 0.748047] [Time: 0.148275]\n",
            "4590-4 [D loss: 0.715932, acc.: 46.15%] [G loss: 0.706746] [Time: 0.148127]\n",
            "4590-5 [D loss: 0.692881, acc.: 40.38%] [G loss: 0.729368] [Time: 0.147242]\n",
            "4590-6 [D loss: 0.702133, acc.: 44.23%] [G loss: 0.707553] [Time: 0.148053]\n",
            "4590-7 [D loss: 0.694171, acc.: 55.77%] [G loss: 0.704964] [Time: 0.150312]\n",
            "4590-8 [D loss: 0.703157, acc.: 34.62%] [G loss: 0.687063] [Time: 0.146895]\n",
            "4590 (test) [D loss: 0.874978, acc.: 48.08%] [G loss: 0.671272] [Time: 0.044658]\n",
            "4591-0 [D loss: 0.679983, acc.: 55.77%] [G loss: 0.755671] [Time: 0.150210]\n",
            "4591-1 [D loss: 0.694192, acc.: 48.08%] [G loss: 0.706386] [Time: 0.148710]\n",
            "4591-2 [D loss: 0.712320, acc.: 32.69%] [G loss: 0.690900] [Time: 0.150902]\n",
            "4591-3 [D loss: 0.680472, acc.: 48.08%] [G loss: 0.719532] [Time: 0.151017]\n",
            "4591-4 [D loss: 0.691265, acc.: 48.08%] [G loss: 0.707567] [Time: 0.153853]\n",
            "4591-5 [D loss: 0.683258, acc.: 44.23%] [G loss: 0.728981] [Time: 0.150556]\n",
            "4591-6 [D loss: 0.683061, acc.: 46.15%] [G loss: 0.730379] [Time: 0.151162]\n",
            "4591-7 [D loss: 0.702637, acc.: 44.23%] [G loss: 0.717433] [Time: 0.150561]\n",
            "4591-8 [D loss: 0.695075, acc.: 40.38%] [G loss: 0.700603] [Time: 0.148327]\n",
            "4591 (test) [D loss: 0.867744, acc.: 46.15%] [G loss: 0.810863] [Time: 0.042884]\n",
            "4592-0 [D loss: 0.680701, acc.: 55.77%] [G loss: 0.742927] [Time: 0.148415]\n",
            "4592-1 [D loss: 0.708170, acc.: 28.85%] [G loss: 0.695596] [Time: 0.150490]\n",
            "4592-2 [D loss: 0.698529, acc.: 42.31%] [G loss: 0.725710] [Time: 0.148250]\n",
            "4592-3 [D loss: 0.688270, acc.: 44.23%] [G loss: 0.746807] [Time: 0.152357]\n",
            "4592-4 [D loss: 0.708499, acc.: 46.15%] [G loss: 0.734228] [Time: 0.148914]\n",
            "4592-5 [D loss: 0.693708, acc.: 42.31%] [G loss: 0.723119] [Time: 0.147982]\n",
            "4592-6 [D loss: 0.690916, acc.: 46.15%] [G loss: 0.719772] [Time: 0.149236]\n",
            "4592-7 [D loss: 0.704610, acc.: 40.38%] [G loss: 0.719102] [Time: 0.146996]\n",
            "4592-8 [D loss: 0.692745, acc.: 40.38%] [G loss: 0.722675] [Time: 0.147988]\n",
            "4592 (test) [D loss: 0.890214, acc.: 48.08%] [G loss: 1.039067] [Time: 0.042811]\n",
            "4593-0 [D loss: 0.683029, acc.: 51.92%] [G loss: 0.785804] [Time: 0.148474]\n",
            "4593-1 [D loss: 0.703288, acc.: 40.38%] [G loss: 0.700469] [Time: 0.147506]\n",
            "4593-2 [D loss: 0.697419, acc.: 50.00%] [G loss: 0.719154] [Time: 0.146977]\n",
            "4593-3 [D loss: 0.678790, acc.: 44.23%] [G loss: 0.752975] [Time: 0.147828]\n",
            "4593-4 [D loss: 0.706717, acc.: 36.54%] [G loss: 0.714405] [Time: 0.152685]\n",
            "4593-5 [D loss: 0.703421, acc.: 32.69%] [G loss: 0.701171] [Time: 0.147872]\n",
            "4593-6 [D loss: 0.698330, acc.: 46.15%] [G loss: 0.721296] [Time: 0.147956]\n",
            "4593-7 [D loss: 0.696790, acc.: 48.08%] [G loss: 0.724068] [Time: 0.148848]\n",
            "4593-8 [D loss: 0.700754, acc.: 40.38%] [G loss: 0.709140] [Time: 0.148802]\n",
            "4593 (test) [D loss: 0.879424, acc.: 46.15%] [G loss: 1.009248] [Time: 0.043811]\n",
            "4594-0 [D loss: 0.685027, acc.: 48.08%] [G loss: 0.746280] [Time: 0.147420]\n",
            "4594-1 [D loss: 0.694559, acc.: 48.08%] [G loss: 0.700573] [Time: 0.150787]\n",
            "4594-2 [D loss: 0.707541, acc.: 32.69%] [G loss: 0.702452] [Time: 0.149151]\n",
            "4594-3 [D loss: 0.701758, acc.: 46.15%] [G loss: 0.751440] [Time: 0.148479]\n",
            "4594-4 [D loss: 0.691643, acc.: 48.08%] [G loss: 0.705414] [Time: 0.148564]\n",
            "4594-5 [D loss: 0.691973, acc.: 40.38%] [G loss: 0.720870] [Time: 0.147429]\n",
            "4594-6 [D loss: 0.691723, acc.: 50.00%] [G loss: 0.690126] [Time: 0.148061]\n",
            "4594-7 [D loss: 0.696103, acc.: 40.38%] [G loss: 0.698614] [Time: 0.147652]\n",
            "4594-8 [D loss: 0.698924, acc.: 40.38%] [G loss: 0.686643] [Time: 0.148152]\n",
            "4594 (test) [D loss: 0.858409, acc.: 48.08%] [G loss: 0.816107] [Time: 0.043149]\n",
            "4595-0 [D loss: 0.662309, acc.: 63.46%] [G loss: 0.711569] [Time: 0.147984]\n",
            "4595-1 [D loss: 0.705674, acc.: 38.46%] [G loss: 0.687236] [Time: 0.149159]\n",
            "4595-2 [D loss: 0.699874, acc.: 42.31%] [G loss: 0.695018] [Time: 0.148218]\n",
            "4595-3 [D loss: 0.666496, acc.: 51.92%] [G loss: 0.734792] [Time: 0.150494]\n",
            "4595-4 [D loss: 0.704112, acc.: 38.46%] [G loss: 0.699989] [Time: 0.151067]\n",
            "4595-5 [D loss: 0.687091, acc.: 42.31%] [G loss: 0.702699] [Time: 0.148590]\n",
            "4595-6 [D loss: 0.693095, acc.: 50.00%] [G loss: 0.704514] [Time: 0.148148]\n",
            "4595-7 [D loss: 0.705365, acc.: 34.62%] [G loss: 0.690717] [Time: 0.147824]\n",
            "4595-8 [D loss: 0.700832, acc.: 44.23%] [G loss: 0.689203] [Time: 0.154341]\n",
            "4595 (test) [D loss: 0.868400, acc.: 48.08%] [G loss: 0.711651] [Time: 0.044170]\n",
            "4596-0 [D loss: 0.679397, acc.: 42.31%] [G loss: 0.712945] [Time: 0.148738]\n",
            "4596-1 [D loss: 0.697176, acc.: 44.23%] [G loss: 0.683643] [Time: 0.147952]\n",
            "4596-2 [D loss: 0.694444, acc.: 36.54%] [G loss: 0.696943] [Time: 0.151796]\n",
            "4596-3 [D loss: 0.665031, acc.: 50.00%] [G loss: 0.735866] [Time: 0.149592]\n",
            "4596-4 [D loss: 0.696893, acc.: 40.38%] [G loss: 0.705419] [Time: 0.149038]\n",
            "4596-5 [D loss: 0.679629, acc.: 53.85%] [G loss: 0.700159] [Time: 0.148707]\n",
            "4596-6 [D loss: 0.705918, acc.: 48.08%] [G loss: 0.698964] [Time: 0.147494]\n",
            "4596-7 [D loss: 0.698340, acc.: 44.23%] [G loss: 0.694864] [Time: 0.147445]\n",
            "4596-8 [D loss: 0.721738, acc.: 48.08%] [G loss: 0.692762] [Time: 0.146542]\n",
            "4596 (test) [D loss: 0.862138, acc.: 48.08%] [G loss: 0.764984] [Time: 0.043590]\n",
            "4597-0 [D loss: 0.667274, acc.: 65.38%] [G loss: 0.733965] [Time: 0.152649]\n",
            "4597-1 [D loss: 0.696837, acc.: 50.00%] [G loss: 0.699844] [Time: 0.148043]\n",
            "4597-2 [D loss: 0.709301, acc.: 40.38%] [G loss: 0.688829] [Time: 0.148796]\n",
            "4597-3 [D loss: 0.672081, acc.: 44.23%] [G loss: 0.710975] [Time: 0.148489]\n",
            "4597-4 [D loss: 0.704259, acc.: 38.46%] [G loss: 0.694939] [Time: 0.150941]\n",
            "4597-5 [D loss: 0.679551, acc.: 50.00%] [G loss: 0.705272] [Time: 0.152621]\n",
            "4597-6 [D loss: 0.689527, acc.: 48.08%] [G loss: 0.716188] [Time: 0.151015]\n",
            "4597-7 [D loss: 0.694225, acc.: 46.15%] [G loss: 0.698784] [Time: 0.149138]\n",
            "4597-8 [D loss: 0.699501, acc.: 40.38%] [G loss: 0.695887] [Time: 0.149528]\n",
            "4597 (test) [D loss: 0.861650, acc.: 50.00%] [G loss: 0.877424] [Time: 0.044118]\n",
            "4598-0 [D loss: 0.687209, acc.: 50.00%] [G loss: 0.746238] [Time: 0.148016]\n",
            "4598-1 [D loss: 0.709070, acc.: 38.46%] [G loss: 0.705222] [Time: 0.150239]\n",
            "4598-2 [D loss: 0.711315, acc.: 28.85%] [G loss: 0.692638] [Time: 0.147038]\n",
            "4598-3 [D loss: 0.664164, acc.: 50.00%] [G loss: 0.744326] [Time: 0.148820]\n",
            "4598-4 [D loss: 0.707321, acc.: 40.38%] [G loss: 0.734038] [Time: 0.149214]\n",
            "4598-5 [D loss: 0.680103, acc.: 55.77%] [G loss: 0.717741] [Time: 0.150608]\n",
            "4598-6 [D loss: 0.697996, acc.: 50.00%] [G loss: 0.717002] [Time: 0.153108]\n",
            "4598-7 [D loss: 0.706097, acc.: 40.38%] [G loss: 0.704876] [Time: 0.155092]\n",
            "4598-8 [D loss: 0.692407, acc.: 44.23%] [G loss: 0.716909] [Time: 0.150735]\n",
            "4598 (test) [D loss: 0.886858, acc.: 50.00%] [G loss: 1.068726] [Time: 0.042891]\n",
            "4599-0 [D loss: 0.674471, acc.: 44.23%] [G loss: 0.756481] [Time: 0.149436]\n",
            "4599-1 [D loss: 0.693830, acc.: 51.92%] [G loss: 0.721022] [Time: 0.147889]\n",
            "4599-2 [D loss: 0.709082, acc.: 36.54%] [G loss: 0.710174] [Time: 0.148826]\n",
            "4599-3 [D loss: 0.665400, acc.: 51.92%] [G loss: 0.748564] [Time: 0.150304]\n",
            "4599-4 [D loss: 0.703892, acc.: 38.46%] [G loss: 0.710903] [Time: 0.155142]\n",
            "4599-5 [D loss: 0.693768, acc.: 40.38%] [G loss: 0.722995] [Time: 0.150327]\n",
            "4599-6 [D loss: 0.699667, acc.: 51.92%] [G loss: 0.712560] [Time: 0.150428]\n",
            "4599-7 [D loss: 0.704830, acc.: 48.08%] [G loss: 0.727042] [Time: 0.147804]\n",
            "4599-8 [D loss: 0.712595, acc.: 34.62%] [G loss: 0.705107] [Time: 0.148529]\n",
            "4599 (test) [D loss: 0.875700, acc.: 50.00%] [G loss: 1.034032] [Time: 0.044295]\n",
            "4600-0 [D loss: 0.693613, acc.: 50.00%] [G loss: 0.750635] [Time: 0.149570]\n",
            "4600-1 [D loss: 0.706161, acc.: 38.46%] [G loss: 0.700821] [Time: 0.150745]\n",
            "4600-2 [D loss: 0.694988, acc.: 44.23%] [G loss: 0.703088] [Time: 0.149011]\n",
            "4600-3 [D loss: 0.673757, acc.: 50.00%] [G loss: 0.757227] [Time: 0.151231]\n",
            "4600-4 [D loss: 0.706843, acc.: 38.46%] [G loss: 0.723033] [Time: 0.147369]\n",
            "4600-5 [D loss: 0.678423, acc.: 48.08%] [G loss: 0.712941] [Time: 0.150904]\n",
            "4600-6 [D loss: 0.688839, acc.: 48.08%] [G loss: 0.727846] [Time: 0.148576]\n",
            "4600-7 [D loss: 0.689284, acc.: 53.85%] [G loss: 0.707664] [Time: 0.151388]\n",
            "4600-8 [D loss: 0.700903, acc.: 42.31%] [G loss: 0.689731] [Time: 0.150989]\n",
            "4600 (test) [D loss: 0.879166, acc.: 48.08%] [G loss: 1.085466] [Time: 0.043628]\n",
            "4601-0 [D loss: 0.682516, acc.: 50.00%] [G loss: 0.749171] [Time: 0.149215]\n",
            "4601-1 [D loss: 0.698067, acc.: 40.38%] [G loss: 0.717779] [Time: 0.149122]\n",
            "4601-2 [D loss: 0.710545, acc.: 32.69%] [G loss: 0.702172] [Time: 0.165141]\n",
            "4601-3 [D loss: 0.665757, acc.: 61.54%] [G loss: 0.738237] [Time: 0.149229]\n",
            "4601-4 [D loss: 0.695883, acc.: 46.15%] [G loss: 0.705336] [Time: 0.148775]\n",
            "4601-5 [D loss: 0.683062, acc.: 42.31%] [G loss: 0.709158] [Time: 0.149818]\n",
            "4601-6 [D loss: 0.700201, acc.: 38.46%] [G loss: 0.719692] [Time: 0.148130]\n",
            "4601-7 [D loss: 0.687994, acc.: 48.08%] [G loss: 0.712396] [Time: 0.147362]\n",
            "4601-8 [D loss: 0.689969, acc.: 38.46%] [G loss: 0.697144] [Time: 0.147453]\n",
            "4601 (test) [D loss: 0.880780, acc.: 48.08%] [G loss: 0.914038] [Time: 0.044333]\n",
            "4602-0 [D loss: 0.685845, acc.: 46.15%] [G loss: 0.750049] [Time: 0.151902]\n",
            "4602-1 [D loss: 0.703536, acc.: 42.31%] [G loss: 0.700899] [Time: 0.147766]\n",
            "4602-2 [D loss: 0.706146, acc.: 40.38%] [G loss: 0.676916] [Time: 0.147512]\n",
            "4602-3 [D loss: 0.660194, acc.: 55.77%] [G loss: 0.733573] [Time: 0.150722]\n",
            "4602-4 [D loss: 0.710072, acc.: 38.46%] [G loss: 0.706045] [Time: 0.148452]\n",
            "4602-5 [D loss: 0.683193, acc.: 42.31%] [G loss: 0.706929] [Time: 0.147916]\n",
            "4602-6 [D loss: 0.689827, acc.: 48.08%] [G loss: 0.717775] [Time: 0.150134]\n",
            "4602-7 [D loss: 0.698740, acc.: 44.23%] [G loss: 0.702771] [Time: 0.148696]\n",
            "4602-8 [D loss: 0.716888, acc.: 38.46%] [G loss: 0.709823] [Time: 0.156377]\n",
            "4602 (test) [D loss: 0.874133, acc.: 51.92%] [G loss: 1.010551] [Time: 0.044568]\n",
            "4603-0 [D loss: 0.676725, acc.: 48.08%] [G loss: 0.759482] [Time: 0.150572]\n",
            "4603-1 [D loss: 0.702106, acc.: 48.08%] [G loss: 0.708432] [Time: 0.151128]\n",
            "4603-2 [D loss: 0.709306, acc.: 32.69%] [G loss: 0.686200] [Time: 0.150461]\n",
            "4603-3 [D loss: 0.678724, acc.: 42.31%] [G loss: 0.751320] [Time: 0.150324]\n",
            "4603-4 [D loss: 0.701400, acc.: 42.31%] [G loss: 0.717638] [Time: 0.148928]\n",
            "4603-5 [D loss: 0.666164, acc.: 53.85%] [G loss: 0.724571] [Time: 0.147771]\n",
            "4603-6 [D loss: 0.696630, acc.: 51.92%] [G loss: 0.734004] [Time: 0.147698]\n",
            "4603-7 [D loss: 0.687042, acc.: 57.69%] [G loss: 0.716113] [Time: 0.149678]\n",
            "4603-8 [D loss: 0.710464, acc.: 48.08%] [G loss: 0.694204] [Time: 0.148165]\n",
            "4603 (test) [D loss: 0.951988, acc.: 50.00%] [G loss: 1.470010] [Time: 0.044110]\n",
            "4604-0 [D loss: 0.699597, acc.: 40.38%] [G loss: 0.745967] [Time: 0.150228]\n",
            "4604-1 [D loss: 0.711149, acc.: 32.69%] [G loss: 0.715120] [Time: 0.148396]\n",
            "4604-2 [D loss: 0.712221, acc.: 34.62%] [G loss: 0.697278] [Time: 0.149129]\n",
            "4604-3 [D loss: 0.669866, acc.: 51.92%] [G loss: 0.748099] [Time: 0.147679]\n",
            "4604-4 [D loss: 0.697692, acc.: 50.00%] [G loss: 0.735410] [Time: 0.147191]\n",
            "4604-5 [D loss: 0.695791, acc.: 34.62%] [G loss: 0.732505] [Time: 0.151716]\n",
            "4604-6 [D loss: 0.698006, acc.: 50.00%] [G loss: 0.718588] [Time: 0.150461]\n",
            "4604-7 [D loss: 0.704406, acc.: 51.92%] [G loss: 0.697929] [Time: 0.156203]\n",
            "4604-8 [D loss: 0.705756, acc.: 36.54%] [G loss: 0.703168] [Time: 0.151017]\n",
            "4604 (test) [D loss: 0.961311, acc.: 50.00%] [G loss: 1.449875] [Time: 0.044630]\n",
            "4605-0 [D loss: 0.674426, acc.: 48.08%] [G loss: 0.764554] [Time: 0.147455]\n",
            "4605-1 [D loss: 0.713455, acc.: 38.46%] [G loss: 0.682426] [Time: 0.152754]\n",
            "4605-2 [D loss: 0.696642, acc.: 38.46%] [G loss: 0.685841] [Time: 0.151723]\n",
            "4605-3 [D loss: 0.684101, acc.: 44.23%] [G loss: 0.762194] [Time: 0.150691]\n",
            "4605-4 [D loss: 0.699477, acc.: 44.23%] [G loss: 0.723398] [Time: 0.152630]\n",
            "4605-5 [D loss: 0.686682, acc.: 34.62%] [G loss: 0.719532] [Time: 0.151496]\n",
            "4605-6 [D loss: 0.696571, acc.: 46.15%] [G loss: 0.700555] [Time: 0.150358]\n",
            "4605-7 [D loss: 0.695776, acc.: 32.69%] [G loss: 0.705044] [Time: 0.152210]\n",
            "4605-8 [D loss: 0.701465, acc.: 42.31%] [G loss: 0.690152] [Time: 0.151668]\n",
            "4605 (test) [D loss: 0.900312, acc.: 51.92%] [G loss: 1.203685] [Time: 0.045566]\n",
            "4606-0 [D loss: 0.690527, acc.: 46.15%] [G loss: 0.735187] [Time: 0.152173]\n",
            "4606-1 [D loss: 0.701100, acc.: 40.38%] [G loss: 0.695203] [Time: 0.147986]\n",
            "4606-2 [D loss: 0.703251, acc.: 40.38%] [G loss: 0.690302] [Time: 0.147568]\n",
            "4606-3 [D loss: 0.669920, acc.: 50.00%] [G loss: 0.724016] [Time: 0.147124]\n",
            "4606-4 [D loss: 0.692509, acc.: 50.00%] [G loss: 0.694756] [Time: 0.147486]\n",
            "4606-5 [D loss: 0.704059, acc.: 40.38%] [G loss: 0.677486] [Time: 0.148318]\n",
            "4606-6 [D loss: 0.697910, acc.: 42.31%] [G loss: 0.699163] [Time: 0.148185]\n",
            "4606-7 [D loss: 0.708681, acc.: 34.62%] [G loss: 0.706176] [Time: 0.149214]\n",
            "4606-8 [D loss: 0.713702, acc.: 46.15%] [G loss: 0.707878] [Time: 0.148042]\n",
            "4606 (test) [D loss: 0.873229, acc.: 50.00%] [G loss: 0.991813] [Time: 0.044290]\n",
            "4607-0 [D loss: 0.668600, acc.: 55.77%] [G loss: 0.752180] [Time: 0.147918]\n",
            "4607-1 [D loss: 0.704280, acc.: 44.23%] [G loss: 0.688789] [Time: 0.149396]\n",
            "4607-2 [D loss: 0.700662, acc.: 42.31%] [G loss: 0.685798] [Time: 0.147114]\n",
            "4607-3 [D loss: 0.673786, acc.: 51.92%] [G loss: 0.745810] [Time: 0.151677]\n",
            "4607-4 [D loss: 0.694788, acc.: 51.92%] [G loss: 0.709194] [Time: 0.151019]\n",
            "4607-5 [D loss: 0.674992, acc.: 53.85%] [G loss: 0.727672] [Time: 0.148266]\n",
            "4607-6 [D loss: 0.691006, acc.: 53.85%] [G loss: 0.724500] [Time: 0.149536]\n",
            "4607-7 [D loss: 0.707062, acc.: 34.62%] [G loss: 0.712906] [Time: 0.148440]\n",
            "4607-8 [D loss: 0.692308, acc.: 44.23%] [G loss: 0.693274] [Time: 0.152174]\n",
            "4607 (test) [D loss: 0.908301, acc.: 51.92%] [G loss: 1.197674] [Time: 0.047053]\n",
            "4608-0 [D loss: 0.686191, acc.: 50.00%] [G loss: 0.784918] [Time: 0.147758]\n",
            "4608-1 [D loss: 0.700756, acc.: 44.23%] [G loss: 0.683510] [Time: 0.149419]\n",
            "4608-2 [D loss: 0.699886, acc.: 36.54%] [G loss: 0.697060] [Time: 0.149073]\n",
            "4608-3 [D loss: 0.664263, acc.: 51.92%] [G loss: 0.746952] [Time: 0.152388]\n",
            "4608-4 [D loss: 0.702161, acc.: 50.00%] [G loss: 0.683597] [Time: 0.148189]\n",
            "4608-5 [D loss: 0.689172, acc.: 36.54%] [G loss: 0.726884] [Time: 0.150079]\n",
            "4608-6 [D loss: 0.698565, acc.: 40.38%] [G loss: 0.712542] [Time: 0.149634]\n",
            "4608-7 [D loss: 0.701061, acc.: 42.31%] [G loss: 0.697111] [Time: 0.151574]\n",
            "4608-8 [D loss: 0.696571, acc.: 48.08%] [G loss: 0.693430] [Time: 0.151951]\n",
            "4608 (test) [D loss: 0.883408, acc.: 50.00%] [G loss: 0.875661] [Time: 0.044621]\n",
            "4609-0 [D loss: 0.682874, acc.: 46.15%] [G loss: 0.745920] [Time: 0.147175]\n",
            "4609-1 [D loss: 0.707180, acc.: 46.15%] [G loss: 0.692314] [Time: 0.147561]\n",
            "4609-2 [D loss: 0.703705, acc.: 38.46%] [G loss: 0.680300] [Time: 0.148266]\n",
            "4609-3 [D loss: 0.673056, acc.: 63.46%] [G loss: 0.731381] [Time: 0.148212]\n",
            "4609-4 [D loss: 0.698623, acc.: 44.23%] [G loss: 0.698927] [Time: 0.151004]\n",
            "4609-5 [D loss: 0.687802, acc.: 40.38%] [G loss: 0.711372] [Time: 0.149043]\n",
            "4609-6 [D loss: 0.697554, acc.: 40.38%] [G loss: 0.724518] [Time: 0.148992]\n",
            "4609-7 [D loss: 0.694213, acc.: 44.23%] [G loss: 0.719281] [Time: 0.146517]\n",
            "4609-8 [D loss: 0.701946, acc.: 51.92%] [G loss: 0.681166] [Time: 0.152725]\n",
            "4609 (test) [D loss: 0.861342, acc.: 50.00%] [G loss: 0.949194] [Time: 0.045156]\n",
            "4610-0 [D loss: 0.691765, acc.: 34.62%] [G loss: 0.746636] [Time: 0.151752]\n",
            "4610-1 [D loss: 0.707414, acc.: 36.54%] [G loss: 0.703367] [Time: 0.148365]\n",
            "4610-2 [D loss: 0.700431, acc.: 40.38%] [G loss: 0.701977] [Time: 0.150344]\n",
            "4610-3 [D loss: 0.672391, acc.: 55.77%] [G loss: 0.737301] [Time: 0.148154]\n",
            "4610-4 [D loss: 0.698940, acc.: 42.31%] [G loss: 0.696753] [Time: 0.148359]\n",
            "4610-5 [D loss: 0.686012, acc.: 40.38%] [G loss: 0.714152] [Time: 0.146742]\n",
            "4610-6 [D loss: 0.696709, acc.: 44.23%] [G loss: 0.702856] [Time: 0.147755]\n",
            "4610-7 [D loss: 0.712623, acc.: 48.08%] [G loss: 0.701251] [Time: 0.149340]\n",
            "4610-8 [D loss: 0.720592, acc.: 42.31%] [G loss: 0.671723] [Time: 0.147782]\n",
            "4610 (test) [D loss: 0.881503, acc.: 50.00%] [G loss: 0.682328] [Time: 0.044906]\n",
            "4611-0 [D loss: 0.688196, acc.: 44.23%] [G loss: 0.723183] [Time: 0.149570]\n",
            "4611-1 [D loss: 0.697161, acc.: 42.31%] [G loss: 0.701784] [Time: 0.148270]\n",
            "4611-2 [D loss: 0.706147, acc.: 34.62%] [G loss: 0.707887] [Time: 0.150712]\n",
            "4611-3 [D loss: 0.666077, acc.: 55.77%] [G loss: 0.734717] [Time: 0.151473]\n",
            "4611-4 [D loss: 0.701744, acc.: 38.46%] [G loss: 0.697740] [Time: 0.150309]\n",
            "4611-5 [D loss: 0.683401, acc.: 36.54%] [G loss: 0.697285] [Time: 0.148615]\n",
            "4611-6 [D loss: 0.686703, acc.: 42.31%] [G loss: 0.707994] [Time: 0.150896]\n",
            "4611-7 [D loss: 0.708926, acc.: 51.92%] [G loss: 0.695859] [Time: 0.147954]\n",
            "4611-8 [D loss: 0.705985, acc.: 42.31%] [G loss: 0.707837] [Time: 0.148512]\n",
            "4611 (test) [D loss: 0.873413, acc.: 46.15%] [G loss: 0.908266] [Time: 0.046090]\n",
            "4612-0 [D loss: 0.664947, acc.: 46.15%] [G loss: 0.750665] [Time: 0.150798]\n",
            "4612-1 [D loss: 0.701049, acc.: 44.23%] [G loss: 0.703496] [Time: 0.148245]\n",
            "4612-2 [D loss: 0.720432, acc.: 40.38%] [G loss: 0.721018] [Time: 0.148559]\n",
            "4612-3 [D loss: 0.670227, acc.: 50.00%] [G loss: 0.759277] [Time: 0.149001]\n",
            "4612-4 [D loss: 0.705572, acc.: 32.69%] [G loss: 0.720964] [Time: 0.148527]\n",
            "4612-5 [D loss: 0.678287, acc.: 36.54%] [G loss: 0.708447] [Time: 0.150923]\n",
            "4612-6 [D loss: 0.702185, acc.: 44.23%] [G loss: 0.732172] [Time: 0.147817]\n",
            "4612-7 [D loss: 0.691667, acc.: 44.23%] [G loss: 0.712154] [Time: 0.149779]\n",
            "4612-8 [D loss: 0.697871, acc.: 53.85%] [G loss: 0.700450] [Time: 0.148015]\n",
            "4612 (test) [D loss: 0.891737, acc.: 48.08%] [G loss: 1.128875] [Time: 0.044021]\n",
            "4613-0 [D loss: 0.682051, acc.: 51.92%] [G loss: 0.751033] [Time: 0.153691]\n",
            "4613-1 [D loss: 0.702305, acc.: 44.23%] [G loss: 0.700891] [Time: 0.147709]\n",
            "4613-2 [D loss: 0.696572, acc.: 40.38%] [G loss: 0.679379] [Time: 0.148240]\n",
            "4613-3 [D loss: 0.674721, acc.: 50.00%] [G loss: 0.738900] [Time: 0.149788]\n",
            "4613-4 [D loss: 0.699739, acc.: 46.15%] [G loss: 0.724309] [Time: 0.147672]\n",
            "4613-5 [D loss: 0.682669, acc.: 36.54%] [G loss: 0.719661] [Time: 0.150894]\n",
            "4613-6 [D loss: 0.685439, acc.: 50.00%] [G loss: 0.710692] [Time: 0.150468]\n",
            "4613-7 [D loss: 0.698581, acc.: 51.92%] [G loss: 0.692340] [Time: 0.150245]\n",
            "4613-8 [D loss: 0.692850, acc.: 38.46%] [G loss: 0.700351] [Time: 0.147877]\n",
            "4613 (test) [D loss: 0.904860, acc.: 48.08%] [G loss: 1.133745] [Time: 0.043897]\n",
            "4614-0 [D loss: 0.685606, acc.: 40.38%] [G loss: 0.748031] [Time: 0.149577]\n",
            "4614-1 [D loss: 0.698924, acc.: 51.92%] [G loss: 0.692475] [Time: 0.150369]\n",
            "4614-2 [D loss: 0.704221, acc.: 36.54%] [G loss: 0.688641] [Time: 0.149844]\n",
            "4614-3 [D loss: 0.665961, acc.: 44.23%] [G loss: 0.726117] [Time: 0.150910]\n",
            "4614-4 [D loss: 0.713816, acc.: 38.46%] [G loss: 0.719248] [Time: 0.147395]\n",
            "4614-5 [D loss: 0.679284, acc.: 38.46%] [G loss: 0.698304] [Time: 0.147825]\n",
            "4614-6 [D loss: 0.689847, acc.: 40.38%] [G loss: 0.722423] [Time: 0.149436]\n",
            "4614-7 [D loss: 0.706484, acc.: 38.46%] [G loss: 0.717254] [Time: 0.148484]\n",
            "4614-8 [D loss: 0.682167, acc.: 40.38%] [G loss: 0.715460] [Time: 0.148197]\n",
            "4614 (test) [D loss: 0.882862, acc.: 48.08%] [G loss: 1.049935] [Time: 0.044035]\n",
            "4615-0 [D loss: 0.691409, acc.: 42.31%] [G loss: 0.713016] [Time: 0.147932]\n",
            "4615-1 [D loss: 0.710887, acc.: 38.46%] [G loss: 0.685275] [Time: 0.148852]\n",
            "4615-2 [D loss: 0.709446, acc.: 34.62%] [G loss: 0.679721] [Time: 0.149321]\n",
            "4615-3 [D loss: 0.672848, acc.: 50.00%] [G loss: 0.737414] [Time: 0.147970]\n",
            "4615-4 [D loss: 0.702173, acc.: 42.31%] [G loss: 0.708069] [Time: 0.149288]\n",
            "4615-5 [D loss: 0.671113, acc.: 53.85%] [G loss: 0.707582] [Time: 0.148287]\n",
            "4615-6 [D loss: 0.685213, acc.: 61.54%] [G loss: 0.692946] [Time: 0.147758]\n",
            "4615-7 [D loss: 0.704344, acc.: 44.23%] [G loss: 0.708868] [Time: 0.149178]\n",
            "4615-8 [D loss: 0.698900, acc.: 48.08%] [G loss: 0.706719] [Time: 0.150288]\n",
            "4615 (test) [D loss: 0.883633, acc.: 46.15%] [G loss: 0.895739] [Time: 0.045073]\n",
            "4616-0 [D loss: 0.679469, acc.: 53.85%] [G loss: 0.703390] [Time: 0.148483]\n",
            "4616-1 [D loss: 0.702709, acc.: 38.46%] [G loss: 0.678991] [Time: 0.146554]\n",
            "4616-2 [D loss: 0.703336, acc.: 42.31%] [G loss: 0.693830] [Time: 0.147990]\n",
            "4616-3 [D loss: 0.689315, acc.: 51.92%] [G loss: 0.716639] [Time: 0.150284]\n",
            "4616-4 [D loss: 0.714377, acc.: 40.38%] [G loss: 0.700542] [Time: 0.150850]\n",
            "4616-5 [D loss: 0.690584, acc.: 36.54%] [G loss: 0.714390] [Time: 0.150562]\n",
            "4616-6 [D loss: 0.707246, acc.: 44.23%] [G loss: 0.721109] [Time: 0.152525]\n",
            "4616-7 [D loss: 0.685129, acc.: 55.77%] [G loss: 0.721048] [Time: 0.152243]\n",
            "4616-8 [D loss: 0.701191, acc.: 51.92%] [G loss: 0.690868] [Time: 0.150714]\n",
            "4616 (test) [D loss: 0.865147, acc.: 46.15%] [G loss: 0.838981] [Time: 0.044786]\n",
            "4617-0 [D loss: 0.683452, acc.: 46.15%] [G loss: 0.750032] [Time: 0.151994]\n",
            "4617-1 [D loss: 0.695196, acc.: 46.15%] [G loss: 0.702984] [Time: 0.147897]\n",
            "4617-2 [D loss: 0.690669, acc.: 51.92%] [G loss: 0.679919] [Time: 0.149505]\n",
            "4617-3 [D loss: 0.679868, acc.: 40.38%] [G loss: 0.717225] [Time: 0.150737]\n",
            "4617-4 [D loss: 0.702650, acc.: 34.62%] [G loss: 0.701480] [Time: 0.148696]\n",
            "4617-5 [D loss: 0.679583, acc.: 55.77%] [G loss: 0.719168] [Time: 0.151080]\n",
            "4617-6 [D loss: 0.692596, acc.: 50.00%] [G loss: 0.707662] [Time: 0.147994]\n",
            "4617-7 [D loss: 0.713758, acc.: 42.31%] [G loss: 0.692211] [Time: 0.149437]\n",
            "4617-8 [D loss: 0.699147, acc.: 36.54%] [G loss: 0.696058] [Time: 0.151890]\n",
            "4617 (test) [D loss: 0.880113, acc.: 48.08%] [G loss: 0.802692] [Time: 0.045046]\n",
            "4618-0 [D loss: 0.690914, acc.: 46.15%] [G loss: 0.743481] [Time: 0.148897]\n",
            "4618-1 [D loss: 0.701479, acc.: 48.08%] [G loss: 0.701789] [Time: 0.149561]\n",
            "4618-2 [D loss: 0.717667, acc.: 38.46%] [G loss: 0.707495] [Time: 0.148718]\n",
            "4618-3 [D loss: 0.672474, acc.: 53.85%] [G loss: 0.766775] [Time: 0.149498]\n",
            "4618-4 [D loss: 0.694615, acc.: 46.15%] [G loss: 0.697519] [Time: 0.146847]\n",
            "4618-5 [D loss: 0.677241, acc.: 50.00%] [G loss: 0.716013] [Time: 0.148103]\n",
            "4618-6 [D loss: 0.692891, acc.: 57.69%] [G loss: 0.709586] [Time: 0.148425]\n",
            "4618-7 [D loss: 0.697995, acc.: 50.00%] [G loss: 0.711259] [Time: 0.147975]\n",
            "4618-8 [D loss: 0.705038, acc.: 46.15%] [G loss: 0.687388] [Time: 0.146588]\n",
            "4618 (test) [D loss: 0.885123, acc.: 50.00%] [G loss: 1.019844] [Time: 0.043288]\n",
            "4619-0 [D loss: 0.687816, acc.: 40.38%] [G loss: 0.753026] [Time: 0.147952]\n",
            "4619-1 [D loss: 0.714932, acc.: 42.31%] [G loss: 0.691056] [Time: 0.147719]\n",
            "4619-2 [D loss: 0.706570, acc.: 40.38%] [G loss: 0.695948] [Time: 0.148876]\n",
            "4619-3 [D loss: 0.673924, acc.: 50.00%] [G loss: 0.721897] [Time: 0.147387]\n",
            "4619-4 [D loss: 0.706922, acc.: 50.00%] [G loss: 0.699779] [Time: 0.150648]\n",
            "4619-5 [D loss: 0.681279, acc.: 46.15%] [G loss: 0.702679] [Time: 0.148390]\n",
            "4619-6 [D loss: 0.707403, acc.: 40.38%] [G loss: 0.720795] [Time: 0.147273]\n",
            "4619-7 [D loss: 0.700767, acc.: 38.46%] [G loss: 0.694465] [Time: 0.147421]\n",
            "4619-8 [D loss: 0.695178, acc.: 36.54%] [G loss: 0.689029] [Time: 0.149430]\n",
            "4619 (test) [D loss: 0.886352, acc.: 48.08%] [G loss: 0.830291] [Time: 0.043815]\n",
            "4620-0 [D loss: 0.661186, acc.: 53.85%] [G loss: 0.731886] [Time: 0.148622]\n",
            "4620-1 [D loss: 0.703250, acc.: 44.23%] [G loss: 0.688035] [Time: 0.150862]\n",
            "4620-2 [D loss: 0.697477, acc.: 46.15%] [G loss: 0.692534] [Time: 0.149415]\n",
            "4620-3 [D loss: 0.668736, acc.: 48.08%] [G loss: 0.720409] [Time: 0.150282]\n",
            "4620-4 [D loss: 0.731736, acc.: 42.31%] [G loss: 0.678355] [Time: 0.150014]\n",
            "4620-5 [D loss: 0.690715, acc.: 38.46%] [G loss: 0.703417] [Time: 0.150902]\n",
            "4620-6 [D loss: 0.682628, acc.: 51.92%] [G loss: 0.709787] [Time: 0.148188]\n",
            "4620-7 [D loss: 0.701097, acc.: 50.00%] [G loss: 0.705120] [Time: 0.149114]\n",
            "4620-8 [D loss: 0.696117, acc.: 46.15%] [G loss: 0.707386] [Time: 0.149410]\n",
            "4620 (test) [D loss: 0.886779, acc.: 51.92%] [G loss: 0.734336] [Time: 0.044045]\n",
            "4621-0 [D loss: 0.679087, acc.: 46.15%] [G loss: 0.730863] [Time: 0.148979]\n",
            "4621-1 [D loss: 0.694873, acc.: 42.31%] [G loss: 0.697062] [Time: 0.149607]\n",
            "4621-2 [D loss: 0.696900, acc.: 48.08%] [G loss: 0.687078] [Time: 0.151873]\n",
            "4621-3 [D loss: 0.681984, acc.: 67.31%] [G loss: 0.739793] [Time: 0.149766]\n",
            "4621-4 [D loss: 0.708083, acc.: 40.38%] [G loss: 0.711866] [Time: 0.148339]\n",
            "4621-5 [D loss: 0.686009, acc.: 40.38%] [G loss: 0.720838] [Time: 0.147623]\n",
            "4621-6 [D loss: 0.698268, acc.: 40.38%] [G loss: 0.715208] [Time: 0.147594]\n",
            "4621-7 [D loss: 0.703155, acc.: 38.46%] [G loss: 0.703715] [Time: 0.148194]\n",
            "4621-8 [D loss: 0.711236, acc.: 38.46%] [G loss: 0.702506] [Time: 0.148595]\n",
            "4621 (test) [D loss: 0.886290, acc.: 46.15%] [G loss: 0.903244] [Time: 0.044312]\n",
            "4622-0 [D loss: 0.670460, acc.: 48.08%] [G loss: 0.741643] [Time: 0.148788]\n",
            "4622-1 [D loss: 0.710763, acc.: 40.38%] [G loss: 0.692980] [Time: 0.153288]\n",
            "4622-2 [D loss: 0.712668, acc.: 28.85%] [G loss: 0.700353] [Time: 0.148102]\n",
            "4622-3 [D loss: 0.679740, acc.: 40.38%] [G loss: 0.724725] [Time: 0.150054]\n",
            "4622-4 [D loss: 0.709270, acc.: 40.38%] [G loss: 0.697244] [Time: 0.149002]\n",
            "4622-5 [D loss: 0.679840, acc.: 46.15%] [G loss: 0.709476] [Time: 0.149721]\n",
            "4622-6 [D loss: 0.696466, acc.: 55.77%] [G loss: 0.693371] [Time: 0.152609]\n",
            "4622-7 [D loss: 0.703037, acc.: 48.08%] [G loss: 0.709949] [Time: 0.149328]\n",
            "4622-8 [D loss: 0.691586, acc.: 40.38%] [G loss: 0.691307] [Time: 0.150191]\n",
            "4622 (test) [D loss: 0.895423, acc.: 50.00%] [G loss: 0.627797] [Time: 0.044415]\n",
            "4623-0 [D loss: 0.669662, acc.: 53.85%] [G loss: 0.722280] [Time: 0.152509]\n",
            "4623-1 [D loss: 0.700994, acc.: 42.31%] [G loss: 0.689119] [Time: 0.150608]\n",
            "4623-2 [D loss: 0.698466, acc.: 48.08%] [G loss: 0.691977] [Time: 0.150427]\n",
            "4623-3 [D loss: 0.676578, acc.: 50.00%] [G loss: 0.720517] [Time: 0.149476]\n",
            "4623-4 [D loss: 0.703053, acc.: 44.23%] [G loss: 0.693307] [Time: 0.152255]\n",
            "4623-5 [D loss: 0.692145, acc.: 46.15%] [G loss: 0.698058] [Time: 0.150496]\n",
            "4623-6 [D loss: 0.683853, acc.: 51.92%] [G loss: 0.711176] [Time: 0.148263]\n",
            "4623-7 [D loss: 0.695780, acc.: 42.31%] [G loss: 0.701945] [Time: 0.149695]\n",
            "4623-8 [D loss: 0.697111, acc.: 34.62%] [G loss: 0.686711] [Time: 0.154196]\n",
            "4623 (test) [D loss: 0.865915, acc.: 46.15%] [G loss: 0.811598] [Time: 0.045130]\n",
            "4624-0 [D loss: 0.669539, acc.: 59.62%] [G loss: 0.730964] [Time: 0.150722]\n",
            "4624-1 [D loss: 0.698398, acc.: 44.23%] [G loss: 0.703244] [Time: 0.150512]\n",
            "4624-2 [D loss: 0.693887, acc.: 50.00%] [G loss: 0.687762] [Time: 0.150391]\n",
            "4624-3 [D loss: 0.664237, acc.: 53.85%] [G loss: 0.723858] [Time: 0.149733]\n",
            "4624-4 [D loss: 0.713387, acc.: 44.23%] [G loss: 0.689428] [Time: 0.147799]\n",
            "4624-5 [D loss: 0.684847, acc.: 48.08%] [G loss: 0.700908] [Time: 0.151881]\n",
            "4624-6 [D loss: 0.701269, acc.: 34.62%] [G loss: 0.719458] [Time: 0.149119]\n",
            "4624-7 [D loss: 0.698018, acc.: 40.38%] [G loss: 0.689309] [Time: 0.150658]\n",
            "4624-8 [D loss: 0.697580, acc.: 44.23%] [G loss: 0.687430] [Time: 0.147923]\n",
            "4624 (test) [D loss: 0.873595, acc.: 46.15%] [G loss: 0.826318] [Time: 0.043652]\n",
            "4625-0 [D loss: 0.671774, acc.: 46.15%] [G loss: 0.754602] [Time: 0.148885]\n",
            "4625-1 [D loss: 0.696634, acc.: 51.92%] [G loss: 0.695696] [Time: 0.147383]\n",
            "4625-2 [D loss: 0.708753, acc.: 36.54%] [G loss: 0.706446] [Time: 0.147037]\n",
            "4625-3 [D loss: 0.679429, acc.: 50.00%] [G loss: 0.744542] [Time: 0.147452]\n",
            "4625-4 [D loss: 0.698313, acc.: 48.08%] [G loss: 0.713954] [Time: 0.147637]\n",
            "4625-5 [D loss: 0.691089, acc.: 38.46%] [G loss: 0.731997] [Time: 0.148324]\n",
            "4625-6 [D loss: 0.689857, acc.: 36.54%] [G loss: 0.731557] [Time: 0.149796]\n",
            "4625-7 [D loss: 0.698497, acc.: 46.15%] [G loss: 0.720750] [Time: 0.149132]\n",
            "4625-8 [D loss: 0.713235, acc.: 36.54%] [G loss: 0.715167] [Time: 0.149492]\n",
            "4625 (test) [D loss: 0.882786, acc.: 48.08%] [G loss: 1.023327] [Time: 0.043693]\n",
            "4626-0 [D loss: 0.674382, acc.: 46.15%] [G loss: 0.747795] [Time: 0.148022]\n",
            "4626-1 [D loss: 0.697624, acc.: 46.15%] [G loss: 0.699571] [Time: 0.148738]\n",
            "4626-2 [D loss: 0.699270, acc.: 30.77%] [G loss: 0.712302] [Time: 0.148453]\n",
            "4626-3 [D loss: 0.677087, acc.: 44.23%] [G loss: 0.740465] [Time: 0.148717]\n",
            "4626-4 [D loss: 0.705707, acc.: 53.85%] [G loss: 0.713338] [Time: 0.148692]\n",
            "4626-5 [D loss: 0.684924, acc.: 40.38%] [G loss: 0.725977] [Time: 0.148883]\n",
            "4626-6 [D loss: 0.698071, acc.: 44.23%] [G loss: 0.730728] [Time: 0.150957]\n",
            "4626-7 [D loss: 0.701433, acc.: 32.69%] [G loss: 0.707893] [Time: 0.148779]\n",
            "4626-8 [D loss: 0.695872, acc.: 42.31%] [G loss: 0.694899] [Time: 0.149776]\n",
            "4626 (test) [D loss: 0.910460, acc.: 46.15%] [G loss: 0.762723] [Time: 0.045017]\n",
            "4627-0 [D loss: 0.672405, acc.: 48.08%] [G loss: 0.759180] [Time: 0.150656]\n",
            "4627-1 [D loss: 0.702753, acc.: 50.00%] [G loss: 0.726070] [Time: 0.150983]\n",
            "4627-2 [D loss: 0.703461, acc.: 32.69%] [G loss: 0.711874] [Time: 0.148270]\n",
            "4627-3 [D loss: 0.673921, acc.: 50.00%] [G loss: 0.725320] [Time: 0.150487]\n",
            "4627-4 [D loss: 0.705147, acc.: 42.31%] [G loss: 0.707887] [Time: 0.147081]\n",
            "4627-5 [D loss: 0.688762, acc.: 48.08%] [G loss: 0.703809] [Time: 0.149879]\n",
            "4627-6 [D loss: 0.693650, acc.: 40.38%] [G loss: 0.716274] [Time: 0.147912]\n",
            "4627-7 [D loss: 0.710983, acc.: 42.31%] [G loss: 0.713256] [Time: 0.148812]\n",
            "4627-8 [D loss: 0.712662, acc.: 38.46%] [G loss: 0.699598] [Time: 0.148492]\n",
            "4627 (test) [D loss: 0.888654, acc.: 50.00%] [G loss: 0.846935] [Time: 0.043733]\n",
            "4628-0 [D loss: 0.675549, acc.: 53.85%] [G loss: 0.719056] [Time: 0.147394]\n",
            "4628-1 [D loss: 0.708517, acc.: 32.69%] [G loss: 0.694537] [Time: 0.147171]\n",
            "4628-2 [D loss: 0.709013, acc.: 26.92%] [G loss: 0.694520] [Time: 0.149775]\n",
            "4628-3 [D loss: 0.658425, acc.: 59.62%] [G loss: 0.727348] [Time: 0.148195]\n",
            "4628-4 [D loss: 0.704445, acc.: 40.38%] [G loss: 0.700544] [Time: 0.152556]\n",
            "4628-5 [D loss: 0.674100, acc.: 48.08%] [G loss: 0.712419] [Time: 0.151323]\n",
            "4628-6 [D loss: 0.687876, acc.: 57.69%] [G loss: 0.695016] [Time: 0.152054]\n",
            "4628-7 [D loss: 0.703745, acc.: 38.46%] [G loss: 0.699335] [Time: 0.149889]\n",
            "4628-8 [D loss: 0.702785, acc.: 44.23%] [G loss: 0.697024] [Time: 0.151029]\n",
            "4628 (test) [D loss: 0.894958, acc.: 51.92%] [G loss: 0.669600] [Time: 0.044377]\n",
            "4629-0 [D loss: 0.684180, acc.: 42.31%] [G loss: 0.735767] [Time: 0.147492]\n",
            "4629-1 [D loss: 0.707137, acc.: 38.46%] [G loss: 0.677357] [Time: 0.148583]\n",
            "4629-2 [D loss: 0.704482, acc.: 36.54%] [G loss: 0.686441] [Time: 0.149573]\n",
            "4629-3 [D loss: 0.676038, acc.: 46.15%] [G loss: 0.730842] [Time: 0.150192]\n",
            "4629-4 [D loss: 0.714552, acc.: 32.69%] [G loss: 0.710791] [Time: 0.150445]\n",
            "4629-5 [D loss: 0.692861, acc.: 46.15%] [G loss: 0.691194] [Time: 0.149423]\n",
            "4629-6 [D loss: 0.720344, acc.: 40.38%] [G loss: 0.710970] [Time: 0.148551]\n",
            "4629-7 [D loss: 0.694451, acc.: 38.46%] [G loss: 0.698527] [Time: 0.148390]\n",
            "4629-8 [D loss: 0.708551, acc.: 38.46%] [G loss: 0.700200] [Time: 0.148913]\n",
            "4629 (test) [D loss: 0.919601, acc.: 50.00%] [G loss: 0.644822] [Time: 0.044451]\n",
            "4630-0 [D loss: 0.682156, acc.: 40.38%] [G loss: 0.750031] [Time: 0.147999]\n",
            "4630-1 [D loss: 0.708169, acc.: 38.46%] [G loss: 0.691066] [Time: 0.147269]\n",
            "4630-2 [D loss: 0.710955, acc.: 42.31%] [G loss: 0.691641] [Time: 0.147360]\n",
            "4630-3 [D loss: 0.664822, acc.: 57.69%] [G loss: 0.748531] [Time: 0.149082]\n",
            "4630-4 [D loss: 0.711657, acc.: 30.77%] [G loss: 0.714212] [Time: 0.148611]\n",
            "4630-5 [D loss: 0.683847, acc.: 48.08%] [G loss: 0.725928] [Time: 0.150090]\n",
            "4630-6 [D loss: 0.689358, acc.: 48.08%] [G loss: 0.724127] [Time: 0.150462]\n",
            "4630-7 [D loss: 0.706404, acc.: 38.46%] [G loss: 0.699644] [Time: 0.152982]\n",
            "4630-8 [D loss: 0.719551, acc.: 36.54%] [G loss: 0.704280] [Time: 0.151965]\n",
            "4630 (test) [D loss: 0.894664, acc.: 50.00%] [G loss: 0.826808] [Time: 0.044776]\n",
            "4631-0 [D loss: 0.680470, acc.: 44.23%] [G loss: 0.760572] [Time: 0.151925]\n",
            "4631-1 [D loss: 0.705043, acc.: 38.46%] [G loss: 0.705985] [Time: 0.151870]\n",
            "4631-2 [D loss: 0.705610, acc.: 42.31%] [G loss: 0.726248] [Time: 0.151821]\n",
            "4631-3 [D loss: 0.674774, acc.: 53.85%] [G loss: 0.731222] [Time: 0.148468]\n",
            "4631-4 [D loss: 0.697293, acc.: 53.85%] [G loss: 0.713260] [Time: 0.150700]\n",
            "4631-5 [D loss: 0.684623, acc.: 46.15%] [G loss: 0.728756] [Time: 0.150335]\n",
            "4631-6 [D loss: 0.698326, acc.: 46.15%] [G loss: 0.705124] [Time: 0.147601]\n",
            "4631-7 [D loss: 0.712024, acc.: 38.46%] [G loss: 0.697689] [Time: 0.148002]\n",
            "4631-8 [D loss: 0.714703, acc.: 34.62%] [G loss: 0.701883] [Time: 0.149424]\n",
            "4631 (test) [D loss: 0.897088, acc.: 50.00%] [G loss: 0.951090] [Time: 0.045686]\n",
            "4632-0 [D loss: 0.677197, acc.: 46.15%] [G loss: 0.770941] [Time: 0.150713]\n",
            "4632-1 [D loss: 0.703580, acc.: 44.23%] [G loss: 0.706022] [Time: 0.151935]\n",
            "4632-2 [D loss: 0.714270, acc.: 32.69%] [G loss: 0.689831] [Time: 0.149387]\n",
            "4632-3 [D loss: 0.675090, acc.: 48.08%] [G loss: 0.721575] [Time: 0.148646]\n",
            "4632-4 [D loss: 0.717366, acc.: 34.62%] [G loss: 0.698951] [Time: 0.149959]\n",
            "4632-5 [D loss: 0.696659, acc.: 38.46%] [G loss: 0.712284] [Time: 0.151692]\n",
            "4632-6 [D loss: 0.693684, acc.: 42.31%] [G loss: 0.702018] [Time: 0.151212]\n",
            "4632-7 [D loss: 0.697258, acc.: 51.92%] [G loss: 0.693295] [Time: 0.150149]\n",
            "4632-8 [D loss: 0.698149, acc.: 42.31%] [G loss: 0.691034] [Time: 0.148414]\n",
            "4632 (test) [D loss: 0.900941, acc.: 46.15%] [G loss: 0.801900] [Time: 0.044100]\n",
            "4633-0 [D loss: 0.687547, acc.: 48.08%] [G loss: 0.728797] [Time: 0.148646]\n",
            "4633-1 [D loss: 0.693830, acc.: 50.00%] [G loss: 0.687167] [Time: 0.147472]\n",
            "4633-2 [D loss: 0.705923, acc.: 30.77%] [G loss: 0.725812] [Time: 0.149119]\n",
            "4633-3 [D loss: 0.669393, acc.: 57.69%] [G loss: 0.727456] [Time: 0.148989]\n",
            "4633-4 [D loss: 0.716073, acc.: 28.85%] [G loss: 0.699102] [Time: 0.148553]\n",
            "4633-5 [D loss: 0.686219, acc.: 42.31%] [G loss: 0.706830] [Time: 0.147277]\n",
            "4633-6 [D loss: 0.695244, acc.: 50.00%] [G loss: 0.705782] [Time: 0.149824]\n",
            "4633-7 [D loss: 0.688137, acc.: 46.15%] [G loss: 0.690715] [Time: 0.151196]\n",
            "4633-8 [D loss: 0.713600, acc.: 44.23%] [G loss: 0.701216] [Time: 0.148050]\n",
            "4633 (test) [D loss: 0.891374, acc.: 48.08%] [G loss: 0.727156] [Time: 0.043219]\n",
            "4634-0 [D loss: 0.676847, acc.: 46.15%] [G loss: 0.746469] [Time: 0.147836]\n",
            "4634-1 [D loss: 0.702557, acc.: 44.23%] [G loss: 0.693836] [Time: 0.147248]\n",
            "4634-2 [D loss: 0.702779, acc.: 48.08%] [G loss: 0.709427] [Time: 0.148794]\n",
            "4634-3 [D loss: 0.668419, acc.: 53.85%] [G loss: 0.730379] [Time: 0.151275]\n",
            "4634-4 [D loss: 0.716110, acc.: 46.15%] [G loss: 0.692504] [Time: 0.146956]\n",
            "4634-5 [D loss: 0.677418, acc.: 55.77%] [G loss: 0.700570] [Time: 0.151815]\n",
            "4634-6 [D loss: 0.695166, acc.: 50.00%] [G loss: 0.690414] [Time: 0.148642]\n",
            "4634-7 [D loss: 0.694275, acc.: 44.23%] [G loss: 0.695259] [Time: 0.148229]\n",
            "4634-8 [D loss: 0.710559, acc.: 38.46%] [G loss: 0.689793] [Time: 0.147398]\n",
            "4634 (test) [D loss: 0.900265, acc.: 50.00%] [G loss: 0.724427] [Time: 0.044894]\n",
            "4635-0 [D loss: 0.680665, acc.: 46.15%] [G loss: 0.756998] [Time: 0.147361]\n",
            "4635-1 [D loss: 0.681233, acc.: 51.92%] [G loss: 0.696098] [Time: 0.147738]\n",
            "4635-2 [D loss: 0.707277, acc.: 36.54%] [G loss: 0.685838] [Time: 0.153506]\n",
            "4635-3 [D loss: 0.680558, acc.: 53.85%] [G loss: 0.718973] [Time: 0.151107]\n",
            "4635-4 [D loss: 0.701479, acc.: 50.00%] [G loss: 0.686903] [Time: 0.149063]\n",
            "4635-5 [D loss: 0.680386, acc.: 42.31%] [G loss: 0.706813] [Time: 0.149196]\n",
            "4635-6 [D loss: 0.690137, acc.: 57.69%] [G loss: 0.731645] [Time: 0.147248]\n",
            "4635-7 [D loss: 0.696250, acc.: 38.46%] [G loss: 0.720813] [Time: 0.149637]\n",
            "4635-8 [D loss: 0.713144, acc.: 44.23%] [G loss: 0.711675] [Time: 0.153220]\n",
            "4635 (test) [D loss: 0.870538, acc.: 50.00%] [G loss: 0.893071] [Time: 0.044952]\n",
            "4636-0 [D loss: 0.683307, acc.: 55.77%] [G loss: 0.749416] [Time: 0.147457]\n",
            "4636-1 [D loss: 0.705678, acc.: 46.15%] [G loss: 0.694706] [Time: 0.149884]\n",
            "4636-2 [D loss: 0.702483, acc.: 46.15%] [G loss: 0.691754] [Time: 0.149791]\n",
            "4636-3 [D loss: 0.663355, acc.: 57.69%] [G loss: 0.748116] [Time: 0.146756]\n",
            "4636-4 [D loss: 0.697930, acc.: 40.38%] [G loss: 0.727010] [Time: 0.147768]\n",
            "4636-5 [D loss: 0.682594, acc.: 34.62%] [G loss: 0.727587] [Time: 0.151905]\n",
            "4636-6 [D loss: 0.689381, acc.: 50.00%] [G loss: 0.719338] [Time: 0.148568]\n",
            "4636-7 [D loss: 0.680104, acc.: 57.69%] [G loss: 0.720472] [Time: 0.148749]\n",
            "4636-8 [D loss: 0.700035, acc.: 44.23%] [G loss: 0.695408] [Time: 0.148587]\n",
            "4636 (test) [D loss: 0.912073, acc.: 48.08%] [G loss: 1.160322] [Time: 0.046191]\n",
            "4637-0 [D loss: 0.669170, acc.: 51.92%] [G loss: 0.765519] [Time: 0.154562]\n",
            "4637-1 [D loss: 0.697800, acc.: 40.38%] [G loss: 0.706657] [Time: 0.149015]\n",
            "4637-2 [D loss: 0.703188, acc.: 34.62%] [G loss: 0.706291] [Time: 0.151536]\n",
            "4637-3 [D loss: 0.670616, acc.: 59.62%] [G loss: 0.743070] [Time: 0.147722]\n",
            "4637-4 [D loss: 0.707460, acc.: 38.46%] [G loss: 0.712805] [Time: 0.147668]\n",
            "4637-5 [D loss: 0.685226, acc.: 46.15%] [G loss: 0.712453] [Time: 0.147128]\n",
            "4637-6 [D loss: 0.690205, acc.: 42.31%] [G loss: 0.705308] [Time: 0.156086]\n",
            "4637-7 [D loss: 0.702104, acc.: 48.08%] [G loss: 0.694858] [Time: 0.150185]\n",
            "4637-8 [D loss: 0.694386, acc.: 42.31%] [G loss: 0.701773] [Time: 0.148391]\n",
            "4637 (test) [D loss: 0.894606, acc.: 46.15%] [G loss: 0.893219] [Time: 0.043612]\n",
            "4638-0 [D loss: 0.680668, acc.: 44.23%] [G loss: 0.745853] [Time: 0.147458]\n",
            "4638-1 [D loss: 0.702351, acc.: 50.00%] [G loss: 0.718271] [Time: 0.149013]\n",
            "4638-2 [D loss: 0.703412, acc.: 36.54%] [G loss: 0.711315] [Time: 0.150558]\n",
            "4638-3 [D loss: 0.659452, acc.: 55.77%] [G loss: 0.715802] [Time: 0.148330]\n",
            "4638-4 [D loss: 0.712279, acc.: 46.15%] [G loss: 0.677230] [Time: 0.151527]\n",
            "4638-5 [D loss: 0.677012, acc.: 53.85%] [G loss: 0.679041] [Time: 0.152363]\n",
            "4638-6 [D loss: 0.704968, acc.: 42.31%] [G loss: 0.706796] [Time: 0.147245]\n",
            "4638-7 [D loss: 0.696052, acc.: 50.00%] [G loss: 0.695509] [Time: 0.149727]\n",
            "4638-8 [D loss: 0.707041, acc.: 46.15%] [G loss: 0.713362] [Time: 0.147398]\n",
            "4638 (test) [D loss: 0.906108, acc.: 50.00%] [G loss: 0.665618] [Time: 0.043280]\n",
            "4639-0 [D loss: 0.671119, acc.: 59.62%] [G loss: 0.753976] [Time: 0.149926]\n",
            "4639-1 [D loss: 0.698780, acc.: 48.08%] [G loss: 0.699939] [Time: 0.149008]\n",
            "4639-2 [D loss: 0.691932, acc.: 50.00%] [G loss: 0.690335] [Time: 0.150029]\n",
            "4639-3 [D loss: 0.658315, acc.: 53.85%] [G loss: 0.709448] [Time: 0.149796]\n",
            "4639-4 [D loss: 0.713831, acc.: 34.62%] [G loss: 0.688824] [Time: 0.152036]\n",
            "4639-5 [D loss: 0.681480, acc.: 51.92%] [G loss: 0.693670] [Time: 0.150063]\n",
            "4639-6 [D loss: 0.688741, acc.: 42.31%] [G loss: 0.706048] [Time: 0.147294]\n",
            "4639-7 [D loss: 0.699092, acc.: 50.00%] [G loss: 0.713961] [Time: 0.148051]\n",
            "4639-8 [D loss: 0.711882, acc.: 38.46%] [G loss: 0.690955] [Time: 0.153541]\n",
            "4639 (test) [D loss: 0.871997, acc.: 48.08%] [G loss: 0.763072] [Time: 0.044709]\n",
            "4640-0 [D loss: 0.696122, acc.: 44.23%] [G loss: 0.744932] [Time: 0.146858]\n",
            "4640-1 [D loss: 0.705999, acc.: 34.62%] [G loss: 0.691625] [Time: 0.147571]\n",
            "4640-2 [D loss: 0.720866, acc.: 38.46%] [G loss: 0.714215] [Time: 0.147889]\n",
            "4640-3 [D loss: 0.665130, acc.: 55.77%] [G loss: 0.742967] [Time: 0.148252]\n",
            "4640-4 [D loss: 0.703230, acc.: 48.08%] [G loss: 0.720331] [Time: 0.147004]\n",
            "4640-5 [D loss: 0.704167, acc.: 36.54%] [G loss: 0.719320] [Time: 0.150229]\n",
            "4640-6 [D loss: 0.699277, acc.: 48.08%] [G loss: 0.725766] [Time: 0.148598]\n",
            "4640-7 [D loss: 0.695610, acc.: 42.31%] [G loss: 0.721726] [Time: 0.146647]\n",
            "4640-8 [D loss: 0.708213, acc.: 40.38%] [G loss: 0.699485] [Time: 0.147654]\n",
            "4640 (test) [D loss: 0.901763, acc.: 50.00%] [G loss: 1.172299] [Time: 0.044177]\n",
            "4641-0 [D loss: 0.680636, acc.: 44.23%] [G loss: 0.769060] [Time: 0.146670]\n",
            "4641-1 [D loss: 0.701908, acc.: 46.15%] [G loss: 0.697750] [Time: 0.146906]\n",
            "4641-2 [D loss: 0.706991, acc.: 44.23%] [G loss: 0.705551] [Time: 0.148029]\n",
            "4641-3 [D loss: 0.663248, acc.: 55.77%] [G loss: 0.743346] [Time: 0.147443]\n",
            "4641-4 [D loss: 0.726153, acc.: 36.54%] [G loss: 0.707338] [Time: 0.147588]\n",
            "4641-5 [D loss: 0.695745, acc.: 36.54%] [G loss: 0.716592] [Time: 0.148910]\n",
            "4641-6 [D loss: 0.691935, acc.: 42.31%] [G loss: 0.716628] [Time: 0.148395]\n",
            "4641-7 [D loss: 0.703796, acc.: 42.31%] [G loss: 0.705614] [Time: 0.150530]\n",
            "4641-8 [D loss: 0.699110, acc.: 46.15%] [G loss: 0.695545] [Time: 0.150276]\n",
            "4641 (test) [D loss: 0.892465, acc.: 48.08%] [G loss: 0.980624] [Time: 0.043957]\n",
            "4642-0 [D loss: 0.682056, acc.: 48.08%] [G loss: 0.748350] [Time: 0.150607]\n",
            "4642-1 [D loss: 0.701137, acc.: 48.08%] [G loss: 0.694858] [Time: 0.148413]\n",
            "4642-2 [D loss: 0.706116, acc.: 42.31%] [G loss: 0.702854] [Time: 0.148199]\n",
            "4642-3 [D loss: 0.682727, acc.: 42.31%] [G loss: 0.709868] [Time: 0.147672]\n",
            "4642-4 [D loss: 0.716837, acc.: 36.54%] [G loss: 0.704980] [Time: 0.149480]\n",
            "4642-5 [D loss: 0.685289, acc.: 57.69%] [G loss: 0.735795] [Time: 0.151232]\n",
            "4642-6 [D loss: 0.698692, acc.: 34.62%] [G loss: 0.721357] [Time: 0.148443]\n",
            "4642-7 [D loss: 0.697128, acc.: 44.23%] [G loss: 0.702319] [Time: 0.149143]\n",
            "4642-8 [D loss: 0.694239, acc.: 48.08%] [G loss: 0.721603] [Time: 0.149521]\n",
            "4642 (test) [D loss: 0.905789, acc.: 46.15%] [G loss: 0.725099] [Time: 0.044172]\n",
            "4643-0 [D loss: 0.671932, acc.: 61.54%] [G loss: 0.763043] [Time: 0.149248]\n",
            "4643-1 [D loss: 0.690287, acc.: 57.69%] [G loss: 0.713717] [Time: 0.149656]\n",
            "4643-2 [D loss: 0.705010, acc.: 36.54%] [G loss: 0.711640] [Time: 0.150787]\n",
            "4643-3 [D loss: 0.663320, acc.: 50.00%] [G loss: 0.720472] [Time: 0.147823]\n",
            "4643-4 [D loss: 0.713145, acc.: 44.23%] [G loss: 0.683779] [Time: 0.149216]\n",
            "4643-5 [D loss: 0.679722, acc.: 44.23%] [G loss: 0.698043] [Time: 0.147772]\n",
            "4643-6 [D loss: 0.705446, acc.: 40.38%] [G loss: 0.706789] [Time: 0.150849]\n",
            "4643-7 [D loss: 0.696958, acc.: 55.77%] [G loss: 0.697668] [Time: 0.151265]\n",
            "4643-8 [D loss: 0.699310, acc.: 34.62%] [G loss: 0.696560] [Time: 0.150558]\n",
            "4643 (test) [D loss: 0.895048, acc.: 48.08%] [G loss: 0.761426] [Time: 0.044051]\n",
            "4644-0 [D loss: 0.668468, acc.: 51.92%] [G loss: 0.739857] [Time: 0.151343]\n",
            "4644-1 [D loss: 0.695845, acc.: 51.92%] [G loss: 0.676011] [Time: 0.149225]\n",
            "4644-2 [D loss: 0.708936, acc.: 42.31%] [G loss: 0.695459] [Time: 0.148108]\n",
            "4644-3 [D loss: 0.677237, acc.: 55.77%] [G loss: 0.722482] [Time: 0.149604]\n",
            "4644-4 [D loss: 0.709335, acc.: 44.23%] [G loss: 0.701061] [Time: 0.149538]\n",
            "4644-5 [D loss: 0.676587, acc.: 44.23%] [G loss: 0.699653] [Time: 0.153893]\n",
            "4644-6 [D loss: 0.697838, acc.: 46.15%] [G loss: 0.701872] [Time: 0.148557]\n",
            "4644-7 [D loss: 0.692647, acc.: 32.69%] [G loss: 0.709561] [Time: 0.147235]\n",
            "4644-8 [D loss: 0.700053, acc.: 38.46%] [G loss: 0.682744] [Time: 0.149046]\n",
            "4644 (test) [D loss: 0.920680, acc.: 50.00%] [G loss: 0.629566] [Time: 0.044183]\n",
            "4645-0 [D loss: 0.681049, acc.: 57.69%] [G loss: 0.707036] [Time: 0.153983]\n",
            "4645-1 [D loss: 0.694243, acc.: 42.31%] [G loss: 0.695244] [Time: 0.148201]\n",
            "4645-2 [D loss: 0.701003, acc.: 44.23%] [G loss: 0.675485] [Time: 0.148932]\n",
            "4645-3 [D loss: 0.666413, acc.: 57.69%] [G loss: 0.728085] [Time: 0.149402]\n",
            "4645-4 [D loss: 0.700922, acc.: 44.23%] [G loss: 0.691723] [Time: 0.149143]\n",
            "4645-5 [D loss: 0.683322, acc.: 42.31%] [G loss: 0.700026] [Time: 0.149450]\n",
            "4645-6 [D loss: 0.701832, acc.: 42.31%] [G loss: 0.710317] [Time: 0.147405]\n",
            "4645-7 [D loss: 0.697730, acc.: 38.46%] [G loss: 0.697621] [Time: 0.147408]\n",
            "4645-8 [D loss: 0.696772, acc.: 57.69%] [G loss: 0.682700] [Time: 0.150111]\n",
            "4645 (test) [D loss: 0.895936, acc.: 50.00%] [G loss: 0.752497] [Time: 0.045733]\n",
            "4646-0 [D loss: 0.681233, acc.: 50.00%] [G loss: 0.721733] [Time: 0.151424]\n",
            "4646-1 [D loss: 0.705005, acc.: 44.23%] [G loss: 0.708138] [Time: 0.150265]\n",
            "4646-2 [D loss: 0.702069, acc.: 48.08%] [G loss: 0.704104] [Time: 0.147135]\n",
            "4646-3 [D loss: 0.668631, acc.: 55.77%] [G loss: 0.727487] [Time: 0.147378]\n",
            "4646-4 [D loss: 0.709363, acc.: 38.46%] [G loss: 0.702220] [Time: 0.172227]\n",
            "4646-5 [D loss: 0.688611, acc.: 36.54%] [G loss: 0.715172] [Time: 0.148191]\n",
            "4646-6 [D loss: 0.695416, acc.: 46.15%] [G loss: 0.727540] [Time: 0.154520]\n",
            "4646-7 [D loss: 0.700459, acc.: 46.15%] [G loss: 0.703001] [Time: 0.147168]\n",
            "4646-8 [D loss: 0.706931, acc.: 44.23%] [G loss: 0.701548] [Time: 0.146608]\n",
            "4646 (test) [D loss: 0.884481, acc.: 50.00%] [G loss: 0.828096] [Time: 0.044683]\n",
            "4647-0 [D loss: 0.680418, acc.: 50.00%] [G loss: 0.737405] [Time: 0.148752]\n",
            "4647-1 [D loss: 0.695195, acc.: 48.08%] [G loss: 0.705218] [Time: 0.152897]\n",
            "4647-2 [D loss: 0.702076, acc.: 46.15%] [G loss: 0.711655] [Time: 0.153112]\n",
            "4647-3 [D loss: 0.676751, acc.: 50.00%] [G loss: 0.733168] [Time: 0.151875]\n",
            "4647-4 [D loss: 0.703638, acc.: 40.38%] [G loss: 0.732742] [Time: 0.151364]\n",
            "4647-5 [D loss: 0.681379, acc.: 40.38%] [G loss: 0.720632] [Time: 0.154063]\n",
            "4647-6 [D loss: 0.687744, acc.: 51.92%] [G loss: 0.734265] [Time: 0.150552]\n",
            "4647-7 [D loss: 0.704622, acc.: 40.38%] [G loss: 0.720896] [Time: 0.150779]\n",
            "4647-8 [D loss: 0.708870, acc.: 42.31%] [G loss: 0.699793] [Time: 0.151404]\n",
            "4647 (test) [D loss: 0.893827, acc.: 50.00%] [G loss: 1.001826] [Time: 0.045710]\n",
            "4648-0 [D loss: 0.681294, acc.: 44.23%] [G loss: 0.751966] [Time: 0.148532]\n",
            "4648-1 [D loss: 0.703285, acc.: 40.38%] [G loss: 0.698939] [Time: 0.151281]\n",
            "4648-2 [D loss: 0.698395, acc.: 44.23%] [G loss: 0.706696] [Time: 0.150352]\n",
            "4648-3 [D loss: 0.670715, acc.: 55.77%] [G loss: 0.727727] [Time: 0.151249]\n",
            "4648-4 [D loss: 0.702533, acc.: 38.46%] [G loss: 0.734037] [Time: 0.153319]\n",
            "4648-5 [D loss: 0.683010, acc.: 36.54%] [G loss: 0.712619] [Time: 0.147512]\n",
            "4648-6 [D loss: 0.697069, acc.: 48.08%] [G loss: 0.716523] [Time: 0.149239]\n",
            "4648-7 [D loss: 0.695261, acc.: 48.08%] [G loss: 0.705506] [Time: 0.149935]\n",
            "4648-8 [D loss: 0.707582, acc.: 40.38%] [G loss: 0.698655] [Time: 0.151125]\n",
            "4648 (test) [D loss: 0.904656, acc.: 50.00%] [G loss: 0.747620] [Time: 0.044496]\n",
            "4649-0 [D loss: 0.683644, acc.: 53.85%] [G loss: 0.752586] [Time: 0.148807]\n",
            "4649-1 [D loss: 0.704316, acc.: 46.15%] [G loss: 0.712346] [Time: 0.154183]\n",
            "4649-2 [D loss: 0.715612, acc.: 34.62%] [G loss: 0.693836] [Time: 0.149445]\n",
            "4649-3 [D loss: 0.663482, acc.: 57.69%] [G loss: 0.695646] [Time: 0.148869]\n",
            "4649-4 [D loss: 0.709184, acc.: 44.23%] [G loss: 0.695064] [Time: 0.149792]\n",
            "4649-5 [D loss: 0.696711, acc.: 40.38%] [G loss: 0.684292] [Time: 0.149986]\n",
            "4649-6 [D loss: 0.696654, acc.: 53.85%] [G loss: 0.713211] [Time: 0.155261]\n",
            "4649-7 [D loss: 0.703523, acc.: 40.38%] [G loss: 0.696011] [Time: 0.150605]\n",
            "4649-8 [D loss: 0.706384, acc.: 32.69%] [G loss: 0.697170] [Time: 0.150560]\n",
            "4649 (test) [D loss: 0.924324, acc.: 50.00%] [G loss: 0.631144] [Time: 0.045383]\n",
            "4650-0 [D loss: 0.686566, acc.: 46.15%] [G loss: 0.700069] [Time: 0.151954]\n",
            "4650-1 [D loss: 0.697539, acc.: 44.23%] [G loss: 0.689209] [Time: 0.151914]\n",
            "4650-2 [D loss: 0.707411, acc.: 32.69%] [G loss: 0.664945] [Time: 0.152494]\n",
            "4650-3 [D loss: 0.678441, acc.: 51.92%] [G loss: 0.734524] [Time: 0.150000]\n",
            "4650-4 [D loss: 0.706009, acc.: 48.08%] [G loss: 0.704510] [Time: 0.148829]\n",
            "4650-5 [D loss: 0.677777, acc.: 44.23%] [G loss: 0.693380] [Time: 0.147254]\n",
            "4650-6 [D loss: 0.694468, acc.: 50.00%] [G loss: 0.686770] [Time: 0.148525]\n",
            "4650-7 [D loss: 0.700810, acc.: 46.15%] [G loss: 0.694303] [Time: 0.147167]\n",
            "4650-8 [D loss: 0.703851, acc.: 38.46%] [G loss: 0.702751] [Time: 0.147541]\n",
            "4650 (test) [D loss: 0.929546, acc.: 50.00%] [G loss: 0.598423] [Time: 0.045757]\n",
            "4651-0 [D loss: 0.670545, acc.: 48.08%] [G loss: 0.733702] [Time: 0.152773]\n",
            "4651-1 [D loss: 0.700875, acc.: 48.08%] [G loss: 0.699609] [Time: 0.153164]\n",
            "4651-2 [D loss: 0.700312, acc.: 42.31%] [G loss: 0.697268] [Time: 0.149306]\n",
            "4651-3 [D loss: 0.673109, acc.: 53.85%] [G loss: 0.707752] [Time: 0.153501]\n",
            "4651-4 [D loss: 0.704852, acc.: 44.23%] [G loss: 0.700600] [Time: 0.151063]\n",
            "4651-5 [D loss: 0.676423, acc.: 50.00%] [G loss: 0.708422] [Time: 0.149636]\n",
            "4651-6 [D loss: 0.686832, acc.: 42.31%] [G loss: 0.722512] [Time: 0.150642]\n",
            "4651-7 [D loss: 0.699912, acc.: 40.38%] [G loss: 0.710653] [Time: 0.149180]\n",
            "4651-8 [D loss: 0.705270, acc.: 32.69%] [G loss: 0.692710] [Time: 0.154666]\n",
            "4651 (test) [D loss: 0.930286, acc.: 50.00%] [G loss: 0.599209] [Time: 0.044361]\n",
            "4652-0 [D loss: 0.667009, acc.: 53.85%] [G loss: 0.744275] [Time: 0.150825]\n",
            "4652-1 [D loss: 0.704801, acc.: 36.54%] [G loss: 0.684449] [Time: 0.156800]\n",
            "4652-2 [D loss: 0.707386, acc.: 42.31%] [G loss: 0.718185] [Time: 0.147581]\n",
            "4652-3 [D loss: 0.684913, acc.: 59.62%] [G loss: 0.745247] [Time: 0.152922]\n",
            "4652-4 [D loss: 0.700453, acc.: 46.15%] [G loss: 0.709205] [Time: 0.149485]\n",
            "4652-5 [D loss: 0.686975, acc.: 42.31%] [G loss: 0.715567] [Time: 0.152018]\n",
            "4652-6 [D loss: 0.694357, acc.: 40.38%] [G loss: 0.716907] [Time: 0.150951]\n",
            "4652-7 [D loss: 0.702015, acc.: 36.54%] [G loss: 0.698738] [Time: 0.149400]\n",
            "4652-8 [D loss: 0.711879, acc.: 44.23%] [G loss: 0.707256] [Time: 0.148890]\n",
            "4652 (test) [D loss: 0.897013, acc.: 46.15%] [G loss: 0.759996] [Time: 0.046155]\n",
            "4653-0 [D loss: 0.687364, acc.: 44.23%] [G loss: 0.743436] [Time: 0.150310]\n",
            "4653-1 [D loss: 0.705778, acc.: 32.69%] [G loss: 0.709993] [Time: 0.151405]\n",
            "4653-2 [D loss: 0.693977, acc.: 38.46%] [G loss: 0.721633] [Time: 0.151371]\n",
            "4653-3 [D loss: 0.669885, acc.: 44.23%] [G loss: 0.742155] [Time: 0.148526]\n",
            "4653-4 [D loss: 0.717254, acc.: 36.54%] [G loss: 0.716448] [Time: 0.149091]\n",
            "4653-5 [D loss: 0.679775, acc.: 53.85%] [G loss: 0.695193] [Time: 0.147245]\n",
            "4653-6 [D loss: 0.698899, acc.: 44.23%] [G loss: 0.716571] [Time: 0.154977]\n",
            "4653-7 [D loss: 0.721065, acc.: 36.54%] [G loss: 0.708326] [Time: 0.150882]\n",
            "4653-8 [D loss: 0.713236, acc.: 38.46%] [G loss: 0.705724] [Time: 0.151542]\n",
            "4653 (test) [D loss: 0.906715, acc.: 48.08%] [G loss: 0.762516] [Time: 0.044158]\n",
            "4654-0 [D loss: 0.667431, acc.: 51.92%] [G loss: 0.742438] [Time: 0.149318]\n",
            "4654-1 [D loss: 0.711474, acc.: 42.31%] [G loss: 0.694421] [Time: 0.150024]\n",
            "4654-2 [D loss: 0.705567, acc.: 36.54%] [G loss: 0.691230] [Time: 0.148018]\n",
            "4654-3 [D loss: 0.680382, acc.: 55.77%] [G loss: 0.716398] [Time: 0.151222]\n",
            "4654-4 [D loss: 0.704715, acc.: 44.23%] [G loss: 0.719404] [Time: 0.150710]\n",
            "4654-5 [D loss: 0.677737, acc.: 50.00%] [G loss: 0.689240] [Time: 0.148678]\n",
            "4654-6 [D loss: 0.691491, acc.: 57.69%] [G loss: 0.717197] [Time: 0.149366]\n",
            "4654-7 [D loss: 0.710141, acc.: 36.54%] [G loss: 0.703268] [Time: 0.148226]\n",
            "4654-8 [D loss: 0.711557, acc.: 38.46%] [G loss: 0.716941] [Time: 0.147343]\n",
            "4654 (test) [D loss: 0.907024, acc.: 50.00%] [G loss: 0.780526] [Time: 0.045072]\n",
            "4655-0 [D loss: 0.685388, acc.: 50.00%] [G loss: 0.748751] [Time: 0.150698]\n",
            "4655-1 [D loss: 0.716582, acc.: 34.62%] [G loss: 0.692234] [Time: 0.149949]\n",
            "4655-2 [D loss: 0.711164, acc.: 46.15%] [G loss: 0.677301] [Time: 0.150926]\n",
            "4655-3 [D loss: 0.670607, acc.: 50.00%] [G loss: 0.751970] [Time: 0.150563]\n",
            "4655-4 [D loss: 0.713281, acc.: 44.23%] [G loss: 0.693661] [Time: 0.153399]\n",
            "4655-5 [D loss: 0.674685, acc.: 53.85%] [G loss: 0.713093] [Time: 0.149356]\n",
            "4655-6 [D loss: 0.694375, acc.: 48.08%] [G loss: 0.720455] [Time: 0.150966]\n",
            "4655-7 [D loss: 0.691185, acc.: 50.00%] [G loss: 0.723513] [Time: 0.149605]\n",
            "4655-8 [D loss: 0.709409, acc.: 40.38%] [G loss: 0.697802] [Time: 0.147437]\n",
            "4655 (test) [D loss: 0.918796, acc.: 48.08%] [G loss: 1.019911] [Time: 0.044250]\n",
            "4656-0 [D loss: 0.679709, acc.: 42.31%] [G loss: 0.781141] [Time: 0.148955]\n",
            "4656-1 [D loss: 0.705625, acc.: 30.77%] [G loss: 0.706587] [Time: 0.147847]\n",
            "4656-2 [D loss: 0.705310, acc.: 38.46%] [G loss: 0.696179] [Time: 0.149769]\n",
            "4656-3 [D loss: 0.665008, acc.: 42.31%] [G loss: 0.728416] [Time: 0.148383]\n",
            "4656-4 [D loss: 0.712218, acc.: 36.54%] [G loss: 0.706845] [Time: 0.149816]\n",
            "4656-5 [D loss: 0.682954, acc.: 51.92%] [G loss: 0.724014] [Time: 0.148892]\n",
            "4656-6 [D loss: 0.695246, acc.: 42.31%] [G loss: 0.702677] [Time: 0.147856]\n",
            "4656-7 [D loss: 0.692469, acc.: 44.23%] [G loss: 0.699175] [Time: 0.149588]\n",
            "4656-8 [D loss: 0.718204, acc.: 44.23%] [G loss: 0.678391] [Time: 0.147943]\n",
            "4656 (test) [D loss: 0.888247, acc.: 51.92%] [G loss: 0.879477] [Time: 0.045343]\n",
            "4657-0 [D loss: 0.682393, acc.: 46.15%] [G loss: 0.747571] [Time: 0.148485]\n",
            "4657-1 [D loss: 0.706633, acc.: 34.62%] [G loss: 0.698902] [Time: 0.148062]\n",
            "4657-2 [D loss: 0.695754, acc.: 48.08%] [G loss: 0.711557] [Time: 0.151922]\n",
            "4657-3 [D loss: 0.663208, acc.: 55.77%] [G loss: 0.709677] [Time: 0.153538]\n",
            "4657-4 [D loss: 0.709535, acc.: 38.46%] [G loss: 0.703516] [Time: 0.150002]\n",
            "4657-5 [D loss: 0.669779, acc.: 44.23%] [G loss: 0.684785] [Time: 0.150176]\n",
            "4657-6 [D loss: 0.698500, acc.: 50.00%] [G loss: 0.707038] [Time: 0.152146]\n",
            "4657-7 [D loss: 0.700495, acc.: 34.62%] [G loss: 0.699221] [Time: 0.155360]\n",
            "4657-8 [D loss: 0.697914, acc.: 34.62%] [G loss: 0.681309] [Time: 0.147563]\n",
            "4657 (test) [D loss: 0.932637, acc.: 50.00%] [G loss: 0.612853] [Time: 0.044812]\n",
            "4658-0 [D loss: 0.672103, acc.: 57.69%] [G loss: 0.712700] [Time: 0.147120]\n",
            "4658-1 [D loss: 0.708082, acc.: 36.54%] [G loss: 0.693200] [Time: 0.148884]\n",
            "4658-2 [D loss: 0.708865, acc.: 44.23%] [G loss: 0.678392] [Time: 0.149766]\n",
            "4658-3 [D loss: 0.671250, acc.: 51.92%] [G loss: 0.724159] [Time: 0.149488]\n",
            "4658-4 [D loss: 0.697692, acc.: 42.31%] [G loss: 0.690136] [Time: 0.148154]\n",
            "4658-5 [D loss: 0.679599, acc.: 46.15%] [G loss: 0.695465] [Time: 0.150189]\n",
            "4658-6 [D loss: 0.690513, acc.: 42.31%] [G loss: 0.715037] [Time: 0.147519]\n",
            "4658-7 [D loss: 0.702945, acc.: 53.85%] [G loss: 0.701592] [Time: 0.149346]\n",
            "4658-8 [D loss: 0.703147, acc.: 42.31%] [G loss: 0.702353] [Time: 0.147018]\n",
            "4658 (test) [D loss: 0.903606, acc.: 48.08%] [G loss: 0.932250] [Time: 0.044653]\n",
            "4659-0 [D loss: 0.682688, acc.: 51.92%] [G loss: 0.784717] [Time: 0.149105]\n",
            "4659-1 [D loss: 0.692158, acc.: 51.92%] [G loss: 0.708435] [Time: 0.148715]\n",
            "4659-2 [D loss: 0.706262, acc.: 40.38%] [G loss: 0.719207] [Time: 0.147534]\n",
            "4659-3 [D loss: 0.681477, acc.: 42.31%] [G loss: 0.744698] [Time: 0.147741]\n",
            "4659-4 [D loss: 0.704805, acc.: 36.54%] [G loss: 0.701719] [Time: 0.148541]\n",
            "4659-5 [D loss: 0.684204, acc.: 44.23%] [G loss: 0.721268] [Time: 0.147388]\n",
            "4659-6 [D loss: 0.698664, acc.: 53.85%] [G loss: 0.728696] [Time: 0.148126]\n",
            "4659-7 [D loss: 0.707297, acc.: 42.31%] [G loss: 0.692070] [Time: 0.148021]\n",
            "4659-8 [D loss: 0.707555, acc.: 44.23%] [G loss: 0.707245] [Time: 0.148612]\n",
            "4659 (test) [D loss: 0.888404, acc.: 46.15%] [G loss: 0.924845] [Time: 0.046118]\n",
            "4660-0 [D loss: 0.685983, acc.: 38.46%] [G loss: 0.753124] [Time: 0.148267]\n",
            "4660-1 [D loss: 0.705705, acc.: 38.46%] [G loss: 0.718099] [Time: 0.148837]\n",
            "4660-2 [D loss: 0.694283, acc.: 48.08%] [G loss: 0.708032] [Time: 0.151385]\n",
            "4660-3 [D loss: 0.666083, acc.: 48.08%] [G loss: 0.738439] [Time: 0.149107]\n",
            "4660-4 [D loss: 0.712470, acc.: 42.31%] [G loss: 0.749655] [Time: 0.149671]\n",
            "4660-5 [D loss: 0.683258, acc.: 46.15%] [G loss: 0.730956] [Time: 0.150431]\n",
            "4660-6 [D loss: 0.695521, acc.: 50.00%] [G loss: 0.719331] [Time: 0.147119]\n",
            "4660-7 [D loss: 0.703881, acc.: 40.38%] [G loss: 0.711477] [Time: 0.148117]\n",
            "4660-8 [D loss: 0.693482, acc.: 42.31%] [G loss: 0.697418] [Time: 0.148175]\n",
            "4660 (test) [D loss: 0.891265, acc.: 48.08%] [G loss: 0.948487] [Time: 0.044428]\n",
            "4661-0 [D loss: 0.680857, acc.: 46.15%] [G loss: 0.747797] [Time: 0.146905]\n",
            "4661-1 [D loss: 0.704539, acc.: 34.62%] [G loss: 0.702225] [Time: 0.149122]\n",
            "4661-2 [D loss: 0.697157, acc.: 50.00%] [G loss: 0.699335] [Time: 0.148354]\n",
            "4661-3 [D loss: 0.680827, acc.: 42.31%] [G loss: 0.725970] [Time: 0.149245]\n",
            "4661-4 [D loss: 0.705421, acc.: 30.77%] [G loss: 0.711343] [Time: 0.151363]\n",
            "4661-5 [D loss: 0.674639, acc.: 48.08%] [G loss: 0.715513] [Time: 0.149874]\n",
            "4661-6 [D loss: 0.691423, acc.: 48.08%] [G loss: 0.724911] [Time: 0.149050]\n",
            "4661-7 [D loss: 0.703682, acc.: 46.15%] [G loss: 0.678069] [Time: 0.149573]\n",
            "4661-8 [D loss: 0.718771, acc.: 38.46%] [G loss: 0.696986] [Time: 0.149017]\n",
            "4661 (test) [D loss: 0.897324, acc.: 48.08%] [G loss: 0.834630] [Time: 0.043400]\n",
            "4662-0 [D loss: 0.690666, acc.: 36.54%] [G loss: 0.744647] [Time: 0.152143]\n",
            "4662-1 [D loss: 0.706445, acc.: 42.31%] [G loss: 0.700737] [Time: 0.151513]\n",
            "4662-2 [D loss: 0.697658, acc.: 40.38%] [G loss: 0.710099] [Time: 0.152824]\n",
            "4662-3 [D loss: 0.688065, acc.: 44.23%] [G loss: 0.736608] [Time: 0.147611]\n",
            "4662-4 [D loss: 0.697543, acc.: 46.15%] [G loss: 0.715732] [Time: 0.148267]\n",
            "4662-5 [D loss: 0.679804, acc.: 48.08%] [G loss: 0.695679] [Time: 0.147597]\n",
            "4662-6 [D loss: 0.699856, acc.: 53.85%] [G loss: 0.711961] [Time: 0.150290]\n",
            "4662-7 [D loss: 0.700192, acc.: 48.08%] [G loss: 0.688182] [Time: 0.147929]\n",
            "4662-8 [D loss: 0.715314, acc.: 42.31%] [G loss: 0.696599] [Time: 0.148864]\n",
            "4662 (test) [D loss: 0.875629, acc.: 50.00%] [G loss: 0.989220] [Time: 0.045231]\n",
            "4663-0 [D loss: 0.692000, acc.: 46.15%] [G loss: 0.743313] [Time: 0.147540]\n",
            "4663-1 [D loss: 0.706344, acc.: 42.31%] [G loss: 0.694877] [Time: 0.149459]\n",
            "4663-2 [D loss: 0.711848, acc.: 38.46%] [G loss: 0.683177] [Time: 0.149722]\n",
            "4663-3 [D loss: 0.670406, acc.: 46.15%] [G loss: 0.708991] [Time: 0.149502]\n",
            "4663-4 [D loss: 0.710423, acc.: 48.08%] [G loss: 0.694571] [Time: 0.149165]\n",
            "4663-5 [D loss: 0.687866, acc.: 50.00%] [G loss: 0.685217] [Time: 0.150911]\n",
            "4663-6 [D loss: 0.700308, acc.: 46.15%] [G loss: 0.724928] [Time: 0.151572]\n",
            "4663-7 [D loss: 0.706804, acc.: 40.38%] [G loss: 0.677995] [Time: 0.151409]\n",
            "4663-8 [D loss: 0.713490, acc.: 36.54%] [G loss: 0.684567] [Time: 0.149522]\n",
            "4663 (test) [D loss: 0.915567, acc.: 50.00%] [G loss: 0.613250] [Time: 0.044929]\n",
            "4664-0 [D loss: 0.673031, acc.: 50.00%] [G loss: 0.755748] [Time: 0.152331]\n",
            "4664-1 [D loss: 0.707964, acc.: 40.38%] [G loss: 0.691288] [Time: 0.152267]\n",
            "4664-2 [D loss: 0.689698, acc.: 51.92%] [G loss: 0.676429] [Time: 0.151453]\n",
            "4664-3 [D loss: 0.663547, acc.: 57.69%] [G loss: 0.713929] [Time: 0.148564]\n",
            "4664-4 [D loss: 0.724348, acc.: 40.38%] [G loss: 0.679624] [Time: 0.149380]\n",
            "4664-5 [D loss: 0.685881, acc.: 40.38%] [G loss: 0.680421] [Time: 0.150107]\n",
            "4664-6 [D loss: 0.696963, acc.: 42.31%] [G loss: 0.701489] [Time: 0.149725]\n",
            "4664-7 [D loss: 0.693880, acc.: 57.69%] [G loss: 0.709949] [Time: 0.150145]\n",
            "4664-8 [D loss: 0.705686, acc.: 30.77%] [G loss: 0.687618] [Time: 0.151062]\n",
            "4664 (test) [D loss: 0.924210, acc.: 50.00%] [G loss: 0.636187] [Time: 0.047138]\n",
            "4665-0 [D loss: 0.682286, acc.: 50.00%] [G loss: 0.743027] [Time: 0.149878]\n",
            "4665-1 [D loss: 0.695881, acc.: 42.31%] [G loss: 0.709574] [Time: 0.148919]\n",
            "4665-2 [D loss: 0.709492, acc.: 36.54%] [G loss: 0.706374] [Time: 0.148883]\n",
            "4665-3 [D loss: 0.679574, acc.: 48.08%] [G loss: 0.713596] [Time: 0.147829]\n",
            "4665-4 [D loss: 0.702443, acc.: 30.77%] [G loss: 0.709597] [Time: 0.148916]\n",
            "4665-5 [D loss: 0.686710, acc.: 42.31%] [G loss: 0.722871] [Time: 0.149420]\n",
            "4665-6 [D loss: 0.698175, acc.: 44.23%] [G loss: 0.726248] [Time: 0.154570]\n",
            "4665-7 [D loss: 0.702373, acc.: 42.31%] [G loss: 0.720400] [Time: 0.150278]\n",
            "4665-8 [D loss: 0.701854, acc.: 30.77%] [G loss: 0.707504] [Time: 0.148955]\n",
            "4665 (test) [D loss: 0.905337, acc.: 48.08%] [G loss: 0.869476] [Time: 0.046039]\n",
            "4666-0 [D loss: 0.676889, acc.: 55.77%] [G loss: 0.791926] [Time: 0.150671]\n",
            "4666-1 [D loss: 0.695400, acc.: 38.46%] [G loss: 0.714364] [Time: 0.147356]\n",
            "4666-2 [D loss: 0.708192, acc.: 32.69%] [G loss: 0.712789] [Time: 0.148782]\n",
            "4666-3 [D loss: 0.682535, acc.: 48.08%] [G loss: 0.733711] [Time: 0.147639]\n",
            "4666-4 [D loss: 0.702218, acc.: 46.15%] [G loss: 0.707792] [Time: 0.148596]\n",
            "4666-5 [D loss: 0.682557, acc.: 40.38%] [G loss: 0.705702] [Time: 0.148196]\n",
            "4666-6 [D loss: 0.690440, acc.: 46.15%] [G loss: 0.714607] [Time: 0.150388]\n",
            "4666-7 [D loss: 0.693132, acc.: 50.00%] [G loss: 0.715998] [Time: 0.147557]\n",
            "4666-8 [D loss: 0.692078, acc.: 42.31%] [G loss: 0.691111] [Time: 0.151116]\n",
            "4666 (test) [D loss: 0.895342, acc.: 50.00%] [G loss: 0.929153] [Time: 0.044842]\n",
            "4667-0 [D loss: 0.671813, acc.: 46.15%] [G loss: 0.726857] [Time: 0.150584]\n",
            "4667-1 [D loss: 0.703134, acc.: 46.15%] [G loss: 0.710177] [Time: 0.148669]\n",
            "4667-2 [D loss: 0.706215, acc.: 44.23%] [G loss: 0.697704] [Time: 0.150268]\n",
            "4667-3 [D loss: 0.667425, acc.: 57.69%] [G loss: 0.727255] [Time: 0.151067]\n",
            "4667-4 [D loss: 0.704293, acc.: 25.00%] [G loss: 0.710041] [Time: 0.147919]\n",
            "4667-5 [D loss: 0.691943, acc.: 32.69%] [G loss: 0.724923] [Time: 0.149447]\n",
            "4667-6 [D loss: 0.691714, acc.: 44.23%] [G loss: 0.714011] [Time: 0.149375]\n",
            "4667-7 [D loss: 0.703734, acc.: 38.46%] [G loss: 0.693998] [Time: 0.148845]\n",
            "4667-8 [D loss: 0.694303, acc.: 50.00%] [G loss: 0.692381] [Time: 0.148390]\n",
            "4667 (test) [D loss: 0.886454, acc.: 50.00%] [G loss: 0.982805] [Time: 0.043670]\n",
            "4668-0 [D loss: 0.673385, acc.: 50.00%] [G loss: 0.746241] [Time: 0.147379]\n",
            "4668-1 [D loss: 0.699655, acc.: 40.38%] [G loss: 0.694098] [Time: 0.153812]\n",
            "4668-2 [D loss: 0.695489, acc.: 50.00%] [G loss: 0.716534] [Time: 0.154699]\n",
            "4668-3 [D loss: 0.685197, acc.: 48.08%] [G loss: 0.733016] [Time: 0.149032]\n",
            "4668-4 [D loss: 0.725235, acc.: 42.31%] [G loss: 0.686876] [Time: 0.147924]\n",
            "4668-5 [D loss: 0.679506, acc.: 46.15%] [G loss: 0.706958] [Time: 0.147842]\n",
            "4668-6 [D loss: 0.702104, acc.: 50.00%] [G loss: 0.707975] [Time: 0.148140]\n",
            "4668-7 [D loss: 0.711794, acc.: 46.15%] [G loss: 0.703906] [Time: 0.150206]\n",
            "4668-8 [D loss: 0.704086, acc.: 32.69%] [G loss: 0.700427] [Time: 0.148777]\n",
            "4668 (test) [D loss: 0.902690, acc.: 48.08%] [G loss: 0.860805] [Time: 0.043522]\n",
            "4669-0 [D loss: 0.670809, acc.: 51.92%] [G loss: 0.746514] [Time: 0.149138]\n",
            "4669-1 [D loss: 0.714198, acc.: 38.46%] [G loss: 0.707847] [Time: 0.146847]\n",
            "4669-2 [D loss: 0.706169, acc.: 46.15%] [G loss: 0.706581] [Time: 0.148684]\n",
            "4669-3 [D loss: 0.679929, acc.: 48.08%] [G loss: 0.720289] [Time: 0.147513]\n",
            "4669-4 [D loss: 0.696435, acc.: 42.31%] [G loss: 0.706508] [Time: 0.148188]\n",
            "4669-5 [D loss: 0.694112, acc.: 38.46%] [G loss: 0.703257] [Time: 0.150568]\n",
            "4669-6 [D loss: 0.688754, acc.: 44.23%] [G loss: 0.726893] [Time: 0.148092]\n",
            "4669-7 [D loss: 0.703483, acc.: 40.38%] [G loss: 0.693243] [Time: 0.149001]\n",
            "4669-8 [D loss: 0.705682, acc.: 44.23%] [G loss: 0.704720] [Time: 0.147414]\n",
            "4669 (test) [D loss: 0.909666, acc.: 46.15%] [G loss: 0.980584] [Time: 0.043911]\n",
            "4670-0 [D loss: 0.666604, acc.: 44.23%] [G loss: 0.780208] [Time: 0.149452]\n",
            "4670-1 [D loss: 0.707322, acc.: 40.38%] [G loss: 0.698167] [Time: 0.150052]\n",
            "4670-2 [D loss: 0.701212, acc.: 40.38%] [G loss: 0.702135] [Time: 0.155997]\n",
            "4670-3 [D loss: 0.680205, acc.: 57.69%] [G loss: 0.738563] [Time: 0.150954]\n",
            "4670-4 [D loss: 0.700543, acc.: 46.15%] [G loss: 0.686973] [Time: 0.147306]\n",
            "4670-5 [D loss: 0.688430, acc.: 42.31%] [G loss: 0.703941] [Time: 0.149489]\n",
            "4670-6 [D loss: 0.702005, acc.: 40.38%] [G loss: 0.719903] [Time: 0.150158]\n",
            "4670-7 [D loss: 0.704368, acc.: 42.31%] [G loss: 0.704316] [Time: 0.151577]\n",
            "4670-8 [D loss: 0.702881, acc.: 44.23%] [G loss: 0.687905] [Time: 0.149075]\n",
            "4670 (test) [D loss: 0.920187, acc.: 48.08%] [G loss: 0.879954] [Time: 0.044329]\n",
            "4671-0 [D loss: 0.676322, acc.: 48.08%] [G loss: 0.739565] [Time: 0.148884]\n",
            "4671-1 [D loss: 0.701664, acc.: 44.23%] [G loss: 0.687553] [Time: 0.146523]\n",
            "4671-2 [D loss: 0.705407, acc.: 46.15%] [G loss: 0.698290] [Time: 0.146984]\n",
            "4671-3 [D loss: 0.683116, acc.: 53.85%] [G loss: 0.721918] [Time: 0.147559]\n",
            "4671-4 [D loss: 0.714565, acc.: 38.46%] [G loss: 0.703516] [Time: 0.148141]\n",
            "4671-5 [D loss: 0.691562, acc.: 34.62%] [G loss: 0.710680] [Time: 0.149168]\n",
            "4671-6 [D loss: 0.691240, acc.: 50.00%] [G loss: 0.721527] [Time: 0.148134]\n",
            "4671-7 [D loss: 0.702095, acc.: 42.31%] [G loss: 0.705773] [Time: 0.153022]\n",
            "4671-8 [D loss: 0.692683, acc.: 44.23%] [G loss: 0.697419] [Time: 0.147174]\n",
            "4671 (test) [D loss: 0.917634, acc.: 48.08%] [G loss: 1.116124] [Time: 0.043764]\n",
            "4672-0 [D loss: 0.682238, acc.: 51.92%] [G loss: 0.761859] [Time: 0.147057]\n",
            "4672-1 [D loss: 0.705067, acc.: 38.46%] [G loss: 0.703931] [Time: 0.149537]\n",
            "4672-2 [D loss: 0.702165, acc.: 30.77%] [G loss: 0.717162] [Time: 0.148345]\n",
            "4672-3 [D loss: 0.665175, acc.: 53.85%] [G loss: 0.718850] [Time: 0.147438]\n",
            "4672-4 [D loss: 0.691827, acc.: 46.15%] [G loss: 0.704905] [Time: 0.151186]\n",
            "4672-5 [D loss: 0.677859, acc.: 46.15%] [G loss: 0.726672] [Time: 0.149495]\n",
            "4672-6 [D loss: 0.695127, acc.: 46.15%] [G loss: 0.712469] [Time: 0.147242]\n",
            "4672-7 [D loss: 0.699583, acc.: 42.31%] [G loss: 0.695550] [Time: 0.148959]\n",
            "4672-8 [D loss: 0.692269, acc.: 59.62%] [G loss: 0.685302] [Time: 0.149855]\n",
            "4672 (test) [D loss: 0.897424, acc.: 46.15%] [G loss: 1.074800] [Time: 0.043799]\n",
            "4673-0 [D loss: 0.680449, acc.: 50.00%] [G loss: 0.773382] [Time: 0.147189]\n",
            "4673-1 [D loss: 0.703404, acc.: 38.46%] [G loss: 0.699138] [Time: 0.147671]\n",
            "4673-2 [D loss: 0.694022, acc.: 42.31%] [G loss: 0.700578] [Time: 0.149495]\n",
            "4673-3 [D loss: 0.673301, acc.: 53.85%] [G loss: 0.704213] [Time: 0.147825]\n",
            "4673-4 [D loss: 0.694538, acc.: 44.23%] [G loss: 0.702845] [Time: 0.150353]\n",
            "4673-5 [D loss: 0.676004, acc.: 42.31%] [G loss: 0.714286] [Time: 0.151577]\n",
            "4673-6 [D loss: 0.698449, acc.: 40.38%] [G loss: 0.705212] [Time: 0.147883]\n",
            "4673-7 [D loss: 0.695437, acc.: 50.00%] [G loss: 0.693501] [Time: 0.150342]\n",
            "4673-8 [D loss: 0.699161, acc.: 38.46%] [G loss: 0.695314] [Time: 0.151166]\n",
            "4673 (test) [D loss: 0.909831, acc.: 48.08%] [G loss: 0.812245] [Time: 0.043947]\n",
            "4674-0 [D loss: 0.679092, acc.: 48.08%] [G loss: 0.719655] [Time: 0.148298]\n",
            "4674-1 [D loss: 0.697912, acc.: 46.15%] [G loss: 0.695520] [Time: 0.155532]\n",
            "4674-2 [D loss: 0.696685, acc.: 50.00%] [G loss: 0.712219] [Time: 0.150904]\n",
            "4674-3 [D loss: 0.682144, acc.: 48.08%] [G loss: 0.763641] [Time: 0.148138]\n",
            "4674-4 [D loss: 0.707198, acc.: 32.69%] [G loss: 0.720817] [Time: 0.147533]\n",
            "4674-5 [D loss: 0.701319, acc.: 36.54%] [G loss: 0.707837] [Time: 0.148549]\n",
            "4674-6 [D loss: 0.706093, acc.: 44.23%] [G loss: 0.710240] [Time: 0.151405]\n",
            "4674-7 [D loss: 0.696576, acc.: 44.23%] [G loss: 0.713184] [Time: 0.150602]\n",
            "4674-8 [D loss: 0.711980, acc.: 34.62%] [G loss: 0.700645] [Time: 0.152760]\n",
            "4674 (test) [D loss: 0.899839, acc.: 50.00%] [G loss: 0.840581] [Time: 0.045931]\n",
            "4675-0 [D loss: 0.692570, acc.: 40.38%] [G loss: 0.737535] [Time: 0.153746]\n",
            "4675-1 [D loss: 0.701034, acc.: 34.62%] [G loss: 0.699901] [Time: 0.148376]\n",
            "4675-2 [D loss: 0.700771, acc.: 46.15%] [G loss: 0.700090] [Time: 0.148239]\n",
            "4675-3 [D loss: 0.686655, acc.: 50.00%] [G loss: 0.753183] [Time: 0.149393]\n",
            "4675-4 [D loss: 0.702346, acc.: 40.38%] [G loss: 0.707216] [Time: 0.147627]\n",
            "4675-5 [D loss: 0.685518, acc.: 50.00%] [G loss: 0.711897] [Time: 0.149817]\n",
            "4675-6 [D loss: 0.698622, acc.: 44.23%] [G loss: 0.711997] [Time: 0.147963]\n",
            "4675-7 [D loss: 0.711222, acc.: 36.54%] [G loss: 0.694465] [Time: 0.149636]\n",
            "4675-8 [D loss: 0.715485, acc.: 42.31%] [G loss: 0.691927] [Time: 0.150611]\n",
            "4675 (test) [D loss: 0.913540, acc.: 50.00%] [G loss: 0.700556] [Time: 0.043235]\n",
            "4676-0 [D loss: 0.687498, acc.: 46.15%] [G loss: 0.743354] [Time: 0.147302]\n",
            "4676-1 [D loss: 0.704988, acc.: 36.54%] [G loss: 0.704999] [Time: 0.149652]\n",
            "4676-2 [D loss: 0.700737, acc.: 38.46%] [G loss: 0.689731] [Time: 0.147604]\n",
            "4676-3 [D loss: 0.683833, acc.: 46.15%] [G loss: 0.710181] [Time: 0.149228]\n",
            "4676-4 [D loss: 0.694585, acc.: 38.46%] [G loss: 0.705465] [Time: 0.148615]\n",
            "4676-5 [D loss: 0.694416, acc.: 36.54%] [G loss: 0.708456] [Time: 0.149319]\n",
            "4676-6 [D loss: 0.691873, acc.: 46.15%] [G loss: 0.702175] [Time: 0.153358]\n",
            "4676-7 [D loss: 0.704425, acc.: 40.38%] [G loss: 0.700670] [Time: 0.150864]\n",
            "4676-8 [D loss: 0.702343, acc.: 38.46%] [G loss: 0.702197] [Time: 0.148887]\n",
            "4676 (test) [D loss: 0.928086, acc.: 50.00%] [G loss: 0.623358] [Time: 0.044311]\n",
            "4677-0 [D loss: 0.674673, acc.: 48.08%] [G loss: 0.731927] [Time: 0.149925]\n",
            "4677-1 [D loss: 0.695754, acc.: 48.08%] [G loss: 0.683892] [Time: 0.149219]\n",
            "4677-2 [D loss: 0.715348, acc.: 30.77%] [G loss: 0.684705] [Time: 0.148519]\n",
            "4677-3 [D loss: 0.686752, acc.: 55.77%] [G loss: 0.723715] [Time: 0.152126]\n",
            "4677-4 [D loss: 0.707956, acc.: 36.54%] [G loss: 0.703259] [Time: 0.148483]\n",
            "4677-5 [D loss: 0.678465, acc.: 46.15%] [G loss: 0.694366] [Time: 0.150529]\n",
            "4677-6 [D loss: 0.686189, acc.: 46.15%] [G loss: 0.723143] [Time: 0.147226]\n",
            "4677-7 [D loss: 0.708432, acc.: 34.62%] [G loss: 0.703846] [Time: 0.147497]\n",
            "4677-8 [D loss: 0.718116, acc.: 48.08%] [G loss: 0.706266] [Time: 0.148741]\n",
            "4677 (test) [D loss: 0.898883, acc.: 48.08%] [G loss: 0.757272] [Time: 0.043767]\n",
            "4678-0 [D loss: 0.682899, acc.: 44.23%] [G loss: 0.707553] [Time: 0.149661]\n",
            "4678-1 [D loss: 0.697151, acc.: 46.15%] [G loss: 0.713997] [Time: 0.150397]\n",
            "4678-2 [D loss: 0.691614, acc.: 44.23%] [G loss: 0.704400] [Time: 0.147701]\n",
            "4678-3 [D loss: 0.672894, acc.: 53.85%] [G loss: 0.722687] [Time: 0.149148]\n",
            "4678-4 [D loss: 0.710659, acc.: 28.85%] [G loss: 0.703186] [Time: 0.148562]\n",
            "4678-5 [D loss: 0.679145, acc.: 38.46%] [G loss: 0.730942] [Time: 0.147684]\n",
            "4678-6 [D loss: 0.694896, acc.: 42.31%] [G loss: 0.720053] [Time: 0.149628]\n",
            "4678-7 [D loss: 0.703041, acc.: 44.23%] [G loss: 0.692377] [Time: 0.147586]\n",
            "4678-8 [D loss: 0.698117, acc.: 40.38%] [G loss: 0.717964] [Time: 0.151366]\n",
            "4678 (test) [D loss: 0.902911, acc.: 48.08%] [G loss: 1.016742] [Time: 0.045542]\n",
            "4679-0 [D loss: 0.682265, acc.: 44.23%] [G loss: 0.759106] [Time: 0.151392]\n",
            "4679-1 [D loss: 0.694678, acc.: 48.08%] [G loss: 0.704911] [Time: 0.147646]\n",
            "4679-2 [D loss: 0.700868, acc.: 34.62%] [G loss: 0.691650] [Time: 0.146729]\n",
            "4679-3 [D loss: 0.668516, acc.: 61.54%] [G loss: 0.744692] [Time: 0.148355]\n",
            "4679-4 [D loss: 0.709386, acc.: 44.23%] [G loss: 0.702896] [Time: 0.152104]\n",
            "4679-5 [D loss: 0.681467, acc.: 48.08%] [G loss: 0.716881] [Time: 0.147375]\n",
            "4679-6 [D loss: 0.703001, acc.: 59.62%] [G loss: 0.707620] [Time: 0.149752]\n",
            "4679-7 [D loss: 0.697981, acc.: 50.00%] [G loss: 0.685233] [Time: 0.147916]\n",
            "4679-8 [D loss: 0.699496, acc.: 46.15%] [G loss: 0.704717] [Time: 0.147541]\n",
            "4679 (test) [D loss: 0.911359, acc.: 50.00%] [G loss: 0.700115] [Time: 0.043343]\n",
            "4680-0 [D loss: 0.680706, acc.: 48.08%] [G loss: 0.731318] [Time: 0.149032]\n",
            "4680-1 [D loss: 0.708243, acc.: 40.38%] [G loss: 0.697109] [Time: 0.150390]\n",
            "4680-2 [D loss: 0.707692, acc.: 38.46%] [G loss: 0.686285] [Time: 0.149984]\n",
            "4680-3 [D loss: 0.675405, acc.: 46.15%] [G loss: 0.741877] [Time: 0.151601]\n",
            "4680-4 [D loss: 0.701162, acc.: 42.31%] [G loss: 0.698727] [Time: 0.148034]\n",
            "4680-5 [D loss: 0.675545, acc.: 46.15%] [G loss: 0.697362] [Time: 0.148510]\n",
            "4680-6 [D loss: 0.700271, acc.: 40.38%] [G loss: 0.713017] [Time: 0.147911]\n",
            "4680-7 [D loss: 0.693614, acc.: 51.92%] [G loss: 0.687653] [Time: 0.149616]\n",
            "4680-8 [D loss: 0.709785, acc.: 34.62%] [G loss: 0.695609] [Time: 0.149164]\n",
            "4680 (test) [D loss: 0.885340, acc.: 46.15%] [G loss: 0.994051] [Time: 0.043183]\n",
            "4681-0 [D loss: 0.682831, acc.: 53.85%] [G loss: 0.756808] [Time: 0.148306]\n",
            "4681-1 [D loss: 0.716053, acc.: 36.54%] [G loss: 0.700816] [Time: 0.150110]\n",
            "4681-2 [D loss: 0.707150, acc.: 38.46%] [G loss: 0.706298] [Time: 0.147585]\n",
            "4681-3 [D loss: 0.672816, acc.: 48.08%] [G loss: 0.726389] [Time: 0.147588]\n",
            "4681-4 [D loss: 0.704223, acc.: 42.31%] [G loss: 0.723216] [Time: 0.147520]\n",
            "4681-5 [D loss: 0.669344, acc.: 46.15%] [G loss: 0.705172] [Time: 0.152685]\n",
            "4681-6 [D loss: 0.694934, acc.: 44.23%] [G loss: 0.726231] [Time: 0.148326]\n",
            "4681-7 [D loss: 0.698217, acc.: 46.15%] [G loss: 0.701928] [Time: 0.147483]\n",
            "4681-8 [D loss: 0.699989, acc.: 44.23%] [G loss: 0.709560] [Time: 0.149068]\n",
            "4681 (test) [D loss: 0.897431, acc.: 48.08%] [G loss: 0.933076] [Time: 0.043919]\n",
            "4682-0 [D loss: 0.665205, acc.: 50.00%] [G loss: 0.732972] [Time: 0.148360]\n",
            "4682-1 [D loss: 0.704866, acc.: 38.46%] [G loss: 0.705580] [Time: 0.147759]\n",
            "4682-2 [D loss: 0.705679, acc.: 46.15%] [G loss: 0.709788] [Time: 0.147989]\n",
            "4682-3 [D loss: 0.680231, acc.: 50.00%] [G loss: 0.732499] [Time: 0.146904]\n",
            "4682-4 [D loss: 0.691384, acc.: 44.23%] [G loss: 0.714970] [Time: 0.146538]\n",
            "4682-5 [D loss: 0.671799, acc.: 46.15%] [G loss: 0.712704] [Time: 0.148622]\n",
            "4682-6 [D loss: 0.703554, acc.: 50.00%] [G loss: 0.701510] [Time: 0.147351]\n",
            "4682-7 [D loss: 0.707746, acc.: 34.62%] [G loss: 0.702280] [Time: 0.147335]\n",
            "4682-8 [D loss: 0.702394, acc.: 34.62%] [G loss: 0.701793] [Time: 0.150831]\n",
            "4682 (test) [D loss: 0.892509, acc.: 50.00%] [G loss: 0.797937] [Time: 0.044318]\n",
            "4683-0 [D loss: 0.686406, acc.: 48.08%] [G loss: 0.740152] [Time: 0.147665]\n",
            "4683-1 [D loss: 0.707041, acc.: 44.23%] [G loss: 0.699969] [Time: 0.148721]\n",
            "4683-2 [D loss: 0.718308, acc.: 48.08%] [G loss: 0.711626] [Time: 0.148740]\n",
            "4683-3 [D loss: 0.674792, acc.: 48.08%] [G loss: 0.760324] [Time: 0.147702]\n",
            "4683-4 [D loss: 0.709958, acc.: 34.62%] [G loss: 0.702569] [Time: 0.150011]\n",
            "4683-5 [D loss: 0.681389, acc.: 42.31%] [G loss: 0.711623] [Time: 0.148096]\n",
            "4683-6 [D loss: 0.702698, acc.: 42.31%] [G loss: 0.716968] [Time: 0.148717]\n",
            "4683-7 [D loss: 0.703071, acc.: 46.15%] [G loss: 0.708888] [Time: 0.148924]\n",
            "4683-8 [D loss: 0.694450, acc.: 50.00%] [G loss: 0.700144] [Time: 0.147899]\n",
            "4683 (test) [D loss: 0.905369, acc.: 50.00%] [G loss: 0.746979] [Time: 0.044217]\n",
            "4684-0 [D loss: 0.671775, acc.: 50.00%] [G loss: 0.734357] [Time: 0.147512]\n",
            "4684-1 [D loss: 0.706926, acc.: 44.23%] [G loss: 0.697888] [Time: 0.149321]\n",
            "4684-2 [D loss: 0.699431, acc.: 44.23%] [G loss: 0.715613] [Time: 0.151719]\n",
            "4684-3 [D loss: 0.676793, acc.: 55.77%] [G loss: 0.714091] [Time: 0.148747]\n",
            "4684-4 [D loss: 0.712984, acc.: 40.38%] [G loss: 0.715112] [Time: 0.149052]\n",
            "4684-5 [D loss: 0.684462, acc.: 36.54%] [G loss: 0.692227] [Time: 0.151417]\n",
            "4684-6 [D loss: 0.698981, acc.: 38.46%] [G loss: 0.710042] [Time: 0.146865]\n",
            "4684-7 [D loss: 0.709197, acc.: 38.46%] [G loss: 0.710824] [Time: 0.147569]\n",
            "4684-8 [D loss: 0.702613, acc.: 44.23%] [G loss: 0.694235] [Time: 0.149490]\n",
            "4684 (test) [D loss: 0.889009, acc.: 50.00%] [G loss: 0.749036] [Time: 0.045216]\n",
            "4685-0 [D loss: 0.678076, acc.: 53.85%] [G loss: 0.726596] [Time: 0.151698]\n",
            "4685-1 [D loss: 0.701400, acc.: 38.46%] [G loss: 0.691125] [Time: 0.151149]\n",
            "4685-2 [D loss: 0.701678, acc.: 40.38%] [G loss: 0.693799] [Time: 0.148486]\n",
            "4685-3 [D loss: 0.683372, acc.: 50.00%] [G loss: 0.712238] [Time: 0.147310]\n",
            "4685-4 [D loss: 0.700582, acc.: 46.15%] [G loss: 0.710367] [Time: 0.148203]\n",
            "4685-5 [D loss: 0.676505, acc.: 48.08%] [G loss: 0.694824] [Time: 0.153011]\n",
            "4685-6 [D loss: 0.692738, acc.: 48.08%] [G loss: 0.699788] [Time: 0.150775]\n",
            "4685-7 [D loss: 0.695458, acc.: 50.00%] [G loss: 0.687140] [Time: 0.148499]\n",
            "4685-8 [D loss: 0.709403, acc.: 40.38%] [G loss: 0.696896] [Time: 0.148794]\n",
            "4685 (test) [D loss: 0.927849, acc.: 50.00%] [G loss: 0.610520] [Time: 0.043580]\n",
            "4686-0 [D loss: 0.670055, acc.: 59.62%] [G loss: 0.733321] [Time: 0.153919]\n",
            "4686-1 [D loss: 0.698211, acc.: 44.23%] [G loss: 0.679246] [Time: 0.147872]\n",
            "4686-2 [D loss: 0.698645, acc.: 42.31%] [G loss: 0.715008] [Time: 0.148372]\n",
            "4686-3 [D loss: 0.677761, acc.: 59.62%] [G loss: 0.725813] [Time: 0.148883]\n",
            "4686-4 [D loss: 0.709115, acc.: 38.46%] [G loss: 0.682938] [Time: 0.150676]\n",
            "4686-5 [D loss: 0.673821, acc.: 50.00%] [G loss: 0.702847] [Time: 0.146875]\n",
            "4686-6 [D loss: 0.696408, acc.: 42.31%] [G loss: 0.711589] [Time: 0.151740]\n",
            "4686-7 [D loss: 0.706452, acc.: 32.69%] [G loss: 0.690513] [Time: 0.149494]\n",
            "4686-8 [D loss: 0.700955, acc.: 36.54%] [G loss: 0.721844] [Time: 0.148871]\n",
            "4686 (test) [D loss: 0.953378, acc.: 50.00%] [G loss: 0.518639] [Time: 0.044658]\n",
            "4687-0 [D loss: 0.682894, acc.: 48.08%] [G loss: 0.749246] [Time: 0.147984]\n",
            "4687-1 [D loss: 0.705771, acc.: 40.38%] [G loss: 0.691024] [Time: 0.146759]\n",
            "4687-2 [D loss: 0.718653, acc.: 34.62%] [G loss: 0.690331] [Time: 0.147425]\n",
            "4687-3 [D loss: 0.669908, acc.: 61.54%] [G loss: 0.753128] [Time: 0.149280]\n",
            "4687-4 [D loss: 0.723327, acc.: 28.85%] [G loss: 0.691507] [Time: 0.147768]\n",
            "4687-5 [D loss: 0.684569, acc.: 38.46%] [G loss: 0.726831] [Time: 0.149210]\n",
            "4687-6 [D loss: 0.686843, acc.: 51.92%] [G loss: 0.713054] [Time: 0.148259]\n",
            "4687-7 [D loss: 0.705960, acc.: 46.15%] [G loss: 0.690353] [Time: 0.147346]\n",
            "4687-8 [D loss: 0.712171, acc.: 50.00%] [G loss: 0.692288] [Time: 0.148329]\n",
            "4687 (test) [D loss: 0.899318, acc.: 50.00%] [G loss: 0.726842] [Time: 0.044704]\n",
            "4688-0 [D loss: 0.683949, acc.: 48.08%] [G loss: 0.729272] [Time: 0.148832]\n",
            "4688-1 [D loss: 0.712209, acc.: 42.31%] [G loss: 0.694087] [Time: 0.152797]\n",
            "4688-2 [D loss: 0.698125, acc.: 46.15%] [G loss: 0.713215] [Time: 0.160258]\n",
            "4688-3 [D loss: 0.661364, acc.: 53.85%] [G loss: 0.758711] [Time: 0.147844]\n",
            "4688-4 [D loss: 0.704547, acc.: 44.23%] [G loss: 0.709443] [Time: 0.149532]\n",
            "4688-5 [D loss: 0.679329, acc.: 38.46%] [G loss: 0.727026] [Time: 0.148175]\n",
            "4688-6 [D loss: 0.688591, acc.: 50.00%] [G loss: 0.715628] [Time: 0.149357]\n",
            "4688-7 [D loss: 0.703241, acc.: 46.15%] [G loss: 0.697307] [Time: 0.151178]\n",
            "4688-8 [D loss: 0.710977, acc.: 42.31%] [G loss: 0.712626] [Time: 0.150696]\n",
            "4688 (test) [D loss: 0.907909, acc.: 44.23%] [G loss: 0.951953] [Time: 0.043895]\n",
            "4689-0 [D loss: 0.679616, acc.: 46.15%] [G loss: 0.757333] [Time: 0.150233]\n",
            "4689-1 [D loss: 0.700703, acc.: 42.31%] [G loss: 0.713914] [Time: 0.149256]\n",
            "4689-2 [D loss: 0.699770, acc.: 46.15%] [G loss: 0.700285] [Time: 0.148242]\n",
            "4689-3 [D loss: 0.671361, acc.: 59.62%] [G loss: 0.732155] [Time: 0.150192]\n",
            "4689-4 [D loss: 0.702129, acc.: 36.54%] [G loss: 0.707954] [Time: 0.150142]\n",
            "4689-5 [D loss: 0.674537, acc.: 42.31%] [G loss: 0.717855] [Time: 0.154539]\n",
            "4689-6 [D loss: 0.694336, acc.: 50.00%] [G loss: 0.706112] [Time: 0.146676]\n",
            "4689-7 [D loss: 0.704063, acc.: 51.92%] [G loss: 0.708801] [Time: 0.147782]\n",
            "4689-8 [D loss: 0.703328, acc.: 40.38%] [G loss: 0.708643] [Time: 0.151835]\n",
            "4689 (test) [D loss: 0.906137, acc.: 46.15%] [G loss: 0.778540] [Time: 0.043098]\n",
            "4690-0 [D loss: 0.672917, acc.: 46.15%] [G loss: 0.754526] [Time: 0.147481]\n",
            "4690-1 [D loss: 0.701066, acc.: 40.38%] [G loss: 0.699796] [Time: 0.150902]\n",
            "4690-2 [D loss: 0.697513, acc.: 36.54%] [G loss: 0.684834] [Time: 0.148130]\n",
            "4690-3 [D loss: 0.665020, acc.: 55.77%] [G loss: 0.715182] [Time: 0.147753]\n",
            "4690-4 [D loss: 0.706881, acc.: 30.77%] [G loss: 0.700121] [Time: 0.149756]\n",
            "4690-5 [D loss: 0.675492, acc.: 44.23%] [G loss: 0.719172] [Time: 0.148251]\n",
            "4690-6 [D loss: 0.681833, acc.: 55.77%] [G loss: 0.710195] [Time: 0.147084]\n",
            "4690-7 [D loss: 0.694790, acc.: 40.38%] [G loss: 0.684700] [Time: 0.149487]\n",
            "4690-8 [D loss: 0.698307, acc.: 50.00%] [G loss: 0.730110] [Time: 0.150627]\n",
            "4690 (test) [D loss: 0.906980, acc.: 48.08%] [G loss: 0.745388] [Time: 0.042830]\n",
            "4691-0 [D loss: 0.670101, acc.: 51.92%] [G loss: 0.753629] [Time: 0.147866]\n",
            "4691-1 [D loss: 0.693845, acc.: 44.23%] [G loss: 0.693184] [Time: 0.147812]\n",
            "4691-2 [D loss: 0.694253, acc.: 40.38%] [G loss: 0.709764] [Time: 0.147293]\n",
            "4691-3 [D loss: 0.674609, acc.: 46.15%] [G loss: 0.745244] [Time: 0.149361]\n",
            "4691-4 [D loss: 0.696200, acc.: 36.54%] [G loss: 0.709267] [Time: 0.147253]\n",
            "4691-5 [D loss: 0.686285, acc.: 44.23%] [G loss: 0.709198] [Time: 0.152155]\n",
            "4691-6 [D loss: 0.714742, acc.: 51.92%] [G loss: 0.713688] [Time: 0.151357]\n",
            "4691-7 [D loss: 0.700832, acc.: 42.31%] [G loss: 0.682639] [Time: 0.146889]\n",
            "4691-8 [D loss: 0.708107, acc.: 51.92%] [G loss: 0.692438] [Time: 0.148416]\n",
            "4691 (test) [D loss: 0.914262, acc.: 48.08%] [G loss: 0.727005] [Time: 0.044317]\n",
            "4692-0 [D loss: 0.685929, acc.: 48.08%] [G loss: 0.746149] [Time: 0.147381]\n",
            "4692-1 [D loss: 0.697226, acc.: 50.00%] [G loss: 0.691677] [Time: 0.152090]\n",
            "4692-2 [D loss: 0.693606, acc.: 38.46%] [G loss: 0.702536] [Time: 0.149961]\n",
            "4692-3 [D loss: 0.680773, acc.: 40.38%] [G loss: 0.727559] [Time: 0.147410]\n",
            "4692-4 [D loss: 0.700803, acc.: 42.31%] [G loss: 0.711708] [Time: 0.149038]\n",
            "4692-5 [D loss: 0.686707, acc.: 38.46%] [G loss: 0.727106] [Time: 0.147481]\n",
            "4692-6 [D loss: 0.687382, acc.: 51.92%] [G loss: 0.713775] [Time: 0.148830]\n",
            "4692-7 [D loss: 0.696562, acc.: 38.46%] [G loss: 0.710066] [Time: 0.148174]\n",
            "4692-8 [D loss: 0.710094, acc.: 34.62%] [G loss: 0.694267] [Time: 0.150453]\n",
            "4692 (test) [D loss: 0.902160, acc.: 48.08%] [G loss: 0.759318] [Time: 0.044494]\n",
            "4693-0 [D loss: 0.656889, acc.: 65.38%] [G loss: 0.764814] [Time: 0.148699]\n",
            "4693-1 [D loss: 0.701070, acc.: 46.15%] [G loss: 0.695999] [Time: 0.150890]\n",
            "4693-2 [D loss: 0.695911, acc.: 40.38%] [G loss: 0.707563] [Time: 0.149044]\n",
            "4693-3 [D loss: 0.684092, acc.: 51.92%] [G loss: 0.738687] [Time: 0.147617]\n",
            "4693-4 [D loss: 0.716689, acc.: 30.77%] [G loss: 0.682757] [Time: 0.147348]\n",
            "4693-5 [D loss: 0.696520, acc.: 42.31%] [G loss: 0.721252] [Time: 0.150288]\n",
            "4693-6 [D loss: 0.695876, acc.: 51.92%] [G loss: 0.724266] [Time: 0.147681]\n",
            "4693-7 [D loss: 0.698899, acc.: 48.08%] [G loss: 0.696234] [Time: 0.150073]\n",
            "4693-8 [D loss: 0.687826, acc.: 40.38%] [G loss: 0.711222] [Time: 0.147057]\n",
            "4693 (test) [D loss: 0.910430, acc.: 50.00%] [G loss: 0.743972] [Time: 0.045071]\n",
            "4694-0 [D loss: 0.683125, acc.: 55.77%] [G loss: 0.741345] [Time: 0.147187]\n",
            "4694-1 [D loss: 0.698724, acc.: 48.08%] [G loss: 0.707764] [Time: 0.147129]\n",
            "4694-2 [D loss: 0.706005, acc.: 40.38%] [G loss: 0.699465] [Time: 0.158041]\n",
            "4694-3 [D loss: 0.668779, acc.: 50.00%] [G loss: 0.737948] [Time: 0.148224]\n",
            "4694-4 [D loss: 0.697427, acc.: 51.92%] [G loss: 0.703438] [Time: 0.147941]\n",
            "4694-5 [D loss: 0.670094, acc.: 46.15%] [G loss: 0.703746] [Time: 0.152058]\n",
            "4694-6 [D loss: 0.705315, acc.: 53.85%] [G loss: 0.726953] [Time: 0.147732]\n",
            "4694-7 [D loss: 0.703255, acc.: 48.08%] [G loss: 0.696975] [Time: 0.148443]\n",
            "4694-8 [D loss: 0.697134, acc.: 48.08%] [G loss: 0.699865] [Time: 0.147518]\n",
            "4694 (test) [D loss: 0.895132, acc.: 48.08%] [G loss: 0.844061] [Time: 0.042967]\n",
            "4695-0 [D loss: 0.675765, acc.: 55.77%] [G loss: 0.774778] [Time: 0.147871]\n",
            "4695-1 [D loss: 0.713238, acc.: 42.31%] [G loss: 0.690082] [Time: 0.152469]\n",
            "4695-2 [D loss: 0.707666, acc.: 40.38%] [G loss: 0.699613] [Time: 0.148550]\n",
            "4695-3 [D loss: 0.664762, acc.: 53.85%] [G loss: 0.728342] [Time: 0.150067]\n",
            "4695-4 [D loss: 0.711178, acc.: 42.31%] [G loss: 0.704832] [Time: 0.148000]\n",
            "4695-5 [D loss: 0.679998, acc.: 32.69%] [G loss: 0.721762] [Time: 0.151102]\n",
            "4695-6 [D loss: 0.687035, acc.: 36.54%] [G loss: 0.712842] [Time: 0.149816]\n",
            "4695-7 [D loss: 0.709488, acc.: 36.54%] [G loss: 0.715682] [Time: 0.146988]\n",
            "4695-8 [D loss: 0.700819, acc.: 44.23%] [G loss: 0.688270] [Time: 0.147656]\n",
            "4695 (test) [D loss: 0.893373, acc.: 48.08%] [G loss: 0.743651] [Time: 0.043375]\n",
            "4696-0 [D loss: 0.689694, acc.: 40.38%] [G loss: 0.736902] [Time: 0.151857]\n",
            "4696-1 [D loss: 0.698956, acc.: 32.69%] [G loss: 0.713524] [Time: 0.148496]\n",
            "4696-2 [D loss: 0.700318, acc.: 32.69%] [G loss: 0.692928] [Time: 0.149330]\n",
            "4696-3 [D loss: 0.669518, acc.: 55.77%] [G loss: 0.725979] [Time: 0.153145]\n",
            "4696-4 [D loss: 0.696580, acc.: 38.46%] [G loss: 0.705598] [Time: 0.146534]\n",
            "4696-5 [D loss: 0.688345, acc.: 50.00%] [G loss: 0.706815] [Time: 0.149558]\n",
            "4696-6 [D loss: 0.695647, acc.: 53.85%] [G loss: 0.718494] [Time: 0.150672]\n",
            "4696-7 [D loss: 0.704733, acc.: 55.77%] [G loss: 0.715140] [Time: 0.149903]\n",
            "4696-8 [D loss: 0.715799, acc.: 32.69%] [G loss: 0.716027] [Time: 0.150595]\n",
            "4696 (test) [D loss: 0.950849, acc.: 48.08%] [G loss: 0.597331] [Time: 0.043352]\n",
            "4697-0 [D loss: 0.679914, acc.: 53.85%] [G loss: 0.751111] [Time: 0.148384]\n",
            "4697-1 [D loss: 0.701959, acc.: 40.38%] [G loss: 0.697502] [Time: 0.150697]\n",
            "4697-2 [D loss: 0.701874, acc.: 40.38%] [G loss: 0.687176] [Time: 0.148204]\n",
            "4697-3 [D loss: 0.672043, acc.: 55.77%] [G loss: 0.703305] [Time: 0.149669]\n",
            "4697-4 [D loss: 0.701308, acc.: 42.31%] [G loss: 0.703377] [Time: 0.147901]\n",
            "4697-5 [D loss: 0.672168, acc.: 59.62%] [G loss: 0.710081] [Time: 0.149406]\n",
            "4697-6 [D loss: 0.694317, acc.: 57.69%] [G loss: 0.710568] [Time: 0.148196]\n",
            "4697-7 [D loss: 0.694023, acc.: 48.08%] [G loss: 0.688309] [Time: 0.147539]\n",
            "4697-8 [D loss: 0.700349, acc.: 38.46%] [G loss: 0.683061] [Time: 0.149187]\n",
            "4697 (test) [D loss: 0.896340, acc.: 50.00%] [G loss: 0.784898] [Time: 0.043549]\n",
            "4698-0 [D loss: 0.675210, acc.: 57.69%] [G loss: 0.764478] [Time: 0.148413]\n",
            "4698-1 [D loss: 0.707358, acc.: 34.62%] [G loss: 0.693916] [Time: 0.147619]\n",
            "4698-2 [D loss: 0.701581, acc.: 51.92%] [G loss: 0.702650] [Time: 0.150546]\n",
            "4698-3 [D loss: 0.666048, acc.: 57.69%] [G loss: 0.720633] [Time: 0.150161]\n",
            "4698-4 [D loss: 0.701431, acc.: 53.85%] [G loss: 0.701444] [Time: 0.147509]\n",
            "4698-5 [D loss: 0.699639, acc.: 38.46%] [G loss: 0.717379] [Time: 0.150103]\n",
            "4698-6 [D loss: 0.707376, acc.: 51.92%] [G loss: 0.722875] [Time: 0.148424]\n",
            "4698-7 [D loss: 0.695711, acc.: 50.00%] [G loss: 0.718457] [Time: 0.149495]\n",
            "4698-8 [D loss: 0.687433, acc.: 42.31%] [G loss: 0.709203] [Time: 0.148609]\n",
            "4698 (test) [D loss: 0.913586, acc.: 46.15%] [G loss: 0.730849] [Time: 0.043464]\n",
            "4699-0 [D loss: 0.682720, acc.: 50.00%] [G loss: 0.759797] [Time: 0.147552]\n",
            "4699-1 [D loss: 0.700585, acc.: 46.15%] [G loss: 0.696450] [Time: 0.149415]\n",
            "4699-2 [D loss: 0.705359, acc.: 44.23%] [G loss: 0.725305] [Time: 0.151356]\n",
            "4699-3 [D loss: 0.682787, acc.: 53.85%] [G loss: 0.741700] [Time: 0.151151]\n",
            "4699-4 [D loss: 0.689523, acc.: 48.08%] [G loss: 0.714431] [Time: 0.149843]\n",
            "4699-5 [D loss: 0.693249, acc.: 34.62%] [G loss: 0.716015] [Time: 0.149066]\n",
            "4699-6 [D loss: 0.695849, acc.: 42.31%] [G loss: 0.736141] [Time: 0.149355]\n",
            "4699-7 [D loss: 0.703124, acc.: 46.15%] [G loss: 0.702305] [Time: 0.147970]\n",
            "4699-8 [D loss: 0.717690, acc.: 44.23%] [G loss: 0.731835] [Time: 0.149407]\n",
            "4699 (test) [D loss: 0.896048, acc.: 48.08%] [G loss: 1.005930] [Time: 0.044685]\n",
            "4700-0 [D loss: 0.674330, acc.: 51.92%] [G loss: 0.762253] [Time: 0.149182]\n",
            "4700-1 [D loss: 0.709233, acc.: 40.38%] [G loss: 0.693706] [Time: 0.149834]\n",
            "4700-2 [D loss: 0.715240, acc.: 40.38%] [G loss: 0.698192] [Time: 0.150920]\n",
            "4700-3 [D loss: 0.666650, acc.: 59.62%] [G loss: 0.719880] [Time: 0.149925]\n",
            "4700-4 [D loss: 0.713608, acc.: 21.15%] [G loss: 0.715895] [Time: 0.151149]\n",
            "4700-5 [D loss: 0.672500, acc.: 51.92%] [G loss: 0.709476] [Time: 0.153913]\n",
            "4700-6 [D loss: 0.701493, acc.: 42.31%] [G loss: 0.725413] [Time: 0.148673]\n",
            "4700-7 [D loss: 0.694926, acc.: 42.31%] [G loss: 0.706517] [Time: 0.147663]\n",
            "4700-8 [D loss: 0.698538, acc.: 42.31%] [G loss: 0.706440] [Time: 0.153388]\n",
            "4700 (test) [D loss: 0.901426, acc.: 50.00%] [G loss: 0.751075] [Time: 0.044984]\n",
            "4701-0 [D loss: 0.675842, acc.: 50.00%] [G loss: 0.729750] [Time: 0.147285]\n",
            "4701-1 [D loss: 0.703890, acc.: 34.62%] [G loss: 0.698172] [Time: 0.146785]\n",
            "4701-2 [D loss: 0.700670, acc.: 34.62%] [G loss: 0.685044] [Time: 0.148416]\n",
            "4701-3 [D loss: 0.669029, acc.: 57.69%] [G loss: 0.749160] [Time: 0.150702]\n",
            "4701-4 [D loss: 0.723823, acc.: 34.62%] [G loss: 0.715498] [Time: 0.154610]\n",
            "4701-5 [D loss: 0.676102, acc.: 34.62%] [G loss: 0.692745] [Time: 0.151298]\n",
            "4701-6 [D loss: 0.697764, acc.: 40.38%] [G loss: 0.709425] [Time: 0.148107]\n",
            "4701-7 [D loss: 0.697484, acc.: 44.23%] [G loss: 0.697466] [Time: 0.152822]\n",
            "4701-8 [D loss: 0.696285, acc.: 48.08%] [G loss: 0.713796] [Time: 0.149504]\n",
            "4701 (test) [D loss: 0.911663, acc.: 50.00%] [G loss: 0.783934] [Time: 0.045413]\n",
            "4702-0 [D loss: 0.678260, acc.: 51.92%] [G loss: 0.746801] [Time: 0.146998]\n",
            "4702-1 [D loss: 0.699022, acc.: 36.54%] [G loss: 0.716033] [Time: 0.153045]\n",
            "4702-2 [D loss: 0.713864, acc.: 42.31%] [G loss: 0.711594] [Time: 0.148429]\n",
            "4702-3 [D loss: 0.682190, acc.: 48.08%] [G loss: 0.729945] [Time: 0.149326]\n",
            "4702-4 [D loss: 0.705890, acc.: 44.23%] [G loss: 0.699308] [Time: 0.148773]\n",
            "4702-5 [D loss: 0.685699, acc.: 30.77%] [G loss: 0.700725] [Time: 0.150063]\n",
            "4702-6 [D loss: 0.679647, acc.: 51.92%] [G loss: 0.709695] [Time: 0.150886]\n",
            "4702-7 [D loss: 0.694118, acc.: 48.08%] [G loss: 0.704898] [Time: 0.149642]\n",
            "4702-8 [D loss: 0.708650, acc.: 36.54%] [G loss: 0.704436] [Time: 0.148420]\n",
            "4702 (test) [D loss: 0.919050, acc.: 48.08%] [G loss: 0.796036] [Time: 0.043887]\n",
            "4703-0 [D loss: 0.667223, acc.: 55.77%] [G loss: 0.743498] [Time: 0.149922]\n",
            "4703-1 [D loss: 0.700443, acc.: 55.77%] [G loss: 0.698381] [Time: 0.150874]\n",
            "4703-2 [D loss: 0.704089, acc.: 32.69%] [G loss: 0.702912] [Time: 0.150223]\n",
            "4703-3 [D loss: 0.676691, acc.: 51.92%] [G loss: 0.733862] [Time: 0.148436]\n",
            "4703-4 [D loss: 0.689254, acc.: 50.00%] [G loss: 0.723963] [Time: 0.150670]\n",
            "4703-5 [D loss: 0.672581, acc.: 50.00%] [G loss: 0.734017] [Time: 0.147975]\n",
            "4703-6 [D loss: 0.688031, acc.: 48.08%] [G loss: 0.725407] [Time: 0.149414]\n",
            "4703-7 [D loss: 0.700653, acc.: 38.46%] [G loss: 0.679341] [Time: 0.149056]\n",
            "4703-8 [D loss: 0.702579, acc.: 40.38%] [G loss: 0.697259] [Time: 0.149340]\n",
            "4703 (test) [D loss: 0.912156, acc.: 48.08%] [G loss: 0.831893] [Time: 0.044788]\n",
            "4704-0 [D loss: 0.665820, acc.: 57.69%] [G loss: 0.737984] [Time: 0.148210]\n",
            "4704-1 [D loss: 0.698051, acc.: 48.08%] [G loss: 0.696456] [Time: 0.153229]\n",
            "4704-2 [D loss: 0.708912, acc.: 36.54%] [G loss: 0.683187] [Time: 0.149179]\n",
            "4704-3 [D loss: 0.681488, acc.: 57.69%] [G loss: 0.739764] [Time: 0.150515]\n",
            "4704-4 [D loss: 0.705452, acc.: 44.23%] [G loss: 0.717837] [Time: 0.147610]\n",
            "4704-5 [D loss: 0.687714, acc.: 38.46%] [G loss: 0.711655] [Time: 0.147670]\n",
            "4704-6 [D loss: 0.695627, acc.: 46.15%] [G loss: 0.716611] [Time: 0.149230]\n",
            "4704-7 [D loss: 0.710398, acc.: 40.38%] [G loss: 0.710139] [Time: 0.149637]\n",
            "4704-8 [D loss: 0.703804, acc.: 32.69%] [G loss: 0.699983] [Time: 0.149544]\n",
            "4704 (test) [D loss: 0.927606, acc.: 48.08%] [G loss: 0.693218] [Time: 0.044455]\n",
            "4705-0 [D loss: 0.688732, acc.: 48.08%] [G loss: 0.734615] [Time: 0.149615]\n",
            "4705-1 [D loss: 0.696183, acc.: 48.08%] [G loss: 0.691713] [Time: 0.148344]\n",
            "4705-2 [D loss: 0.710718, acc.: 36.54%] [G loss: 0.696075] [Time: 0.149113]\n",
            "4705-3 [D loss: 0.666707, acc.: 63.46%] [G loss: 0.712436] [Time: 0.153311]\n",
            "4705-4 [D loss: 0.709653, acc.: 48.08%] [G loss: 0.703991] [Time: 0.150280]\n",
            "4705-5 [D loss: 0.671084, acc.: 50.00%] [G loss: 0.718513] [Time: 0.147915]\n",
            "4705-6 [D loss: 0.699392, acc.: 42.31%] [G loss: 0.698561] [Time: 0.151042]\n",
            "4705-7 [D loss: 0.707134, acc.: 36.54%] [G loss: 0.691007] [Time: 0.151309]\n",
            "4705-8 [D loss: 0.698553, acc.: 48.08%] [G loss: 0.692843] [Time: 0.149101]\n",
            "4705 (test) [D loss: 0.920645, acc.: 46.15%] [G loss: 0.892092] [Time: 0.043665]\n",
            "4706-0 [D loss: 0.689184, acc.: 53.85%] [G loss: 0.731712] [Time: 0.148481]\n",
            "4706-1 [D loss: 0.701521, acc.: 30.77%] [G loss: 0.708687] [Time: 0.152421]\n",
            "4706-2 [D loss: 0.722231, acc.: 30.77%] [G loss: 0.695985] [Time: 0.148007]\n",
            "4706-3 [D loss: 0.672806, acc.: 48.08%] [G loss: 0.748659] [Time: 0.149020]\n",
            "4706-4 [D loss: 0.705304, acc.: 36.54%] [G loss: 0.728738] [Time: 0.150374]\n",
            "4706-5 [D loss: 0.682304, acc.: 46.15%] [G loss: 0.705320] [Time: 0.148646]\n",
            "4706-6 [D loss: 0.691116, acc.: 46.15%] [G loss: 0.717242] [Time: 0.147838]\n",
            "4706-7 [D loss: 0.695356, acc.: 40.38%] [G loss: 0.693575] [Time: 0.152249]\n",
            "4706-8 [D loss: 0.703573, acc.: 36.54%] [G loss: 0.704262] [Time: 0.149061]\n",
            "4706 (test) [D loss: 0.914004, acc.: 48.08%] [G loss: 0.948713] [Time: 0.044033]\n",
            "4707-0 [D loss: 0.679977, acc.: 55.77%] [G loss: 0.751371] [Time: 0.149841]\n",
            "4707-1 [D loss: 0.699051, acc.: 44.23%] [G loss: 0.714177] [Time: 0.147398]\n",
            "4707-2 [D loss: 0.707096, acc.: 40.38%] [G loss: 0.718102] [Time: 0.148399]\n",
            "4707-3 [D loss: 0.665569, acc.: 50.00%] [G loss: 0.745366] [Time: 0.152509]\n",
            "4707-4 [D loss: 0.701812, acc.: 44.23%] [G loss: 0.731365] [Time: 0.152292]\n",
            "4707-5 [D loss: 0.691026, acc.: 36.54%] [G loss: 0.736571] [Time: 0.152491]\n",
            "4707-6 [D loss: 0.698945, acc.: 40.38%] [G loss: 0.716175] [Time: 0.147836]\n",
            "4707-7 [D loss: 0.702232, acc.: 48.08%] [G loss: 0.701650] [Time: 0.149279]\n",
            "4707-8 [D loss: 0.701112, acc.: 50.00%] [G loss: 0.708043] [Time: 0.148029]\n",
            "4707 (test) [D loss: 0.934320, acc.: 50.00%] [G loss: 0.870767] [Time: 0.045185]\n",
            "4708-0 [D loss: 0.668888, acc.: 51.92%] [G loss: 0.750992] [Time: 0.151608]\n",
            "4708-1 [D loss: 0.700885, acc.: 38.46%] [G loss: 0.693178] [Time: 0.149873]\n",
            "4708-2 [D loss: 0.699801, acc.: 42.31%] [G loss: 0.724891] [Time: 0.150068]\n",
            "4708-3 [D loss: 0.679911, acc.: 48.08%] [G loss: 0.719684] [Time: 0.149163]\n",
            "4708-4 [D loss: 0.717363, acc.: 30.77%] [G loss: 0.710779] [Time: 0.149519]\n",
            "4708-5 [D loss: 0.688352, acc.: 44.23%] [G loss: 0.721344] [Time: 0.147846]\n",
            "4708-6 [D loss: 0.688078, acc.: 48.08%] [G loss: 0.713231] [Time: 0.148572]\n",
            "4708-7 [D loss: 0.699598, acc.: 38.46%] [G loss: 0.699817] [Time: 0.150954]\n",
            "4708-8 [D loss: 0.702987, acc.: 38.46%] [G loss: 0.714101] [Time: 0.148535]\n",
            "4708 (test) [D loss: 0.920511, acc.: 50.00%] [G loss: 0.789618] [Time: 0.045496]\n",
            "4709-0 [D loss: 0.671390, acc.: 46.15%] [G loss: 0.740851] [Time: 0.151809]\n",
            "4709-1 [D loss: 0.703720, acc.: 46.15%] [G loss: 0.696706] [Time: 0.151181]\n",
            "4709-2 [D loss: 0.707425, acc.: 48.08%] [G loss: 0.695639] [Time: 0.150507]\n",
            "4709-3 [D loss: 0.677860, acc.: 38.46%] [G loss: 0.726632] [Time: 0.150179]\n",
            "4709-4 [D loss: 0.704966, acc.: 42.31%] [G loss: 0.706017] [Time: 0.148162]\n",
            "4709-5 [D loss: 0.692749, acc.: 38.46%] [G loss: 0.694575] [Time: 0.148723]\n",
            "4709-6 [D loss: 0.692137, acc.: 34.62%] [G loss: 0.706399] [Time: 0.147210]\n",
            "4709-7 [D loss: 0.700485, acc.: 42.31%] [G loss: 0.693679] [Time: 0.147893]\n",
            "4709-8 [D loss: 0.727302, acc.: 28.85%] [G loss: 0.699522] [Time: 0.148536]\n",
            "4709 (test) [D loss: 0.947593, acc.: 50.00%] [G loss: 0.644309] [Time: 0.044874]\n",
            "4710-0 [D loss: 0.674005, acc.: 59.62%] [G loss: 0.744916] [Time: 0.146980]\n",
            "4710-1 [D loss: 0.703277, acc.: 40.38%] [G loss: 0.697713] [Time: 0.148030]\n",
            "4710-2 [D loss: 0.702829, acc.: 38.46%] [G loss: 0.665938] [Time: 0.149824]\n",
            "4710-3 [D loss: 0.681398, acc.: 53.85%] [G loss: 0.729322] [Time: 0.148569]\n",
            "4710-4 [D loss: 0.685192, acc.: 50.00%] [G loss: 0.684232] [Time: 0.152359]\n",
            "4710-5 [D loss: 0.679872, acc.: 46.15%] [G loss: 0.709039] [Time: 0.149213]\n",
            "4710-6 [D loss: 0.695068, acc.: 44.23%] [G loss: 0.699767] [Time: 0.148209]\n",
            "4710-7 [D loss: 0.706484, acc.: 48.08%] [G loss: 0.696885] [Time: 0.149566]\n",
            "4710-8 [D loss: 0.710589, acc.: 32.69%] [G loss: 0.697744] [Time: 0.147082]\n",
            "4710 (test) [D loss: 0.923300, acc.: 51.92%] [G loss: 0.792974] [Time: 0.043553]\n",
            "4711-0 [D loss: 0.669144, acc.: 57.69%] [G loss: 0.749539] [Time: 0.147927]\n",
            "4711-1 [D loss: 0.696605, acc.: 48.08%] [G loss: 0.695663] [Time: 0.148922]\n",
            "4711-2 [D loss: 0.704252, acc.: 32.69%] [G loss: 0.709437] [Time: 0.147500]\n",
            "4711-3 [D loss: 0.680740, acc.: 42.31%] [G loss: 0.718956] [Time: 0.146765]\n",
            "4711-4 [D loss: 0.701613, acc.: 34.62%] [G loss: 0.706571] [Time: 0.150805]\n",
            "4711-5 [D loss: 0.679043, acc.: 42.31%] [G loss: 0.723355] [Time: 0.149966]\n",
            "4711-6 [D loss: 0.692423, acc.: 34.62%] [G loss: 0.710443] [Time: 0.149538]\n",
            "4711-7 [D loss: 0.704237, acc.: 38.46%] [G loss: 0.712274] [Time: 0.150851]\n",
            "4711-8 [D loss: 0.697724, acc.: 38.46%] [G loss: 0.713725] [Time: 0.149117]\n",
            "4711 (test) [D loss: 0.922530, acc.: 48.08%] [G loss: 1.087816] [Time: 0.044821]\n",
            "4712-0 [D loss: 0.693522, acc.: 51.92%] [G loss: 0.745767] [Time: 0.156806]\n",
            "4712-1 [D loss: 0.708392, acc.: 40.38%] [G loss: 0.712551] [Time: 0.150995]\n",
            "4712-2 [D loss: 0.710425, acc.: 34.62%] [G loss: 0.730535] [Time: 0.148599]\n",
            "4712-3 [D loss: 0.673400, acc.: 53.85%] [G loss: 0.705316] [Time: 0.149130]\n",
            "4712-4 [D loss: 0.687710, acc.: 48.08%] [G loss: 0.720857] [Time: 0.146889]\n",
            "4712-5 [D loss: 0.674621, acc.: 44.23%] [G loss: 0.720253] [Time: 0.147329]\n",
            "4712-6 [D loss: 0.696935, acc.: 50.00%] [G loss: 0.742529] [Time: 0.151007]\n",
            "4712-7 [D loss: 0.702867, acc.: 44.23%] [G loss: 0.700062] [Time: 0.153363]\n",
            "4712-8 [D loss: 0.716749, acc.: 42.31%] [G loss: 0.698538] [Time: 0.149714]\n",
            "4712 (test) [D loss: 0.945442, acc.: 48.08%] [G loss: 0.818686] [Time: 0.045789]\n",
            "4713-0 [D loss: 0.674072, acc.: 55.77%] [G loss: 0.739006] [Time: 0.151085]\n",
            "4713-1 [D loss: 0.708470, acc.: 40.38%] [G loss: 0.698691] [Time: 0.151082]\n",
            "4713-2 [D loss: 0.703774, acc.: 38.46%] [G loss: 0.710166] [Time: 0.154350]\n",
            "4713-3 [D loss: 0.687088, acc.: 50.00%] [G loss: 0.743012] [Time: 0.153091]\n",
            "4713-4 [D loss: 0.701061, acc.: 50.00%] [G loss: 0.716679] [Time: 0.148325]\n",
            "4713-5 [D loss: 0.683840, acc.: 44.23%] [G loss: 0.693946] [Time: 0.149575]\n",
            "4713-6 [D loss: 0.700480, acc.: 38.46%] [G loss: 0.715899] [Time: 0.149846]\n",
            "4713-7 [D loss: 0.706175, acc.: 46.15%] [G loss: 0.686714] [Time: 0.150190]\n",
            "4713-8 [D loss: 0.708081, acc.: 46.15%] [G loss: 0.700913] [Time: 0.147696]\n",
            "4713 (test) [D loss: 0.930057, acc.: 50.00%] [G loss: 0.869034] [Time: 0.046268]\n",
            "4714-0 [D loss: 0.674631, acc.: 61.54%] [G loss: 0.750570] [Time: 0.154846]\n",
            "4714-1 [D loss: 0.703483, acc.: 38.46%] [G loss: 0.704401] [Time: 0.148248]\n",
            "4714-2 [D loss: 0.686684, acc.: 50.00%] [G loss: 0.693893] [Time: 0.146912]\n",
            "4714-3 [D loss: 0.668683, acc.: 50.00%] [G loss: 0.751405] [Time: 0.150481]\n",
            "4714-4 [D loss: 0.695442, acc.: 40.38%] [G loss: 0.724026] [Time: 0.151731]\n",
            "4714-5 [D loss: 0.678601, acc.: 50.00%] [G loss: 0.721822] [Time: 0.147671]\n",
            "4714-6 [D loss: 0.699264, acc.: 30.77%] [G loss: 0.733412] [Time: 0.149911]\n",
            "4714-7 [D loss: 0.700082, acc.: 50.00%] [G loss: 0.698450] [Time: 0.148723]\n",
            "4714-8 [D loss: 0.715434, acc.: 42.31%] [G loss: 0.719238] [Time: 0.151298]\n",
            "4714 (test) [D loss: 0.927686, acc.: 48.08%] [G loss: 0.937387] [Time: 0.046798]\n",
            "4715-0 [D loss: 0.665984, acc.: 53.85%] [G loss: 0.758049] [Time: 0.149192]\n",
            "4715-1 [D loss: 0.703897, acc.: 48.08%] [G loss: 0.712444] [Time: 0.146824]\n",
            "4715-2 [D loss: 0.706844, acc.: 42.31%] [G loss: 0.694434] [Time: 0.147663]\n",
            "4715-3 [D loss: 0.680591, acc.: 48.08%] [G loss: 0.743858] [Time: 0.147629]\n",
            "4715-4 [D loss: 0.702123, acc.: 34.62%] [G loss: 0.698957] [Time: 0.146993]\n",
            "4715-5 [D loss: 0.681717, acc.: 34.62%] [G loss: 0.715208] [Time: 0.147762]\n",
            "4715-6 [D loss: 0.693417, acc.: 42.31%] [G loss: 0.716841] [Time: 0.150781]\n",
            "4715-7 [D loss: 0.709088, acc.: 38.46%] [G loss: 0.722287] [Time: 0.150995]\n",
            "4715-8 [D loss: 0.698782, acc.: 34.62%] [G loss: 0.700232] [Time: 0.147438]\n",
            "4715 (test) [D loss: 0.924462, acc.: 53.85%] [G loss: 0.813824] [Time: 0.044495]\n",
            "4716-0 [D loss: 0.680495, acc.: 51.92%] [G loss: 0.753631] [Time: 0.153517]\n",
            "4716-1 [D loss: 0.713146, acc.: 40.38%] [G loss: 0.705061] [Time: 0.155960]\n",
            "4716-2 [D loss: 0.725280, acc.: 23.08%] [G loss: 0.685139] [Time: 0.154492]\n",
            "4716-3 [D loss: 0.669874, acc.: 53.85%] [G loss: 0.723540] [Time: 0.152737]\n",
            "4716-4 [D loss: 0.706314, acc.: 40.38%] [G loss: 0.703352] [Time: 0.152576]\n",
            "4716-5 [D loss: 0.688112, acc.: 48.08%] [G loss: 0.701975] [Time: 0.147735]\n",
            "4716-6 [D loss: 0.690526, acc.: 40.38%] [G loss: 0.720334] [Time: 0.150396]\n",
            "4716-7 [D loss: 0.699382, acc.: 51.92%] [G loss: 0.677839] [Time: 0.149939]\n",
            "4716-8 [D loss: 0.697170, acc.: 38.46%] [G loss: 0.704094] [Time: 0.150584]\n",
            "4716 (test) [D loss: 0.960293, acc.: 50.00%] [G loss: 0.615722] [Time: 0.045196]\n",
            "4717-0 [D loss: 0.665721, acc.: 57.69%] [G loss: 0.701961] [Time: 0.149373]\n",
            "4717-1 [D loss: 0.703606, acc.: 40.38%] [G loss: 0.695917] [Time: 0.148003]\n",
            "4717-2 [D loss: 0.697997, acc.: 46.15%] [G loss: 0.694790] [Time: 0.150387]\n",
            "4717-3 [D loss: 0.670462, acc.: 48.08%] [G loss: 0.725754] [Time: 0.149200]\n",
            "4717-4 [D loss: 0.697281, acc.: 38.46%] [G loss: 0.686011] [Time: 0.149312]\n",
            "4717-5 [D loss: 0.679994, acc.: 51.92%] [G loss: 0.697194] [Time: 0.148667]\n",
            "4717-6 [D loss: 0.696254, acc.: 42.31%] [G loss: 0.708634] [Time: 0.152496]\n",
            "4717-7 [D loss: 0.705746, acc.: 28.85%] [G loss: 0.681865] [Time: 0.147330]\n",
            "4717-8 [D loss: 0.701815, acc.: 46.15%] [G loss: 0.702091] [Time: 0.149213]\n",
            "4717 (test) [D loss: 0.999078, acc.: 48.08%] [G loss: 0.573866] [Time: 0.044946]\n",
            "4718-0 [D loss: 0.669547, acc.: 63.46%] [G loss: 0.761379] [Time: 0.148454]\n",
            "4718-1 [D loss: 0.698440, acc.: 42.31%] [G loss: 0.688119] [Time: 0.149010]\n",
            "4718-2 [D loss: 0.705687, acc.: 38.46%] [G loss: 0.689755] [Time: 0.147419]\n",
            "4718-3 [D loss: 0.676921, acc.: 61.54%] [G loss: 0.737960] [Time: 0.148283]\n",
            "4718-4 [D loss: 0.696090, acc.: 46.15%] [G loss: 0.720758] [Time: 0.150659]\n",
            "4718-5 [D loss: 0.693419, acc.: 36.54%] [G loss: 0.716059] [Time: 0.150165]\n",
            "4718-6 [D loss: 0.698839, acc.: 55.77%] [G loss: 0.730210] [Time: 0.152694]\n",
            "4718-7 [D loss: 0.710965, acc.: 40.38%] [G loss: 0.693570] [Time: 0.152925]\n",
            "4718-8 [D loss: 0.688219, acc.: 53.85%] [G loss: 0.709094] [Time: 0.150558]\n",
            "4718 (test) [D loss: 0.934479, acc.: 48.08%] [G loss: 0.964152] [Time: 0.043509]\n",
            "4719-0 [D loss: 0.678370, acc.: 57.69%] [G loss: 0.777652] [Time: 0.150070]\n",
            "4719-1 [D loss: 0.698532, acc.: 48.08%] [G loss: 0.702183] [Time: 0.148480]\n",
            "4719-2 [D loss: 0.725541, acc.: 40.38%] [G loss: 0.727901] [Time: 0.148185]\n",
            "4719-3 [D loss: 0.663760, acc.: 59.62%] [G loss: 0.741975] [Time: 0.147875]\n",
            "4719-4 [D loss: 0.702449, acc.: 51.92%] [G loss: 0.749614] [Time: 0.147637]\n",
            "4719-5 [D loss: 0.684938, acc.: 51.92%] [G loss: 0.723612] [Time: 0.149837]\n",
            "4719-6 [D loss: 0.698375, acc.: 42.31%] [G loss: 0.724020] [Time: 0.146742]\n",
            "4719-7 [D loss: 0.700838, acc.: 55.77%] [G loss: 0.709999] [Time: 0.149710]\n",
            "4719-8 [D loss: 0.698247, acc.: 25.00%] [G loss: 0.704317] [Time: 0.147037]\n",
            "4719 (test) [D loss: 0.945658, acc.: 46.15%] [G loss: 0.820548] [Time: 0.043147]\n",
            "4720-0 [D loss: 0.658385, acc.: 55.77%] [G loss: 0.764884] [Time: 0.156045]\n",
            "4720-1 [D loss: 0.695441, acc.: 46.15%] [G loss: 0.718317] [Time: 0.148954]\n",
            "4720-2 [D loss: 0.694356, acc.: 46.15%] [G loss: 0.714459] [Time: 0.151399]\n",
            "4720-3 [D loss: 0.660640, acc.: 53.85%] [G loss: 0.734992] [Time: 0.149248]\n",
            "4720-4 [D loss: 0.702308, acc.: 32.69%] [G loss: 0.698142] [Time: 0.148315]\n",
            "4720-5 [D loss: 0.685745, acc.: 38.46%] [G loss: 0.709928] [Time: 0.148004]\n",
            "4720-6 [D loss: 0.693831, acc.: 63.46%] [G loss: 0.704132] [Time: 0.151343]\n",
            "4720-7 [D loss: 0.700437, acc.: 46.15%] [G loss: 0.703503] [Time: 0.147557]\n",
            "4720-8 [D loss: 0.713463, acc.: 42.31%] [G loss: 0.705081] [Time: 0.149098]\n",
            "4720 (test) [D loss: 0.932890, acc.: 50.00%] [G loss: 0.888913] [Time: 0.042888]\n",
            "4721-0 [D loss: 0.669940, acc.: 55.77%] [G loss: 0.728741] [Time: 0.147984]\n",
            "4721-1 [D loss: 0.703499, acc.: 42.31%] [G loss: 0.693238] [Time: 0.147062]\n",
            "4721-2 [D loss: 0.697740, acc.: 46.15%] [G loss: 0.712851] [Time: 0.149519]\n",
            "4721-3 [D loss: 0.662754, acc.: 63.46%] [G loss: 0.710824] [Time: 0.150235]\n",
            "4721-4 [D loss: 0.696688, acc.: 40.38%] [G loss: 0.707204] [Time: 0.151426]\n",
            "4721-5 [D loss: 0.682104, acc.: 50.00%] [G loss: 0.698461] [Time: 0.150136]\n",
            "4721-6 [D loss: 0.699401, acc.: 42.31%] [G loss: 0.701741] [Time: 0.150354]\n",
            "4721-7 [D loss: 0.697502, acc.: 48.08%] [G loss: 0.705315] [Time: 0.148590]\n",
            "4721-8 [D loss: 0.704063, acc.: 36.54%] [G loss: 0.691237] [Time: 0.148403]\n",
            "4721 (test) [D loss: 0.939993, acc.: 50.00%] [G loss: 0.855454] [Time: 0.043878]\n",
            "4722-0 [D loss: 0.669066, acc.: 61.54%] [G loss: 0.753536] [Time: 0.150234]\n",
            "4722-1 [D loss: 0.709685, acc.: 34.62%] [G loss: 0.693355] [Time: 0.152596]\n",
            "4722-2 [D loss: 0.709549, acc.: 40.38%] [G loss: 0.699142] [Time: 0.150040]\n",
            "4722-3 [D loss: 0.665867, acc.: 53.85%] [G loss: 0.728734] [Time: 0.148348]\n",
            "4722-4 [D loss: 0.703506, acc.: 53.85%] [G loss: 0.675066] [Time: 0.146995]\n",
            "4722-5 [D loss: 0.669932, acc.: 42.31%] [G loss: 0.722298] [Time: 0.148442]\n",
            "4722-6 [D loss: 0.704471, acc.: 38.46%] [G loss: 0.699968] [Time: 0.148239]\n",
            "4722-7 [D loss: 0.700111, acc.: 40.38%] [G loss: 0.679798] [Time: 0.148512]\n",
            "4722-8 [D loss: 0.698313, acc.: 55.77%] [G loss: 0.710787] [Time: 0.147074]\n",
            "4722 (test) [D loss: 0.983755, acc.: 48.08%] [G loss: 0.644815] [Time: 0.043796]\n",
            "4723-0 [D loss: 0.672723, acc.: 63.46%] [G loss: 0.731505] [Time: 0.147158]\n",
            "4723-1 [D loss: 0.692419, acc.: 53.85%] [G loss: 0.700493] [Time: 0.148509]\n",
            "4723-2 [D loss: 0.719161, acc.: 30.77%] [G loss: 0.689483] [Time: 0.148842]\n",
            "4723-3 [D loss: 0.680068, acc.: 53.85%] [G loss: 0.716409] [Time: 0.149015]\n",
            "4723-4 [D loss: 0.701464, acc.: 44.23%] [G loss: 0.729634] [Time: 0.148170]\n",
            "4723-5 [D loss: 0.676918, acc.: 50.00%] [G loss: 0.729571] [Time: 0.149358]\n",
            "4723-6 [D loss: 0.698756, acc.: 38.46%] [G loss: 0.711206] [Time: 0.149871]\n",
            "4723-7 [D loss: 0.697674, acc.: 51.92%] [G loss: 0.713991] [Time: 0.148835]\n",
            "4723-8 [D loss: 0.699569, acc.: 38.46%] [G loss: 0.725551] [Time: 0.150250]\n",
            "4723 (test) [D loss: 0.921883, acc.: 50.00%] [G loss: 0.889046] [Time: 0.043948]\n",
            "4724-0 [D loss: 0.680787, acc.: 55.77%] [G loss: 0.754672] [Time: 0.156706]\n",
            "4724-1 [D loss: 0.700468, acc.: 48.08%] [G loss: 0.695906] [Time: 0.149219]\n",
            "4724-2 [D loss: 0.699846, acc.: 51.92%] [G loss: 0.717890] [Time: 0.155267]\n",
            "4724-3 [D loss: 0.662030, acc.: 51.92%] [G loss: 0.721216] [Time: 0.149997]\n",
            "4724-4 [D loss: 0.717959, acc.: 34.62%] [G loss: 0.701726] [Time: 0.150746]\n",
            "4724-5 [D loss: 0.679003, acc.: 38.46%] [G loss: 0.718376] [Time: 0.149078]\n",
            "4724-6 [D loss: 0.690067, acc.: 44.23%] [G loss: 0.712626] [Time: 0.149058]\n",
            "4724-7 [D loss: 0.692908, acc.: 50.00%] [G loss: 0.706447] [Time: 0.151826]\n",
            "4724-8 [D loss: 0.692222, acc.: 51.92%] [G loss: 0.713605] [Time: 0.151845]\n",
            "4724 (test) [D loss: 0.944620, acc.: 50.00%] [G loss: 0.783971] [Time: 0.044672]\n",
            "4725-0 [D loss: 0.659566, acc.: 63.46%] [G loss: 0.739941] [Time: 0.149025]\n",
            "4725-1 [D loss: 0.702641, acc.: 38.46%] [G loss: 0.703362] [Time: 0.148736]\n",
            "4725-2 [D loss: 0.706719, acc.: 40.38%] [G loss: 0.689253] [Time: 0.149126]\n",
            "4725-3 [D loss: 0.674735, acc.: 48.08%] [G loss: 0.725190] [Time: 0.149590]\n",
            "4725-4 [D loss: 0.705917, acc.: 34.62%] [G loss: 0.704928] [Time: 0.149476]\n",
            "4725-5 [D loss: 0.685513, acc.: 38.46%] [G loss: 0.714465] [Time: 0.147558]\n",
            "4725-6 [D loss: 0.699388, acc.: 38.46%] [G loss: 0.731084] [Time: 0.147589]\n",
            "4725-7 [D loss: 0.697580, acc.: 36.54%] [G loss: 0.696762] [Time: 0.147185]\n",
            "4725-8 [D loss: 0.705532, acc.: 38.46%] [G loss: 0.708877] [Time: 0.147979]\n",
            "4725 (test) [D loss: 0.915151, acc.: 48.08%] [G loss: 0.823349] [Time: 0.043778]\n",
            "4726-0 [D loss: 0.672748, acc.: 61.54%] [G loss: 0.743517] [Time: 0.149623]\n",
            "4726-1 [D loss: 0.712744, acc.: 40.38%] [G loss: 0.691949] [Time: 0.147387]\n",
            "4726-2 [D loss: 0.711392, acc.: 42.31%] [G loss: 0.706062] [Time: 0.148190]\n",
            "4726-3 [D loss: 0.673995, acc.: 59.62%] [G loss: 0.709710] [Time: 0.148241]\n",
            "4726-4 [D loss: 0.691438, acc.: 40.38%] [G loss: 0.726201] [Time: 0.147366]\n",
            "4726-5 [D loss: 0.675623, acc.: 48.08%] [G loss: 0.706575] [Time: 0.147237]\n",
            "4726-6 [D loss: 0.706628, acc.: 36.54%] [G loss: 0.698312] [Time: 0.151160]\n",
            "4726-7 [D loss: 0.692032, acc.: 50.00%] [G loss: 0.686558] [Time: 0.148018]\n",
            "4726-8 [D loss: 0.705220, acc.: 40.38%] [G loss: 0.699408] [Time: 0.148133]\n",
            "4726 (test) [D loss: 0.929306, acc.: 50.00%] [G loss: 0.737374] [Time: 0.043659]\n",
            "4727-0 [D loss: 0.666466, acc.: 63.46%] [G loss: 0.745796] [Time: 0.150300]\n",
            "4727-1 [D loss: 0.699925, acc.: 42.31%] [G loss: 0.691140] [Time: 0.150573]\n",
            "4727-2 [D loss: 0.710658, acc.: 40.38%] [G loss: 0.702582] [Time: 0.151162]\n",
            "4727-3 [D loss: 0.684502, acc.: 51.92%] [G loss: 0.719870] [Time: 0.153774]\n",
            "4727-4 [D loss: 0.712439, acc.: 26.92%] [G loss: 0.707785] [Time: 0.150707]\n",
            "4727-5 [D loss: 0.680747, acc.: 48.08%] [G loss: 0.727963] [Time: 0.150460]\n",
            "4727-6 [D loss: 0.696884, acc.: 51.92%] [G loss: 0.702488] [Time: 0.149508]\n",
            "4727-7 [D loss: 0.720554, acc.: 46.15%] [G loss: 0.685147] [Time: 0.151227]\n",
            "4727-8 [D loss: 0.705948, acc.: 32.69%] [G loss: 0.701601] [Time: 0.152197]\n",
            "4727 (test) [D loss: 0.959805, acc.: 50.00%] [G loss: 0.673811] [Time: 0.044677]\n",
            "4728-0 [D loss: 0.678374, acc.: 59.62%] [G loss: 0.753269] [Time: 0.150234]\n",
            "4728-1 [D loss: 0.709459, acc.: 36.54%] [G loss: 0.679674] [Time: 0.148153]\n",
            "4728-2 [D loss: 0.704888, acc.: 36.54%] [G loss: 0.713562] [Time: 0.148630]\n",
            "4728-3 [D loss: 0.669428, acc.: 51.92%] [G loss: 0.770625] [Time: 0.149360]\n",
            "4728-4 [D loss: 0.712997, acc.: 42.31%] [G loss: 0.714337] [Time: 0.149602]\n",
            "4728-5 [D loss: 0.683408, acc.: 42.31%] [G loss: 0.712299] [Time: 0.148458]\n",
            "4728-6 [D loss: 0.683515, acc.: 55.77%] [G loss: 0.716551] [Time: 0.148717]\n",
            "4728-7 [D loss: 0.702486, acc.: 48.08%] [G loss: 0.710935] [Time: 0.149611]\n",
            "4728-8 [D loss: 0.711447, acc.: 38.46%] [G loss: 0.710124] [Time: 0.146897]\n",
            "4728 (test) [D loss: 0.912474, acc.: 50.00%] [G loss: 1.092925] [Time: 0.043740]\n",
            "4729-0 [D loss: 0.675532, acc.: 53.85%] [G loss: 0.767992] [Time: 0.149382]\n",
            "4729-1 [D loss: 0.693281, acc.: 48.08%] [G loss: 0.712367] [Time: 0.148820]\n",
            "4729-2 [D loss: 0.702445, acc.: 38.46%] [G loss: 0.720677] [Time: 0.149758]\n",
            "4729-3 [D loss: 0.667743, acc.: 61.54%] [G loss: 0.763688] [Time: 0.149832]\n",
            "4729-4 [D loss: 0.704812, acc.: 34.62%] [G loss: 0.719541] [Time: 0.148023]\n",
            "4729-5 [D loss: 0.680341, acc.: 46.15%] [G loss: 0.724415] [Time: 0.148464]\n",
            "4729-6 [D loss: 0.698849, acc.: 46.15%] [G loss: 0.716669] [Time: 0.148391]\n",
            "4729-7 [D loss: 0.695709, acc.: 53.85%] [G loss: 0.697630] [Time: 0.147736]\n",
            "4729-8 [D loss: 0.705438, acc.: 30.77%] [G loss: 0.717852] [Time: 0.148394]\n",
            "4729 (test) [D loss: 0.934052, acc.: 46.15%] [G loss: 1.082723] [Time: 0.044016]\n",
            "4730-0 [D loss: 0.668237, acc.: 65.38%] [G loss: 0.736976] [Time: 0.148436]\n",
            "4730-1 [D loss: 0.696917, acc.: 50.00%] [G loss: 0.706271] [Time: 0.151418]\n",
            "4730-2 [D loss: 0.700157, acc.: 40.38%] [G loss: 0.724477] [Time: 0.149853]\n",
            "4730-3 [D loss: 0.668709, acc.: 63.46%] [G loss: 0.724765] [Time: 0.147369]\n",
            "4730-4 [D loss: 0.718364, acc.: 34.62%] [G loss: 0.701603] [Time: 0.148288]\n",
            "4730-5 [D loss: 0.684286, acc.: 38.46%] [G loss: 0.720568] [Time: 0.149199]\n",
            "4730-6 [D loss: 0.714319, acc.: 26.92%] [G loss: 0.712587] [Time: 0.153657]\n",
            "4730-7 [D loss: 0.695194, acc.: 48.08%] [G loss: 0.703218] [Time: 0.149107]\n",
            "4730-8 [D loss: 0.706492, acc.: 44.23%] [G loss: 0.681804] [Time: 0.147878]\n",
            "4730 (test) [D loss: 0.926884, acc.: 50.00%] [G loss: 0.782772] [Time: 0.043749]\n",
            "4731-0 [D loss: 0.676369, acc.: 57.69%] [G loss: 0.734212] [Time: 0.147768]\n",
            "4731-1 [D loss: 0.703219, acc.: 50.00%] [G loss: 0.691007] [Time: 0.147826]\n",
            "4731-2 [D loss: 0.704520, acc.: 44.23%] [G loss: 0.711353] [Time: 0.147561]\n",
            "4731-3 [D loss: 0.669344, acc.: 59.62%] [G loss: 0.711413] [Time: 0.150122]\n",
            "4731-4 [D loss: 0.702120, acc.: 55.77%] [G loss: 0.688610] [Time: 0.151129]\n",
            "4731-5 [D loss: 0.678700, acc.: 44.23%] [G loss: 0.676334] [Time: 0.147851]\n",
            "4731-6 [D loss: 0.691614, acc.: 48.08%] [G loss: 0.691594] [Time: 0.150033]\n",
            "4731-7 [D loss: 0.717799, acc.: 38.46%] [G loss: 0.667349] [Time: 0.148978]\n",
            "4731-8 [D loss: 0.713890, acc.: 38.46%] [G loss: 0.695312] [Time: 0.147151]\n",
            "4731 (test) [D loss: 0.998457, acc.: 50.00%] [G loss: 0.588996] [Time: 0.044498]\n",
            "4732-0 [D loss: 0.689928, acc.: 53.85%] [G loss: 0.727231] [Time: 0.153774]\n",
            "4732-1 [D loss: 0.705102, acc.: 42.31%] [G loss: 0.704823] [Time: 0.149678]\n",
            "4732-2 [D loss: 0.704519, acc.: 46.15%] [G loss: 0.684102] [Time: 0.148947]\n",
            "4732-3 [D loss: 0.671523, acc.: 55.77%] [G loss: 0.721688] [Time: 0.147804]\n",
            "4732-4 [D loss: 0.711079, acc.: 32.69%] [G loss: 0.703142] [Time: 0.148184]\n",
            "4732-5 [D loss: 0.677343, acc.: 44.23%] [G loss: 0.708989] [Time: 0.150730]\n",
            "4732-6 [D loss: 0.703121, acc.: 48.08%] [G loss: 0.709988] [Time: 0.151551]\n",
            "4732-7 [D loss: 0.702783, acc.: 42.31%] [G loss: 0.720257] [Time: 0.148272]\n",
            "4732-8 [D loss: 0.702559, acc.: 36.54%] [G loss: 0.692383] [Time: 0.146771]\n",
            "4732 (test) [D loss: 0.929549, acc.: 51.92%] [G loss: 0.772068] [Time: 0.043503]\n",
            "4733-0 [D loss: 0.660946, acc.: 63.46%] [G loss: 0.779418] [Time: 0.147494]\n",
            "4733-1 [D loss: 0.708767, acc.: 42.31%] [G loss: 0.690389] [Time: 0.150898]\n",
            "4733-2 [D loss: 0.711365, acc.: 42.31%] [G loss: 0.700318] [Time: 0.154336]\n",
            "4733-3 [D loss: 0.672526, acc.: 50.00%] [G loss: 0.742673] [Time: 0.150401]\n",
            "4733-4 [D loss: 0.697619, acc.: 36.54%] [G loss: 0.734992] [Time: 0.151111]\n",
            "4733-5 [D loss: 0.675760, acc.: 46.15%] [G loss: 0.737822] [Time: 0.147854]\n",
            "4733-6 [D loss: 0.690377, acc.: 46.15%] [G loss: 0.733708] [Time: 0.148931]\n",
            "4733-7 [D loss: 0.704251, acc.: 40.38%] [G loss: 0.700672] [Time: 0.149384]\n",
            "4733-8 [D loss: 0.704034, acc.: 48.08%] [G loss: 0.717486] [Time: 0.148405]\n",
            "4733 (test) [D loss: 0.943100, acc.: 48.08%] [G loss: 1.083830] [Time: 0.044543]\n",
            "4734-0 [D loss: 0.667346, acc.: 63.46%] [G loss: 0.724810] [Time: 0.151755]\n",
            "4734-1 [D loss: 0.698876, acc.: 44.23%] [G loss: 0.715625] [Time: 0.151873]\n",
            "4734-2 [D loss: 0.706134, acc.: 42.31%] [G loss: 0.722605] [Time: 0.149692]\n",
            "4734-3 [D loss: 0.676691, acc.: 51.92%] [G loss: 0.730204] [Time: 0.146839]\n",
            "4734-4 [D loss: 0.708225, acc.: 32.69%] [G loss: 0.707230] [Time: 0.147435]\n",
            "4734-5 [D loss: 0.679332, acc.: 50.00%] [G loss: 0.712871] [Time: 0.147458]\n",
            "4734-6 [D loss: 0.687678, acc.: 46.15%] [G loss: 0.721294] [Time: 0.151764]\n",
            "4734-7 [D loss: 0.702934, acc.: 50.00%] [G loss: 0.717362] [Time: 0.148546]\n",
            "4734-8 [D loss: 0.697548, acc.: 40.38%] [G loss: 0.709512] [Time: 0.151993]\n",
            "4734 (test) [D loss: 0.931113, acc.: 44.23%] [G loss: 0.987607] [Time: 0.045712]\n",
            "4735-0 [D loss: 0.680961, acc.: 55.77%] [G loss: 0.753544] [Time: 0.150221]\n",
            "4735-1 [D loss: 0.703154, acc.: 42.31%] [G loss: 0.712983] [Time: 0.149046]\n",
            "4735-2 [D loss: 0.723544, acc.: 32.69%] [G loss: 0.726003] [Time: 0.147293]\n",
            "4735-3 [D loss: 0.663152, acc.: 55.77%] [G loss: 0.727174] [Time: 0.146734]\n",
            "4735-4 [D loss: 0.698690, acc.: 38.46%] [G loss: 0.700895] [Time: 0.148796]\n",
            "4735-5 [D loss: 0.691457, acc.: 38.46%] [G loss: 0.689647] [Time: 0.147656]\n",
            "4735-6 [D loss: 0.684733, acc.: 48.08%] [G loss: 0.703926] [Time: 0.151649]\n",
            "4735-7 [D loss: 0.702341, acc.: 38.46%] [G loss: 0.688472] [Time: 0.149369]\n",
            "4735-8 [D loss: 0.711177, acc.: 44.23%] [G loss: 0.698330] [Time: 0.149024]\n",
            "4735 (test) [D loss: 0.922595, acc.: 48.08%] [G loss: 0.943985] [Time: 0.051037]\n",
            "4736-0 [D loss: 0.684818, acc.: 48.08%] [G loss: 0.763908] [Time: 0.149990]\n",
            "4736-1 [D loss: 0.704375, acc.: 38.46%] [G loss: 0.683091] [Time: 0.150712]\n",
            "4736-2 [D loss: 0.705501, acc.: 44.23%] [G loss: 0.683586] [Time: 0.148915]\n",
            "4736-3 [D loss: 0.684774, acc.: 51.92%] [G loss: 0.724761] [Time: 0.148851]\n",
            "4736-4 [D loss: 0.703365, acc.: 36.54%] [G loss: 0.703870] [Time: 0.148539]\n",
            "4736-5 [D loss: 0.676412, acc.: 42.31%] [G loss: 0.703593] [Time: 0.150352]\n",
            "4736-6 [D loss: 0.686909, acc.: 40.38%] [G loss: 0.715416] [Time: 0.153560]\n",
            "4736-7 [D loss: 0.696644, acc.: 38.46%] [G loss: 0.687283] [Time: 0.149984]\n",
            "4736-8 [D loss: 0.702544, acc.: 38.46%] [G loss: 0.688474] [Time: 0.151214]\n",
            "4736 (test) [D loss: 0.929149, acc.: 48.08%] [G loss: 0.806725] [Time: 0.045048]\n",
            "4737-0 [D loss: 0.669179, acc.: 53.85%] [G loss: 0.740809] [Time: 0.147665]\n",
            "4737-1 [D loss: 0.692223, acc.: 48.08%] [G loss: 0.696250] [Time: 0.147238]\n",
            "4737-2 [D loss: 0.707209, acc.: 34.62%] [G loss: 0.696034] [Time: 0.147021]\n",
            "4737-3 [D loss: 0.669435, acc.: 51.92%] [G loss: 0.745094] [Time: 0.149809]\n",
            "4737-4 [D loss: 0.697329, acc.: 46.15%] [G loss: 0.715722] [Time: 0.148669]\n",
            "4737-5 [D loss: 0.687192, acc.: 40.38%] [G loss: 0.709537] [Time: 0.152644]\n",
            "4737-6 [D loss: 0.702538, acc.: 32.69%] [G loss: 0.736407] [Time: 0.146930]\n",
            "4737-7 [D loss: 0.712391, acc.: 26.92%] [G loss: 0.693896] [Time: 0.148503]\n",
            "4737-8 [D loss: 0.716324, acc.: 46.15%] [G loss: 0.724495] [Time: 0.147071]\n",
            "4737 (test) [D loss: 0.929110, acc.: 50.00%] [G loss: 0.831268] [Time: 0.044516]\n",
            "4738-0 [D loss: 0.682698, acc.: 51.92%] [G loss: 0.742601] [Time: 0.149966]\n",
            "4738-1 [D loss: 0.703447, acc.: 36.54%] [G loss: 0.676739] [Time: 0.151697]\n",
            "4738-2 [D loss: 0.708008, acc.: 36.54%] [G loss: 0.701714] [Time: 0.149525]\n",
            "4738-3 [D loss: 0.667012, acc.: 59.62%] [G loss: 0.713843] [Time: 0.150359]\n",
            "4738-4 [D loss: 0.715282, acc.: 34.62%] [G loss: 0.684646] [Time: 0.147192]\n",
            "4738-5 [D loss: 0.680558, acc.: 38.46%] [G loss: 0.705573] [Time: 0.150070]\n",
            "4738-6 [D loss: 0.693427, acc.: 42.31%] [G loss: 0.720848] [Time: 0.147357]\n",
            "4738-7 [D loss: 0.699036, acc.: 46.15%] [G loss: 0.705918] [Time: 0.151851]\n",
            "4738-8 [D loss: 0.717988, acc.: 44.23%] [G loss: 0.713029] [Time: 0.149759]\n",
            "4738 (test) [D loss: 0.921679, acc.: 50.00%] [G loss: 0.901065] [Time: 0.045227]\n",
            "4739-0 [D loss: 0.657730, acc.: 57.69%] [G loss: 0.758822] [Time: 0.150014]\n",
            "4739-1 [D loss: 0.703960, acc.: 34.62%] [G loss: 0.716477] [Time: 0.148560]\n",
            "4739-2 [D loss: 0.699216, acc.: 50.00%] [G loss: 0.708210] [Time: 0.147518]\n",
            "4739-3 [D loss: 0.675125, acc.: 61.54%] [G loss: 0.723889] [Time: 0.150622]\n",
            "4739-4 [D loss: 0.722915, acc.: 32.69%] [G loss: 0.722842] [Time: 0.152250]\n",
            "4739-5 [D loss: 0.687849, acc.: 44.23%] [G loss: 0.723174] [Time: 0.147873]\n",
            "4739-6 [D loss: 0.694379, acc.: 44.23%] [G loss: 0.718019] [Time: 0.147834]\n",
            "4739-7 [D loss: 0.707628, acc.: 48.08%] [G loss: 0.697115] [Time: 0.147409]\n",
            "4739-8 [D loss: 0.706820, acc.: 34.62%] [G loss: 0.701234] [Time: 0.147871]\n",
            "4739 (test) [D loss: 0.917692, acc.: 50.00%] [G loss: 0.913695] [Time: 0.045006]\n",
            "4740-0 [D loss: 0.699939, acc.: 53.85%] [G loss: 0.742285] [Time: 0.149798]\n",
            "4740-1 [D loss: 0.698737, acc.: 48.08%] [G loss: 0.708236] [Time: 0.149268]\n",
            "4740-2 [D loss: 0.718865, acc.: 28.85%] [G loss: 0.699246] [Time: 0.147702]\n",
            "4740-3 [D loss: 0.667959, acc.: 50.00%] [G loss: 0.718125] [Time: 0.148251]\n",
            "4740-4 [D loss: 0.712786, acc.: 42.31%] [G loss: 0.708982] [Time: 0.148966]\n",
            "4740-5 [D loss: 0.669402, acc.: 55.77%] [G loss: 0.709846] [Time: 0.152849]\n",
            "4740-6 [D loss: 0.688192, acc.: 46.15%] [G loss: 0.723012] [Time: 0.147544]\n",
            "4740-7 [D loss: 0.702544, acc.: 50.00%] [G loss: 0.694794] [Time: 0.149185]\n",
            "4740-8 [D loss: 0.687110, acc.: 53.85%] [G loss: 0.710836] [Time: 0.148443]\n",
            "4740 (test) [D loss: 0.916643, acc.: 51.92%] [G loss: 0.871615] [Time: 0.043581]\n",
            "4741-0 [D loss: 0.664353, acc.: 55.77%] [G loss: 0.732862] [Time: 0.146745]\n",
            "4741-1 [D loss: 0.690740, acc.: 40.38%] [G loss: 0.696375] [Time: 0.149305]\n",
            "4741-2 [D loss: 0.706100, acc.: 44.23%] [G loss: 0.713510] [Time: 0.149072]\n",
            "4741-3 [D loss: 0.670139, acc.: 55.77%] [G loss: 0.731085] [Time: 0.149245]\n",
            "4741-4 [D loss: 0.706040, acc.: 44.23%] [G loss: 0.715197] [Time: 0.150987]\n",
            "4741-5 [D loss: 0.679820, acc.: 46.15%] [G loss: 0.716794] [Time: 0.150182]\n",
            "4741-6 [D loss: 0.692890, acc.: 34.62%] [G loss: 0.725763] [Time: 0.148585]\n",
            "4741-7 [D loss: 0.710318, acc.: 32.69%] [G loss: 0.688642] [Time: 0.148328]\n",
            "4741-8 [D loss: 0.705850, acc.: 46.15%] [G loss: 0.684190] [Time: 0.149913]\n",
            "4741 (test) [D loss: 0.949316, acc.: 51.92%] [G loss: 0.749003] [Time: 0.044391]\n",
            "4742-0 [D loss: 0.687469, acc.: 57.69%] [G loss: 0.730555] [Time: 0.147574]\n",
            "4742-1 [D loss: 0.692802, acc.: 38.46%] [G loss: 0.703920] [Time: 0.146896]\n",
            "4742-2 [D loss: 0.710902, acc.: 42.31%] [G loss: 0.700405] [Time: 0.150013]\n",
            "4742-3 [D loss: 0.676804, acc.: 51.92%] [G loss: 0.735262] [Time: 0.148541]\n",
            "4742-4 [D loss: 0.698701, acc.: 44.23%] [G loss: 0.711971] [Time: 0.148407]\n",
            "4742-5 [D loss: 0.678953, acc.: 38.46%] [G loss: 0.712277] [Time: 0.147457]\n",
            "4742-6 [D loss: 0.698625, acc.: 42.31%] [G loss: 0.722582] [Time: 0.149354]\n",
            "4742-7 [D loss: 0.705352, acc.: 34.62%] [G loss: 0.696267] [Time: 0.147856]\n",
            "4742-8 [D loss: 0.695270, acc.: 50.00%] [G loss: 0.693993] [Time: 0.148252]\n",
            "4742 (test) [D loss: 0.917183, acc.: 51.92%] [G loss: 0.799551] [Time: 0.043309]\n",
            "4743-0 [D loss: 0.672745, acc.: 57.69%] [G loss: 0.768444] [Time: 0.147464]\n",
            "4743-1 [D loss: 0.702607, acc.: 40.38%] [G loss: 0.713759] [Time: 0.147017]\n",
            "4743-2 [D loss: 0.694756, acc.: 48.08%] [G loss: 0.717850] [Time: 0.148102]\n",
            "4743-3 [D loss: 0.678078, acc.: 50.00%] [G loss: 0.723017] [Time: 0.149546]\n",
            "4743-4 [D loss: 0.699871, acc.: 46.15%] [G loss: 0.720757] [Time: 0.148176]\n",
            "4743-5 [D loss: 0.670890, acc.: 57.69%] [G loss: 0.712175] [Time: 0.150380]\n",
            "4743-6 [D loss: 0.702207, acc.: 40.38%] [G loss: 0.727059] [Time: 0.149813]\n",
            "4743-7 [D loss: 0.702122, acc.: 44.23%] [G loss: 0.709999] [Time: 0.148661]\n",
            "4743-8 [D loss: 0.709090, acc.: 32.69%] [G loss: 0.701306] [Time: 0.147521]\n",
            "4743 (test) [D loss: 0.914005, acc.: 50.00%] [G loss: 0.868194] [Time: 0.045022]\n",
            "4744-0 [D loss: 0.659953, acc.: 65.38%] [G loss: 0.726170] [Time: 0.150739]\n",
            "4744-1 [D loss: 0.700955, acc.: 44.23%] [G loss: 0.717538] [Time: 0.148944]\n",
            "4744-2 [D loss: 0.711313, acc.: 32.69%] [G loss: 0.709732] [Time: 0.150755]\n",
            "4744-3 [D loss: 0.688567, acc.: 42.31%] [G loss: 0.736206] [Time: 0.150314]\n",
            "4744-4 [D loss: 0.711732, acc.: 26.92%] [G loss: 0.699577] [Time: 0.147994]\n",
            "4744-5 [D loss: 0.677702, acc.: 44.23%] [G loss: 0.720991] [Time: 0.147346]\n",
            "4744-6 [D loss: 0.700950, acc.: 36.54%] [G loss: 0.717987] [Time: 0.150001]\n",
            "4744-7 [D loss: 0.710665, acc.: 36.54%] [G loss: 0.695912] [Time: 0.153782]\n",
            "4744-8 [D loss: 0.703767, acc.: 38.46%] [G loss: 0.711039] [Time: 0.149762]\n",
            "4744 (test) [D loss: 0.922631, acc.: 50.00%] [G loss: 0.821688] [Time: 0.043846]\n",
            "4745-0 [D loss: 0.670003, acc.: 55.77%] [G loss: 0.740503] [Time: 0.146747]\n",
            "4745-1 [D loss: 0.706598, acc.: 34.62%] [G loss: 0.702664] [Time: 0.148157]\n",
            "4745-2 [D loss: 0.702123, acc.: 44.23%] [G loss: 0.711525] [Time: 0.151194]\n",
            "4745-3 [D loss: 0.669846, acc.: 50.00%] [G loss: 0.733981] [Time: 0.153841]\n",
            "4745-4 [D loss: 0.711016, acc.: 23.08%] [G loss: 0.702552] [Time: 0.148666]\n",
            "4745-5 [D loss: 0.675546, acc.: 40.38%] [G loss: 0.703377] [Time: 0.148221]\n",
            "4745-6 [D loss: 0.701291, acc.: 42.31%] [G loss: 0.708130] [Time: 0.150433]\n",
            "4745-7 [D loss: 0.687150, acc.: 46.15%] [G loss: 0.693830] [Time: 0.148376]\n",
            "4745-8 [D loss: 0.706862, acc.: 42.31%] [G loss: 0.698790] [Time: 0.150608]\n",
            "4745 (test) [D loss: 0.976859, acc.: 50.00%] [G loss: 0.616572] [Time: 0.044804]\n",
            "4746-0 [D loss: 0.675375, acc.: 50.00%] [G loss: 0.759859] [Time: 0.149329]\n",
            "4746-1 [D loss: 0.699023, acc.: 40.38%] [G loss: 0.679510] [Time: 0.148230]\n",
            "4746-2 [D loss: 0.712654, acc.: 53.85%] [G loss: 0.703049] [Time: 0.147780]\n",
            "4746-3 [D loss: 0.667611, acc.: 53.85%] [G loss: 0.705258] [Time: 0.151910]\n",
            "4746-4 [D loss: 0.703391, acc.: 34.62%] [G loss: 0.697899] [Time: 0.147567]\n",
            "4746-5 [D loss: 0.680423, acc.: 36.54%] [G loss: 0.695494] [Time: 0.147953]\n",
            "4746-6 [D loss: 0.698562, acc.: 44.23%] [G loss: 0.718391] [Time: 0.147489]\n",
            "4746-7 [D loss: 0.713738, acc.: 48.08%] [G loss: 0.689389] [Time: 0.150679]\n",
            "4746-8 [D loss: 0.707495, acc.: 48.08%] [G loss: 0.686673] [Time: 0.149917]\n",
            "4746 (test) [D loss: 1.004488, acc.: 50.00%] [G loss: 0.586169] [Time: 0.045178]\n",
            "4747-0 [D loss: 0.694470, acc.: 42.31%] [G loss: 0.715225] [Time: 0.147809]\n",
            "4747-1 [D loss: 0.706513, acc.: 44.23%] [G loss: 0.683663] [Time: 0.147273]\n",
            "4747-2 [D loss: 0.704518, acc.: 42.31%] [G loss: 0.694892] [Time: 0.152056]\n",
            "4747-3 [D loss: 0.680159, acc.: 51.92%] [G loss: 0.727900] [Time: 0.148863]\n",
            "4747-4 [D loss: 0.700762, acc.: 34.62%] [G loss: 0.689557] [Time: 0.148258]\n",
            "4747-5 [D loss: 0.684206, acc.: 46.15%] [G loss: 0.715821] [Time: 0.147966]\n",
            "4747-6 [D loss: 0.705303, acc.: 38.46%] [G loss: 0.720377] [Time: 0.147544]\n",
            "4747-7 [D loss: 0.705581, acc.: 36.54%] [G loss: 0.692947] [Time: 0.148913]\n",
            "4747-8 [D loss: 0.715613, acc.: 48.08%] [G loss: 0.718848] [Time: 0.147452]\n",
            "4747 (test) [D loss: 0.974825, acc.: 50.00%] [G loss: 0.743848] [Time: 0.048332]\n",
            "4748-0 [D loss: 0.667283, acc.: 51.92%] [G loss: 0.753950] [Time: 0.151435]\n",
            "4748-1 [D loss: 0.694314, acc.: 50.00%] [G loss: 0.692465] [Time: 0.148152]\n",
            "4748-2 [D loss: 0.694831, acc.: 36.54%] [G loss: 0.710870] [Time: 0.151168]\n",
            "4748-3 [D loss: 0.677527, acc.: 44.23%] [G loss: 0.763196] [Time: 0.150067]\n",
            "4748-4 [D loss: 0.698485, acc.: 46.15%] [G loss: 0.707636] [Time: 0.147057]\n",
            "4748-5 [D loss: 0.685024, acc.: 40.38%] [G loss: 0.741254] [Time: 0.148667]\n",
            "4748-6 [D loss: 0.691219, acc.: 51.92%] [G loss: 0.715813] [Time: 0.149470]\n",
            "4748-7 [D loss: 0.702642, acc.: 40.38%] [G loss: 0.707617] [Time: 0.146918]\n",
            "4748-8 [D loss: 0.700069, acc.: 48.08%] [G loss: 0.705661] [Time: 0.149591]\n",
            "4748 (test) [D loss: 0.940699, acc.: 50.00%] [G loss: 0.920377] [Time: 0.045378]\n",
            "4749-0 [D loss: 0.652020, acc.: 67.31%] [G loss: 0.749364] [Time: 0.150370]\n",
            "4749-1 [D loss: 0.703068, acc.: 42.31%] [G loss: 0.710358] [Time: 0.147274]\n",
            "4749-2 [D loss: 0.719226, acc.: 34.62%] [G loss: 0.703405] [Time: 0.148220]\n",
            "4749-3 [D loss: 0.669275, acc.: 55.77%] [G loss: 0.753132] [Time: 0.149634]\n",
            "4749-4 [D loss: 0.715518, acc.: 36.54%] [G loss: 0.708067] [Time: 0.148391]\n",
            "4749-5 [D loss: 0.669323, acc.: 51.92%] [G loss: 0.727495] [Time: 0.149808]\n",
            "4749-6 [D loss: 0.697028, acc.: 40.38%] [G loss: 0.719084] [Time: 0.147109]\n",
            "4749-7 [D loss: 0.690616, acc.: 50.00%] [G loss: 0.696448] [Time: 0.150097]\n",
            "4749-8 [D loss: 0.706476, acc.: 36.54%] [G loss: 0.697906] [Time: 0.149565]\n",
            "4749 (test) [D loss: 0.948444, acc.: 50.00%] [G loss: 0.815080] [Time: 0.049778]\n",
            "4750-0 [D loss: 0.656253, acc.: 73.08%] [G loss: 0.752674] [Time: 0.152625]\n",
            "4750-1 [D loss: 0.711138, acc.: 36.54%] [G loss: 0.690455] [Time: 0.149071]\n",
            "4750-2 [D loss: 0.704057, acc.: 46.15%] [G loss: 0.715263] [Time: 0.147143]\n",
            "4750-3 [D loss: 0.670532, acc.: 55.77%] [G loss: 0.758000] [Time: 0.147696]\n",
            "4750-4 [D loss: 0.708516, acc.: 40.38%] [G loss: 0.695752] [Time: 0.149536]\n",
            "4750-5 [D loss: 0.684324, acc.: 48.08%] [G loss: 0.727033] [Time: 0.151550]\n",
            "4750-6 [D loss: 0.708970, acc.: 44.23%] [G loss: 0.730511] [Time: 0.152488]\n",
            "4750-7 [D loss: 0.699559, acc.: 36.54%] [G loss: 0.714382] [Time: 0.150032]\n",
            "4750-8 [D loss: 0.722964, acc.: 34.62%] [G loss: 0.700278] [Time: 0.148119]\n",
            "4750 (test) [D loss: 0.951745, acc.: 50.00%] [G loss: 0.879725] [Time: 0.043364]\n",
            "4751-0 [D loss: 0.669882, acc.: 50.00%] [G loss: 0.746418] [Time: 0.148419]\n",
            "4751-1 [D loss: 0.708618, acc.: 30.77%] [G loss: 0.691884] [Time: 0.147177]\n",
            "4751-2 [D loss: 0.704539, acc.: 53.85%] [G loss: 0.700311] [Time: 0.147987]\n",
            "4751-3 [D loss: 0.663775, acc.: 59.62%] [G loss: 0.724189] [Time: 0.151703]\n",
            "4751-4 [D loss: 0.706478, acc.: 34.62%] [G loss: 0.709055] [Time: 0.149911]\n",
            "4751-5 [D loss: 0.678845, acc.: 36.54%] [G loss: 0.729116] [Time: 0.147301]\n",
            "4751-6 [D loss: 0.699540, acc.: 38.46%] [G loss: 0.704379] [Time: 0.148845]\n",
            "4751-7 [D loss: 0.695941, acc.: 46.15%] [G loss: 0.692015] [Time: 0.152104]\n",
            "4751-8 [D loss: 0.692943, acc.: 44.23%] [G loss: 0.689576] [Time: 0.147611]\n",
            "4751 (test) [D loss: 0.968583, acc.: 50.00%] [G loss: 0.712231] [Time: 0.045617]\n",
            "4752-0 [D loss: 0.680145, acc.: 61.54%] [G loss: 0.727723] [Time: 0.150728]\n",
            "4752-1 [D loss: 0.701945, acc.: 34.62%] [G loss: 0.690783] [Time: 0.149432]\n",
            "4752-2 [D loss: 0.692185, acc.: 53.85%] [G loss: 0.701885] [Time: 0.150981]\n",
            "4752-3 [D loss: 0.664370, acc.: 59.62%] [G loss: 0.746185] [Time: 0.148307]\n",
            "4752-4 [D loss: 0.688761, acc.: 51.92%] [G loss: 0.698544] [Time: 0.151292]\n",
            "4752-5 [D loss: 0.679142, acc.: 53.85%] [G loss: 0.705474] [Time: 0.152613]\n",
            "4752-6 [D loss: 0.693966, acc.: 48.08%] [G loss: 0.714586] [Time: 0.149045]\n",
            "4752-7 [D loss: 0.695841, acc.: 38.46%] [G loss: 0.697772] [Time: 0.149449]\n",
            "4752-8 [D loss: 0.698022, acc.: 51.92%] [G loss: 0.700238] [Time: 0.148744]\n",
            "4752 (test) [D loss: 1.003174, acc.: 50.00%] [G loss: 0.632251] [Time: 0.043667]\n",
            "4753-0 [D loss: 0.673031, acc.: 50.00%] [G loss: 0.731503] [Time: 0.147465]\n",
            "4753-1 [D loss: 0.693533, acc.: 50.00%] [G loss: 0.695623] [Time: 0.151028]\n",
            "4753-2 [D loss: 0.710179, acc.: 36.54%] [G loss: 0.702963] [Time: 0.148183]\n",
            "4753-3 [D loss: 0.676681, acc.: 55.77%] [G loss: 0.717996] [Time: 0.147928]\n",
            "4753-4 [D loss: 0.702678, acc.: 42.31%] [G loss: 0.671310] [Time: 0.147833]\n",
            "4753-5 [D loss: 0.688682, acc.: 40.38%] [G loss: 0.703279] [Time: 0.148063]\n",
            "4753-6 [D loss: 0.683072, acc.: 46.15%] [G loss: 0.721749] [Time: 0.148387]\n",
            "4753-7 [D loss: 0.697969, acc.: 42.31%] [G loss: 0.692372] [Time: 0.148780]\n",
            "4753-8 [D loss: 0.711414, acc.: 44.23%] [G loss: 0.689928] [Time: 0.151813]\n",
            "4753 (test) [D loss: 0.986124, acc.: 50.00%] [G loss: 0.697595] [Time: 0.044127]\n",
            "4754-0 [D loss: 0.679445, acc.: 53.85%] [G loss: 0.745984] [Time: 0.149546]\n",
            "4754-1 [D loss: 0.704355, acc.: 48.08%] [G loss: 0.693744] [Time: 0.148499]\n",
            "4754-2 [D loss: 0.693580, acc.: 46.15%] [G loss: 0.705559] [Time: 0.148433]\n",
            "4754-3 [D loss: 0.674327, acc.: 46.15%] [G loss: 0.730619] [Time: 0.147582]\n",
            "4754-4 [D loss: 0.709011, acc.: 42.31%] [G loss: 0.708161] [Time: 0.148714]\n",
            "4754-5 [D loss: 0.691448, acc.: 38.46%] [G loss: 0.722694] [Time: 0.147129]\n",
            "4754-6 [D loss: 0.698098, acc.: 36.54%] [G loss: 0.723586] [Time: 0.146830]\n",
            "4754-7 [D loss: 0.699616, acc.: 38.46%] [G loss: 0.688456] [Time: 0.150736]\n",
            "4754-8 [D loss: 0.712217, acc.: 48.08%] [G loss: 0.695795] [Time: 0.148738]\n",
            "4754 (test) [D loss: 0.966732, acc.: 50.00%] [G loss: 0.768389] [Time: 0.044302]\n",
            "4755-0 [D loss: 0.657985, acc.: 65.38%] [G loss: 0.739694] [Time: 0.148922]\n",
            "4755-1 [D loss: 0.705678, acc.: 40.38%] [G loss: 0.688634] [Time: 0.153125]\n",
            "4755-2 [D loss: 0.709694, acc.: 44.23%] [G loss: 0.716017] [Time: 0.149721]\n",
            "4755-3 [D loss: 0.679337, acc.: 57.69%] [G loss: 0.762805] [Time: 0.147749]\n",
            "4755-4 [D loss: 0.702489, acc.: 42.31%] [G loss: 0.715216] [Time: 0.150762]\n",
            "4755-5 [D loss: 0.676844, acc.: 48.08%] [G loss: 0.730058] [Time: 0.150528]\n",
            "4755-6 [D loss: 0.690680, acc.: 46.15%] [G loss: 0.702309] [Time: 0.150055]\n",
            "4755-7 [D loss: 0.696628, acc.: 44.23%] [G loss: 0.703149] [Time: 0.150794]\n",
            "4755-8 [D loss: 0.699849, acc.: 44.23%] [G loss: 0.711976] [Time: 0.147992]\n",
            "4755 (test) [D loss: 0.962902, acc.: 50.00%] [G loss: 0.768252] [Time: 0.045495]\n",
            "4756-0 [D loss: 0.674975, acc.: 65.38%] [G loss: 0.756879] [Time: 0.148167]\n",
            "4756-1 [D loss: 0.703951, acc.: 44.23%] [G loss: 0.694601] [Time: 0.150848]\n",
            "4756-2 [D loss: 0.703855, acc.: 40.38%] [G loss: 0.716933] [Time: 0.151137]\n",
            "4756-3 [D loss: 0.668757, acc.: 57.69%] [G loss: 0.724827] [Time: 0.151014]\n",
            "4756-4 [D loss: 0.703321, acc.: 34.62%] [G loss: 0.722265] [Time: 0.149694]\n",
            "4756-5 [D loss: 0.683507, acc.: 25.00%] [G loss: 0.725960] [Time: 0.148600]\n",
            "4756-6 [D loss: 0.693295, acc.: 40.38%] [G loss: 0.743817] [Time: 0.147422]\n",
            "4756-7 [D loss: 0.705835, acc.: 26.92%] [G loss: 0.710871] [Time: 0.148028]\n",
            "4756-8 [D loss: 0.713267, acc.: 38.46%] [G loss: 0.694213] [Time: 0.154472]\n",
            "4756 (test) [D loss: 0.938339, acc.: 50.00%] [G loss: 0.904705] [Time: 0.045694]\n",
            "4757-0 [D loss: 0.667954, acc.: 57.69%] [G loss: 0.747051] [Time: 0.151875]\n",
            "4757-1 [D loss: 0.714139, acc.: 50.00%] [G loss: 0.684084] [Time: 0.148806]\n",
            "4757-2 [D loss: 0.705472, acc.: 40.38%] [G loss: 0.714620] [Time: 0.150419]\n",
            "4757-3 [D loss: 0.673448, acc.: 51.92%] [G loss: 0.733288] [Time: 0.151931]\n",
            "4757-4 [D loss: 0.713362, acc.: 38.46%] [G loss: 0.690869] [Time: 0.150028]\n",
            "4757-5 [D loss: 0.680544, acc.: 46.15%] [G loss: 0.715343] [Time: 0.148071]\n",
            "4757-6 [D loss: 0.696894, acc.: 44.23%] [G loss: 0.714331] [Time: 0.148701]\n",
            "4757-7 [D loss: 0.694623, acc.: 51.92%] [G loss: 0.687254] [Time: 0.150006]\n",
            "4757-8 [D loss: 0.707907, acc.: 36.54%] [G loss: 0.699693] [Time: 0.149959]\n",
            "4757 (test) [D loss: 0.982879, acc.: 50.00%] [G loss: 0.707348] [Time: 0.043696]\n",
            "4758-0 [D loss: 0.669950, acc.: 61.54%] [G loss: 0.712784] [Time: 0.148227]\n",
            "4758-1 [D loss: 0.703184, acc.: 38.46%] [G loss: 0.690156] [Time: 0.151248]\n",
            "4758-2 [D loss: 0.692957, acc.: 55.77%] [G loss: 0.695495] [Time: 0.153467]\n",
            "4758-3 [D loss: 0.678001, acc.: 53.85%] [G loss: 0.752519] [Time: 0.150324]\n",
            "4758-4 [D loss: 0.697249, acc.: 42.31%] [G loss: 0.700117] [Time: 0.149573]\n",
            "4758-5 [D loss: 0.679491, acc.: 48.08%] [G loss: 0.713079] [Time: 0.148046]\n",
            "4758-6 [D loss: 0.684742, acc.: 42.31%] [G loss: 0.734070] [Time: 0.147500]\n",
            "4758-7 [D loss: 0.697878, acc.: 36.54%] [G loss: 0.700624] [Time: 0.147976]\n",
            "4758-8 [D loss: 0.697783, acc.: 32.69%] [G loss: 0.714195] [Time: 0.147869]\n",
            "4758 (test) [D loss: 0.945850, acc.: 51.92%] [G loss: 0.913399] [Time: 0.043974]\n",
            "4759-0 [D loss: 0.675025, acc.: 57.69%] [G loss: 0.740966] [Time: 0.149061]\n",
            "4759-1 [D loss: 0.696508, acc.: 50.00%] [G loss: 0.703632] [Time: 0.155595]\n",
            "4759-2 [D loss: 0.703334, acc.: 36.54%] [G loss: 0.711932] [Time: 0.149921]\n",
            "4759-3 [D loss: 0.666733, acc.: 57.69%] [G loss: 0.741348] [Time: 0.148232]\n",
            "4759-4 [D loss: 0.698302, acc.: 40.38%] [G loss: 0.695041] [Time: 0.150652]\n",
            "4759-5 [D loss: 0.682308, acc.: 42.31%] [G loss: 0.728833] [Time: 0.149985]\n",
            "4759-6 [D loss: 0.701625, acc.: 38.46%] [G loss: 0.713178] [Time: 0.148366]\n",
            "4759-7 [D loss: 0.700441, acc.: 44.23%] [G loss: 0.694857] [Time: 0.150037]\n",
            "4759-8 [D loss: 0.695313, acc.: 46.15%] [G loss: 0.686302] [Time: 0.148786]\n",
            "4759 (test) [D loss: 0.954964, acc.: 50.00%] [G loss: 0.761848] [Time: 0.045144]\n",
            "4760-0 [D loss: 0.686327, acc.: 50.00%] [G loss: 0.734576] [Time: 0.151433]\n",
            "4760-1 [D loss: 0.706980, acc.: 32.69%] [G loss: 0.691757] [Time: 0.148247]\n",
            "4760-2 [D loss: 0.702866, acc.: 44.23%] [G loss: 0.702053] [Time: 0.151004]\n",
            "4760-3 [D loss: 0.663622, acc.: 51.92%] [G loss: 0.742569] [Time: 0.149415]\n",
            "4760-4 [D loss: 0.705034, acc.: 30.77%] [G loss: 0.684020] [Time: 0.148068]\n",
            "4760-5 [D loss: 0.684746, acc.: 36.54%] [G loss: 0.702625] [Time: 0.150201]\n",
            "4760-6 [D loss: 0.701204, acc.: 42.31%] [G loss: 0.705724] [Time: 0.147547]\n",
            "4760-7 [D loss: 0.705075, acc.: 42.31%] [G loss: 0.704418] [Time: 0.150174]\n",
            "4760-8 [D loss: 0.704850, acc.: 38.46%] [G loss: 0.697686] [Time: 0.150186]\n",
            "4760 (test) [D loss: 0.946163, acc.: 50.00%] [G loss: 0.789150] [Time: 0.043460]\n",
            "4761-0 [D loss: 0.678019, acc.: 61.54%] [G loss: 0.715163] [Time: 0.148255]\n",
            "4761-1 [D loss: 0.692822, acc.: 53.85%] [G loss: 0.696168] [Time: 0.155579]\n",
            "4761-2 [D loss: 0.705149, acc.: 44.23%] [G loss: 0.696347] [Time: 0.148016]\n",
            "4761-3 [D loss: 0.666197, acc.: 53.85%] [G loss: 0.719597] [Time: 0.147689]\n",
            "4761-4 [D loss: 0.700659, acc.: 44.23%] [G loss: 0.691223] [Time: 0.147956]\n",
            "4761-5 [D loss: 0.676330, acc.: 44.23%] [G loss: 0.707063] [Time: 0.148775]\n",
            "4761-6 [D loss: 0.697391, acc.: 42.31%] [G loss: 0.700779] [Time: 0.152117]\n",
            "4761-7 [D loss: 0.705077, acc.: 30.77%] [G loss: 0.702182] [Time: 0.147500]\n",
            "4761-8 [D loss: 0.718619, acc.: 36.54%] [G loss: 0.714098] [Time: 0.150454]\n",
            "4761 (test) [D loss: 0.957838, acc.: 50.00%] [G loss: 0.816319] [Time: 0.044200]\n",
            "4762-0 [D loss: 0.679706, acc.: 48.08%] [G loss: 0.753370] [Time: 0.148819]\n",
            "4762-1 [D loss: 0.688187, acc.: 51.92%] [G loss: 0.702092] [Time: 0.150994]\n",
            "4762-2 [D loss: 0.698465, acc.: 32.69%] [G loss: 0.707598] [Time: 0.148764]\n",
            "4762-3 [D loss: 0.675188, acc.: 44.23%] [G loss: 0.746045] [Time: 0.149509]\n",
            "4762-4 [D loss: 0.706614, acc.: 36.54%] [G loss: 0.691991] [Time: 0.149188]\n",
            "4762-5 [D loss: 0.703959, acc.: 32.69%] [G loss: 0.727956] [Time: 0.147745]\n",
            "4762-6 [D loss: 0.690948, acc.: 48.08%] [G loss: 0.712537] [Time: 0.152711]\n",
            "4762-7 [D loss: 0.694710, acc.: 46.15%] [G loss: 0.682975] [Time: 0.148531]\n",
            "4762-8 [D loss: 0.703308, acc.: 32.69%] [G loss: 0.685920] [Time: 0.148904]\n",
            "4762 (test) [D loss: 0.931748, acc.: 50.00%] [G loss: 0.918352] [Time: 0.044778]\n",
            "4763-0 [D loss: 0.669038, acc.: 51.92%] [G loss: 0.724104] [Time: 0.147796]\n",
            "4763-1 [D loss: 0.693030, acc.: 55.77%] [G loss: 0.704976] [Time: 0.149172]\n",
            "4763-2 [D loss: 0.716457, acc.: 32.69%] [G loss: 0.701820] [Time: 0.147273]\n",
            "4763-3 [D loss: 0.680353, acc.: 42.31%] [G loss: 0.713827] [Time: 0.149071]\n",
            "4763-4 [D loss: 0.738316, acc.: 40.38%] [G loss: 0.687421] [Time: 0.148605]\n",
            "4763-5 [D loss: 0.693828, acc.: 32.69%] [G loss: 0.703438] [Time: 0.147454]\n",
            "4763-6 [D loss: 0.709628, acc.: 32.69%] [G loss: 0.698786] [Time: 0.150846]\n",
            "4763-7 [D loss: 0.699670, acc.: 42.31%] [G loss: 0.700226] [Time: 0.150074]\n",
            "4763-8 [D loss: 0.695379, acc.: 42.31%] [G loss: 0.718905] [Time: 0.147527]\n",
            "4763 (test) [D loss: 0.938853, acc.: 50.00%] [G loss: 0.861155] [Time: 0.044481]\n",
            "4764-0 [D loss: 0.755792, acc.: 46.15%] [G loss: 0.630393] [Time: 0.149429]\n",
            "4764-1 [D loss: 0.706373, acc.: 53.85%] [G loss: 0.716798] [Time: 0.148441]\n",
            "4764-2 [D loss: 0.707858, acc.: 36.54%] [G loss: 0.730907] [Time: 0.147388]\n",
            "4764-3 [D loss: 0.729621, acc.: 38.46%] [G loss: 0.685616] [Time: 0.149055]\n",
            "4764-4 [D loss: 0.713642, acc.: 32.69%] [G loss: 0.711718] [Time: 0.154002]\n",
            "4764-5 [D loss: 0.687175, acc.: 48.08%] [G loss: 0.750708] [Time: 0.147958]\n",
            "4764-6 [D loss: 0.710176, acc.: 44.23%] [G loss: 0.739754] [Time: 0.149057]\n",
            "4764-7 [D loss: 0.711957, acc.: 32.69%] [G loss: 0.721255] [Time: 0.147809]\n",
            "4764-8 [D loss: 0.711073, acc.: 34.62%] [G loss: 0.676528] [Time: 0.161323]\n",
            "4764 (test) [D loss: 0.998320, acc.: 50.00%] [G loss: 0.672166] [Time: 0.043298]\n",
            "4765-0 [D loss: 0.736371, acc.: 42.31%] [G loss: 0.690199] [Time: 0.148945]\n",
            "4765-1 [D loss: 0.694145, acc.: 42.31%] [G loss: 0.691686] [Time: 0.147218]\n",
            "4765-2 [D loss: 0.699488, acc.: 42.31%] [G loss: 0.685570] [Time: 0.148490]\n",
            "4765-3 [D loss: 0.723044, acc.: 38.46%] [G loss: 0.703811] [Time: 0.148265]\n",
            "4765-4 [D loss: 0.702844, acc.: 42.31%] [G loss: 0.671847] [Time: 0.149855]\n",
            "4765-5 [D loss: 0.699895, acc.: 48.08%] [G loss: 0.682477] [Time: 0.149383]\n",
            "4765-6 [D loss: 0.692963, acc.: 46.15%] [G loss: 0.709543] [Time: 0.149828]\n",
            "4765-7 [D loss: 0.701429, acc.: 50.00%] [G loss: 0.680377] [Time: 0.150840]\n",
            "4765-8 [D loss: 0.703273, acc.: 48.08%] [G loss: 0.691374] [Time: 0.148260]\n",
            "4765 (test) [D loss: 1.178354, acc.: 50.00%] [G loss: 0.407258] [Time: 0.043559]\n",
            "4766-0 [D loss: 0.714849, acc.: 44.23%] [G loss: 0.665922] [Time: 0.149105]\n",
            "4766-1 [D loss: 0.698404, acc.: 42.31%] [G loss: 0.666493] [Time: 0.150364]\n",
            "4766-2 [D loss: 0.715360, acc.: 44.23%] [G loss: 0.677388] [Time: 0.148753]\n",
            "4766-3 [D loss: 0.695269, acc.: 46.15%] [G loss: 0.718287] [Time: 0.147634]\n",
            "4766-4 [D loss: 0.704323, acc.: 46.15%] [G loss: 0.682248] [Time: 0.148025]\n",
            "4766-5 [D loss: 0.718504, acc.: 40.38%] [G loss: 0.679557] [Time: 0.149869]\n",
            "4766-6 [D loss: 0.705909, acc.: 48.08%] [G loss: 0.695352] [Time: 0.147795]\n",
            "4766-7 [D loss: 0.700923, acc.: 51.92%] [G loss: 0.692225] [Time: 0.151315]\n",
            "4766-8 [D loss: 0.704208, acc.: 46.15%] [G loss: 0.700709] [Time: 0.149597]\n",
            "4766 (test) [D loss: 1.121986, acc.: 50.00%] [G loss: 0.476761] [Time: 0.042691]\n",
            "4767-0 [D loss: 0.726304, acc.: 40.38%] [G loss: 0.673208] [Time: 0.147344]\n",
            "4767-1 [D loss: 0.704300, acc.: 32.69%] [G loss: 0.678120] [Time: 0.150888]\n",
            "4767-2 [D loss: 0.705913, acc.: 36.54%] [G loss: 0.694495] [Time: 0.148065]\n",
            "4767-3 [D loss: 0.690323, acc.: 51.92%] [G loss: 0.710189] [Time: 0.148426]\n",
            "4767-4 [D loss: 0.706100, acc.: 38.46%] [G loss: 0.684247] [Time: 0.148866]\n",
            "4767-5 [D loss: 0.710715, acc.: 36.54%] [G loss: 0.680290] [Time: 0.148970]\n",
            "4767-6 [D loss: 0.710822, acc.: 44.23%] [G loss: 0.693990] [Time: 0.149274]\n",
            "4767-7 [D loss: 0.708003, acc.: 48.08%] [G loss: 0.699121] [Time: 0.152234]\n",
            "4767-8 [D loss: 0.692158, acc.: 46.15%] [G loss: 0.723815] [Time: 0.148009]\n",
            "4767 (test) [D loss: 0.995232, acc.: 50.00%] [G loss: 0.766663] [Time: 0.044474]\n",
            "4768-0 [D loss: 0.722466, acc.: 32.69%] [G loss: 0.707754] [Time: 0.150270]\n",
            "4768-1 [D loss: 0.695000, acc.: 44.23%] [G loss: 0.693181] [Time: 0.149296]\n",
            "4768-2 [D loss: 0.704648, acc.: 48.08%] [G loss: 0.700662] [Time: 0.148697]\n",
            "4768-3 [D loss: 0.716205, acc.: 46.15%] [G loss: 0.706297] [Time: 0.148317]\n",
            "4768-4 [D loss: 0.699851, acc.: 36.54%] [G loss: 0.726789] [Time: 0.154077]\n",
            "4768-5 [D loss: 0.712883, acc.: 32.69%] [G loss: 0.714265] [Time: 0.147323]\n",
            "4768-6 [D loss: 0.700350, acc.: 44.23%] [G loss: 0.719873] [Time: 0.151901]\n",
            "4768-7 [D loss: 0.705276, acc.: 38.46%] [G loss: 0.714315] [Time: 0.149097]\n",
            "4768-8 [D loss: 0.695905, acc.: 44.23%] [G loss: 0.730947] [Time: 0.147889]\n",
            "4768 (test) [D loss: 0.984362, acc.: 50.00%] [G loss: 1.010138] [Time: 0.044187]\n",
            "4769-0 [D loss: 0.716940, acc.: 38.46%] [G loss: 0.727674] [Time: 0.147511]\n",
            "4769-1 [D loss: 0.696712, acc.: 48.08%] [G loss: 0.688391] [Time: 0.150588]\n",
            "4769-2 [D loss: 0.710938, acc.: 44.23%] [G loss: 0.724508] [Time: 0.147922]\n",
            "4769-3 [D loss: 0.698892, acc.: 38.46%] [G loss: 0.720760] [Time: 0.151183]\n",
            "4769-4 [D loss: 0.704985, acc.: 42.31%] [G loss: 0.702526] [Time: 0.148294]\n",
            "4769-5 [D loss: 0.710089, acc.: 34.62%] [G loss: 0.678031] [Time: 0.151563]\n",
            "4769-6 [D loss: 0.700482, acc.: 51.92%] [G loss: 0.728210] [Time: 0.150844]\n",
            "4769-7 [D loss: 0.706744, acc.: 42.31%] [G loss: 0.706769] [Time: 0.149116]\n",
            "4769-8 [D loss: 0.696519, acc.: 36.54%] [G loss: 0.685567] [Time: 0.154215]\n",
            "4769 (test) [D loss: 0.958024, acc.: 50.00%] [G loss: 0.897955] [Time: 0.044599]\n",
            "4770-0 [D loss: 0.692739, acc.: 36.54%] [G loss: 0.727513] [Time: 0.150835]\n",
            "4770-1 [D loss: 0.703102, acc.: 42.31%] [G loss: 0.706269] [Time: 0.147671]\n",
            "4770-2 [D loss: 0.721767, acc.: 30.77%] [G loss: 0.698898] [Time: 0.149183]\n",
            "4770-3 [D loss: 0.731807, acc.: 38.46%] [G loss: 0.729003] [Time: 0.148266]\n",
            "4770-4 [D loss: 0.699069, acc.: 42.31%] [G loss: 0.708136] [Time: 0.156622]\n",
            "4770-5 [D loss: 0.716474, acc.: 38.46%] [G loss: 0.697923] [Time: 0.147441]\n",
            "4770-6 [D loss: 0.705402, acc.: 48.08%] [G loss: 0.706403] [Time: 0.148924]\n",
            "4770-7 [D loss: 0.693863, acc.: 48.08%] [G loss: 0.704796] [Time: 0.147802]\n",
            "4770-8 [D loss: 0.705845, acc.: 46.15%] [G loss: 0.700430] [Time: 0.156566]\n",
            "4770 (test) [D loss: 1.001210, acc.: 51.92%] [G loss: 0.782102] [Time: 0.044749]\n",
            "4771-0 [D loss: 0.708344, acc.: 42.31%] [G loss: 0.704660] [Time: 0.146718]\n",
            "4771-1 [D loss: 0.693532, acc.: 51.92%] [G loss: 0.689464] [Time: 0.149728]\n",
            "4771-2 [D loss: 0.711080, acc.: 46.15%] [G loss: 0.690198] [Time: 0.153207]\n",
            "4771-3 [D loss: 0.706890, acc.: 44.23%] [G loss: 0.725575] [Time: 0.151663]\n",
            "4771-4 [D loss: 0.709927, acc.: 34.62%] [G loss: 0.680283] [Time: 0.148430]\n",
            "4771-5 [D loss: 0.701564, acc.: 44.23%] [G loss: 0.688384] [Time: 0.151220]\n",
            "4771-6 [D loss: 0.692348, acc.: 50.00%] [G loss: 0.720761] [Time: 0.146616]\n",
            "4771-7 [D loss: 0.709025, acc.: 44.23%] [G loss: 0.694857] [Time: 0.151256]\n",
            "4771-8 [D loss: 0.715921, acc.: 36.54%] [G loss: 0.695623] [Time: 0.148259]\n",
            "4771 (test) [D loss: 1.089397, acc.: 50.00%] [G loss: 0.596792] [Time: 0.044759]\n",
            "4772-0 [D loss: 0.710591, acc.: 42.31%] [G loss: 0.681289] [Time: 0.151076]\n",
            "4772-1 [D loss: 0.695546, acc.: 48.08%] [G loss: 0.699680] [Time: 0.149269]\n",
            "4772-2 [D loss: 0.698239, acc.: 40.38%] [G loss: 0.679847] [Time: 0.148334]\n",
            "4772-3 [D loss: 0.705482, acc.: 42.31%] [G loss: 0.704786] [Time: 0.152549]\n",
            "4772-4 [D loss: 0.690083, acc.: 53.85%] [G loss: 0.702482] [Time: 0.151964]\n",
            "4772-5 [D loss: 0.713056, acc.: 40.38%] [G loss: 0.684954] [Time: 0.148782]\n",
            "4772-6 [D loss: 0.693003, acc.: 38.46%] [G loss: 0.686186] [Time: 0.147133]\n",
            "4772-7 [D loss: 0.705163, acc.: 50.00%] [G loss: 0.704258] [Time: 0.151249]\n",
            "4772-8 [D loss: 0.710939, acc.: 40.38%] [G loss: 0.678302] [Time: 0.147318]\n",
            "4772 (test) [D loss: 1.047858, acc.: 50.00%] [G loss: 0.616332] [Time: 0.045182]\n",
            "4773-0 [D loss: 0.704796, acc.: 40.38%] [G loss: 0.692448] [Time: 0.148408]\n",
            "4773-1 [D loss: 0.701254, acc.: 42.31%] [G loss: 0.679438] [Time: 0.149267]\n",
            "4773-2 [D loss: 0.705093, acc.: 42.31%] [G loss: 0.692778] [Time: 0.150195]\n",
            "4773-3 [D loss: 0.705135, acc.: 42.31%] [G loss: 0.732308] [Time: 0.147721]\n",
            "4773-4 [D loss: 0.705080, acc.: 28.85%] [G loss: 0.684590] [Time: 0.149323]\n",
            "4773-5 [D loss: 0.708472, acc.: 36.54%] [G loss: 0.673012] [Time: 0.148184]\n",
            "4773-6 [D loss: 0.705768, acc.: 44.23%] [G loss: 0.701637] [Time: 0.151421]\n",
            "4773-7 [D loss: 0.705867, acc.: 44.23%] [G loss: 0.686858] [Time: 0.149537]\n",
            "4773-8 [D loss: 0.702765, acc.: 42.31%] [G loss: 0.669564] [Time: 0.149254]\n",
            "4773 (test) [D loss: 1.103970, acc.: 50.00%] [G loss: 0.536843] [Time: 0.044751]\n",
            "4774-0 [D loss: 0.687303, acc.: 46.15%] [G loss: 0.699878] [Time: 0.153835]\n",
            "4774-1 [D loss: 0.693607, acc.: 51.92%] [G loss: 0.704977] [Time: 0.148812]\n",
            "4774-2 [D loss: 0.714790, acc.: 28.85%] [G loss: 0.686213] [Time: 0.147968]\n",
            "4774-3 [D loss: 0.706265, acc.: 38.46%] [G loss: 0.725922] [Time: 0.147532]\n",
            "4774-4 [D loss: 0.698539, acc.: 38.46%] [G loss: 0.690333] [Time: 0.149159]\n",
            "4774-5 [D loss: 0.686954, acc.: 51.92%] [G loss: 0.680763] [Time: 0.147284]\n",
            "4774-6 [D loss: 0.697679, acc.: 36.54%] [G loss: 0.712270] [Time: 0.150560]\n",
            "4774-7 [D loss: 0.706441, acc.: 44.23%] [G loss: 0.704856] [Time: 0.149320]\n",
            "4774-8 [D loss: 0.705088, acc.: 42.31%] [G loss: 0.685476] [Time: 0.147335]\n",
            "4774 (test) [D loss: 1.040476, acc.: 50.00%] [G loss: 0.643758] [Time: 0.043507]\n",
            "4775-0 [D loss: 0.716474, acc.: 34.62%] [G loss: 0.706739] [Time: 0.149197]\n",
            "4775-1 [D loss: 0.700238, acc.: 50.00%] [G loss: 0.715061] [Time: 0.147994]\n",
            "4775-2 [D loss: 0.698487, acc.: 44.23%] [G loss: 0.687743] [Time: 0.148273]\n",
            "4775-3 [D loss: 0.706631, acc.: 53.85%] [G loss: 0.711329] [Time: 0.147561]\n",
            "4775-4 [D loss: 0.690579, acc.: 51.92%] [G loss: 0.667073] [Time: 0.149709]\n",
            "4775-5 [D loss: 0.710691, acc.: 34.62%] [G loss: 0.692748] [Time: 0.147901]\n",
            "4775-6 [D loss: 0.720103, acc.: 38.46%] [G loss: 0.687924] [Time: 0.146860]\n",
            "4775-7 [D loss: 0.704341, acc.: 53.85%] [G loss: 0.681709] [Time: 0.150454]\n",
            "4775-8 [D loss: 0.710555, acc.: 36.54%] [G loss: 0.683896] [Time: 0.147376]\n",
            "4775 (test) [D loss: 0.997815, acc.: 50.00%] [G loss: 0.795938] [Time: 0.046006]\n",
            "4776-0 [D loss: 0.701711, acc.: 38.46%] [G loss: 0.701997] [Time: 0.149817]\n",
            "4776-1 [D loss: 0.706206, acc.: 36.54%] [G loss: 0.694013] [Time: 0.147406]\n",
            "4776-2 [D loss: 0.692099, acc.: 46.15%] [G loss: 0.687239] [Time: 0.149654]\n",
            "4776-3 [D loss: 0.701810, acc.: 38.46%] [G loss: 0.712405] [Time: 0.146845]\n",
            "4776-4 [D loss: 0.693442, acc.: 42.31%] [G loss: 0.692596] [Time: 0.148492]\n",
            "4776-5 [D loss: 0.703161, acc.: 42.31%] [G loss: 0.692511] [Time: 0.148093]\n",
            "4776-6 [D loss: 0.695707, acc.: 48.08%] [G loss: 0.707771] [Time: 0.148579]\n",
            "4776-7 [D loss: 0.688636, acc.: 57.69%] [G loss: 0.694831] [Time: 0.150707]\n",
            "4776-8 [D loss: 0.719937, acc.: 38.46%] [G loss: 0.689432] [Time: 0.147929]\n",
            "4776 (test) [D loss: 0.996485, acc.: 50.00%] [G loss: 0.772153] [Time: 0.044889]\n",
            "4777-0 [D loss: 0.710608, acc.: 34.62%] [G loss: 0.720890] [Time: 0.150211]\n",
            "4777-1 [D loss: 0.702550, acc.: 40.38%] [G loss: 0.708527] [Time: 0.148994]\n",
            "4777-2 [D loss: 0.702332, acc.: 32.69%] [G loss: 0.693880] [Time: 0.147618]\n",
            "4777-3 [D loss: 0.706649, acc.: 42.31%] [G loss: 0.719471] [Time: 0.150527]\n",
            "4777-4 [D loss: 0.704850, acc.: 42.31%] [G loss: 0.688303] [Time: 0.149996]\n",
            "4777-5 [D loss: 0.693062, acc.: 44.23%] [G loss: 0.691829] [Time: 0.146833]\n",
            "4777-6 [D loss: 0.703548, acc.: 42.31%] [G loss: 0.715829] [Time: 0.153462]\n",
            "4777-7 [D loss: 0.697885, acc.: 46.15%] [G loss: 0.697481] [Time: 0.148281]\n",
            "4777-8 [D loss: 0.716229, acc.: 38.46%] [G loss: 0.687628] [Time: 0.149644]\n",
            "4777 (test) [D loss: 1.043800, acc.: 48.08%] [G loss: 0.656041] [Time: 0.044198]\n",
            "4778-0 [D loss: 0.690123, acc.: 48.08%] [G loss: 0.705663] [Time: 0.147391]\n",
            "4778-1 [D loss: 0.700823, acc.: 55.77%] [G loss: 0.696751] [Time: 0.147456]\n",
            "4778-2 [D loss: 0.688535, acc.: 53.85%] [G loss: 0.680959] [Time: 0.150404]\n",
            "4778-3 [D loss: 0.712941, acc.: 36.54%] [G loss: 0.705510] [Time: 0.147875]\n",
            "4778-4 [D loss: 0.690576, acc.: 51.92%] [G loss: 0.666336] [Time: 0.149604]\n",
            "4778-5 [D loss: 0.701820, acc.: 44.23%] [G loss: 0.691412] [Time: 0.152951]\n",
            "4778-6 [D loss: 0.695230, acc.: 44.23%] [G loss: 0.708290] [Time: 0.148342]\n",
            "4778-7 [D loss: 0.701544, acc.: 48.08%] [G loss: 0.692792] [Time: 0.148894]\n",
            "4778-8 [D loss: 0.706437, acc.: 44.23%] [G loss: 0.703077] [Time: 0.149741]\n",
            "4778 (test) [D loss: 1.075371, acc.: 50.00%] [G loss: 0.624999] [Time: 0.044530]\n",
            "4779-0 [D loss: 0.700753, acc.: 28.85%] [G loss: 0.700542] [Time: 0.148206]\n",
            "4779-1 [D loss: 0.693123, acc.: 53.85%] [G loss: 0.689337] [Time: 0.147476]\n",
            "4779-2 [D loss: 0.689572, acc.: 44.23%] [G loss: 0.683035] [Time: 0.149423]\n",
            "4779-3 [D loss: 0.719695, acc.: 38.46%] [G loss: 0.712966] [Time: 0.151429]\n",
            "4779-4 [D loss: 0.691066, acc.: 44.23%] [G loss: 0.709792] [Time: 0.155812]\n",
            "4779-5 [D loss: 0.700918, acc.: 40.38%] [G loss: 0.706414] [Time: 0.148740]\n",
            "4779-6 [D loss: 0.685634, acc.: 55.77%] [G loss: 0.710051] [Time: 0.147931]\n",
            "4779-7 [D loss: 0.707092, acc.: 36.54%] [G loss: 0.702974] [Time: 0.150032]\n",
            "4779-8 [D loss: 0.702688, acc.: 44.23%] [G loss: 0.679222] [Time: 0.148681]\n",
            "4779 (test) [D loss: 0.978245, acc.: 50.00%] [G loss: 0.833564] [Time: 0.043658]\n",
            "4780-0 [D loss: 0.727742, acc.: 23.08%] [G loss: 0.719877] [Time: 0.150794]\n",
            "4780-1 [D loss: 0.698963, acc.: 42.31%] [G loss: 0.710976] [Time: 0.150495]\n",
            "4780-2 [D loss: 0.699199, acc.: 44.23%] [G loss: 0.691084] [Time: 0.148333]\n",
            "4780-3 [D loss: 0.695233, acc.: 51.92%] [G loss: 0.728892] [Time: 0.149528]\n",
            "4780-4 [D loss: 0.708485, acc.: 36.54%] [G loss: 0.686548] [Time: 0.152336]\n",
            "4780-5 [D loss: 0.697574, acc.: 38.46%] [G loss: 0.690049] [Time: 0.150065]\n",
            "4780-6 [D loss: 0.689762, acc.: 51.92%] [G loss: 0.706346] [Time: 0.148262]\n",
            "4780-7 [D loss: 0.700226, acc.: 48.08%] [G loss: 0.708817] [Time: 0.148091]\n",
            "4780-8 [D loss: 0.726178, acc.: 30.77%] [G loss: 0.688874] [Time: 0.146852]\n",
            "4780 (test) [D loss: 1.056563, acc.: 50.00%] [G loss: 0.720501] [Time: 0.044134]\n",
            "4781-0 [D loss: 0.713095, acc.: 40.38%] [G loss: 0.688310] [Time: 0.147198]\n",
            "4781-1 [D loss: 0.701828, acc.: 48.08%] [G loss: 0.698718] [Time: 0.149587]\n",
            "4781-2 [D loss: 0.697699, acc.: 42.31%] [G loss: 0.693669] [Time: 0.152700]\n",
            "4781-3 [D loss: 0.700846, acc.: 53.85%] [G loss: 0.708466] [Time: 0.149063]\n",
            "4781-4 [D loss: 0.690563, acc.: 48.08%] [G loss: 0.678734] [Time: 0.149064]\n",
            "4781-5 [D loss: 0.703519, acc.: 40.38%] [G loss: 0.710317] [Time: 0.150353]\n",
            "4781-6 [D loss: 0.706834, acc.: 51.92%] [G loss: 0.706880] [Time: 0.150318]\n",
            "4781-7 [D loss: 0.696614, acc.: 44.23%] [G loss: 0.694066] [Time: 0.149596]\n",
            "4781-8 [D loss: 0.701045, acc.: 48.08%] [G loss: 0.679861] [Time: 0.150033]\n",
            "4781 (test) [D loss: 1.060282, acc.: 50.00%] [G loss: 0.682260] [Time: 0.047436]\n",
            "4782-0 [D loss: 0.698678, acc.: 38.46%] [G loss: 0.697952] [Time: 0.148079]\n",
            "4782-1 [D loss: 0.702512, acc.: 48.08%] [G loss: 0.695259] [Time: 0.147837]\n",
            "4782-2 [D loss: 0.692105, acc.: 51.92%] [G loss: 0.690797] [Time: 0.148568]\n",
            "4782-3 [D loss: 0.705982, acc.: 44.23%] [G loss: 0.708891] [Time: 0.148765]\n",
            "4782-4 [D loss: 0.702196, acc.: 42.31%] [G loss: 0.678012] [Time: 0.151968]\n",
            "4782-5 [D loss: 0.700316, acc.: 42.31%] [G loss: 0.678215] [Time: 0.148867]\n",
            "4782-6 [D loss: 0.691043, acc.: 50.00%] [G loss: 0.696684] [Time: 0.148642]\n",
            "4782-7 [D loss: 0.713708, acc.: 30.77%] [G loss: 0.693081] [Time: 0.147859]\n",
            "4782-8 [D loss: 0.697967, acc.: 50.00%] [G loss: 0.686362] [Time: 0.148091]\n",
            "4782 (test) [D loss: 1.192866, acc.: 48.08%] [G loss: 0.471885] [Time: 0.043160]\n",
            "4783-0 [D loss: 0.693396, acc.: 40.38%] [G loss: 0.693042] [Time: 0.146859]\n",
            "4783-1 [D loss: 0.697349, acc.: 44.23%] [G loss: 0.704358] [Time: 0.149290]\n",
            "4783-2 [D loss: 0.697012, acc.: 48.08%] [G loss: 0.674424] [Time: 0.148405]\n",
            "4783-3 [D loss: 0.722015, acc.: 46.15%] [G loss: 0.701041] [Time: 0.150548]\n",
            "4783-4 [D loss: 0.696623, acc.: 48.08%] [G loss: 0.693600] [Time: 0.147336]\n",
            "4783-5 [D loss: 0.720652, acc.: 38.46%] [G loss: 0.677419] [Time: 0.148967]\n",
            "4783-6 [D loss: 0.700112, acc.: 44.23%] [G loss: 0.684101] [Time: 0.152530]\n",
            "4783-7 [D loss: 0.694745, acc.: 44.23%] [G loss: 0.674272] [Time: 0.149738]\n",
            "4783-8 [D loss: 0.703874, acc.: 42.31%] [G loss: 0.686629] [Time: 0.146847]\n",
            "4783 (test) [D loss: 1.095204, acc.: 50.00%] [G loss: 0.544663] [Time: 0.045231]\n",
            "4784-0 [D loss: 0.707523, acc.: 34.62%] [G loss: 0.701416] [Time: 0.150880]\n",
            "4784-1 [D loss: 0.701585, acc.: 44.23%] [G loss: 0.680882] [Time: 0.150698]\n",
            "4784-2 [D loss: 0.712643, acc.: 40.38%] [G loss: 0.661837] [Time: 0.150884]\n",
            "4784-3 [D loss: 0.709211, acc.: 46.15%] [G loss: 0.714525] [Time: 0.151002]\n",
            "4784-4 [D loss: 0.704527, acc.: 42.31%] [G loss: 0.680867] [Time: 0.154320]\n",
            "4784-5 [D loss: 0.697245, acc.: 38.46%] [G loss: 0.703698] [Time: 0.150040]\n",
            "4784-6 [D loss: 0.696415, acc.: 48.08%] [G loss: 0.711804] [Time: 0.149402]\n",
            "4784-7 [D loss: 0.720707, acc.: 34.62%] [G loss: 0.693450] [Time: 0.150069]\n",
            "4784-8 [D loss: 0.690116, acc.: 40.38%] [G loss: 0.684101] [Time: 0.148003]\n",
            "4784 (test) [D loss: 1.020308, acc.: 51.92%] [G loss: 0.687357] [Time: 0.043461]\n",
            "4785-0 [D loss: 0.725325, acc.: 40.38%] [G loss: 0.712403] [Time: 0.149603]\n",
            "4785-1 [D loss: 0.698582, acc.: 38.46%] [G loss: 0.704228] [Time: 0.152768]\n",
            "4785-2 [D loss: 0.704416, acc.: 46.15%] [G loss: 0.693887] [Time: 0.148785]\n",
            "4785-3 [D loss: 0.705360, acc.: 48.08%] [G loss: 0.726430] [Time: 0.147692]\n",
            "4785-4 [D loss: 0.699922, acc.: 53.85%] [G loss: 0.706640] [Time: 0.150348]\n",
            "4785-5 [D loss: 0.685136, acc.: 57.69%] [G loss: 0.698372] [Time: 0.148244]\n",
            "4785-6 [D loss: 0.691432, acc.: 48.08%] [G loss: 0.710592] [Time: 0.148723]\n",
            "4785-7 [D loss: 0.693478, acc.: 51.92%] [G loss: 0.709584] [Time: 0.151606]\n",
            "4785-8 [D loss: 0.709501, acc.: 34.62%] [G loss: 0.685271] [Time: 0.150066]\n",
            "4785 (test) [D loss: 1.088343, acc.: 53.85%] [G loss: 0.571502] [Time: 0.044100]\n",
            "4786-0 [D loss: 0.708332, acc.: 40.38%] [G loss: 0.714098] [Time: 0.150158]\n",
            "4786-1 [D loss: 0.695890, acc.: 48.08%] [G loss: 0.695987] [Time: 0.147572]\n",
            "4786-2 [D loss: 0.717545, acc.: 42.31%] [G loss: 0.678503] [Time: 0.147161]\n",
            "4786-3 [D loss: 0.695767, acc.: 48.08%] [G loss: 0.717178] [Time: 0.147953]\n",
            "4786-4 [D loss: 0.698389, acc.: 53.85%] [G loss: 0.682477] [Time: 0.151046]\n",
            "4786-5 [D loss: 0.709733, acc.: 36.54%] [G loss: 0.677542] [Time: 0.147583]\n",
            "4786-6 [D loss: 0.681189, acc.: 50.00%] [G loss: 0.700604] [Time: 0.149024]\n",
            "4786-7 [D loss: 0.692738, acc.: 48.08%] [G loss: 0.690474] [Time: 0.146809]\n",
            "4786-8 [D loss: 0.692969, acc.: 55.77%] [G loss: 0.704050] [Time: 0.148847]\n",
            "4786 (test) [D loss: 1.112086, acc.: 53.85%] [G loss: 0.542943] [Time: 0.043882]\n",
            "4787-0 [D loss: 0.700071, acc.: 44.23%] [G loss: 0.724974] [Time: 0.148899]\n",
            "4787-1 [D loss: 0.706485, acc.: 46.15%] [G loss: 0.710177] [Time: 0.149297]\n",
            "4787-2 [D loss: 0.698433, acc.: 50.00%] [G loss: 0.699866] [Time: 0.152835]\n",
            "4787-3 [D loss: 0.697361, acc.: 50.00%] [G loss: 0.722731] [Time: 0.149198]\n",
            "4787-4 [D loss: 0.687608, acc.: 44.23%] [G loss: 0.693975] [Time: 0.148133]\n",
            "4787-5 [D loss: 0.706138, acc.: 32.69%] [G loss: 0.679808] [Time: 0.149102]\n",
            "4787-6 [D loss: 0.697902, acc.: 48.08%] [G loss: 0.706270] [Time: 0.148535]\n",
            "4787-7 [D loss: 0.708451, acc.: 34.62%] [G loss: 0.700422] [Time: 0.149983]\n",
            "4787-8 [D loss: 0.702502, acc.: 40.38%] [G loss: 0.696202] [Time: 0.147745]\n",
            "4787 (test) [D loss: 1.051413, acc.: 51.92%] [G loss: 0.582005] [Time: 0.043235]\n",
            "4788-0 [D loss: 0.704804, acc.: 42.31%] [G loss: 0.698158] [Time: 0.147798]\n",
            "4788-1 [D loss: 0.699425, acc.: 44.23%] [G loss: 0.702691] [Time: 0.147335]\n",
            "4788-2 [D loss: 0.705717, acc.: 40.38%] [G loss: 0.712474] [Time: 0.147698]\n",
            "4788-3 [D loss: 0.697436, acc.: 40.38%] [G loss: 0.709620] [Time: 0.151175]\n",
            "4788-4 [D loss: 0.697272, acc.: 42.31%] [G loss: 0.694992] [Time: 0.148707]\n",
            "4788-5 [D loss: 0.698349, acc.: 38.46%] [G loss: 0.691298] [Time: 0.147273]\n",
            "4788-6 [D loss: 0.695262, acc.: 44.23%] [G loss: 0.695644] [Time: 0.147730]\n",
            "4788-7 [D loss: 0.709388, acc.: 42.31%] [G loss: 0.700875] [Time: 0.151648]\n",
            "4788-8 [D loss: 0.687570, acc.: 51.92%] [G loss: 0.687258] [Time: 0.149144]\n",
            "4788 (test) [D loss: 1.044308, acc.: 51.92%] [G loss: 0.612873] [Time: 0.044060]\n",
            "4789-0 [D loss: 0.709791, acc.: 40.38%] [G loss: 0.703814] [Time: 0.149943]\n",
            "4789-1 [D loss: 0.697196, acc.: 40.38%] [G loss: 0.698693] [Time: 0.149560]\n",
            "4789-2 [D loss: 0.692731, acc.: 50.00%] [G loss: 0.701922] [Time: 0.151379]\n",
            "4789-3 [D loss: 0.689101, acc.: 57.69%] [G loss: 0.706109] [Time: 0.152202]\n",
            "4789-4 [D loss: 0.709188, acc.: 42.31%] [G loss: 0.711015] [Time: 0.149176]\n",
            "4789-5 [D loss: 0.695203, acc.: 48.08%] [G loss: 0.691793] [Time: 0.147507]\n",
            "4789-6 [D loss: 0.684961, acc.: 46.15%] [G loss: 0.701710] [Time: 0.148029]\n",
            "4789-7 [D loss: 0.698717, acc.: 44.23%] [G loss: 0.694513] [Time: 0.150192]\n",
            "4789-8 [D loss: 0.695460, acc.: 40.38%] [G loss: 0.690132] [Time: 0.146708]\n",
            "4789 (test) [D loss: 1.031263, acc.: 48.08%] [G loss: 0.673549] [Time: 0.044034]\n",
            "4790-0 [D loss: 0.700982, acc.: 36.54%] [G loss: 0.712053] [Time: 0.147925]\n",
            "4790-1 [D loss: 0.701498, acc.: 40.38%] [G loss: 0.705387] [Time: 0.149918]\n",
            "4790-2 [D loss: 0.682786, acc.: 44.23%] [G loss: 0.694525] [Time: 0.150361]\n",
            "4790-3 [D loss: 0.696693, acc.: 44.23%] [G loss: 0.740420] [Time: 0.150563]\n",
            "4790-4 [D loss: 0.680935, acc.: 50.00%] [G loss: 0.708346] [Time: 0.149548]\n",
            "4790-5 [D loss: 0.699229, acc.: 40.38%] [G loss: 0.694035] [Time: 0.147927]\n",
            "4790-6 [D loss: 0.691402, acc.: 46.15%] [G loss: 0.707826] [Time: 0.148789]\n",
            "4790-7 [D loss: 0.695624, acc.: 48.08%] [G loss: 0.691424] [Time: 0.147347]\n",
            "4790-8 [D loss: 0.699091, acc.: 44.23%] [G loss: 0.691129] [Time: 0.147049]\n",
            "4790 (test) [D loss: 1.043152, acc.: 50.00%] [G loss: 0.629130] [Time: 0.044321]\n",
            "4791-0 [D loss: 0.698947, acc.: 40.38%] [G loss: 0.729256] [Time: 0.147506]\n",
            "4791-1 [D loss: 0.692084, acc.: 44.23%] [G loss: 0.696285] [Time: 0.148029]\n",
            "4791-2 [D loss: 0.701291, acc.: 42.31%] [G loss: 0.700912] [Time: 0.148495]\n",
            "4791-3 [D loss: 0.694274, acc.: 55.77%] [G loss: 0.713869] [Time: 0.147539]\n",
            "4791-4 [D loss: 0.689851, acc.: 53.85%] [G loss: 0.689287] [Time: 0.151516]\n",
            "4791-5 [D loss: 0.705789, acc.: 40.38%] [G loss: 0.695130] [Time: 0.152501]\n",
            "4791-6 [D loss: 0.686008, acc.: 53.85%] [G loss: 0.700498] [Time: 0.148146]\n",
            "4791-7 [D loss: 0.698581, acc.: 38.46%] [G loss: 0.692019] [Time: 0.149035]\n",
            "4791-8 [D loss: 0.710249, acc.: 32.69%] [G loss: 0.685958] [Time: 0.150641]\n",
            "4791 (test) [D loss: 1.079703, acc.: 50.00%] [G loss: 0.584426] [Time: 0.044436]\n",
            "4792-0 [D loss: 0.687451, acc.: 50.00%] [G loss: 0.719130] [Time: 0.147889]\n",
            "4792-1 [D loss: 0.705124, acc.: 46.15%] [G loss: 0.691597] [Time: 0.147451]\n",
            "4792-2 [D loss: 0.689643, acc.: 50.00%] [G loss: 0.691136] [Time: 0.150929]\n",
            "4792-3 [D loss: 0.712829, acc.: 36.54%] [G loss: 0.706815] [Time: 0.148159]\n",
            "4792-4 [D loss: 0.671888, acc.: 55.77%] [G loss: 0.681534] [Time: 0.148609]\n",
            "4792-5 [D loss: 0.707355, acc.: 40.38%] [G loss: 0.706513] [Time: 0.150194]\n",
            "4792-6 [D loss: 0.681801, acc.: 55.77%] [G loss: 0.711867] [Time: 0.149699]\n",
            "4792-7 [D loss: 0.698878, acc.: 38.46%] [G loss: 0.693638] [Time: 0.147789]\n",
            "4792-8 [D loss: 0.703979, acc.: 36.54%] [G loss: 0.682162] [Time: 0.148258]\n",
            "4792 (test) [D loss: 1.040058, acc.: 50.00%] [G loss: 0.599892] [Time: 0.043319]\n",
            "4793-0 [D loss: 0.712167, acc.: 26.92%] [G loss: 0.691912] [Time: 0.147358]\n",
            "4793-1 [D loss: 0.703095, acc.: 40.38%] [G loss: 0.672664] [Time: 0.147963]\n",
            "4793-2 [D loss: 0.701666, acc.: 32.69%] [G loss: 0.683594] [Time: 0.151194]\n",
            "4793-3 [D loss: 0.703368, acc.: 40.38%] [G loss: 0.738791] [Time: 0.151711]\n",
            "4793-4 [D loss: 0.691656, acc.: 40.38%] [G loss: 0.711042] [Time: 0.154488]\n",
            "4793-5 [D loss: 0.707878, acc.: 46.15%] [G loss: 0.675128] [Time: 0.148418]\n",
            "4793-6 [D loss: 0.701490, acc.: 42.31%] [G loss: 0.701059] [Time: 0.151490]\n",
            "4793-7 [D loss: 0.715019, acc.: 36.54%] [G loss: 0.705958] [Time: 0.148555]\n",
            "4793-8 [D loss: 0.705804, acc.: 36.54%] [G loss: 0.697290] [Time: 0.148801]\n",
            "4793 (test) [D loss: 1.035952, acc.: 51.92%] [G loss: 0.555865] [Time: 0.044651]\n",
            "4794-0 [D loss: 0.712025, acc.: 46.15%] [G loss: 0.718040] [Time: 0.147446]\n",
            "4794-1 [D loss: 0.696616, acc.: 42.31%] [G loss: 0.683035] [Time: 0.155203]\n",
            "4794-2 [D loss: 0.696278, acc.: 36.54%] [G loss: 0.683722] [Time: 0.150169]\n",
            "4794-3 [D loss: 0.701499, acc.: 50.00%] [G loss: 0.722763] [Time: 0.146919]\n",
            "4794-4 [D loss: 0.688893, acc.: 44.23%] [G loss: 0.676624] [Time: 0.148399]\n",
            "4794-5 [D loss: 0.725445, acc.: 40.38%] [G loss: 0.685996] [Time: 0.148460]\n",
            "4794-6 [D loss: 0.692920, acc.: 44.23%] [G loss: 0.695639] [Time: 0.147742]\n",
            "4794-7 [D loss: 0.703201, acc.: 50.00%] [G loss: 0.686853] [Time: 0.147548]\n",
            "4794-8 [D loss: 0.719548, acc.: 34.62%] [G loss: 0.691306] [Time: 0.150105]\n",
            "4794 (test) [D loss: 1.046855, acc.: 53.85%] [G loss: 0.571469] [Time: 0.045319]\n",
            "4795-0 [D loss: 0.687372, acc.: 40.38%] [G loss: 0.707432] [Time: 0.152969]\n",
            "4795-1 [D loss: 0.687085, acc.: 42.31%] [G loss: 0.697653] [Time: 0.149038]\n",
            "4795-2 [D loss: 0.708216, acc.: 34.62%] [G loss: 0.679711] [Time: 0.148330]\n",
            "4795-3 [D loss: 0.704394, acc.: 55.77%] [G loss: 0.730500] [Time: 0.147136]\n",
            "4795-4 [D loss: 0.696088, acc.: 44.23%] [G loss: 0.681900] [Time: 0.148867]\n",
            "4795-5 [D loss: 0.707754, acc.: 46.15%] [G loss: 0.694951] [Time: 0.151420]\n",
            "4795-6 [D loss: 0.683120, acc.: 48.08%] [G loss: 0.714082] [Time: 0.148811]\n",
            "4795-7 [D loss: 0.697104, acc.: 38.46%] [G loss: 0.698918] [Time: 0.149073]\n",
            "4795-8 [D loss: 0.700263, acc.: 36.54%] [G loss: 0.694545] [Time: 0.152366]\n",
            "4795 (test) [D loss: 1.011751, acc.: 50.00%] [G loss: 0.657224] [Time: 0.043785]\n",
            "4796-0 [D loss: 0.699998, acc.: 48.08%] [G loss: 0.717757] [Time: 0.149830]\n",
            "4796-1 [D loss: 0.690462, acc.: 48.08%] [G loss: 0.713797] [Time: 0.147425]\n",
            "4796-2 [D loss: 0.704914, acc.: 42.31%] [G loss: 0.706762] [Time: 0.149286]\n",
            "4796-3 [D loss: 0.705962, acc.: 57.69%] [G loss: 0.715899] [Time: 0.148585]\n",
            "4796-4 [D loss: 0.691261, acc.: 55.77%] [G loss: 0.718593] [Time: 0.149114]\n",
            "4796-5 [D loss: 0.722426, acc.: 25.00%] [G loss: 0.696492] [Time: 0.149292]\n",
            "4796-6 [D loss: 0.689878, acc.: 51.92%] [G loss: 0.714872] [Time: 0.148084]\n",
            "4796-7 [D loss: 0.702043, acc.: 36.54%] [G loss: 0.691614] [Time: 0.148367]\n",
            "4796-8 [D loss: 0.710100, acc.: 38.46%] [G loss: 0.690830] [Time: 0.147396]\n",
            "4796 (test) [D loss: 1.004133, acc.: 48.08%] [G loss: 0.714661] [Time: 0.044112]\n",
            "4797-0 [D loss: 0.705233, acc.: 34.62%] [G loss: 0.691515] [Time: 0.150227]\n",
            "4797-1 [D loss: 0.705322, acc.: 40.38%] [G loss: 0.699044] [Time: 0.150575]\n",
            "4797-2 [D loss: 0.689146, acc.: 48.08%] [G loss: 0.694569] [Time: 0.150753]\n",
            "4797-3 [D loss: 0.700909, acc.: 44.23%] [G loss: 0.714192] [Time: 0.149244]\n",
            "4797-4 [D loss: 0.690208, acc.: 50.00%] [G loss: 0.714837] [Time: 0.147014]\n",
            "4797-5 [D loss: 0.701267, acc.: 42.31%] [G loss: 0.708335] [Time: 0.149234]\n",
            "4797-6 [D loss: 0.696073, acc.: 50.00%] [G loss: 0.705274] [Time: 0.148044]\n",
            "4797-7 [D loss: 0.700987, acc.: 55.77%] [G loss: 0.695213] [Time: 0.149533]\n",
            "4797-8 [D loss: 0.712939, acc.: 32.69%] [G loss: 0.693645] [Time: 0.153737]\n",
            "4797 (test) [D loss: 1.049738, acc.: 50.00%] [G loss: 0.643188] [Time: 0.044472]\n",
            "4798-0 [D loss: 0.703511, acc.: 40.38%] [G loss: 0.723946] [Time: 0.150200]\n",
            "4798-1 [D loss: 0.697726, acc.: 40.38%] [G loss: 0.691295] [Time: 0.147167]\n",
            "4798-2 [D loss: 0.707108, acc.: 38.46%] [G loss: 0.711081] [Time: 0.148194]\n",
            "4798-3 [D loss: 0.715584, acc.: 42.31%] [G loss: 0.700521] [Time: 0.146542]\n",
            "4798-4 [D loss: 0.694115, acc.: 30.77%] [G loss: 0.694113] [Time: 0.150192]\n",
            "4798-5 [D loss: 0.703082, acc.: 38.46%] [G loss: 0.702415] [Time: 0.150508]\n",
            "4798-6 [D loss: 0.689045, acc.: 46.15%] [G loss: 0.704711] [Time: 0.149881]\n",
            "4798-7 [D loss: 0.693155, acc.: 38.46%] [G loss: 0.690787] [Time: 0.150292]\n",
            "4798-8 [D loss: 0.704823, acc.: 42.31%] [G loss: 0.686637] [Time: 0.152722]\n",
            "4798 (test) [D loss: 1.041652, acc.: 50.00%] [G loss: 0.598203] [Time: 0.044331]\n",
            "4799-0 [D loss: 0.708631, acc.: 34.62%] [G loss: 0.713081] [Time: 0.148067]\n",
            "4799-1 [D loss: 0.705987, acc.: 36.54%] [G loss: 0.708386] [Time: 0.151106]\n",
            "4799-2 [D loss: 0.716405, acc.: 26.92%] [G loss: 0.675055] [Time: 0.152045]\n",
            "4799-3 [D loss: 0.687511, acc.: 48.08%] [G loss: 0.720615] [Time: 0.150670]\n",
            "4799-4 [D loss: 0.706307, acc.: 42.31%] [G loss: 0.679095] [Time: 0.150096]\n",
            "4799-5 [D loss: 0.698203, acc.: 42.31%] [G loss: 0.692652] [Time: 0.148084]\n",
            "4799-6 [D loss: 0.698832, acc.: 42.31%] [G loss: 0.701335] [Time: 0.148255]\n",
            "4799-7 [D loss: 0.703705, acc.: 44.23%] [G loss: 0.699826] [Time: 0.151029]\n",
            "4799-8 [D loss: 0.700230, acc.: 42.31%] [G loss: 0.679525] [Time: 0.147123]\n",
            "4799 (test) [D loss: 1.078946, acc.: 50.00%] [G loss: 0.562126] [Time: 0.043235]\n",
            "4800-0 [D loss: 0.704480, acc.: 44.23%] [G loss: 0.710441] [Time: 0.147833]\n",
            "4800-1 [D loss: 0.704866, acc.: 44.23%] [G loss: 0.699946] [Time: 0.147866]\n",
            "4800-2 [D loss: 0.710215, acc.: 48.08%] [G loss: 0.698343] [Time: 0.148346]\n",
            "4800-3 [D loss: 0.707517, acc.: 40.38%] [G loss: 0.718040] [Time: 0.147136]\n",
            "4800-4 [D loss: 0.699113, acc.: 40.38%] [G loss: 0.703333] [Time: 0.148120]\n",
            "4800-5 [D loss: 0.703865, acc.: 34.62%] [G loss: 0.701389] [Time: 0.149003]\n",
            "4800-6 [D loss: 0.691465, acc.: 42.31%] [G loss: 0.712330] [Time: 0.150035]\n",
            "4800-7 [D loss: 0.701992, acc.: 40.38%] [G loss: 0.689679] [Time: 0.150616]\n",
            "4800-8 [D loss: 0.700741, acc.: 36.54%] [G loss: 0.702155] [Time: 0.149841]\n",
            "4800 (test) [D loss: 1.001122, acc.: 50.00%] [G loss: 0.662385] [Time: 0.042941]\n",
            "4801-0 [D loss: 0.707951, acc.: 38.46%] [G loss: 0.688957] [Time: 0.150873]\n",
            "4801-1 [D loss: 0.705897, acc.: 48.08%] [G loss: 0.678632] [Time: 0.150279]\n",
            "4801-2 [D loss: 0.720387, acc.: 36.54%] [G loss: 0.691278] [Time: 0.149210]\n",
            "4801-3 [D loss: 0.691620, acc.: 51.92%] [G loss: 0.724363] [Time: 0.149194]\n",
            "4801-4 [D loss: 0.700834, acc.: 38.46%] [G loss: 0.700137] [Time: 0.167242]\n",
            "4801-5 [D loss: 0.696755, acc.: 44.23%] [G loss: 0.694962] [Time: 0.149348]\n",
            "4801-6 [D loss: 0.687531, acc.: 50.00%] [G loss: 0.698390] [Time: 0.148640]\n",
            "4801-7 [D loss: 0.696528, acc.: 42.31%] [G loss: 0.697781] [Time: 0.153314]\n",
            "4801-8 [D loss: 0.716944, acc.: 36.54%] [G loss: 0.690231] [Time: 0.151526]\n",
            "4801 (test) [D loss: 1.051821, acc.: 51.92%] [G loss: 0.555076] [Time: 0.043541]\n",
            "4802-0 [D loss: 0.700824, acc.: 42.31%] [G loss: 0.711029] [Time: 0.149185]\n",
            "4802-1 [D loss: 0.699495, acc.: 48.08%] [G loss: 0.697750] [Time: 0.168514]\n",
            "4802-2 [D loss: 0.710317, acc.: 26.92%] [G loss: 0.694765] [Time: 0.150571]\n",
            "4802-3 [D loss: 0.701995, acc.: 46.15%] [G loss: 0.727389] [Time: 0.150279]\n",
            "4802-4 [D loss: 0.700422, acc.: 50.00%] [G loss: 0.695056] [Time: 0.148326]\n",
            "4802-5 [D loss: 0.703242, acc.: 34.62%] [G loss: 0.710610] [Time: 0.149313]\n",
            "4802-6 [D loss: 0.687518, acc.: 51.92%] [G loss: 0.719428] [Time: 0.149694]\n",
            "4802-7 [D loss: 0.708425, acc.: 38.46%] [G loss: 0.700384] [Time: 0.148649]\n",
            "4802-8 [D loss: 0.721836, acc.: 36.54%] [G loss: 0.690507] [Time: 0.149387]\n",
            "4802 (test) [D loss: 0.968934, acc.: 51.92%] [G loss: 0.661981] [Time: 0.044665]\n",
            "4803-0 [D loss: 0.709913, acc.: 32.69%] [G loss: 0.712698] [Time: 0.148155]\n",
            "4803-1 [D loss: 0.698314, acc.: 50.00%] [G loss: 0.698829] [Time: 0.149599]\n",
            "4803-2 [D loss: 0.703211, acc.: 42.31%] [G loss: 0.706063] [Time: 0.148188]\n",
            "4803-3 [D loss: 0.694173, acc.: 51.92%] [G loss: 0.719696] [Time: 0.147567]\n",
            "4803-4 [D loss: 0.678660, acc.: 48.08%] [G loss: 0.717809] [Time: 0.149802]\n",
            "4803-5 [D loss: 0.697437, acc.: 42.31%] [G loss: 0.699782] [Time: 0.148602]\n",
            "4803-6 [D loss: 0.682270, acc.: 51.92%] [G loss: 0.710979] [Time: 0.148143]\n",
            "4803-7 [D loss: 0.705035, acc.: 34.62%] [G loss: 0.687917] [Time: 0.149314]\n",
            "4803-8 [D loss: 0.689884, acc.: 46.15%] [G loss: 0.679488] [Time: 0.148575]\n",
            "4803 (test) [D loss: 0.983365, acc.: 48.08%] [G loss: 0.655209] [Time: 0.044939]\n",
            "4804-0 [D loss: 0.698541, acc.: 40.38%] [G loss: 0.709957] [Time: 0.148329]\n",
            "4804-1 [D loss: 0.683710, acc.: 53.85%] [G loss: 0.692006] [Time: 0.150465]\n",
            "4804-2 [D loss: 0.709166, acc.: 38.46%] [G loss: 0.694291] [Time: 0.152161]\n",
            "4804-3 [D loss: 0.708125, acc.: 42.31%] [G loss: 0.709579] [Time: 0.146905]\n",
            "4804-4 [D loss: 0.685681, acc.: 53.85%] [G loss: 0.715193] [Time: 0.147703]\n",
            "4804-5 [D loss: 0.710302, acc.: 44.23%] [G loss: 0.716270] [Time: 0.148139]\n",
            "4804-6 [D loss: 0.700770, acc.: 46.15%] [G loss: 0.721126] [Time: 0.150572]\n",
            "4804-7 [D loss: 0.701071, acc.: 40.38%] [G loss: 0.690673] [Time: 0.149697]\n",
            "4804-8 [D loss: 0.710739, acc.: 48.08%] [G loss: 0.683218] [Time: 0.152119]\n",
            "4804 (test) [D loss: 0.958065, acc.: 51.92%] [G loss: 0.682864] [Time: 0.045119]\n",
            "4805-0 [D loss: 0.709192, acc.: 38.46%] [G loss: 0.708141] [Time: 0.153537]\n",
            "4805-1 [D loss: 0.700946, acc.: 38.46%] [G loss: 0.707956] [Time: 0.150383]\n",
            "4805-2 [D loss: 0.699519, acc.: 44.23%] [G loss: 0.710582] [Time: 0.147941]\n",
            "4805-3 [D loss: 0.700633, acc.: 44.23%] [G loss: 0.698531] [Time: 0.147380]\n",
            "4805-4 [D loss: 0.683118, acc.: 48.08%] [G loss: 0.701814] [Time: 0.148526]\n",
            "4805-5 [D loss: 0.698753, acc.: 38.46%] [G loss: 0.690625] [Time: 0.150924]\n",
            "4805-6 [D loss: 0.690998, acc.: 46.15%] [G loss: 0.701668] [Time: 0.151194]\n",
            "4805-7 [D loss: 0.693082, acc.: 40.38%] [G loss: 0.714112] [Time: 0.149165]\n",
            "4805-8 [D loss: 0.703652, acc.: 42.31%] [G loss: 0.688555] [Time: 0.148554]\n",
            "4805 (test) [D loss: 1.041203, acc.: 51.92%] [G loss: 0.504143] [Time: 0.042841]\n",
            "4806-0 [D loss: 0.686828, acc.: 36.54%] [G loss: 0.723166] [Time: 0.148307]\n",
            "4806-1 [D loss: 0.706229, acc.: 38.46%] [G loss: 0.695819] [Time: 0.151084]\n",
            "4806-2 [D loss: 0.703360, acc.: 38.46%] [G loss: 0.699262] [Time: 0.153339]\n",
            "4806-3 [D loss: 0.707549, acc.: 42.31%] [G loss: 0.735481] [Time: 0.148116]\n",
            "4806-4 [D loss: 0.685598, acc.: 44.23%] [G loss: 0.686729] [Time: 0.149057]\n",
            "4806-5 [D loss: 0.701861, acc.: 36.54%] [G loss: 0.690645] [Time: 0.149177]\n",
            "4806-6 [D loss: 0.681866, acc.: 55.77%] [G loss: 0.718302] [Time: 0.149860]\n",
            "4806-7 [D loss: 0.709477, acc.: 30.77%] [G loss: 0.707771] [Time: 0.146699]\n",
            "4806-8 [D loss: 0.713561, acc.: 36.54%] [G loss: 0.678168] [Time: 0.149791]\n",
            "4806 (test) [D loss: 1.042797, acc.: 51.92%] [G loss: 0.493136] [Time: 0.042938]\n",
            "4807-0 [D loss: 0.700635, acc.: 44.23%] [G loss: 0.699402] [Time: 0.148413]\n",
            "4807-1 [D loss: 0.700961, acc.: 46.15%] [G loss: 0.699572] [Time: 0.146924]\n",
            "4807-2 [D loss: 0.704765, acc.: 44.23%] [G loss: 0.690612] [Time: 0.147945]\n",
            "4807-3 [D loss: 0.707395, acc.: 42.31%] [G loss: 0.693456] [Time: 0.147871]\n",
            "4807-4 [D loss: 0.699012, acc.: 48.08%] [G loss: 0.686352] [Time: 0.147839]\n",
            "4807-5 [D loss: 0.709118, acc.: 30.77%] [G loss: 0.713956] [Time: 0.149645]\n",
            "4807-6 [D loss: 0.693894, acc.: 48.08%] [G loss: 0.705949] [Time: 0.151579]\n",
            "4807-7 [D loss: 0.710433, acc.: 38.46%] [G loss: 0.686263] [Time: 0.153330]\n",
            "4807-8 [D loss: 0.708417, acc.: 42.31%] [G loss: 0.685795] [Time: 0.147892]\n",
            "4807 (test) [D loss: 0.993168, acc.: 50.00%] [G loss: 0.504768] [Time: 0.043742]\n",
            "4808-0 [D loss: 0.696094, acc.: 44.23%] [G loss: 0.703823] [Time: 0.148748]\n",
            "4808-1 [D loss: 0.698404, acc.: 46.15%] [G loss: 0.695435] [Time: 0.147810]\n",
            "4808-2 [D loss: 0.692146, acc.: 53.85%] [G loss: 0.680780] [Time: 0.151104]\n",
            "4808-3 [D loss: 0.716096, acc.: 36.54%] [G loss: 0.712085] [Time: 0.147723]\n",
            "4808-4 [D loss: 0.690652, acc.: 48.08%] [G loss: 0.696940] [Time: 0.148697]\n",
            "4808-5 [D loss: 0.711644, acc.: 34.62%] [G loss: 0.709771] [Time: 0.149872]\n",
            "4808-6 [D loss: 0.681008, acc.: 50.00%] [G loss: 0.702668] [Time: 0.150114]\n",
            "4808-7 [D loss: 0.705912, acc.: 40.38%] [G loss: 0.694186] [Time: 0.147515]\n",
            "4808-8 [D loss: 0.709989, acc.: 40.38%] [G loss: 0.697552] [Time: 0.148078]\n",
            "4808 (test) [D loss: 0.989566, acc.: 50.00%] [G loss: 0.576665] [Time: 0.043507]\n",
            "4809-0 [D loss: 0.692504, acc.: 46.15%] [G loss: 0.740043] [Time: 0.147601]\n",
            "4809-1 [D loss: 0.699871, acc.: 44.23%] [G loss: 0.694714] [Time: 0.148478]\n",
            "4809-2 [D loss: 0.717127, acc.: 36.54%] [G loss: 0.688769] [Time: 0.148319]\n",
            "4809-3 [D loss: 0.713455, acc.: 42.31%] [G loss: 0.698141] [Time: 0.149463]\n",
            "4809-4 [D loss: 0.690136, acc.: 44.23%] [G loss: 0.678215] [Time: 0.148699]\n",
            "4809-5 [D loss: 0.705440, acc.: 34.62%] [G loss: 0.712390] [Time: 0.151238]\n",
            "4809-6 [D loss: 0.681601, acc.: 57.69%] [G loss: 0.703571] [Time: 0.149658]\n",
            "4809-7 [D loss: 0.705193, acc.: 28.85%] [G loss: 0.691414] [Time: 0.147136]\n",
            "4809-8 [D loss: 0.693295, acc.: 48.08%] [G loss: 0.701836] [Time: 0.148340]\n",
            "4809 (test) [D loss: 1.078099, acc.: 50.00%] [G loss: 0.441376] [Time: 0.043949]\n",
            "4810-0 [D loss: 0.701051, acc.: 38.46%] [G loss: 0.705646] [Time: 0.149814]\n",
            "4810-1 [D loss: 0.708935, acc.: 42.31%] [G loss: 0.687567] [Time: 0.149786]\n",
            "4810-2 [D loss: 0.705291, acc.: 40.38%] [G loss: 0.683710] [Time: 0.155873]\n",
            "4810-3 [D loss: 0.708824, acc.: 42.31%] [G loss: 0.706594] [Time: 0.152738]\n",
            "4810-4 [D loss: 0.697561, acc.: 53.85%] [G loss: 0.702751] [Time: 0.150135]\n",
            "4810-5 [D loss: 0.702008, acc.: 42.31%] [G loss: 0.715481] [Time: 0.147905]\n",
            "4810-6 [D loss: 0.685975, acc.: 46.15%] [G loss: 0.720978] [Time: 0.149772]\n",
            "4810-7 [D loss: 0.706827, acc.: 46.15%] [G loss: 0.699526] [Time: 0.147649]\n",
            "4810-8 [D loss: 0.699008, acc.: 38.46%] [G loss: 0.702387] [Time: 0.149784]\n",
            "4810 (test) [D loss: 1.031276, acc.: 51.92%] [G loss: 0.495186] [Time: 0.046121]\n",
            "4811-0 [D loss: 0.718514, acc.: 30.77%] [G loss: 0.709890] [Time: 0.147851]\n",
            "4811-1 [D loss: 0.702345, acc.: 38.46%] [G loss: 0.702237] [Time: 0.147913]\n",
            "4811-2 [D loss: 0.708655, acc.: 36.54%] [G loss: 0.683449] [Time: 0.148573]\n",
            "4811-3 [D loss: 0.698480, acc.: 50.00%] [G loss: 0.734548] [Time: 0.150342]\n",
            "4811-4 [D loss: 0.687731, acc.: 42.31%] [G loss: 0.711607] [Time: 0.150972]\n",
            "4811-5 [D loss: 0.695209, acc.: 50.00%] [G loss: 0.719516] [Time: 0.151071]\n",
            "4811-6 [D loss: 0.690102, acc.: 51.92%] [G loss: 0.701191] [Time: 0.147673]\n",
            "4811-7 [D loss: 0.700204, acc.: 46.15%] [G loss: 0.716230] [Time: 0.147511]\n",
            "4811-8 [D loss: 0.708872, acc.: 26.92%] [G loss: 0.706687] [Time: 0.148093]\n",
            "4811 (test) [D loss: 0.958680, acc.: 48.08%] [G loss: 0.629926] [Time: 0.043035]\n",
            "4812-0 [D loss: 0.694557, acc.: 42.31%] [G loss: 0.724371] [Time: 0.149068]\n",
            "4812-1 [D loss: 0.702896, acc.: 40.38%] [G loss: 0.708536] [Time: 0.148115]\n",
            "4812-2 [D loss: 0.714429, acc.: 40.38%] [G loss: 0.703002] [Time: 0.150452]\n",
            "4812-3 [D loss: 0.694212, acc.: 40.38%] [G loss: 0.709840] [Time: 0.151416]\n",
            "4812-4 [D loss: 0.679036, acc.: 51.92%] [G loss: 0.705953] [Time: 0.151488]\n",
            "4812-5 [D loss: 0.700700, acc.: 30.77%] [G loss: 0.705054] [Time: 0.147972]\n",
            "4812-6 [D loss: 0.695546, acc.: 48.08%] [G loss: 0.708439] [Time: 0.150005]\n",
            "4812-7 [D loss: 0.698560, acc.: 40.38%] [G loss: 0.722394] [Time: 0.148029]\n",
            "4812-8 [D loss: 0.710274, acc.: 30.77%] [G loss: 0.690682] [Time: 0.149942]\n",
            "4812 (test) [D loss: 0.970000, acc.: 50.00%] [G loss: 0.609064] [Time: 0.044882]\n",
            "4813-0 [D loss: 0.700701, acc.: 32.69%] [G loss: 0.714636] [Time: 0.150488]\n",
            "4813-1 [D loss: 0.698203, acc.: 48.08%] [G loss: 0.719258] [Time: 0.148241]\n",
            "4813-2 [D loss: 0.695851, acc.: 50.00%] [G loss: 0.690620] [Time: 0.148881]\n",
            "4813-3 [D loss: 0.697482, acc.: 32.69%] [G loss: 0.700024] [Time: 0.148242]\n",
            "4813-4 [D loss: 0.685903, acc.: 44.23%] [G loss: 0.730602] [Time: 0.148327]\n",
            "4813-5 [D loss: 0.710326, acc.: 26.92%] [G loss: 0.720278] [Time: 0.149661]\n",
            "4813-6 [D loss: 0.692581, acc.: 48.08%] [G loss: 0.707930] [Time: 0.150395]\n",
            "4813-7 [D loss: 0.706209, acc.: 50.00%] [G loss: 0.687978] [Time: 0.147190]\n",
            "4813-8 [D loss: 0.688970, acc.: 50.00%] [G loss: 0.673627] [Time: 0.148591]\n",
            "4813 (test) [D loss: 0.973065, acc.: 50.00%] [G loss: 0.573044] [Time: 0.044867]\n",
            "4814-0 [D loss: 0.703040, acc.: 44.23%] [G loss: 0.702342] [Time: 0.147119]\n",
            "4814-1 [D loss: 0.703492, acc.: 42.31%] [G loss: 0.693119] [Time: 0.147836]\n",
            "4814-2 [D loss: 0.701534, acc.: 36.54%] [G loss: 0.692460] [Time: 0.148216]\n",
            "4814-3 [D loss: 0.707847, acc.: 44.23%] [G loss: 0.716874] [Time: 0.148711]\n",
            "4814-4 [D loss: 0.693287, acc.: 42.31%] [G loss: 0.699450] [Time: 0.148351]\n",
            "4814-5 [D loss: 0.704287, acc.: 34.62%] [G loss: 0.703746] [Time: 0.147238]\n",
            "4814-6 [D loss: 0.681536, acc.: 48.08%] [G loss: 0.705759] [Time: 0.147938]\n",
            "4814-7 [D loss: 0.690769, acc.: 51.92%] [G loss: 0.696396] [Time: 0.147067]\n",
            "4814-8 [D loss: 0.715423, acc.: 30.77%] [G loss: 0.694557] [Time: 0.151903]\n",
            "4814 (test) [D loss: 0.938329, acc.: 50.00%] [G loss: 0.670861] [Time: 0.042896]\n",
            "4815-0 [D loss: 0.702577, acc.: 50.00%] [G loss: 0.706068] [Time: 0.148120]\n",
            "4815-1 [D loss: 0.701186, acc.: 36.54%] [G loss: 0.703049] [Time: 0.147098]\n",
            "4815-2 [D loss: 0.703097, acc.: 42.31%] [G loss: 0.699472] [Time: 0.149837]\n",
            "4815-3 [D loss: 0.688945, acc.: 40.38%] [G loss: 0.707868] [Time: 0.148753]\n",
            "4815-4 [D loss: 0.694516, acc.: 34.62%] [G loss: 0.713196] [Time: 0.148622]\n",
            "4815-5 [D loss: 0.703119, acc.: 42.31%] [G loss: 0.710478] [Time: 0.147500]\n",
            "4815-6 [D loss: 0.680455, acc.: 59.62%] [G loss: 0.715793] [Time: 0.147162]\n",
            "4815-7 [D loss: 0.696888, acc.: 50.00%] [G loss: 0.688211] [Time: 0.150843]\n",
            "4815-8 [D loss: 0.702149, acc.: 46.15%] [G loss: 0.687903] [Time: 0.151038]\n",
            "4815 (test) [D loss: 1.061310, acc.: 50.00%] [G loss: 0.490226] [Time: 0.044900]\n",
            "4816-0 [D loss: 0.701120, acc.: 38.46%] [G loss: 0.696805] [Time: 0.149722]\n",
            "4816-1 [D loss: 0.699100, acc.: 46.15%] [G loss: 0.684630] [Time: 0.150743]\n",
            "4816-2 [D loss: 0.705033, acc.: 38.46%] [G loss: 0.674765] [Time: 0.149743]\n",
            "4816-3 [D loss: 0.699256, acc.: 36.54%] [G loss: 0.689301] [Time: 0.150757]\n",
            "4816-4 [D loss: 0.694641, acc.: 50.00%] [G loss: 0.691788] [Time: 0.147673]\n",
            "4816-5 [D loss: 0.696602, acc.: 46.15%] [G loss: 0.701098] [Time: 0.147395]\n",
            "4816-6 [D loss: 0.681762, acc.: 55.77%] [G loss: 0.695226] [Time: 0.148308]\n",
            "4816-7 [D loss: 0.698145, acc.: 48.08%] [G loss: 0.675133] [Time: 0.148691]\n",
            "4816-8 [D loss: 0.698498, acc.: 44.23%] [G loss: 0.671629] [Time: 0.150455]\n",
            "4816 (test) [D loss: 1.139097, acc.: 50.00%] [G loss: 0.377988] [Time: 0.043382]\n",
            "4817-0 [D loss: 0.698566, acc.: 44.23%] [G loss: 0.698022] [Time: 0.149336]\n",
            "4817-1 [D loss: 0.700994, acc.: 50.00%] [G loss: 0.678295] [Time: 0.147517]\n",
            "4817-2 [D loss: 0.721168, acc.: 30.77%] [G loss: 0.676770] [Time: 0.148947]\n",
            "4817-3 [D loss: 0.698473, acc.: 46.15%] [G loss: 0.715724] [Time: 0.147505]\n",
            "4817-4 [D loss: 0.679716, acc.: 57.69%] [G loss: 0.694063] [Time: 0.148470]\n",
            "4817-5 [D loss: 0.698548, acc.: 44.23%] [G loss: 0.706097] [Time: 0.147566]\n",
            "4817-6 [D loss: 0.677489, acc.: 38.46%] [G loss: 0.712457] [Time: 0.147931]\n",
            "4817-7 [D loss: 0.704968, acc.: 30.77%] [G loss: 0.705017] [Time: 0.147251]\n",
            "4817-8 [D loss: 0.718982, acc.: 42.31%] [G loss: 0.699749] [Time: 0.152725]\n",
            "4817 (test) [D loss: 1.020078, acc.: 50.00%] [G loss: 0.488482] [Time: 0.043968]\n",
            "4818-0 [D loss: 0.695281, acc.: 42.31%] [G loss: 0.736576] [Time: 0.150957]\n",
            "4818-1 [D loss: 0.697179, acc.: 38.46%] [G loss: 0.693041] [Time: 0.150399]\n",
            "4818-2 [D loss: 0.716564, acc.: 26.92%] [G loss: 0.692983] [Time: 0.152784]\n",
            "4818-3 [D loss: 0.700399, acc.: 48.08%] [G loss: 0.704143] [Time: 0.152164]\n",
            "4818-4 [D loss: 0.693079, acc.: 36.54%] [G loss: 0.685898] [Time: 0.149080]\n",
            "4818-5 [D loss: 0.706774, acc.: 32.69%] [G loss: 0.703303] [Time: 0.151366]\n",
            "4818-6 [D loss: 0.692921, acc.: 50.00%] [G loss: 0.705606] [Time: 0.150437]\n",
            "4818-7 [D loss: 0.698092, acc.: 50.00%] [G loss: 0.696123] [Time: 0.151581]\n",
            "4818-8 [D loss: 0.700752, acc.: 51.92%] [G loss: 0.703948] [Time: 0.151155]\n",
            "4818 (test) [D loss: 1.016066, acc.: 50.00%] [G loss: 0.555665] [Time: 0.045195]\n",
            "4819-0 [D loss: 0.707087, acc.: 40.38%] [G loss: 0.744280] [Time: 0.149065]\n",
            "4819-1 [D loss: 0.697876, acc.: 50.00%] [G loss: 0.681225] [Time: 0.150008]\n",
            "4819-2 [D loss: 0.710363, acc.: 42.31%] [G loss: 0.698115] [Time: 0.151343]\n",
            "4819-3 [D loss: 0.699562, acc.: 44.23%] [G loss: 0.725382] [Time: 0.146960]\n",
            "4819-4 [D loss: 0.685968, acc.: 46.15%] [G loss: 0.697845] [Time: 0.149502]\n",
            "4819-5 [D loss: 0.682836, acc.: 53.85%] [G loss: 0.701156] [Time: 0.152893]\n",
            "4819-6 [D loss: 0.697382, acc.: 50.00%] [G loss: 0.693403] [Time: 0.147235]\n",
            "4819-7 [D loss: 0.701866, acc.: 51.92%] [G loss: 0.707986] [Time: 0.147909]\n",
            "4819-8 [D loss: 0.705419, acc.: 46.15%] [G loss: 0.696191] [Time: 0.148601]\n",
            "4819 (test) [D loss: 0.982224, acc.: 48.08%] [G loss: 0.644515] [Time: 0.044546]\n",
            "4820-0 [D loss: 0.685449, acc.: 44.23%] [G loss: 0.724276] [Time: 0.151446]\n",
            "4820-1 [D loss: 0.690077, acc.: 61.54%] [G loss: 0.697201] [Time: 0.146961]\n",
            "4820-2 [D loss: 0.692279, acc.: 50.00%] [G loss: 0.704634] [Time: 0.147835]\n",
            "4820-3 [D loss: 0.694715, acc.: 51.92%] [G loss: 0.709802] [Time: 0.147864]\n",
            "4820-4 [D loss: 0.690919, acc.: 40.38%] [G loss: 0.718569] [Time: 0.147280]\n",
            "4820-5 [D loss: 0.704463, acc.: 44.23%] [G loss: 0.743651] [Time: 0.148540]\n",
            "4820-6 [D loss: 0.690256, acc.: 38.46%] [G loss: 0.717293] [Time: 0.151897]\n",
            "4820-7 [D loss: 0.709652, acc.: 44.23%] [G loss: 0.690492] [Time: 0.150444]\n",
            "4820-8 [D loss: 0.715407, acc.: 30.77%] [G loss: 0.692597] [Time: 0.148468]\n",
            "4820 (test) [D loss: 0.975517, acc.: 46.15%] [G loss: 0.679799] [Time: 0.044425]\n",
            "4821-0 [D loss: 0.694741, acc.: 40.38%] [G loss: 0.716850] [Time: 0.149609]\n",
            "4821-1 [D loss: 0.698272, acc.: 42.31%] [G loss: 0.684174] [Time: 0.149676]\n",
            "4821-2 [D loss: 0.701523, acc.: 42.31%] [G loss: 0.710784] [Time: 0.151721]\n",
            "4821-3 [D loss: 0.697778, acc.: 42.31%] [G loss: 0.726073] [Time: 0.149888]\n",
            "4821-4 [D loss: 0.687079, acc.: 40.38%] [G loss: 0.696168] [Time: 0.147645]\n",
            "4821-5 [D loss: 0.696797, acc.: 42.31%] [G loss: 0.701738] [Time: 0.151472]\n",
            "4821-6 [D loss: 0.693485, acc.: 44.23%] [G loss: 0.699353] [Time: 0.151402]\n",
            "4821-7 [D loss: 0.699221, acc.: 44.23%] [G loss: 0.708686] [Time: 0.149271]\n",
            "4821-8 [D loss: 0.714163, acc.: 44.23%] [G loss: 0.695505] [Time: 0.148581]\n",
            "4821 (test) [D loss: 0.973869, acc.: 48.08%] [G loss: 0.595949] [Time: 0.044093]\n",
            "4822-0 [D loss: 0.688730, acc.: 36.54%] [G loss: 0.731350] [Time: 0.148414]\n",
            "4822-1 [D loss: 0.704778, acc.: 44.23%] [G loss: 0.715325] [Time: 0.147978]\n",
            "4822-2 [D loss: 0.699293, acc.: 46.15%] [G loss: 0.696981] [Time: 0.150378]\n",
            "4822-3 [D loss: 0.698675, acc.: 44.23%] [G loss: 0.719298] [Time: 0.147923]\n",
            "4822-4 [D loss: 0.683831, acc.: 44.23%] [G loss: 0.695830] [Time: 0.149279]\n",
            "4822-5 [D loss: 0.713291, acc.: 38.46%] [G loss: 0.697400] [Time: 0.149167]\n",
            "4822-6 [D loss: 0.691946, acc.: 44.23%] [G loss: 0.703626] [Time: 0.149927]\n",
            "4822-7 [D loss: 0.705188, acc.: 48.08%] [G loss: 0.698297] [Time: 0.149688]\n",
            "4822-8 [D loss: 0.696095, acc.: 40.38%] [G loss: 0.681507] [Time: 0.148256]\n",
            "4822 (test) [D loss: 0.974954, acc.: 48.08%] [G loss: 0.584939] [Time: 0.044482]\n",
            "4823-0 [D loss: 0.692088, acc.: 42.31%] [G loss: 0.727795] [Time: 0.150624]\n",
            "4823-1 [D loss: 0.700883, acc.: 40.38%] [G loss: 0.691657] [Time: 0.150237]\n",
            "4823-2 [D loss: 0.705968, acc.: 42.31%] [G loss: 0.700050] [Time: 0.150221]\n",
            "4823-3 [D loss: 0.698880, acc.: 36.54%] [G loss: 0.708510] [Time: 0.149545]\n",
            "4823-4 [D loss: 0.706777, acc.: 40.38%] [G loss: 0.695664] [Time: 0.149316]\n",
            "4823-5 [D loss: 0.704630, acc.: 46.15%] [G loss: 0.715558] [Time: 0.149257]\n",
            "4823-6 [D loss: 0.683705, acc.: 55.77%] [G loss: 0.706672] [Time: 0.149266]\n",
            "4823-7 [D loss: 0.709194, acc.: 36.54%] [G loss: 0.684739] [Time: 0.148063]\n",
            "4823-8 [D loss: 0.705004, acc.: 28.85%] [G loss: 0.696531] [Time: 0.148167]\n",
            "4823 (test) [D loss: 0.936361, acc.: 48.08%] [G loss: 0.655805] [Time: 0.043712]\n",
            "4824-0 [D loss: 0.707892, acc.: 40.38%] [G loss: 0.724173] [Time: 0.150428]\n",
            "4824-1 [D loss: 0.698298, acc.: 51.92%] [G loss: 0.692827] [Time: 0.148073]\n",
            "4824-2 [D loss: 0.697362, acc.: 34.62%] [G loss: 0.698161] [Time: 0.149464]\n",
            "4824-3 [D loss: 0.700178, acc.: 36.54%] [G loss: 0.724177] [Time: 0.148697]\n",
            "4824-4 [D loss: 0.680867, acc.: 50.00%] [G loss: 0.699807] [Time: 0.149171]\n",
            "4824-5 [D loss: 0.701442, acc.: 40.38%] [G loss: 0.704322] [Time: 0.149412]\n",
            "4824-6 [D loss: 0.676941, acc.: 63.46%] [G loss: 0.717734] [Time: 0.148068]\n",
            "4824-7 [D loss: 0.712768, acc.: 38.46%] [G loss: 0.686771] [Time: 0.151998]\n",
            "4824-8 [D loss: 0.710200, acc.: 48.08%] [G loss: 0.693259] [Time: 0.152648]\n",
            "4824 (test) [D loss: 0.957134, acc.: 48.08%] [G loss: 0.615388] [Time: 0.043756]\n",
            "4825-0 [D loss: 0.697321, acc.: 38.46%] [G loss: 0.705431] [Time: 0.147944]\n",
            "4825-1 [D loss: 0.694591, acc.: 53.85%] [G loss: 0.704489] [Time: 0.150939]\n",
            "4825-2 [D loss: 0.704633, acc.: 34.62%] [G loss: 0.681460] [Time: 0.147661]\n",
            "4825-3 [D loss: 0.698723, acc.: 44.23%] [G loss: 0.698506] [Time: 0.149637]\n",
            "4825-4 [D loss: 0.693069, acc.: 46.15%] [G loss: 0.684297] [Time: 0.150402]\n",
            "4825-5 [D loss: 0.691838, acc.: 38.46%] [G loss: 0.687872] [Time: 0.152279]\n",
            "4825-6 [D loss: 0.681749, acc.: 55.77%] [G loss: 0.704153] [Time: 0.149838]\n",
            "4825-7 [D loss: 0.696466, acc.: 42.31%] [G loss: 0.702472] [Time: 0.150154]\n",
            "4825-8 [D loss: 0.701253, acc.: 50.00%] [G loss: 0.702895] [Time: 0.147977]\n",
            "4825 (test) [D loss: 1.064948, acc.: 51.92%] [G loss: 0.467921] [Time: 0.045064]\n",
            "4826-0 [D loss: 0.685610, acc.: 51.92%] [G loss: 0.715912] [Time: 0.149371]\n",
            "4826-1 [D loss: 0.688906, acc.: 48.08%] [G loss: 0.697926] [Time: 0.149741]\n",
            "4826-2 [D loss: 0.706886, acc.: 36.54%] [G loss: 0.679506] [Time: 0.156169]\n",
            "4826-3 [D loss: 0.710158, acc.: 36.54%] [G loss: 0.714234] [Time: 0.149867]\n",
            "4826-4 [D loss: 0.680407, acc.: 48.08%] [G loss: 0.700304] [Time: 0.148997]\n",
            "4826-5 [D loss: 0.699810, acc.: 44.23%] [G loss: 0.716450] [Time: 0.148253]\n",
            "4826-6 [D loss: 0.687538, acc.: 50.00%] [G loss: 0.719432] [Time: 0.148736]\n",
            "4826-7 [D loss: 0.699729, acc.: 46.15%] [G loss: 0.698566] [Time: 0.148825]\n",
            "4826-8 [D loss: 0.703322, acc.: 48.08%] [G loss: 0.678223] [Time: 0.149776]\n",
            "4826 (test) [D loss: 0.999757, acc.: 50.00%] [G loss: 0.538014] [Time: 0.044687]\n",
            "4827-0 [D loss: 0.685104, acc.: 46.15%] [G loss: 0.730966] [Time: 0.153185]\n",
            "4827-1 [D loss: 0.699050, acc.: 46.15%] [G loss: 0.699705] [Time: 0.151973]\n",
            "4827-2 [D loss: 0.681793, acc.: 50.00%] [G loss: 0.707741] [Time: 0.147404]\n",
            "4827-3 [D loss: 0.705505, acc.: 50.00%] [G loss: 0.717757] [Time: 0.148542]\n",
            "4827-4 [D loss: 0.689441, acc.: 55.77%] [G loss: 0.711227] [Time: 0.148938]\n",
            "4827-5 [D loss: 0.691186, acc.: 51.92%] [G loss: 0.714634] [Time: 0.151360]\n",
            "4827-6 [D loss: 0.700267, acc.: 40.38%] [G loss: 0.735792] [Time: 0.153054]\n",
            "4827-7 [D loss: 0.699046, acc.: 44.23%] [G loss: 0.675615] [Time: 0.149549]\n",
            "4827-8 [D loss: 0.710410, acc.: 30.77%] [G loss: 0.696403] [Time: 0.152070]\n",
            "4827 (test) [D loss: 1.088035, acc.: 48.08%] [G loss: 0.479624] [Time: 0.043052]\n",
            "4828-0 [D loss: 0.702882, acc.: 46.15%] [G loss: 0.719034] [Time: 0.150476]\n",
            "4828-1 [D loss: 0.700919, acc.: 46.15%] [G loss: 0.688287] [Time: 0.147688]\n",
            "4828-2 [D loss: 0.710329, acc.: 38.46%] [G loss: 0.692153] [Time: 0.149630]\n",
            "4828-3 [D loss: 0.689106, acc.: 51.92%] [G loss: 0.704768] [Time: 0.148379]\n",
            "4828-4 [D loss: 0.683142, acc.: 51.92%] [G loss: 0.717276] [Time: 0.149272]\n",
            "4828-5 [D loss: 0.703517, acc.: 46.15%] [G loss: 0.717611] [Time: 0.147791]\n",
            "4828-6 [D loss: 0.697225, acc.: 51.92%] [G loss: 0.719156] [Time: 0.147204]\n",
            "4828-7 [D loss: 0.701512, acc.: 44.23%] [G loss: 0.687977] [Time: 0.150328]\n",
            "4828-8 [D loss: 0.698904, acc.: 40.38%] [G loss: 0.690387] [Time: 0.151343]\n",
            "4828 (test) [D loss: 0.993398, acc.: 48.08%] [G loss: 0.610426] [Time: 0.044603]\n",
            "4829-0 [D loss: 0.709415, acc.: 30.77%] [G loss: 0.740619] [Time: 0.151609]\n",
            "4829-1 [D loss: 0.700194, acc.: 38.46%] [G loss: 0.703942] [Time: 0.149289]\n",
            "4829-2 [D loss: 0.709373, acc.: 40.38%] [G loss: 0.709676] [Time: 0.149175]\n",
            "4829-3 [D loss: 0.704001, acc.: 40.38%] [G loss: 0.691217] [Time: 0.150049]\n",
            "4829-4 [D loss: 0.683266, acc.: 44.23%] [G loss: 0.691918] [Time: 0.148070]\n",
            "4829-5 [D loss: 0.698424, acc.: 46.15%] [G loss: 0.704168] [Time: 0.148131]\n",
            "4829-6 [D loss: 0.678696, acc.: 57.69%] [G loss: 0.717862] [Time: 0.146682]\n",
            "4829-7 [D loss: 0.707314, acc.: 48.08%] [G loss: 0.689348] [Time: 0.147827]\n",
            "4829-8 [D loss: 0.711934, acc.: 46.15%] [G loss: 0.687784] [Time: 0.155443]\n",
            "4829 (test) [D loss: 1.081136, acc.: 50.00%] [G loss: 0.456193] [Time: 0.044105]\n",
            "4830-0 [D loss: 0.694899, acc.: 42.31%] [G loss: 0.707394] [Time: 0.147996]\n",
            "4830-1 [D loss: 0.709049, acc.: 40.38%] [G loss: 0.693999] [Time: 0.150784]\n",
            "4830-2 [D loss: 0.708813, acc.: 40.38%] [G loss: 0.680118] [Time: 0.148904]\n",
            "4830-3 [D loss: 0.694734, acc.: 50.00%] [G loss: 0.710626] [Time: 0.147907]\n",
            "4830-4 [D loss: 0.697057, acc.: 40.38%] [G loss: 0.693700] [Time: 0.150904]\n",
            "4830-5 [D loss: 0.710251, acc.: 38.46%] [G loss: 0.694033] [Time: 0.147156]\n",
            "4830-6 [D loss: 0.686111, acc.: 57.69%] [G loss: 0.696931] [Time: 0.152055]\n",
            "4830-7 [D loss: 0.708949, acc.: 46.15%] [G loss: 0.696660] [Time: 0.150909]\n",
            "4830-8 [D loss: 0.701650, acc.: 28.85%] [G loss: 0.696611] [Time: 0.152549]\n",
            "4830 (test) [D loss: 1.032954, acc.: 50.00%] [G loss: 0.534472] [Time: 0.045457]\n",
            "4831-0 [D loss: 0.689948, acc.: 46.15%] [G loss: 0.725215] [Time: 0.150924]\n",
            "4831-1 [D loss: 0.704729, acc.: 46.15%] [G loss: 0.699288] [Time: 0.147509]\n",
            "4831-2 [D loss: 0.692433, acc.: 48.08%] [G loss: 0.701492] [Time: 0.147512]\n",
            "4831-3 [D loss: 0.696642, acc.: 48.08%] [G loss: 0.709585] [Time: 0.148067]\n",
            "4831-4 [D loss: 0.688790, acc.: 38.46%] [G loss: 0.699615] [Time: 0.147699]\n",
            "4831-5 [D loss: 0.715879, acc.: 42.31%] [G loss: 0.702173] [Time: 0.150708]\n",
            "4831-6 [D loss: 0.685707, acc.: 50.00%] [G loss: 0.692448] [Time: 0.147842]\n",
            "4831-7 [D loss: 0.712720, acc.: 38.46%] [G loss: 0.682491] [Time: 0.149356]\n",
            "4831-8 [D loss: 0.686604, acc.: 44.23%] [G loss: 0.693463] [Time: 0.151699]\n",
            "4831 (test) [D loss: 1.043444, acc.: 50.00%] [G loss: 0.521121] [Time: 0.043674]\n",
            "4832-0 [D loss: 0.691896, acc.: 53.85%] [G loss: 0.694498] [Time: 0.147542]\n",
            "4832-1 [D loss: 0.694708, acc.: 51.92%] [G loss: 0.688563] [Time: 0.148975]\n",
            "4832-2 [D loss: 0.703929, acc.: 42.31%] [G loss: 0.705201] [Time: 0.148906]\n",
            "4832-3 [D loss: 0.695703, acc.: 44.23%] [G loss: 0.699012] [Time: 0.148905]\n",
            "4832-4 [D loss: 0.692706, acc.: 50.00%] [G loss: 0.680549] [Time: 0.151768]\n",
            "4832-5 [D loss: 0.701897, acc.: 40.38%] [G loss: 0.699117] [Time: 0.148715]\n",
            "4832-6 [D loss: 0.680240, acc.: 50.00%] [G loss: 0.703457] [Time: 0.149296]\n",
            "4832-7 [D loss: 0.701695, acc.: 44.23%] [G loss: 0.687739] [Time: 0.148382]\n",
            "4832-8 [D loss: 0.694900, acc.: 46.15%] [G loss: 0.686517] [Time: 0.148822]\n",
            "4832 (test) [D loss: 0.985106, acc.: 48.08%] [G loss: 0.564927] [Time: 0.045497]\n",
            "4833-0 [D loss: 0.716220, acc.: 23.08%] [G loss: 0.720986] [Time: 0.150855]\n",
            "4833-1 [D loss: 0.697821, acc.: 40.38%] [G loss: 0.686519] [Time: 0.147985]\n",
            "4833-2 [D loss: 0.703135, acc.: 48.08%] [G loss: 0.694372] [Time: 0.151149]\n",
            "4833-3 [D loss: 0.701734, acc.: 48.08%] [G loss: 0.702316] [Time: 0.147593]\n",
            "4833-4 [D loss: 0.697568, acc.: 42.31%] [G loss: 0.693016] [Time: 0.147637]\n",
            "4833-5 [D loss: 0.689800, acc.: 46.15%] [G loss: 0.713139] [Time: 0.148908]\n",
            "4833-6 [D loss: 0.689727, acc.: 42.31%] [G loss: 0.709330] [Time: 0.148579]\n",
            "4833-7 [D loss: 0.689878, acc.: 46.15%] [G loss: 0.716735] [Time: 0.147888]\n",
            "4833-8 [D loss: 0.699726, acc.: 46.15%] [G loss: 0.690288] [Time: 0.153334]\n",
            "4833 (test) [D loss: 0.841387, acc.: 48.08%] [G loss: 0.990650] [Time: 0.043833]\n",
            "4834-0 [D loss: 0.677013, acc.: 51.92%] [G loss: 0.699370] [Time: 0.149549]\n",
            "4834-1 [D loss: 0.700983, acc.: 38.46%] [G loss: 0.719694] [Time: 0.148653]\n",
            "4834-2 [D loss: 0.704392, acc.: 36.54%] [G loss: 0.689133] [Time: 0.148709]\n",
            "4834-3 [D loss: 0.694263, acc.: 51.92%] [G loss: 0.720639] [Time: 0.150487]\n",
            "4834-4 [D loss: 0.691939, acc.: 50.00%] [G loss: 0.703770] [Time: 0.149096]\n",
            "4834-5 [D loss: 0.695896, acc.: 38.46%] [G loss: 0.707414] [Time: 0.147552]\n",
            "4834-6 [D loss: 0.689635, acc.: 48.08%] [G loss: 0.699285] [Time: 0.147012]\n",
            "4834-7 [D loss: 0.696616, acc.: 48.08%] [G loss: 0.694542] [Time: 0.149212]\n",
            "4834-8 [D loss: 0.690749, acc.: 44.23%] [G loss: 0.703071] [Time: 0.152671]\n",
            "4834 (test) [D loss: 0.832340, acc.: 50.00%] [G loss: 0.800369] [Time: 0.043998]\n",
            "4835-0 [D loss: 0.701190, acc.: 44.23%] [G loss: 0.708519] [Time: 0.149031]\n",
            "4835-1 [D loss: 0.701731, acc.: 38.46%] [G loss: 0.705228] [Time: 0.147461]\n",
            "4835-2 [D loss: 0.713547, acc.: 32.69%] [G loss: 0.687508] [Time: 0.148456]\n",
            "4835-3 [D loss: 0.699548, acc.: 40.38%] [G loss: 0.683639] [Time: 0.147704]\n",
            "4835-4 [D loss: 0.703631, acc.: 36.54%] [G loss: 0.696273] [Time: 0.149042]\n",
            "4835-5 [D loss: 0.709403, acc.: 46.15%] [G loss: 0.692655] [Time: 0.147601]\n",
            "4835-6 [D loss: 0.690173, acc.: 44.23%] [G loss: 0.716100] [Time: 0.148667]\n",
            "4835-7 [D loss: 0.693346, acc.: 50.00%] [G loss: 0.703772] [Time: 0.148712]\n",
            "4835-8 [D loss: 0.734418, acc.: 34.62%] [G loss: 0.708107] [Time: 0.149977]\n",
            "4835 (test) [D loss: 0.811603, acc.: 48.08%] [G loss: 0.938282] [Time: 0.044591]\n",
            "4836-0 [D loss: 0.683577, acc.: 57.69%] [G loss: 0.700239] [Time: 0.155669]\n",
            "4836-1 [D loss: 0.704094, acc.: 44.23%] [G loss: 0.706017] [Time: 0.151258]\n",
            "4836-2 [D loss: 0.702602, acc.: 42.31%] [G loss: 0.683968] [Time: 0.150654]\n",
            "4836-3 [D loss: 0.688383, acc.: 53.85%] [G loss: 0.696014] [Time: 0.147226]\n",
            "4836-4 [D loss: 0.698174, acc.: 34.62%] [G loss: 0.707896] [Time: 0.149327]\n",
            "4836-5 [D loss: 0.692154, acc.: 48.08%] [G loss: 0.694639] [Time: 0.147942]\n",
            "4836-6 [D loss: 0.691309, acc.: 46.15%] [G loss: 0.690532] [Time: 0.151308]\n",
            "4836-7 [D loss: 0.706970, acc.: 42.31%] [G loss: 0.698845] [Time: 0.148418]\n",
            "4836-8 [D loss: 0.707384, acc.: 34.62%] [G loss: 0.690145] [Time: 0.147348]\n",
            "4836 (test) [D loss: 0.797790, acc.: 50.00%] [G loss: 0.667556] [Time: 0.044172]\n",
            "4837-0 [D loss: 0.690355, acc.: 51.92%] [G loss: 0.692998] [Time: 0.147319]\n",
            "4837-1 [D loss: 0.701423, acc.: 38.46%] [G loss: 0.712764] [Time: 0.150805]\n",
            "4837-2 [D loss: 0.699566, acc.: 42.31%] [G loss: 0.701093] [Time: 0.148502]\n",
            "4837-3 [D loss: 0.678061, acc.: 51.92%] [G loss: 0.721696] [Time: 0.149701]\n",
            "4837-4 [D loss: 0.694394, acc.: 46.15%] [G loss: 0.705635] [Time: 0.147846]\n",
            "4837-5 [D loss: 0.710382, acc.: 36.54%] [G loss: 0.711808] [Time: 0.148920]\n",
            "4837-6 [D loss: 0.698464, acc.: 40.38%] [G loss: 0.708971] [Time: 0.147945]\n",
            "4837-7 [D loss: 0.695390, acc.: 46.15%] [G loss: 0.699439] [Time: 0.148982]\n",
            "4837-8 [D loss: 0.707308, acc.: 40.38%] [G loss: 0.711556] [Time: 0.150306]\n",
            "4837 (test) [D loss: 0.808699, acc.: 50.00%] [G loss: 0.705058] [Time: 0.045009]\n",
            "4838-0 [D loss: 0.696135, acc.: 46.15%] [G loss: 0.700917] [Time: 0.148482]\n",
            "4838-1 [D loss: 0.696411, acc.: 51.92%] [G loss: 0.719932] [Time: 0.151031]\n",
            "4838-2 [D loss: 0.696282, acc.: 38.46%] [G loss: 0.686076] [Time: 0.149435]\n",
            "4838-3 [D loss: 0.686481, acc.: 44.23%] [G loss: 0.703555] [Time: 0.147521]\n",
            "4838-4 [D loss: 0.696077, acc.: 46.15%] [G loss: 0.706134] [Time: 0.147951]\n",
            "4838-5 [D loss: 0.698783, acc.: 44.23%] [G loss: 0.692215] [Time: 0.148756]\n",
            "4838-6 [D loss: 0.689248, acc.: 51.92%] [G loss: 0.699701] [Time: 0.151242]\n",
            "4838-7 [D loss: 0.701012, acc.: 48.08%] [G loss: 0.707463] [Time: 0.149046]\n",
            "4838-8 [D loss: 0.718691, acc.: 28.85%] [G loss: 0.723647] [Time: 0.147588]\n",
            "4838 (test) [D loss: 0.815620, acc.: 50.00%] [G loss: 0.620002] [Time: 0.044637]\n",
            "4839-0 [D loss: 0.693479, acc.: 51.92%] [G loss: 0.715831] [Time: 0.146887]\n",
            "4839-1 [D loss: 0.691591, acc.: 46.15%] [G loss: 0.711923] [Time: 0.148681]\n",
            "4839-2 [D loss: 0.703979, acc.: 36.54%] [G loss: 0.695300] [Time: 0.149755]\n",
            "4839-3 [D loss: 0.692699, acc.: 50.00%] [G loss: 0.700306] [Time: 0.149923]\n",
            "4839-4 [D loss: 0.688181, acc.: 50.00%] [G loss: 0.680402] [Time: 0.149923]\n",
            "4839-5 [D loss: 0.710005, acc.: 36.54%] [G loss: 0.677407] [Time: 0.148196]\n",
            "4839-6 [D loss: 0.697158, acc.: 48.08%] [G loss: 0.695040] [Time: 0.149918]\n",
            "4839-7 [D loss: 0.701200, acc.: 44.23%] [G loss: 0.686321] [Time: 0.151221]\n",
            "4839-8 [D loss: 0.702502, acc.: 48.08%] [G loss: 0.701207] [Time: 0.151784]\n",
            "4839 (test) [D loss: 0.816435, acc.: 50.00%] [G loss: 0.597303] [Time: 0.044129]\n",
            "4840-0 [D loss: 0.681528, acc.: 48.08%] [G loss: 0.717742] [Time: 0.149119]\n",
            "4840-1 [D loss: 0.703510, acc.: 46.15%] [G loss: 0.700542] [Time: 0.150634]\n",
            "4840-2 [D loss: 0.706400, acc.: 34.62%] [G loss: 0.698652] [Time: 0.149868]\n",
            "4840-3 [D loss: 0.694707, acc.: 30.77%] [G loss: 0.732415] [Time: 0.148642]\n",
            "4840-4 [D loss: 0.690290, acc.: 48.08%] [G loss: 0.692180] [Time: 0.150301]\n",
            "4840-5 [D loss: 0.703384, acc.: 36.54%] [G loss: 0.681655] [Time: 0.150755]\n",
            "4840-6 [D loss: 0.691354, acc.: 48.08%] [G loss: 0.693840] [Time: 0.149623]\n",
            "4840-7 [D loss: 0.697337, acc.: 44.23%] [G loss: 0.709823] [Time: 0.150947]\n",
            "4840-8 [D loss: 0.695640, acc.: 51.92%] [G loss: 0.696587] [Time: 0.151217]\n",
            "4840 (test) [D loss: 0.820106, acc.: 50.00%] [G loss: 0.696172] [Time: 0.043818]\n",
            "4841-0 [D loss: 0.692474, acc.: 50.00%] [G loss: 0.747103] [Time: 0.152165]\n",
            "4841-1 [D loss: 0.711845, acc.: 36.54%] [G loss: 0.705733] [Time: 0.149220]\n",
            "4841-2 [D loss: 0.703954, acc.: 42.31%] [G loss: 0.695426] [Time: 0.149268]\n",
            "4841-3 [D loss: 0.675352, acc.: 42.31%] [G loss: 0.709382] [Time: 0.150775]\n",
            "4841-4 [D loss: 0.701702, acc.: 50.00%] [G loss: 0.703387] [Time: 0.149065]\n",
            "4841-5 [D loss: 0.720940, acc.: 42.31%] [G loss: 0.688153] [Time: 0.149316]\n",
            "4841-6 [D loss: 0.689074, acc.: 40.38%] [G loss: 0.701244] [Time: 0.151396]\n",
            "4841-7 [D loss: 0.704220, acc.: 44.23%] [G loss: 0.704983] [Time: 0.148772]\n",
            "4841-8 [D loss: 0.693081, acc.: 50.00%] [G loss: 0.724245] [Time: 0.149135]\n",
            "4841 (test) [D loss: 0.843101, acc.: 48.08%] [G loss: 0.605934] [Time: 0.044837]\n",
            "4842-0 [D loss: 0.698918, acc.: 50.00%] [G loss: 0.716294] [Time: 0.148262]\n",
            "4842-1 [D loss: 0.708300, acc.: 42.31%] [G loss: 0.723537] [Time: 0.151687]\n",
            "4842-2 [D loss: 0.703476, acc.: 48.08%] [G loss: 0.701474] [Time: 0.150307]\n",
            "4842-3 [D loss: 0.686841, acc.: 55.77%] [G loss: 0.716566] [Time: 0.147909]\n",
            "4842-4 [D loss: 0.708506, acc.: 42.31%] [G loss: 0.686971] [Time: 0.148103]\n",
            "4842-5 [D loss: 0.709800, acc.: 40.38%] [G loss: 0.679278] [Time: 0.149500]\n",
            "4842-6 [D loss: 0.699343, acc.: 48.08%] [G loss: 0.702705] [Time: 0.149307]\n",
            "4842-7 [D loss: 0.703872, acc.: 44.23%] [G loss: 0.711109] [Time: 0.148818]\n",
            "4842-8 [D loss: 0.708944, acc.: 50.00%] [G loss: 0.702366] [Time: 0.147780]\n",
            "4842 (test) [D loss: 0.828519, acc.: 48.08%] [G loss: 0.699194] [Time: 0.043210]\n",
            "4843-0 [D loss: 0.682071, acc.: 53.85%] [G loss: 0.710645] [Time: 0.148035]\n",
            "4843-1 [D loss: 0.699176, acc.: 38.46%] [G loss: 0.706627] [Time: 0.147022]\n",
            "4843-2 [D loss: 0.706062, acc.: 36.54%] [G loss: 0.708622] [Time: 0.146759]\n",
            "4843-3 [D loss: 0.671014, acc.: 51.92%] [G loss: 0.733254] [Time: 0.150303]\n",
            "4843-4 [D loss: 0.697401, acc.: 51.92%] [G loss: 0.717423] [Time: 0.149516]\n",
            "4843-5 [D loss: 0.710418, acc.: 38.46%] [G loss: 0.708815] [Time: 0.148786]\n",
            "4843-6 [D loss: 0.685789, acc.: 51.92%] [G loss: 0.702749] [Time: 0.150193]\n",
            "4843-7 [D loss: 0.696813, acc.: 48.08%] [G loss: 0.722287] [Time: 0.147099]\n",
            "4843-8 [D loss: 0.710561, acc.: 42.31%] [G loss: 0.724960] [Time: 0.147839]\n",
            "4843 (test) [D loss: 0.809269, acc.: 50.00%] [G loss: 0.903824] [Time: 0.045143]\n",
            "4844-0 [D loss: 0.690273, acc.: 48.08%] [G loss: 0.730387] [Time: 0.151540]\n",
            "4844-1 [D loss: 0.700589, acc.: 48.08%] [G loss: 0.727229] [Time: 0.151527]\n",
            "4844-2 [D loss: 0.708585, acc.: 32.69%] [G loss: 0.710441] [Time: 0.149809]\n",
            "4844-3 [D loss: 0.673343, acc.: 55.77%] [G loss: 0.715823] [Time: 0.149213]\n",
            "4844-4 [D loss: 0.682389, acc.: 55.77%] [G loss: 0.697643] [Time: 0.150578]\n",
            "4844-5 [D loss: 0.720567, acc.: 23.08%] [G loss: 0.677749] [Time: 0.152601]\n",
            "4844-6 [D loss: 0.691868, acc.: 42.31%] [G loss: 0.701160] [Time: 0.148480]\n",
            "4844-7 [D loss: 0.693079, acc.: 40.38%] [G loss: 0.697371] [Time: 0.149700]\n",
            "4844-8 [D loss: 0.702997, acc.: 42.31%] [G loss: 0.700203] [Time: 0.153167]\n",
            "4844 (test) [D loss: 0.838659, acc.: 48.08%] [G loss: 0.544068] [Time: 0.045193]\n",
            "4845-0 [D loss: 0.682380, acc.: 50.00%] [G loss: 0.711996] [Time: 0.147908]\n",
            "4845-1 [D loss: 0.701761, acc.: 48.08%] [G loss: 0.693681] [Time: 0.147369]\n",
            "4845-2 [D loss: 0.719001, acc.: 36.54%] [G loss: 0.699968] [Time: 0.148874]\n",
            "4845-3 [D loss: 0.678904, acc.: 44.23%] [G loss: 0.698636] [Time: 0.149451]\n",
            "4845-4 [D loss: 0.703896, acc.: 44.23%] [G loss: 0.685827] [Time: 0.151147]\n",
            "4845-5 [D loss: 0.707894, acc.: 42.31%] [G loss: 0.672803] [Time: 0.151207]\n",
            "4845-6 [D loss: 0.702082, acc.: 40.38%] [G loss: 0.698809] [Time: 0.149680]\n",
            "4845-7 [D loss: 0.702286, acc.: 44.23%] [G loss: 0.698370] [Time: 0.148338]\n",
            "4845-8 [D loss: 0.700616, acc.: 51.92%] [G loss: 0.678947] [Time: 0.148190]\n",
            "4845 (test) [D loss: 0.822716, acc.: 50.00%] [G loss: 0.581183] [Time: 0.043530]\n",
            "4846-0 [D loss: 0.683167, acc.: 51.92%] [G loss: 0.705059] [Time: 0.147496]\n",
            "4846-1 [D loss: 0.703874, acc.: 36.54%] [G loss: 0.704821] [Time: 0.149117]\n",
            "4846-2 [D loss: 0.711970, acc.: 40.38%] [G loss: 0.694028] [Time: 0.149326]\n",
            "4846-3 [D loss: 0.664049, acc.: 55.77%] [G loss: 0.724074] [Time: 0.149647]\n",
            "4846-4 [D loss: 0.699075, acc.: 40.38%] [G loss: 0.719604] [Time: 0.146973]\n",
            "4846-5 [D loss: 0.695332, acc.: 42.31%] [G loss: 0.687752] [Time: 0.148377]\n",
            "4846-6 [D loss: 0.694928, acc.: 48.08%] [G loss: 0.707627] [Time: 0.148785]\n",
            "4846-7 [D loss: 0.700533, acc.: 48.08%] [G loss: 0.701581] [Time: 0.147721]\n",
            "4846-8 [D loss: 0.707116, acc.: 36.54%] [G loss: 0.704482] [Time: 0.148388]\n",
            "4846 (test) [D loss: 0.819014, acc.: 46.15%] [G loss: 0.629333] [Time: 0.044169]\n",
            "4847-0 [D loss: 0.680984, acc.: 44.23%] [G loss: 0.715410] [Time: 0.151283]\n",
            "4847-1 [D loss: 0.704733, acc.: 38.46%] [G loss: 0.697638] [Time: 0.150755]\n",
            "4847-2 [D loss: 0.697225, acc.: 42.31%] [G loss: 0.695074] [Time: 0.153548]\n",
            "4847-3 [D loss: 0.689471, acc.: 50.00%] [G loss: 0.709114] [Time: 0.150331]\n",
            "4847-4 [D loss: 0.702223, acc.: 44.23%] [G loss: 0.708617] [Time: 0.150289]\n",
            "4847-5 [D loss: 0.702892, acc.: 38.46%] [G loss: 0.689527] [Time: 0.151539]\n",
            "4847-6 [D loss: 0.687692, acc.: 46.15%] [G loss: 0.702614] [Time: 0.151702]\n",
            "4847-7 [D loss: 0.699921, acc.: 51.92%] [G loss: 0.692495] [Time: 0.147166]\n",
            "4847-8 [D loss: 0.701394, acc.: 42.31%] [G loss: 0.709215] [Time: 0.147099]\n",
            "4847 (test) [D loss: 0.846994, acc.: 48.08%] [G loss: 0.587791] [Time: 0.043921]\n",
            "4848-0 [D loss: 0.687588, acc.: 48.08%] [G loss: 0.735171] [Time: 0.146699]\n",
            "4848-1 [D loss: 0.705763, acc.: 34.62%] [G loss: 0.714515] [Time: 0.150311]\n",
            "4848-2 [D loss: 0.707485, acc.: 26.92%] [G loss: 0.709630] [Time: 0.149817]\n",
            "4848-3 [D loss: 0.679769, acc.: 53.85%] [G loss: 0.720040] [Time: 0.149071]\n",
            "4848-4 [D loss: 0.708396, acc.: 42.31%] [G loss: 0.696790] [Time: 0.148446]\n",
            "4848-5 [D loss: 0.706353, acc.: 38.46%] [G loss: 0.710343] [Time: 0.147555]\n",
            "4848-6 [D loss: 0.696857, acc.: 42.31%] [G loss: 0.728001] [Time: 0.149727]\n",
            "4848-7 [D loss: 0.709923, acc.: 34.62%] [G loss: 0.702573] [Time: 0.151901]\n",
            "4848-8 [D loss: 0.700504, acc.: 46.15%] [G loss: 0.706532] [Time: 0.152383]\n",
            "4848 (test) [D loss: 0.821347, acc.: 48.08%] [G loss: 0.679174] [Time: 0.044008]\n",
            "4849-0 [D loss: 0.679928, acc.: 48.08%] [G loss: 0.731139] [Time: 0.148316]\n",
            "4849-1 [D loss: 0.699021, acc.: 46.15%] [G loss: 0.704640] [Time: 0.146883]\n",
            "4849-2 [D loss: 0.702514, acc.: 40.38%] [G loss: 0.715697] [Time: 0.149202]\n",
            "4849-3 [D loss: 0.683425, acc.: 51.92%] [G loss: 0.704157] [Time: 0.155418]\n",
            "4849-4 [D loss: 0.705856, acc.: 36.54%] [G loss: 0.713067] [Time: 0.155735]\n",
            "4849-5 [D loss: 0.686731, acc.: 57.69%] [G loss: 0.695097] [Time: 0.151421]\n",
            "4849-6 [D loss: 0.692475, acc.: 50.00%] [G loss: 0.696858] [Time: 0.151846]\n",
            "4849-7 [D loss: 0.711161, acc.: 42.31%] [G loss: 0.701107] [Time: 0.148310]\n",
            "4849-8 [D loss: 0.718012, acc.: 46.15%] [G loss: 0.692607] [Time: 0.149888]\n",
            "4849 (test) [D loss: 0.823255, acc.: 50.00%] [G loss: 0.988799] [Time: 0.045989]\n",
            "4850-0 [D loss: 0.695701, acc.: 46.15%] [G loss: 0.727481] [Time: 0.152379]\n",
            "4850-1 [D loss: 0.702048, acc.: 42.31%] [G loss: 0.707529] [Time: 0.150362]\n",
            "4850-2 [D loss: 0.709550, acc.: 34.62%] [G loss: 0.716463] [Time: 0.149668]\n",
            "4850-3 [D loss: 0.692151, acc.: 50.00%] [G loss: 0.710750] [Time: 0.150635]\n",
            "4850-4 [D loss: 0.693636, acc.: 50.00%] [G loss: 0.703168] [Time: 0.150945]\n",
            "4850-5 [D loss: 0.712094, acc.: 30.77%] [G loss: 0.683454] [Time: 0.147823]\n",
            "4850-6 [D loss: 0.694512, acc.: 40.38%] [G loss: 0.705043] [Time: 0.147923]\n",
            "4850-7 [D loss: 0.705223, acc.: 34.62%] [G loss: 0.697720] [Time: 0.157030]\n",
            "4850-8 [D loss: 0.715207, acc.: 44.23%] [G loss: 0.712178] [Time: 0.151679]\n",
            "4850 (test) [D loss: 0.823189, acc.: 46.15%] [G loss: 0.682542] [Time: 0.044275]\n",
            "4851-0 [D loss: 0.668176, acc.: 55.77%] [G loss: 0.736335] [Time: 0.148801]\n",
            "4851-1 [D loss: 0.694004, acc.: 48.08%] [G loss: 0.697087] [Time: 0.148760]\n",
            "4851-2 [D loss: 0.700659, acc.: 38.46%] [G loss: 0.705059] [Time: 0.147391]\n",
            "4851-3 [D loss: 0.677030, acc.: 57.69%] [G loss: 0.719676] [Time: 0.151036]\n",
            "4851-4 [D loss: 0.706295, acc.: 48.08%] [G loss: 0.704222] [Time: 0.147914]\n",
            "4851-5 [D loss: 0.710901, acc.: 28.85%] [G loss: 0.687249] [Time: 0.147390]\n",
            "4851-6 [D loss: 0.691343, acc.: 53.85%] [G loss: 0.697410] [Time: 0.147425]\n",
            "4851-7 [D loss: 0.692822, acc.: 40.38%] [G loss: 0.689911] [Time: 0.149603]\n",
            "4851-8 [D loss: 0.704122, acc.: 38.46%] [G loss: 0.720646] [Time: 0.150588]\n",
            "4851 (test) [D loss: 0.828105, acc.: 50.00%] [G loss: 0.945025] [Time: 0.044231]\n",
            "4852-0 [D loss: 0.678925, acc.: 50.00%] [G loss: 0.746947] [Time: 0.149923]\n",
            "4852-1 [D loss: 0.696732, acc.: 38.46%] [G loss: 0.716178] [Time: 0.149330]\n",
            "4852-2 [D loss: 0.696022, acc.: 46.15%] [G loss: 0.709319] [Time: 0.148693]\n",
            "4852-3 [D loss: 0.665793, acc.: 46.15%] [G loss: 0.701369] [Time: 0.148216]\n",
            "4852-4 [D loss: 0.688771, acc.: 44.23%] [G loss: 0.704070] [Time: 0.152906]\n",
            "4852-5 [D loss: 0.703029, acc.: 40.38%] [G loss: 0.703409] [Time: 0.148228]\n",
            "4852-6 [D loss: 0.696034, acc.: 50.00%] [G loss: 0.702174] [Time: 0.150087]\n",
            "4852-7 [D loss: 0.691945, acc.: 50.00%] [G loss: 0.709611] [Time: 0.150229]\n",
            "4852-8 [D loss: 0.711675, acc.: 30.77%] [G loss: 0.694510] [Time: 0.151161]\n",
            "4852 (test) [D loss: 0.828986, acc.: 46.15%] [G loss: 0.659216] [Time: 0.045779]\n",
            "4853-0 [D loss: 0.682861, acc.: 48.08%] [G loss: 0.750100] [Time: 0.149419]\n",
            "4853-1 [D loss: 0.705521, acc.: 38.46%] [G loss: 0.713949] [Time: 0.150420]\n",
            "4853-2 [D loss: 0.712000, acc.: 28.85%] [G loss: 0.703037] [Time: 0.153370]\n",
            "4853-3 [D loss: 0.678746, acc.: 57.69%] [G loss: 0.719047] [Time: 0.149549]\n",
            "4853-4 [D loss: 0.689813, acc.: 48.08%] [G loss: 0.688867] [Time: 0.151818]\n",
            "4853-5 [D loss: 0.692130, acc.: 50.00%] [G loss: 0.676707] [Time: 0.150475]\n",
            "4853-6 [D loss: 0.686640, acc.: 51.92%] [G loss: 0.696137] [Time: 0.151855]\n",
            "4853-7 [D loss: 0.715651, acc.: 42.31%] [G loss: 0.703111] [Time: 0.151961]\n",
            "4853-8 [D loss: 0.697139, acc.: 42.31%] [G loss: 0.680730] [Time: 0.163241]\n",
            "4853 (test) [D loss: 0.861435, acc.: 46.15%] [G loss: 0.530666] [Time: 0.044659]\n",
            "4854-0 [D loss: 0.673415, acc.: 63.46%] [G loss: 0.722646] [Time: 0.151058]\n",
            "4854-1 [D loss: 0.697544, acc.: 50.00%] [G loss: 0.721597] [Time: 0.153882]\n",
            "4854-2 [D loss: 0.701279, acc.: 40.38%] [G loss: 0.708423] [Time: 0.150028]\n",
            "4854-3 [D loss: 0.681995, acc.: 50.00%] [G loss: 0.706613] [Time: 0.151748]\n",
            "4854-4 [D loss: 0.692016, acc.: 48.08%] [G loss: 0.705378] [Time: 0.151458]\n",
            "4854-5 [D loss: 0.709659, acc.: 42.31%] [G loss: 0.712268] [Time: 0.150778]\n",
            "4854-6 [D loss: 0.697540, acc.: 42.31%] [G loss: 0.720637] [Time: 0.147895]\n",
            "4854-7 [D loss: 0.691693, acc.: 46.15%] [G loss: 0.687011] [Time: 0.148261]\n",
            "4854-8 [D loss: 0.704031, acc.: 42.31%] [G loss: 0.713252] [Time: 0.151494]\n",
            "4854 (test) [D loss: 0.845013, acc.: 48.08%] [G loss: 0.744028] [Time: 0.045075]\n",
            "4855-0 [D loss: 0.679927, acc.: 59.62%] [G loss: 0.739518] [Time: 0.150820]\n",
            "4855-1 [D loss: 0.707836, acc.: 34.62%] [G loss: 0.698607] [Time: 0.149615]\n",
            "4855-2 [D loss: 0.709563, acc.: 28.85%] [G loss: 0.722273] [Time: 0.149624]\n",
            "4855-3 [D loss: 0.675589, acc.: 50.00%] [G loss: 0.727489] [Time: 0.149614]\n",
            "4855-4 [D loss: 0.697532, acc.: 53.85%] [G loss: 0.712039] [Time: 0.150057]\n",
            "4855-5 [D loss: 0.715582, acc.: 36.54%] [G loss: 0.708419] [Time: 0.151049]\n",
            "4855-6 [D loss: 0.688719, acc.: 42.31%] [G loss: 0.702612] [Time: 0.150913]\n",
            "4855-7 [D loss: 0.702595, acc.: 48.08%] [G loss: 0.701283] [Time: 0.150039]\n",
            "4855-8 [D loss: 0.718526, acc.: 38.46%] [G loss: 0.700413] [Time: 0.153287]\n",
            "4855 (test) [D loss: 0.879887, acc.: 46.15%] [G loss: 0.538152] [Time: 0.043849]\n",
            "4856-0 [D loss: 0.682542, acc.: 51.92%] [G loss: 0.744129] [Time: 0.146974]\n",
            "4856-1 [D loss: 0.697084, acc.: 50.00%] [G loss: 0.711530] [Time: 0.151238]\n",
            "4856-2 [D loss: 0.702365, acc.: 50.00%] [G loss: 0.704899] [Time: 0.149535]\n",
            "4856-3 [D loss: 0.665844, acc.: 55.77%] [G loss: 0.721095] [Time: 0.147845]\n",
            "4856-4 [D loss: 0.701946, acc.: 42.31%] [G loss: 0.704756] [Time: 0.148020]\n",
            "4856-5 [D loss: 0.707077, acc.: 36.54%] [G loss: 0.689642] [Time: 0.150823]\n",
            "4856-6 [D loss: 0.686868, acc.: 48.08%] [G loss: 0.706128] [Time: 0.149603]\n",
            "4856-7 [D loss: 0.698799, acc.: 40.38%] [G loss: 0.696773] [Time: 0.153233]\n",
            "4856-8 [D loss: 0.712849, acc.: 38.46%] [G loss: 0.713626] [Time: 0.148249]\n",
            "4856 (test) [D loss: 0.845051, acc.: 46.15%] [G loss: 0.637952] [Time: 0.045541]\n",
            "4857-0 [D loss: 0.674825, acc.: 57.69%] [G loss: 0.719275] [Time: 0.150048]\n",
            "4857-1 [D loss: 0.695930, acc.: 46.15%] [G loss: 0.702228] [Time: 0.150232]\n",
            "4857-2 [D loss: 0.689050, acc.: 46.15%] [G loss: 0.701997] [Time: 0.149189]\n",
            "4857-3 [D loss: 0.682157, acc.: 48.08%] [G loss: 0.715109] [Time: 0.160361]\n",
            "4857-4 [D loss: 0.702535, acc.: 36.54%] [G loss: 0.694118] [Time: 0.147146]\n",
            "4857-5 [D loss: 0.706897, acc.: 46.15%] [G loss: 0.715488] [Time: 0.147383]\n",
            "4857-6 [D loss: 0.688785, acc.: 42.31%] [G loss: 0.708933] [Time: 0.148225]\n",
            "4857-7 [D loss: 0.706527, acc.: 38.46%] [G loss: 0.702149] [Time: 0.146994]\n",
            "4857-8 [D loss: 0.694625, acc.: 46.15%] [G loss: 0.716047] [Time: 0.151681]\n",
            "4857 (test) [D loss: 0.838747, acc.: 46.15%] [G loss: 0.679166] [Time: 0.043503]\n",
            "4858-0 [D loss: 0.675953, acc.: 55.77%] [G loss: 0.740262] [Time: 0.150793]\n",
            "4858-1 [D loss: 0.697081, acc.: 42.31%] [G loss: 0.693056] [Time: 0.150251]\n",
            "4858-2 [D loss: 0.697683, acc.: 36.54%] [G loss: 0.720159] [Time: 0.150309]\n",
            "4858-3 [D loss: 0.668704, acc.: 48.08%] [G loss: 0.720091] [Time: 0.153766]\n",
            "4858-4 [D loss: 0.694435, acc.: 53.85%] [G loss: 0.714902] [Time: 0.148819]\n",
            "4858-5 [D loss: 0.699266, acc.: 46.15%] [G loss: 0.688972] [Time: 0.148541]\n",
            "4858-6 [D loss: 0.682389, acc.: 59.62%] [G loss: 0.699970] [Time: 0.146891]\n",
            "4858-7 [D loss: 0.702908, acc.: 34.62%] [G loss: 0.695353] [Time: 0.147671]\n",
            "4858-8 [D loss: 0.698986, acc.: 48.08%] [G loss: 0.702848] [Time: 0.148467]\n",
            "4858 (test) [D loss: 0.829202, acc.: 48.08%] [G loss: 0.670792] [Time: 0.044539]\n",
            "4859-0 [D loss: 0.692743, acc.: 51.92%] [G loss: 0.755655] [Time: 0.149081]\n",
            "4859-1 [D loss: 0.704722, acc.: 40.38%] [G loss: 0.715182] [Time: 0.148621]\n",
            "4859-2 [D loss: 0.715896, acc.: 42.31%] [G loss: 0.746089] [Time: 0.150398]\n",
            "4859-3 [D loss: 0.677483, acc.: 53.85%] [G loss: 0.726137] [Time: 0.152297]\n",
            "4859-4 [D loss: 0.712363, acc.: 50.00%] [G loss: 0.702410] [Time: 0.151001]\n",
            "4859-5 [D loss: 0.702930, acc.: 36.54%] [G loss: 0.692811] [Time: 0.149520]\n",
            "4859-6 [D loss: 0.686770, acc.: 57.69%] [G loss: 0.691257] [Time: 0.149008]\n",
            "4859-7 [D loss: 0.687846, acc.: 53.85%] [G loss: 0.713333] [Time: 0.149602]\n",
            "4859-8 [D loss: 0.690671, acc.: 42.31%] [G loss: 0.696581] [Time: 0.150751]\n",
            "4859 (test) [D loss: 0.819844, acc.: 50.00%] [G loss: 0.930310] [Time: 0.044956]\n",
            "4860-0 [D loss: 0.692165, acc.: 48.08%] [G loss: 0.740736] [Time: 0.153245]\n",
            "4860-1 [D loss: 0.703233, acc.: 40.38%] [G loss: 0.697698] [Time: 0.150922]\n",
            "4860-2 [D loss: 0.711828, acc.: 34.62%] [G loss: 0.701399] [Time: 0.149796]\n",
            "4860-3 [D loss: 0.676969, acc.: 50.00%] [G loss: 0.716661] [Time: 0.146631]\n",
            "4860-4 [D loss: 0.695487, acc.: 46.15%] [G loss: 0.695836] [Time: 0.147618]\n",
            "4860-5 [D loss: 0.709132, acc.: 51.92%] [G loss: 0.703485] [Time: 0.152379]\n",
            "4860-6 [D loss: 0.685936, acc.: 55.77%] [G loss: 0.717205] [Time: 0.148967]\n",
            "4860-7 [D loss: 0.698898, acc.: 36.54%] [G loss: 0.699037] [Time: 0.146866]\n",
            "4860-8 [D loss: 0.704600, acc.: 44.23%] [G loss: 0.714206] [Time: 0.149740]\n",
            "4860 (test) [D loss: 0.820232, acc.: 46.15%] [G loss: 0.633050] [Time: 0.044642]\n",
            "4861-0 [D loss: 0.689365, acc.: 50.00%] [G loss: 0.715638] [Time: 0.148885]\n",
            "4861-1 [D loss: 0.690633, acc.: 46.15%] [G loss: 0.708387] [Time: 0.149213]\n",
            "4861-2 [D loss: 0.702528, acc.: 48.08%] [G loss: 0.695623] [Time: 0.150931]\n",
            "4861-3 [D loss: 0.669227, acc.: 44.23%] [G loss: 0.693846] [Time: 0.148339]\n",
            "4861-4 [D loss: 0.704146, acc.: 38.46%] [G loss: 0.679210] [Time: 0.148513]\n",
            "4861-5 [D loss: 0.698473, acc.: 36.54%] [G loss: 0.677920] [Time: 0.147950]\n",
            "4861-6 [D loss: 0.687083, acc.: 46.15%] [G loss: 0.696130] [Time: 0.149351]\n",
            "4861-7 [D loss: 0.707707, acc.: 40.38%] [G loss: 0.689694] [Time: 0.149866]\n",
            "4861-8 [D loss: 0.698436, acc.: 46.15%] [G loss: 0.707427] [Time: 0.153361]\n",
            "4861 (test) [D loss: 0.871746, acc.: 46.15%] [G loss: 0.477522] [Time: 0.044355]\n",
            "4862-0 [D loss: 0.686816, acc.: 55.77%] [G loss: 0.710218] [Time: 0.150408]\n",
            "4862-1 [D loss: 0.698885, acc.: 55.77%] [G loss: 0.697899] [Time: 0.147413]\n",
            "4862-2 [D loss: 0.703615, acc.: 36.54%] [G loss: 0.699153] [Time: 0.149965]\n",
            "4862-3 [D loss: 0.684938, acc.: 53.85%] [G loss: 0.702757] [Time: 0.146829]\n",
            "4862-4 [D loss: 0.691782, acc.: 53.85%] [G loss: 0.694793] [Time: 0.148217]\n",
            "4862-5 [D loss: 0.699443, acc.: 44.23%] [G loss: 0.688469] [Time: 0.148208]\n",
            "4862-6 [D loss: 0.687650, acc.: 50.00%] [G loss: 0.697144] [Time: 0.149094]\n",
            "4862-7 [D loss: 0.709806, acc.: 36.54%] [G loss: 0.700934] [Time: 0.152202]\n",
            "4862-8 [D loss: 0.709726, acc.: 48.08%] [G loss: 0.712367] [Time: 0.154943]\n",
            "4862 (test) [D loss: 0.841164, acc.: 46.15%] [G loss: 0.540657] [Time: 0.045690]\n",
            "4863-0 [D loss: 0.676675, acc.: 61.54%] [G loss: 0.730183] [Time: 0.147292]\n",
            "4863-1 [D loss: 0.710995, acc.: 38.46%] [G loss: 0.703278] [Time: 0.147226]\n",
            "4863-2 [D loss: 0.718252, acc.: 34.62%] [G loss: 0.705670] [Time: 0.146786]\n",
            "4863-3 [D loss: 0.681808, acc.: 59.62%] [G loss: 0.709614] [Time: 0.148217]\n",
            "4863-4 [D loss: 0.688074, acc.: 44.23%] [G loss: 0.717961] [Time: 0.149442]\n",
            "4863-5 [D loss: 0.709816, acc.: 42.31%] [G loss: 0.712308] [Time: 0.151199]\n",
            "4863-6 [D loss: 0.686523, acc.: 48.08%] [G loss: 0.710060] [Time: 0.148006]\n",
            "4863-7 [D loss: 0.690103, acc.: 53.85%] [G loss: 0.701437] [Time: 0.150498]\n",
            "4863-8 [D loss: 0.706430, acc.: 38.46%] [G loss: 0.730673] [Time: 0.152077]\n",
            "4863 (test) [D loss: 0.832917, acc.: 50.00%] [G loss: 0.873042] [Time: 0.044509]\n",
            "4864-0 [D loss: 0.680423, acc.: 63.46%] [G loss: 0.724197] [Time: 0.150500]\n",
            "4864-1 [D loss: 0.709494, acc.: 36.54%] [G loss: 0.693909] [Time: 0.148848]\n",
            "4864-2 [D loss: 0.696245, acc.: 48.08%] [G loss: 0.715668] [Time: 0.147027]\n",
            "4864-3 [D loss: 0.672108, acc.: 57.69%] [G loss: 0.716143] [Time: 0.148666]\n",
            "4864-4 [D loss: 0.699482, acc.: 48.08%] [G loss: 0.710080] [Time: 0.148079]\n",
            "4864-5 [D loss: 0.713351, acc.: 50.00%] [G loss: 0.694830] [Time: 0.148256]\n",
            "4864-6 [D loss: 0.683596, acc.: 50.00%] [G loss: 0.708090] [Time: 0.150087]\n",
            "4864-7 [D loss: 0.713783, acc.: 36.54%] [G loss: 0.698893] [Time: 0.150348]\n",
            "4864-8 [D loss: 0.698261, acc.: 44.23%] [G loss: 0.699977] [Time: 0.151360]\n",
            "4864 (test) [D loss: 0.844734, acc.: 46.15%] [G loss: 0.579285] [Time: 0.043922]\n",
            "4865-0 [D loss: 0.688469, acc.: 55.77%] [G loss: 0.735028] [Time: 0.147730]\n",
            "4865-1 [D loss: 0.697921, acc.: 40.38%] [G loss: 0.709532] [Time: 0.148577]\n",
            "4865-2 [D loss: 0.703817, acc.: 44.23%] [G loss: 0.713044] [Time: 0.150423]\n",
            "4865-3 [D loss: 0.676503, acc.: 50.00%] [G loss: 0.719267] [Time: 0.148994]\n",
            "4865-4 [D loss: 0.689443, acc.: 46.15%] [G loss: 0.693615] [Time: 0.149641]\n",
            "4865-5 [D loss: 0.696480, acc.: 46.15%] [G loss: 0.698440] [Time: 0.147687]\n",
            "4865-6 [D loss: 0.687743, acc.: 44.23%] [G loss: 0.711137] [Time: 0.147432]\n",
            "4865-7 [D loss: 0.691704, acc.: 48.08%] [G loss: 0.709406] [Time: 0.150208]\n",
            "4865-8 [D loss: 0.697129, acc.: 42.31%] [G loss: 0.720406] [Time: 0.149121]\n",
            "4865 (test) [D loss: 0.827744, acc.: 48.08%] [G loss: 0.669615] [Time: 0.044093]\n",
            "4866-0 [D loss: 0.672386, acc.: 55.77%] [G loss: 0.756296] [Time: 0.148592]\n",
            "4866-1 [D loss: 0.705334, acc.: 38.46%] [G loss: 0.683672] [Time: 0.150728]\n",
            "4866-2 [D loss: 0.711863, acc.: 42.31%] [G loss: 0.724003] [Time: 0.150937]\n",
            "4866-3 [D loss: 0.680481, acc.: 50.00%] [G loss: 0.691061] [Time: 0.151666]\n",
            "4866-4 [D loss: 0.699281, acc.: 46.15%] [G loss: 0.707507] [Time: 0.152131]\n",
            "4866-5 [D loss: 0.725777, acc.: 32.69%] [G loss: 0.680312] [Time: 0.153802]\n",
            "4866-6 [D loss: 0.699241, acc.: 36.54%] [G loss: 0.711684] [Time: 0.150094]\n",
            "4866-7 [D loss: 0.701174, acc.: 46.15%] [G loss: 0.687591] [Time: 0.148213]\n",
            "4866-8 [D loss: 0.690228, acc.: 55.77%] [G loss: 0.696519] [Time: 0.149062]\n",
            "4866 (test) [D loss: 0.866277, acc.: 46.15%] [G loss: 0.535628] [Time: 0.044735]\n",
            "4867-0 [D loss: 0.681965, acc.: 53.85%] [G loss: 0.733112] [Time: 0.148130]\n",
            "4867-1 [D loss: 0.692958, acc.: 48.08%] [G loss: 0.694067] [Time: 0.150760]\n",
            "4867-2 [D loss: 0.710228, acc.: 28.85%] [G loss: 0.715885] [Time: 0.150495]\n",
            "4867-3 [D loss: 0.661839, acc.: 55.77%] [G loss: 0.715310] [Time: 0.149112]\n",
            "4867-4 [D loss: 0.692249, acc.: 48.08%] [G loss: 0.694772] [Time: 0.148417]\n",
            "4867-5 [D loss: 0.706980, acc.: 48.08%] [G loss: 0.686298] [Time: 0.147229]\n",
            "4867-6 [D loss: 0.684309, acc.: 55.77%] [G loss: 0.692281] [Time: 0.147752]\n",
            "4867-7 [D loss: 0.702267, acc.: 42.31%] [G loss: 0.691806] [Time: 0.150380]\n",
            "4867-8 [D loss: 0.694203, acc.: 40.38%] [G loss: 0.710562] [Time: 0.147647]\n",
            "4867 (test) [D loss: 0.845579, acc.: 46.15%] [G loss: 0.528929] [Time: 0.044034]\n",
            "4868-0 [D loss: 0.682230, acc.: 50.00%] [G loss: 0.732953] [Time: 0.147922]\n",
            "4868-1 [D loss: 0.706005, acc.: 38.46%] [G loss: 0.713365] [Time: 0.149299]\n",
            "4868-2 [D loss: 0.698757, acc.: 42.31%] [G loss: 0.694052] [Time: 0.147171]\n",
            "4868-3 [D loss: 0.667130, acc.: 57.69%] [G loss: 0.693951] [Time: 0.148801]\n",
            "4868-4 [D loss: 0.695355, acc.: 44.23%] [G loss: 0.699317] [Time: 0.147118]\n",
            "4868-5 [D loss: 0.698627, acc.: 48.08%] [G loss: 0.679395] [Time: 0.149214]\n",
            "4868-6 [D loss: 0.697710, acc.: 44.23%] [G loss: 0.702352] [Time: 0.148808]\n",
            "4868-7 [D loss: 0.700527, acc.: 46.15%] [G loss: 0.695753] [Time: 0.149296]\n",
            "4868-8 [D loss: 0.690051, acc.: 57.69%] [G loss: 0.706824] [Time: 0.148918]\n",
            "4868 (test) [D loss: 0.856391, acc.: 48.08%] [G loss: 0.521694] [Time: 0.043604]\n",
            "4869-0 [D loss: 0.677592, acc.: 53.85%] [G loss: 0.750001] [Time: 0.148980]\n",
            "4869-1 [D loss: 0.705295, acc.: 40.38%] [G loss: 0.702713] [Time: 0.150239]\n",
            "4869-2 [D loss: 0.702989, acc.: 38.46%] [G loss: 0.719484] [Time: 0.151245]\n",
            "4869-3 [D loss: 0.667480, acc.: 53.85%] [G loss: 0.729217] [Time: 0.152719]\n",
            "4869-4 [D loss: 0.701067, acc.: 48.08%] [G loss: 0.683345] [Time: 0.148547]\n",
            "4869-5 [D loss: 0.715020, acc.: 38.46%] [G loss: 0.681820] [Time: 0.150440]\n",
            "4869-6 [D loss: 0.683355, acc.: 40.38%] [G loss: 0.710120] [Time: 0.151585]\n",
            "4869-7 [D loss: 0.699820, acc.: 48.08%] [G loss: 0.697858] [Time: 0.150661]\n",
            "4869-8 [D loss: 0.693299, acc.: 50.00%] [G loss: 0.695787] [Time: 0.149161]\n",
            "4869 (test) [D loss: 0.896480, acc.: 48.08%] [G loss: 0.426451] [Time: 0.044633]\n",
            "4870-0 [D loss: 0.667926, acc.: 65.38%] [G loss: 0.732797] [Time: 0.148568]\n",
            "4870-1 [D loss: 0.703526, acc.: 40.38%] [G loss: 0.692833] [Time: 0.147105]\n",
            "4870-2 [D loss: 0.689065, acc.: 40.38%] [G loss: 0.687394] [Time: 0.148437]\n",
            "4870-3 [D loss: 0.671959, acc.: 57.69%] [G loss: 0.687022] [Time: 0.149984]\n",
            "4870-4 [D loss: 0.688676, acc.: 53.85%] [G loss: 0.694101] [Time: 0.149477]\n",
            "4870-5 [D loss: 0.700975, acc.: 40.38%] [G loss: 0.691533] [Time: 0.149084]\n",
            "4870-6 [D loss: 0.679305, acc.: 51.92%] [G loss: 0.715433] [Time: 0.150377]\n",
            "4870-7 [D loss: 0.709871, acc.: 46.15%] [G loss: 0.698729] [Time: 0.151477]\n",
            "4870-8 [D loss: 0.695195, acc.: 53.85%] [G loss: 0.704178] [Time: 0.151513]\n",
            "4870 (test) [D loss: 0.844779, acc.: 48.08%] [G loss: 0.585251] [Time: 0.044418]\n",
            "4871-0 [D loss: 0.670427, acc.: 61.54%] [G loss: 0.760885] [Time: 0.151774]\n",
            "4871-1 [D loss: 0.705761, acc.: 42.31%] [G loss: 0.720740] [Time: 0.149857]\n",
            "4871-2 [D loss: 0.700860, acc.: 42.31%] [G loss: 0.723774] [Time: 0.154857]\n",
            "4871-3 [D loss: 0.670163, acc.: 55.77%] [G loss: 0.732341] [Time: 0.148298]\n",
            "4871-4 [D loss: 0.678122, acc.: 50.00%] [G loss: 0.701765] [Time: 0.149075]\n",
            "4871-5 [D loss: 0.707927, acc.: 44.23%] [G loss: 0.726862] [Time: 0.149060]\n",
            "4871-6 [D loss: 0.685333, acc.: 50.00%] [G loss: 0.716384] [Time: 0.150493]\n",
            "4871-7 [D loss: 0.693502, acc.: 48.08%] [G loss: 0.724294] [Time: 0.150136]\n",
            "4871-8 [D loss: 0.707624, acc.: 42.31%] [G loss: 0.726275] [Time: 0.148542]\n",
            "4871 (test) [D loss: 0.820430, acc.: 50.00%] [G loss: 0.822261] [Time: 0.044272]\n",
            "4872-0 [D loss: 0.677023, acc.: 50.00%] [G loss: 0.756987] [Time: 0.147267]\n",
            "4872-1 [D loss: 0.693594, acc.: 46.15%] [G loss: 0.706154] [Time: 0.147161]\n",
            "4872-2 [D loss: 0.705646, acc.: 38.46%] [G loss: 0.714769] [Time: 0.147837]\n",
            "4872-3 [D loss: 0.669534, acc.: 51.92%] [G loss: 0.717403] [Time: 0.148356]\n",
            "4872-4 [D loss: 0.712189, acc.: 44.23%] [G loss: 0.713777] [Time: 0.148813]\n",
            "4872-5 [D loss: 0.704625, acc.: 36.54%] [G loss: 0.703870] [Time: 0.148767]\n",
            "4872-6 [D loss: 0.677309, acc.: 46.15%] [G loss: 0.715962] [Time: 0.151717]\n",
            "4872-7 [D loss: 0.702485, acc.: 34.62%] [G loss: 0.707931] [Time: 0.148182]\n",
            "4872-8 [D loss: 0.707775, acc.: 42.31%] [G loss: 0.711423] [Time: 0.148056]\n",
            "4872 (test) [D loss: 0.851074, acc.: 48.08%] [G loss: 0.623326] [Time: 0.047230]\n",
            "4873-0 [D loss: 0.679591, acc.: 55.77%] [G loss: 0.757208] [Time: 0.147887]\n",
            "4873-1 [D loss: 0.704410, acc.: 30.77%] [G loss: 0.688877] [Time: 0.148546]\n",
            "4873-2 [D loss: 0.714377, acc.: 36.54%] [G loss: 0.707843] [Time: 0.152129]\n",
            "4873-3 [D loss: 0.664772, acc.: 61.54%] [G loss: 0.719469] [Time: 0.150449]\n",
            "4873-4 [D loss: 0.692698, acc.: 40.38%] [G loss: 0.699056] [Time: 0.150640]\n",
            "4873-5 [D loss: 0.702660, acc.: 40.38%] [G loss: 0.693726] [Time: 0.151290]\n",
            "4873-6 [D loss: 0.690603, acc.: 50.00%] [G loss: 0.695147] [Time: 0.150932]\n",
            "4873-7 [D loss: 0.710415, acc.: 42.31%] [G loss: 0.698560] [Time: 0.147344]\n",
            "4873-8 [D loss: 0.702562, acc.: 32.69%] [G loss: 0.714356] [Time: 0.151014]\n",
            "4873 (test) [D loss: 0.872847, acc.: 48.08%] [G loss: 0.538112] [Time: 0.044337]\n",
            "4874-0 [D loss: 0.679862, acc.: 57.69%] [G loss: 0.736453] [Time: 0.148942]\n",
            "4874-1 [D loss: 0.709159, acc.: 46.15%] [G loss: 0.704101] [Time: 0.151267]\n",
            "4874-2 [D loss: 0.709584, acc.: 40.38%] [G loss: 0.725460] [Time: 0.149048]\n",
            "4874-3 [D loss: 0.664804, acc.: 57.69%] [G loss: 0.733054] [Time: 0.148646]\n",
            "4874-4 [D loss: 0.706208, acc.: 38.46%] [G loss: 0.681760] [Time: 0.150492]\n",
            "4874-5 [D loss: 0.714351, acc.: 42.31%] [G loss: 0.705873] [Time: 0.150465]\n",
            "4874-6 [D loss: 0.677002, acc.: 53.85%] [G loss: 0.719266] [Time: 0.152107]\n",
            "4874-7 [D loss: 0.705064, acc.: 36.54%] [G loss: 0.691166] [Time: 0.148372]\n",
            "4874-8 [D loss: 0.696157, acc.: 36.54%] [G loss: 0.695719] [Time: 0.149737]\n",
            "4874 (test) [D loss: 0.868443, acc.: 48.08%] [G loss: 0.534811] [Time: 0.044112]\n",
            "4875-0 [D loss: 0.666287, acc.: 59.62%] [G loss: 0.720708] [Time: 0.153827]\n",
            "4875-1 [D loss: 0.706116, acc.: 50.00%] [G loss: 0.698183] [Time: 0.147038]\n",
            "4875-2 [D loss: 0.723155, acc.: 32.69%] [G loss: 0.722336] [Time: 0.148017]\n",
            "4875-3 [D loss: 0.679347, acc.: 46.15%] [G loss: 0.730858] [Time: 0.147835]\n",
            "4875-4 [D loss: 0.703128, acc.: 40.38%] [G loss: 0.698117] [Time: 0.148044]\n",
            "4875-5 [D loss: 0.702121, acc.: 38.46%] [G loss: 0.712560] [Time: 0.147336]\n",
            "4875-6 [D loss: 0.677909, acc.: 53.85%] [G loss: 0.715078] [Time: 0.147357]\n",
            "4875-7 [D loss: 0.703819, acc.: 40.38%] [G loss: 0.706470] [Time: 0.152508]\n",
            "4875-8 [D loss: 0.707261, acc.: 44.23%] [G loss: 0.709013] [Time: 0.147640]\n",
            "4875 (test) [D loss: 0.825189, acc.: 46.15%] [G loss: 0.676100] [Time: 0.043111]\n",
            "4876-0 [D loss: 0.669299, acc.: 59.62%] [G loss: 0.743938] [Time: 0.147931]\n",
            "4876-1 [D loss: 0.711943, acc.: 38.46%] [G loss: 0.701283] [Time: 0.150288]\n",
            "4876-2 [D loss: 0.703747, acc.: 44.23%] [G loss: 0.718296] [Time: 0.149077]\n",
            "4876-3 [D loss: 0.677623, acc.: 57.69%] [G loss: 0.721244] [Time: 0.148265]\n",
            "4876-4 [D loss: 0.699240, acc.: 38.46%] [G loss: 0.699207] [Time: 0.148771]\n",
            "4876-5 [D loss: 0.705867, acc.: 42.31%] [G loss: 0.700693] [Time: 0.153692]\n",
            "4876-6 [D loss: 0.683492, acc.: 48.08%] [G loss: 0.728765] [Time: 0.147444]\n",
            "4876-7 [D loss: 0.709313, acc.: 36.54%] [G loss: 0.690564] [Time: 0.147615]\n",
            "4876-8 [D loss: 0.696661, acc.: 51.92%] [G loss: 0.701230] [Time: 0.147117]\n",
            "4876 (test) [D loss: 0.833317, acc.: 48.08%] [G loss: 0.657393] [Time: 0.043801]\n",
            "4877-0 [D loss: 0.692340, acc.: 46.15%] [G loss: 0.734944] [Time: 0.147388]\n",
            "4877-1 [D loss: 0.702296, acc.: 42.31%] [G loss: 0.716908] [Time: 0.151045]\n",
            "4877-2 [D loss: 0.706454, acc.: 40.38%] [G loss: 0.701950] [Time: 0.151934]\n",
            "4877-3 [D loss: 0.680988, acc.: 51.92%] [G loss: 0.711704] [Time: 0.147003]\n",
            "4877-4 [D loss: 0.690600, acc.: 55.77%] [G loss: 0.689901] [Time: 0.147677]\n",
            "4877-5 [D loss: 0.705929, acc.: 46.15%] [G loss: 0.722658] [Time: 0.149155]\n",
            "4877-6 [D loss: 0.683021, acc.: 61.54%] [G loss: 0.696561] [Time: 0.150374]\n",
            "4877-7 [D loss: 0.708624, acc.: 40.38%] [G loss: 0.686380] [Time: 0.151393]\n",
            "4877-8 [D loss: 0.713600, acc.: 44.23%] [G loss: 0.696488] [Time: 0.149104]\n",
            "4877 (test) [D loss: 0.839341, acc.: 48.08%] [G loss: 0.587843] [Time: 0.044463]\n",
            "4878-0 [D loss: 0.674262, acc.: 51.92%] [G loss: 0.734112] [Time: 0.151552]\n",
            "4878-1 [D loss: 0.707531, acc.: 30.77%] [G loss: 0.695475] [Time: 0.148389]\n",
            "4878-2 [D loss: 0.697353, acc.: 44.23%] [G loss: 0.722227] [Time: 0.148283]\n",
            "4878-3 [D loss: 0.665360, acc.: 61.54%] [G loss: 0.727776] [Time: 0.150799]\n",
            "4878-4 [D loss: 0.691224, acc.: 46.15%] [G loss: 0.708450] [Time: 0.151923]\n",
            "4878-5 [D loss: 0.710431, acc.: 34.62%] [G loss: 0.683225] [Time: 0.150203]\n",
            "4878-6 [D loss: 0.682482, acc.: 50.00%] [G loss: 0.710418] [Time: 0.148319]\n",
            "4878-7 [D loss: 0.699266, acc.: 46.15%] [G loss: 0.685924] [Time: 0.149478]\n",
            "4878-8 [D loss: 0.705805, acc.: 34.62%] [G loss: 0.693372] [Time: 0.152937]\n",
            "4878 (test) [D loss: 0.845036, acc.: 48.08%] [G loss: 0.566414] [Time: 0.043944]\n",
            "4879-0 [D loss: 0.666593, acc.: 59.62%] [G loss: 0.746045] [Time: 0.148606]\n",
            "4879-1 [D loss: 0.705186, acc.: 51.92%] [G loss: 0.691887] [Time: 0.148757]\n",
            "4879-2 [D loss: 0.714132, acc.: 40.38%] [G loss: 0.701756] [Time: 0.147763]\n",
            "4879-3 [D loss: 0.672988, acc.: 55.77%] [G loss: 0.717050] [Time: 0.149239]\n",
            "4879-4 [D loss: 0.708554, acc.: 50.00%] [G loss: 0.693339] [Time: 0.148339]\n",
            "4879-5 [D loss: 0.714669, acc.: 28.85%] [G loss: 0.701283] [Time: 0.149511]\n",
            "4879-6 [D loss: 0.692395, acc.: 42.31%] [G loss: 0.703843] [Time: 0.149259]\n",
            "4879-7 [D loss: 0.706266, acc.: 36.54%] [G loss: 0.681053] [Time: 0.148614]\n",
            "4879-8 [D loss: 0.697097, acc.: 46.15%] [G loss: 0.694806] [Time: 0.148647]\n",
            "4879 (test) [D loss: 0.863413, acc.: 48.08%] [G loss: 0.513350] [Time: 0.043159]\n",
            "4880-0 [D loss: 0.663862, acc.: 59.62%] [G loss: 0.732145] [Time: 0.153881]\n",
            "4880-1 [D loss: 0.698414, acc.: 38.46%] [G loss: 0.698901] [Time: 0.149018]\n",
            "4880-2 [D loss: 0.713883, acc.: 36.54%] [G loss: 0.705840] [Time: 0.147073]\n",
            "4880-3 [D loss: 0.676936, acc.: 50.00%] [G loss: 0.699927] [Time: 0.147258]\n",
            "4880-4 [D loss: 0.705639, acc.: 34.62%] [G loss: 0.706298] [Time: 0.151092]\n",
            "4880-5 [D loss: 0.693892, acc.: 48.08%] [G loss: 0.696887] [Time: 0.147954]\n",
            "4880-6 [D loss: 0.678375, acc.: 57.69%] [G loss: 0.722996] [Time: 0.149856]\n",
            "4880-7 [D loss: 0.691251, acc.: 46.15%] [G loss: 0.694422] [Time: 0.151839]\n",
            "4880-8 [D loss: 0.709753, acc.: 32.69%] [G loss: 0.699216] [Time: 0.150676]\n",
            "4880 (test) [D loss: 0.868955, acc.: 48.08%] [G loss: 0.536793] [Time: 0.043701]\n",
            "4881-0 [D loss: 0.681230, acc.: 50.00%] [G loss: 0.732888] [Time: 0.146934]\n",
            "4881-1 [D loss: 0.706018, acc.: 36.54%] [G loss: 0.692906] [Time: 0.154615]\n",
            "4881-2 [D loss: 0.695374, acc.: 46.15%] [G loss: 0.688823] [Time: 0.149694]\n",
            "4881-3 [D loss: 0.672142, acc.: 53.85%] [G loss: 0.769791] [Time: 0.149349]\n",
            "4881-4 [D loss: 0.693452, acc.: 51.92%] [G loss: 0.723540] [Time: 0.147432]\n",
            "4881-5 [D loss: 0.711381, acc.: 32.69%] [G loss: 0.677818] [Time: 0.150490]\n",
            "4881-6 [D loss: 0.674543, acc.: 57.69%] [G loss: 0.703581] [Time: 0.147106]\n",
            "4881-7 [D loss: 0.702950, acc.: 42.31%] [G loss: 0.708318] [Time: 0.148618]\n",
            "4881-8 [D loss: 0.702591, acc.: 48.08%] [G loss: 0.712164] [Time: 0.147918]\n",
            "4881 (test) [D loss: 0.966912, acc.: 48.08%] [G loss: 0.360583] [Time: 0.046294]\n",
            "4882-0 [D loss: 0.686073, acc.: 48.08%] [G loss: 0.710174] [Time: 0.150323]\n",
            "4882-1 [D loss: 0.698132, acc.: 50.00%] [G loss: 0.709239] [Time: 0.147361]\n",
            "4882-2 [D loss: 0.702359, acc.: 40.38%] [G loss: 0.728921] [Time: 0.151162]\n",
            "4882-3 [D loss: 0.718095, acc.: 46.15%] [G loss: 0.726743] [Time: 0.147935]\n",
            "4882-4 [D loss: 0.694111, acc.: 38.46%] [G loss: 0.784240] [Time: 0.150023]\n",
            "4882-5 [D loss: 0.685774, acc.: 48.08%] [G loss: 0.736750] [Time: 0.147336]\n",
            "4882-6 [D loss: 0.679562, acc.: 67.31%] [G loss: 0.738155] [Time: 0.148433]\n",
            "4882-7 [D loss: 0.685120, acc.: 59.62%] [G loss: 0.712656] [Time: 0.147657]\n",
            "4882-8 [D loss: 0.709820, acc.: 51.92%] [G loss: 0.707961] [Time: 0.148441]\n",
            "4882 (test) [D loss: 0.975890, acc.: 48.08%] [G loss: 0.333225] [Time: 0.043072]\n",
            "4883-0 [D loss: 0.715992, acc.: 46.15%] [G loss: 0.732563] [Time: 0.147683]\n",
            "4883-1 [D loss: 0.694325, acc.: 46.15%] [G loss: 0.691407] [Time: 0.146571]\n",
            "4883-2 [D loss: 0.715339, acc.: 32.69%] [G loss: 0.736249] [Time: 0.148649]\n",
            "4883-3 [D loss: 0.706406, acc.: 48.08%] [G loss: 0.688889] [Time: 0.148015]\n",
            "4883-4 [D loss: 0.697073, acc.: 42.31%] [G loss: 0.680460] [Time: 0.149745]\n",
            "4883-5 [D loss: 0.706210, acc.: 46.15%] [G loss: 0.699303] [Time: 0.148488]\n",
            "4883-6 [D loss: 0.691751, acc.: 46.15%] [G loss: 0.711506] [Time: 0.147491]\n",
            "4883-7 [D loss: 0.704304, acc.: 51.92%] [G loss: 0.698328] [Time: 0.148307]\n",
            "4883-8 [D loss: 0.695814, acc.: 55.77%] [G loss: 0.698236] [Time: 0.150639]\n",
            "4883 (test) [D loss: 1.081159, acc.: 48.08%] [G loss: 0.242101] [Time: 0.044524]\n",
            "4884-0 [D loss: 0.723425, acc.: 46.15%] [G loss: 0.719244] [Time: 0.153688]\n",
            "4884-1 [D loss: 0.706306, acc.: 48.08%] [G loss: 0.668671] [Time: 0.148412]\n",
            "4884-2 [D loss: 0.704857, acc.: 44.23%] [G loss: 0.688882] [Time: 0.148640]\n",
            "4884-3 [D loss: 0.708663, acc.: 40.38%] [G loss: 0.688249] [Time: 0.149585]\n",
            "4884-4 [D loss: 0.710537, acc.: 34.62%] [G loss: 0.681259] [Time: 0.153714]\n",
            "4884-5 [D loss: 0.699159, acc.: 44.23%] [G loss: 0.691561] [Time: 0.150034]\n",
            "4884-6 [D loss: 0.681738, acc.: 50.00%] [G loss: 0.707611] [Time: 0.151044]\n",
            "4884-7 [D loss: 0.699892, acc.: 44.23%] [G loss: 0.691079] [Time: 0.146840]\n",
            "4884-8 [D loss: 0.690228, acc.: 42.31%] [G loss: 0.697252] [Time: 0.151268]\n",
            "4884 (test) [D loss: 1.077664, acc.: 50.00%] [G loss: 0.254511] [Time: 0.045155]\n",
            "4885-0 [D loss: 0.718465, acc.: 42.31%] [G loss: 0.682266] [Time: 0.148497]\n",
            "4885-1 [D loss: 0.694878, acc.: 46.15%] [G loss: 0.688986] [Time: 0.148125]\n",
            "4885-2 [D loss: 0.703718, acc.: 46.15%] [G loss: 0.686214] [Time: 0.149184]\n",
            "4885-3 [D loss: 0.717155, acc.: 40.38%] [G loss: 0.746489] [Time: 0.148848]\n",
            "4885-4 [D loss: 0.683486, acc.: 48.08%] [G loss: 0.740214] [Time: 0.147019]\n",
            "4885-5 [D loss: 0.710632, acc.: 40.38%] [G loss: 0.714022] [Time: 0.149326]\n",
            "4885-6 [D loss: 0.694075, acc.: 40.38%] [G loss: 0.715862] [Time: 0.148705]\n",
            "4885-7 [D loss: 0.689555, acc.: 59.62%] [G loss: 0.709849] [Time: 0.148044]\n",
            "4885-8 [D loss: 0.690286, acc.: 51.92%] [G loss: 0.701003] [Time: 0.149907]\n",
            "4885 (test) [D loss: 0.894141, acc.: 50.00%] [G loss: 0.508180] [Time: 0.043890]\n",
            "4886-0 [D loss: 0.714220, acc.: 34.62%] [G loss: 0.731711] [Time: 0.149910]\n",
            "4886-1 [D loss: 0.699247, acc.: 40.38%] [G loss: 0.706800] [Time: 0.147411]\n",
            "4886-2 [D loss: 0.706511, acc.: 38.46%] [G loss: 0.726550] [Time: 0.149536]\n",
            "4886-3 [D loss: 0.718212, acc.: 34.62%] [G loss: 0.729552] [Time: 0.150630]\n",
            "4886-4 [D loss: 0.693877, acc.: 44.23%] [G loss: 0.710354] [Time: 0.150196]\n",
            "4886-5 [D loss: 0.701442, acc.: 46.15%] [G loss: 0.690683] [Time: 0.149775]\n",
            "4886-6 [D loss: 0.689397, acc.: 38.46%] [G loss: 0.714809] [Time: 0.147909]\n",
            "4886-7 [D loss: 0.709733, acc.: 28.85%] [G loss: 0.693842] [Time: 0.149312]\n",
            "4886-8 [D loss: 0.714405, acc.: 46.15%] [G loss: 0.692251] [Time: 0.149089]\n",
            "4886 (test) [D loss: 0.973110, acc.: 50.00%] [G loss: 0.434454] [Time: 0.044233]\n",
            "4887-0 [D loss: 0.703314, acc.: 50.00%] [G loss: 0.716747] [Time: 0.148679]\n",
            "4887-1 [D loss: 0.710367, acc.: 34.62%] [G loss: 0.686779] [Time: 0.150090]\n",
            "4887-2 [D loss: 0.706140, acc.: 46.15%] [G loss: 0.695740] [Time: 0.147610]\n",
            "4887-3 [D loss: 0.705594, acc.: 50.00%] [G loss: 0.711501] [Time: 0.148671]\n",
            "4887-4 [D loss: 0.703881, acc.: 32.69%] [G loss: 0.677532] [Time: 0.149474]\n",
            "4887-5 [D loss: 0.698290, acc.: 38.46%] [G loss: 0.680327] [Time: 0.148876]\n",
            "4887-6 [D loss: 0.689617, acc.: 34.62%] [G loss: 0.698614] [Time: 0.148125]\n",
            "4887-7 [D loss: 0.706938, acc.: 44.23%] [G loss: 0.686022] [Time: 0.147791]\n",
            "4887-8 [D loss: 0.697345, acc.: 46.15%] [G loss: 0.665287] [Time: 0.147012]\n",
            "4887 (test) [D loss: 1.099234, acc.: 50.00%] [G loss: 0.322197] [Time: 0.043538]\n",
            "4888-0 [D loss: 0.710372, acc.: 46.15%] [G loss: 0.710086] [Time: 0.147403]\n",
            "4888-1 [D loss: 0.700339, acc.: 55.77%] [G loss: 0.688583] [Time: 0.149456]\n",
            "4888-2 [D loss: 0.704148, acc.: 42.31%] [G loss: 0.687468] [Time: 0.151411]\n",
            "4888-3 [D loss: 0.710456, acc.: 46.15%] [G loss: 0.716721] [Time: 0.147583]\n",
            "4888-4 [D loss: 0.697078, acc.: 38.46%] [G loss: 0.695014] [Time: 0.149530]\n",
            "4888-5 [D loss: 0.699809, acc.: 44.23%] [G loss: 0.701233] [Time: 0.153269]\n",
            "4888-6 [D loss: 0.686183, acc.: 53.85%] [G loss: 0.713914] [Time: 0.149403]\n",
            "4888-7 [D loss: 0.698523, acc.: 50.00%] [G loss: 0.686880] [Time: 0.150404]\n",
            "4888-8 [D loss: 0.713056, acc.: 40.38%] [G loss: 0.703987] [Time: 0.150909]\n",
            "4888 (test) [D loss: 1.057191, acc.: 50.00%] [G loss: 0.385833] [Time: 0.044171]\n",
            "4889-0 [D loss: 0.700394, acc.: 51.92%] [G loss: 0.717163] [Time: 0.150448]\n",
            "4889-1 [D loss: 0.710258, acc.: 40.38%] [G loss: 0.701989] [Time: 0.150468]\n",
            "4889-2 [D loss: 0.714913, acc.: 38.46%] [G loss: 0.697792] [Time: 0.150316]\n",
            "4889-3 [D loss: 0.704049, acc.: 46.15%] [G loss: 0.726103] [Time: 0.154866]\n",
            "4889-4 [D loss: 0.687239, acc.: 44.23%] [G loss: 0.708134] [Time: 0.147939]\n",
            "4889-5 [D loss: 0.698975, acc.: 38.46%] [G loss: 0.686436] [Time: 0.151709]\n",
            "4889-6 [D loss: 0.686804, acc.: 48.08%] [G loss: 0.711323] [Time: 0.148823]\n",
            "4889-7 [D loss: 0.709152, acc.: 48.08%] [G loss: 0.689842] [Time: 0.150388]\n",
            "4889-8 [D loss: 0.701993, acc.: 40.38%] [G loss: 0.693334] [Time: 0.149091]\n",
            "4889 (test) [D loss: 1.019311, acc.: 50.00%] [G loss: 0.485268] [Time: 0.044445]\n",
            "4890-0 [D loss: 0.695308, acc.: 40.38%] [G loss: 0.715089] [Time: 0.149134]\n",
            "4890-1 [D loss: 0.704711, acc.: 38.46%] [G loss: 0.702161] [Time: 0.150164]\n",
            "4890-2 [D loss: 0.686982, acc.: 59.62%] [G loss: 0.702194] [Time: 0.149349]\n",
            "4890-3 [D loss: 0.711084, acc.: 42.31%] [G loss: 0.714243] [Time: 0.147799]\n",
            "4890-4 [D loss: 0.695000, acc.: 44.23%] [G loss: 0.688627] [Time: 0.149567]\n",
            "4890-5 [D loss: 0.700384, acc.: 36.54%] [G loss: 0.691199] [Time: 0.149055]\n",
            "4890-6 [D loss: 0.691776, acc.: 53.85%] [G loss: 0.713625] [Time: 0.146970]\n",
            "4890-7 [D loss: 0.693549, acc.: 44.23%] [G loss: 0.694853] [Time: 0.148953]\n",
            "4890-8 [D loss: 0.695221, acc.: 46.15%] [G loss: 0.693556] [Time: 0.149508]\n",
            "4890 (test) [D loss: 1.118791, acc.: 48.08%] [G loss: 0.414822] [Time: 0.043753]\n",
            "4891-0 [D loss: 0.700064, acc.: 44.23%] [G loss: 0.717435] [Time: 0.147543]\n",
            "4891-1 [D loss: 0.694010, acc.: 50.00%] [G loss: 0.678707] [Time: 0.147245]\n",
            "4891-2 [D loss: 0.695695, acc.: 48.08%] [G loss: 0.684584] [Time: 0.150269]\n",
            "4891-3 [D loss: 0.709701, acc.: 55.77%] [G loss: 0.696876] [Time: 0.151227]\n",
            "4891-4 [D loss: 0.694005, acc.: 40.38%] [G loss: 0.681556] [Time: 0.147752]\n",
            "4891-5 [D loss: 0.703981, acc.: 40.38%] [G loss: 0.690563] [Time: 0.151532]\n",
            "4891-6 [D loss: 0.687386, acc.: 48.08%] [G loss: 0.708529] [Time: 0.150883]\n",
            "4891-7 [D loss: 0.696098, acc.: 46.15%] [G loss: 0.686461] [Time: 0.152790]\n",
            "4891-8 [D loss: 0.699093, acc.: 48.08%] [G loss: 0.669274] [Time: 0.148775]\n",
            "4891 (test) [D loss: 1.125705, acc.: 48.08%] [G loss: 0.390248] [Time: 0.043613]\n",
            "4892-0 [D loss: 0.713580, acc.: 50.00%] [G loss: 0.705800] [Time: 0.147324]\n",
            "4892-1 [D loss: 0.696645, acc.: 50.00%] [G loss: 0.685700] [Time: 0.148873]\n",
            "4892-2 [D loss: 0.694001, acc.: 48.08%] [G loss: 0.687267] [Time: 0.149189]\n",
            "4892-3 [D loss: 0.706359, acc.: 44.23%] [G loss: 0.723542] [Time: 0.147596]\n",
            "4892-4 [D loss: 0.696939, acc.: 50.00%] [G loss: 0.695020] [Time: 0.147308]\n",
            "4892-5 [D loss: 0.697801, acc.: 48.08%] [G loss: 0.680535] [Time: 0.155091]\n",
            "4892-6 [D loss: 0.684169, acc.: 51.92%] [G loss: 0.712741] [Time: 0.150702]\n",
            "4892-7 [D loss: 0.700169, acc.: 48.08%] [G loss: 0.687290] [Time: 0.149568]\n",
            "4892-8 [D loss: 0.711625, acc.: 44.23%] [G loss: 0.689592] [Time: 0.148199]\n",
            "4892 (test) [D loss: 1.049759, acc.: 48.08%] [G loss: 0.444890] [Time: 0.044166]\n",
            "4893-0 [D loss: 0.695727, acc.: 42.31%] [G loss: 0.715595] [Time: 0.148479]\n",
            "4893-1 [D loss: 0.700162, acc.: 59.62%] [G loss: 0.676413] [Time: 0.153081]\n",
            "4893-2 [D loss: 0.706475, acc.: 38.46%] [G loss: 0.693848] [Time: 0.149230]\n",
            "4893-3 [D loss: 0.695973, acc.: 48.08%] [G loss: 0.705227] [Time: 0.148085]\n",
            "4893-4 [D loss: 0.683063, acc.: 50.00%] [G loss: 0.694119] [Time: 0.153928]\n",
            "4893-5 [D loss: 0.708613, acc.: 53.85%] [G loss: 0.704692] [Time: 0.149851]\n",
            "4893-6 [D loss: 0.682869, acc.: 46.15%] [G loss: 0.715523] [Time: 0.152487]\n",
            "4893-7 [D loss: 0.696098, acc.: 40.38%] [G loss: 0.705710] [Time: 0.148255]\n",
            "4893-8 [D loss: 0.707867, acc.: 40.38%] [G loss: 0.688719] [Time: 0.148812]\n",
            "4893 (test) [D loss: 0.988030, acc.: 46.15%] [G loss: 0.634893] [Time: 0.044405]\n",
            "4894-0 [D loss: 0.709453, acc.: 46.15%] [G loss: 0.732273] [Time: 0.147246]\n",
            "4894-1 [D loss: 0.697618, acc.: 46.15%] [G loss: 0.703286] [Time: 0.148001]\n",
            "4894-2 [D loss: 0.704180, acc.: 36.54%] [G loss: 0.683739] [Time: 0.149556]\n",
            "4894-3 [D loss: 0.702641, acc.: 50.00%] [G loss: 0.729648] [Time: 0.150668]\n",
            "4894-4 [D loss: 0.691113, acc.: 38.46%] [G loss: 0.689985] [Time: 0.148730]\n",
            "4894-5 [D loss: 0.691756, acc.: 44.23%] [G loss: 0.696970] [Time: 0.150031]\n",
            "4894-6 [D loss: 0.681160, acc.: 51.92%] [G loss: 0.712388] [Time: 0.150448]\n",
            "4894-7 [D loss: 0.706200, acc.: 38.46%] [G loss: 0.708079] [Time: 0.148713]\n",
            "4894-8 [D loss: 0.702710, acc.: 42.31%] [G loss: 0.673738] [Time: 0.148154]\n",
            "4894 (test) [D loss: 1.076043, acc.: 46.15%] [G loss: 0.533173] [Time: 0.044483]\n",
            "4895-0 [D loss: 0.695712, acc.: 44.23%] [G loss: 0.737596] [Time: 0.153180]\n",
            "4895-1 [D loss: 0.705398, acc.: 42.31%] [G loss: 0.683815] [Time: 0.148847]\n",
            "4895-2 [D loss: 0.689598, acc.: 46.15%] [G loss: 0.686373] [Time: 0.151134]\n",
            "4895-3 [D loss: 0.712753, acc.: 40.38%] [G loss: 0.715595] [Time: 0.149190]\n",
            "4895-4 [D loss: 0.700728, acc.: 34.62%] [G loss: 0.715375] [Time: 0.148731]\n",
            "4895-5 [D loss: 0.712308, acc.: 36.54%] [G loss: 0.705478] [Time: 0.148895]\n",
            "4895-6 [D loss: 0.700535, acc.: 44.23%] [G loss: 0.708505] [Time: 0.148577]\n",
            "4895-7 [D loss: 0.696814, acc.: 44.23%] [G loss: 0.698345] [Time: 0.149485]\n",
            "4895-8 [D loss: 0.705339, acc.: 40.38%] [G loss: 0.666161] [Time: 0.148266]\n",
            "4895 (test) [D loss: 0.993642, acc.: 48.08%] [G loss: 0.693084] [Time: 0.044271]\n",
            "4896-0 [D loss: 0.690273, acc.: 38.46%] [G loss: 0.724833] [Time: 0.149143]\n",
            "4896-1 [D loss: 0.698270, acc.: 40.38%] [G loss: 0.698819] [Time: 0.147782]\n",
            "4896-2 [D loss: 0.692541, acc.: 48.08%] [G loss: 0.673124] [Time: 0.147092]\n",
            "4896-3 [D loss: 0.715281, acc.: 40.38%] [G loss: 0.739309] [Time: 0.150057]\n",
            "4896-4 [D loss: 0.694900, acc.: 46.15%] [G loss: 0.703152] [Time: 0.146878]\n",
            "4896-5 [D loss: 0.704479, acc.: 42.31%] [G loss: 0.706888] [Time: 0.148337]\n",
            "4896-6 [D loss: 0.689413, acc.: 53.85%] [G loss: 0.701833] [Time: 0.149656]\n",
            "4896-7 [D loss: 0.700547, acc.: 44.23%] [G loss: 0.692821] [Time: 0.154306]\n",
            "4896-8 [D loss: 0.697580, acc.: 46.15%] [G loss: 0.677602] [Time: 0.149701]\n",
            "4896 (test) [D loss: 1.060280, acc.: 48.08%] [G loss: 0.544516] [Time: 0.044278]\n",
            "4897-0 [D loss: 0.701810, acc.: 30.77%] [G loss: 0.727884] [Time: 0.150324]\n",
            "4897-1 [D loss: 0.689597, acc.: 42.31%] [G loss: 0.707749] [Time: 0.149959]\n",
            "4897-2 [D loss: 0.686908, acc.: 48.08%] [G loss: 0.687287] [Time: 0.151200]\n",
            "4897-3 [D loss: 0.702323, acc.: 50.00%] [G loss: 0.706807] [Time: 0.151451]\n",
            "4897-4 [D loss: 0.699559, acc.: 40.38%] [G loss: 0.693989] [Time: 0.147511]\n",
            "4897-5 [D loss: 0.708982, acc.: 42.31%] [G loss: 0.687055] [Time: 0.147355]\n",
            "4897-6 [D loss: 0.701077, acc.: 44.23%] [G loss: 0.694585] [Time: 0.146767]\n",
            "4897-7 [D loss: 0.701182, acc.: 40.38%] [G loss: 0.692652] [Time: 0.147899]\n",
            "4897-8 [D loss: 0.696142, acc.: 51.92%] [G loss: 0.683675] [Time: 0.148339]\n",
            "4897 (test) [D loss: 1.088484, acc.: 48.08%] [G loss: 0.521327] [Time: 0.043943]\n",
            "4898-0 [D loss: 0.695307, acc.: 40.38%] [G loss: 0.705183] [Time: 0.150173]\n",
            "4898-1 [D loss: 0.707277, acc.: 42.31%] [G loss: 0.685089] [Time: 0.150285]\n",
            "4898-2 [D loss: 0.701170, acc.: 42.31%] [G loss: 0.687692] [Time: 0.147059]\n",
            "4898-3 [D loss: 0.701383, acc.: 48.08%] [G loss: 0.722835] [Time: 0.148324]\n",
            "4898-4 [D loss: 0.695672, acc.: 40.38%] [G loss: 0.663491] [Time: 0.147986]\n",
            "4898-5 [D loss: 0.698872, acc.: 40.38%] [G loss: 0.685247] [Time: 0.147676]\n",
            "4898-6 [D loss: 0.689654, acc.: 48.08%] [G loss: 0.699931] [Time: 0.147320]\n",
            "4898-7 [D loss: 0.699419, acc.: 42.31%] [G loss: 0.701547] [Time: 0.147553]\n",
            "4898-8 [D loss: 0.699517, acc.: 44.23%] [G loss: 0.683275] [Time: 0.149776]\n",
            "4898 (test) [D loss: 1.108318, acc.: 50.00%] [G loss: 0.459218] [Time: 0.044770]\n",
            "4899-0 [D loss: 0.697621, acc.: 40.38%] [G loss: 0.706484] [Time: 0.150982]\n",
            "4899-1 [D loss: 0.705647, acc.: 42.31%] [G loss: 0.682123] [Time: 0.148834]\n",
            "4899-2 [D loss: 0.699012, acc.: 44.23%] [G loss: 0.675400] [Time: 0.147353]\n",
            "4899-3 [D loss: 0.712372, acc.: 48.08%] [G loss: 0.705906] [Time: 0.149761]\n",
            "4899-4 [D loss: 0.693763, acc.: 44.23%] [G loss: 0.705282] [Time: 0.150544]\n",
            "4899-5 [D loss: 0.691411, acc.: 51.92%] [G loss: 0.697532] [Time: 0.151184]\n",
            "4899-6 [D loss: 0.705918, acc.: 40.38%] [G loss: 0.702130] [Time: 0.148828]\n",
            "4899-7 [D loss: 0.705659, acc.: 42.31%] [G loss: 0.694055] [Time: 0.149863]\n",
            "4899-8 [D loss: 0.723032, acc.: 44.23%] [G loss: 0.688653] [Time: 0.147953]\n",
            "4899 (test) [D loss: 1.016859, acc.: 46.15%] [G loss: 0.610004] [Time: 0.044193]\n",
            "4900-0 [D loss: 0.694710, acc.: 44.23%] [G loss: 0.742032] [Time: 0.150058]\n",
            "4900-1 [D loss: 0.695839, acc.: 42.31%] [G loss: 0.686566] [Time: 0.148583]\n",
            "4900-2 [D loss: 0.712801, acc.: 40.38%] [G loss: 0.701927] [Time: 0.149942]\n",
            "4900-3 [D loss: 0.705742, acc.: 32.69%] [G loss: 0.721998] [Time: 0.147979]\n",
            "4900-4 [D loss: 0.688290, acc.: 46.15%] [G loss: 0.707762] [Time: 0.150113]\n",
            "4900-5 [D loss: 0.704647, acc.: 38.46%] [G loss: 0.706772] [Time: 0.150275]\n",
            "4900-6 [D loss: 0.686564, acc.: 48.08%] [G loss: 0.694153] [Time: 0.148365]\n",
            "4900-7 [D loss: 0.698203, acc.: 46.15%] [G loss: 0.698234] [Time: 0.149970]\n",
            "4900-8 [D loss: 0.711362, acc.: 44.23%] [G loss: 0.693072] [Time: 0.148610]\n",
            "4900 (test) [D loss: 1.092499, acc.: 50.00%] [G loss: 0.497880] [Time: 0.044255]\n",
            "4901-0 [D loss: 0.701687, acc.: 40.38%] [G loss: 0.737513] [Time: 0.149741]\n",
            "4901-1 [D loss: 0.703447, acc.: 40.38%] [G loss: 0.685996] [Time: 0.151184]\n",
            "4901-2 [D loss: 0.698311, acc.: 40.38%] [G loss: 0.677087] [Time: 0.150872]\n",
            "4901-3 [D loss: 0.705853, acc.: 38.46%] [G loss: 0.748870] [Time: 0.148621]\n",
            "4901-4 [D loss: 0.680026, acc.: 51.92%] [G loss: 0.709548] [Time: 0.149008]\n",
            "4901-5 [D loss: 0.713442, acc.: 36.54%] [G loss: 0.691192] [Time: 0.149726]\n",
            "4901-6 [D loss: 0.697357, acc.: 48.08%] [G loss: 0.691276] [Time: 0.152994]\n",
            "4901-7 [D loss: 0.710610, acc.: 44.23%] [G loss: 0.703954] [Time: 0.148213]\n",
            "4901-8 [D loss: 0.716613, acc.: 30.77%] [G loss: 0.670268] [Time: 0.150748]\n",
            "4901 (test) [D loss: 1.023768, acc.: 46.15%] [G loss: 0.582309] [Time: 0.043571]\n",
            "4902-0 [D loss: 0.698783, acc.: 44.23%] [G loss: 0.734991] [Time: 0.146618]\n",
            "4902-1 [D loss: 0.708324, acc.: 44.23%] [G loss: 0.694347] [Time: 0.148129]\n",
            "4902-2 [D loss: 0.696432, acc.: 44.23%] [G loss: 0.684950] [Time: 0.148343]\n",
            "4902-3 [D loss: 0.701008, acc.: 48.08%] [G loss: 0.732963] [Time: 0.147246]\n",
            "4902-4 [D loss: 0.685134, acc.: 46.15%] [G loss: 0.714205] [Time: 0.151494]\n",
            "4902-5 [D loss: 0.707238, acc.: 34.62%] [G loss: 0.697087] [Time: 0.148745]\n",
            "4902-6 [D loss: 0.693755, acc.: 46.15%] [G loss: 0.698912] [Time: 0.148940]\n",
            "4902-7 [D loss: 0.702345, acc.: 48.08%] [G loss: 0.703402] [Time: 0.148835]\n",
            "4902-8 [D loss: 0.697594, acc.: 40.38%] [G loss: 0.694747] [Time: 0.150707]\n",
            "4902 (test) [D loss: 1.031356, acc.: 48.08%] [G loss: 0.568190] [Time: 0.043348]\n",
            "4903-0 [D loss: 0.693739, acc.: 46.15%] [G loss: 0.744192] [Time: 0.149762]\n",
            "4903-1 [D loss: 0.701755, acc.: 38.46%] [G loss: 0.689881] [Time: 0.149625]\n",
            "4903-2 [D loss: 0.703480, acc.: 48.08%] [G loss: 0.682025] [Time: 0.148899]\n",
            "4903-3 [D loss: 0.696182, acc.: 48.08%] [G loss: 0.713142] [Time: 0.146893]\n",
            "4903-4 [D loss: 0.684729, acc.: 44.23%] [G loss: 0.691728] [Time: 0.155549]\n",
            "4903-5 [D loss: 0.719125, acc.: 40.38%] [G loss: 0.702888] [Time: 0.148645]\n",
            "4903-6 [D loss: 0.679905, acc.: 51.92%] [G loss: 0.707590] [Time: 0.151689]\n",
            "4903-7 [D loss: 0.702230, acc.: 40.38%] [G loss: 0.708113] [Time: 0.155997]\n",
            "4903-8 [D loss: 0.703497, acc.: 51.92%] [G loss: 0.699615] [Time: 0.151773]\n",
            "4903 (test) [D loss: 1.047562, acc.: 50.00%] [G loss: 0.587966] [Time: 0.045702]\n",
            "4904-0 [D loss: 0.710698, acc.: 38.46%] [G loss: 0.731480] [Time: 0.152372]\n",
            "4904-1 [D loss: 0.703825, acc.: 44.23%] [G loss: 0.697577] [Time: 0.151217]\n",
            "4904-2 [D loss: 0.696802, acc.: 40.38%] [G loss: 0.694915] [Time: 0.150358]\n",
            "4904-3 [D loss: 0.726036, acc.: 48.08%] [G loss: 0.707456] [Time: 0.150298]\n",
            "4904-4 [D loss: 0.687526, acc.: 48.08%] [G loss: 0.713724] [Time: 0.148320]\n",
            "4904-5 [D loss: 0.709207, acc.: 30.77%] [G loss: 0.681607] [Time: 0.148407]\n",
            "4904-6 [D loss: 0.692614, acc.: 51.92%] [G loss: 0.709516] [Time: 0.149599]\n",
            "4904-7 [D loss: 0.696124, acc.: 44.23%] [G loss: 0.698867] [Time: 0.152665]\n",
            "4904-8 [D loss: 0.702152, acc.: 44.23%] [G loss: 0.694146] [Time: 0.147265]\n",
            "4904 (test) [D loss: 1.112663, acc.: 50.00%] [G loss: 0.469218] [Time: 0.043863]\n",
            "4905-0 [D loss: 0.697533, acc.: 34.62%] [G loss: 0.720413] [Time: 0.150787]\n",
            "4905-1 [D loss: 0.709359, acc.: 38.46%] [G loss: 0.690078] [Time: 0.147551]\n",
            "4905-2 [D loss: 0.702739, acc.: 40.38%] [G loss: 0.708769] [Time: 0.149410]\n",
            "4905-3 [D loss: 0.705724, acc.: 44.23%] [G loss: 0.714472] [Time: 0.147782]\n",
            "4905-4 [D loss: 0.686430, acc.: 40.38%] [G loss: 0.687009] [Time: 0.148012]\n",
            "4905-5 [D loss: 0.707201, acc.: 40.38%] [G loss: 0.687439] [Time: 0.147441]\n",
            "4905-6 [D loss: 0.685625, acc.: 48.08%] [G loss: 0.695544] [Time: 0.149430]\n",
            "4905-7 [D loss: 0.711005, acc.: 48.08%] [G loss: 0.693626] [Time: 0.149591]\n",
            "4905-8 [D loss: 0.693513, acc.: 44.23%] [G loss: 0.692936] [Time: 0.151800]\n",
            "4905 (test) [D loss: 1.024278, acc.: 48.08%] [G loss: 0.580555] [Time: 0.044453]\n",
            "4906-0 [D loss: 0.696908, acc.: 44.23%] [G loss: 0.715802] [Time: 0.148031]\n",
            "4906-1 [D loss: 0.704412, acc.: 42.31%] [G loss: 0.695153] [Time: 0.147862]\n",
            "4906-2 [D loss: 0.693582, acc.: 48.08%] [G loss: 0.690790] [Time: 0.147163]\n",
            "4906-3 [D loss: 0.691804, acc.: 50.00%] [G loss: 0.721490] [Time: 0.148168]\n",
            "4906-4 [D loss: 0.692482, acc.: 48.08%] [G loss: 0.710380] [Time: 0.147180]\n",
            "4906-5 [D loss: 0.703748, acc.: 44.23%] [G loss: 0.694708] [Time: 0.148306]\n",
            "4906-6 [D loss: 0.691266, acc.: 53.85%] [G loss: 0.690439] [Time: 0.148871]\n",
            "4906-7 [D loss: 0.700176, acc.: 46.15%] [G loss: 0.700013] [Time: 0.147176]\n",
            "4906-8 [D loss: 0.701689, acc.: 36.54%] [G loss: 0.683215] [Time: 0.151247]\n",
            "4906 (test) [D loss: 1.018469, acc.: 48.08%] [G loss: 0.585660] [Time: 0.044523]\n",
            "4907-0 [D loss: 0.706839, acc.: 46.15%] [G loss: 0.697092] [Time: 0.154395]\n",
            "4907-1 [D loss: 0.712763, acc.: 42.31%] [G loss: 0.703042] [Time: 0.150275]\n",
            "4907-2 [D loss: 0.702002, acc.: 46.15%] [G loss: 0.683388] [Time: 0.150178]\n",
            "4907-3 [D loss: 0.705350, acc.: 51.92%] [G loss: 0.724429] [Time: 0.160528]\n",
            "4907-4 [D loss: 0.698671, acc.: 48.08%] [G loss: 0.701588] [Time: 0.152864]\n",
            "4907-5 [D loss: 0.705447, acc.: 48.08%] [G loss: 0.675274] [Time: 0.150100]\n",
            "4907-6 [D loss: 0.693586, acc.: 44.23%] [G loss: 0.697663] [Time: 0.149988]\n",
            "4907-7 [D loss: 0.705634, acc.: 28.85%] [G loss: 0.704640] [Time: 0.150527]\n",
            "4907-8 [D loss: 0.696571, acc.: 55.77%] [G loss: 0.693889] [Time: 0.148540]\n",
            "4907 (test) [D loss: 1.106746, acc.: 50.00%] [G loss: 0.456116] [Time: 0.043284]\n",
            "4908-0 [D loss: 0.695599, acc.: 46.15%] [G loss: 0.700121] [Time: 0.148936]\n",
            "4908-1 [D loss: 0.696312, acc.: 46.15%] [G loss: 0.692567] [Time: 0.151463]\n",
            "4908-2 [D loss: 0.706281, acc.: 44.23%] [G loss: 0.677563] [Time: 0.150073]\n",
            "4908-3 [D loss: 0.706446, acc.: 36.54%] [G loss: 0.727608] [Time: 0.147904]\n",
            "4908-4 [D loss: 0.682513, acc.: 48.08%] [G loss: 0.670463] [Time: 0.149571]\n",
            "4908-5 [D loss: 0.694899, acc.: 50.00%] [G loss: 0.688084] [Time: 0.148907]\n",
            "4908-6 [D loss: 0.691973, acc.: 48.08%] [G loss: 0.710988] [Time: 0.152042]\n",
            "4908-7 [D loss: 0.705837, acc.: 44.23%] [G loss: 0.696968] [Time: 0.150653]\n",
            "4908-8 [D loss: 0.688343, acc.: 51.92%] [G loss: 0.690270] [Time: 0.149851]\n",
            "4908 (test) [D loss: 1.040291, acc.: 50.00%] [G loss: 0.493009] [Time: 0.047482]\n",
            "4909-0 [D loss: 0.685342, acc.: 46.15%] [G loss: 0.719490] [Time: 0.148764]\n",
            "4909-1 [D loss: 0.696816, acc.: 51.92%] [G loss: 0.687429] [Time: 0.149178]\n",
            "4909-2 [D loss: 0.708455, acc.: 38.46%] [G loss: 0.693000] [Time: 0.147817]\n",
            "4909-3 [D loss: 0.704259, acc.: 40.38%] [G loss: 0.714927] [Time: 0.150428]\n",
            "4909-4 [D loss: 0.693594, acc.: 48.08%] [G loss: 0.698978] [Time: 0.151949]\n",
            "4909-5 [D loss: 0.703475, acc.: 40.38%] [G loss: 0.715324] [Time: 0.148046]\n",
            "4909-6 [D loss: 0.708579, acc.: 44.23%] [G loss: 0.691517] [Time: 0.148900]\n",
            "4909-7 [D loss: 0.703423, acc.: 40.38%] [G loss: 0.698809] [Time: 0.152371]\n",
            "4909-8 [D loss: 0.702661, acc.: 44.23%] [G loss: 0.691325] [Time: 0.150830]\n",
            "4909 (test) [D loss: 1.089232, acc.: 50.00%] [G loss: 0.491125] [Time: 0.044491]\n",
            "4910-0 [D loss: 0.704457, acc.: 30.77%] [G loss: 0.712280] [Time: 0.147586]\n",
            "4910-1 [D loss: 0.702041, acc.: 44.23%] [G loss: 0.709335] [Time: 0.151353]\n",
            "4910-2 [D loss: 0.701207, acc.: 42.31%] [G loss: 0.680943] [Time: 0.147149]\n",
            "4910-3 [D loss: 0.693918, acc.: 42.31%] [G loss: 0.720895] [Time: 0.149021]\n",
            "4910-4 [D loss: 0.704205, acc.: 36.54%] [G loss: 0.714929] [Time: 0.147734]\n",
            "4910-5 [D loss: 0.699093, acc.: 48.08%] [G loss: 0.710061] [Time: 0.148412]\n",
            "4910-6 [D loss: 0.691300, acc.: 53.85%] [G loss: 0.722678] [Time: 0.150773]\n",
            "4910-7 [D loss: 0.691240, acc.: 51.92%] [G loss: 0.704305] [Time: 0.149879]\n",
            "4910-8 [D loss: 0.694947, acc.: 48.08%] [G loss: 0.702521] [Time: 0.149669]\n",
            "4910 (test) [D loss: 0.962684, acc.: 48.08%] [G loss: 0.720662] [Time: 0.045329]\n",
            "4911-0 [D loss: 0.696035, acc.: 44.23%] [G loss: 0.719846] [Time: 0.149110]\n",
            "4911-1 [D loss: 0.704607, acc.: 42.31%] [G loss: 0.700290] [Time: 0.150576]\n",
            "4911-2 [D loss: 0.696384, acc.: 40.38%] [G loss: 0.706008] [Time: 0.152396]\n",
            "4911-3 [D loss: 0.699506, acc.: 42.31%] [G loss: 0.722819] [Time: 0.151143]\n",
            "4911-4 [D loss: 0.668404, acc.: 53.85%] [G loss: 0.715739] [Time: 0.147868]\n",
            "4911-5 [D loss: 0.711751, acc.: 42.31%] [G loss: 0.698397] [Time: 0.149031]\n",
            "4911-6 [D loss: 0.702718, acc.: 42.31%] [G loss: 0.701857] [Time: 0.148411]\n",
            "4911-7 [D loss: 0.716433, acc.: 40.38%] [G loss: 0.701101] [Time: 0.147688]\n",
            "4911-8 [D loss: 0.705042, acc.: 32.69%] [G loss: 0.705859] [Time: 0.147185]\n",
            "4911 (test) [D loss: 1.013746, acc.: 48.08%] [G loss: 0.635679] [Time: 0.043861]\n",
            "4912-0 [D loss: 0.694818, acc.: 30.77%] [G loss: 0.738693] [Time: 0.152062]\n",
            "4912-1 [D loss: 0.696989, acc.: 42.31%] [G loss: 0.703613] [Time: 0.147912]\n",
            "4912-2 [D loss: 0.694800, acc.: 48.08%] [G loss: 0.691689] [Time: 0.148973]\n",
            "4912-3 [D loss: 0.694489, acc.: 51.92%] [G loss: 0.705749] [Time: 0.147743]\n",
            "4912-4 [D loss: 0.687409, acc.: 44.23%] [G loss: 0.697503] [Time: 0.150116]\n",
            "4912-5 [D loss: 0.691322, acc.: 50.00%] [G loss: 0.709064] [Time: 0.150327]\n",
            "4912-6 [D loss: 0.694130, acc.: 48.08%] [G loss: 0.711093] [Time: 0.149599]\n",
            "4912-7 [D loss: 0.707970, acc.: 46.15%] [G loss: 0.697666] [Time: 0.151562]\n",
            "4912-8 [D loss: 0.712225, acc.: 34.62%] [G loss: 0.692354] [Time: 0.151537]\n",
            "4912 (test) [D loss: 1.051526, acc.: 46.15%] [G loss: 0.586188] [Time: 0.045647]\n",
            "4913-0 [D loss: 0.707069, acc.: 36.54%] [G loss: 0.725964] [Time: 0.149733]\n",
            "4913-1 [D loss: 0.697821, acc.: 40.38%] [G loss: 0.689293] [Time: 0.150200]\n",
            "4913-2 [D loss: 0.693717, acc.: 46.15%] [G loss: 0.686976] [Time: 0.152124]\n",
            "4913-3 [D loss: 0.699568, acc.: 44.23%] [G loss: 0.724912] [Time: 0.149527]\n",
            "4913-4 [D loss: 0.687746, acc.: 44.23%] [G loss: 0.705097] [Time: 0.147568]\n",
            "4913-5 [D loss: 0.702648, acc.: 30.77%] [G loss: 0.711020] [Time: 0.148617]\n",
            "4913-6 [D loss: 0.695923, acc.: 51.92%] [G loss: 0.711739] [Time: 0.151195]\n",
            "4913-7 [D loss: 0.701436, acc.: 46.15%] [G loss: 0.701712] [Time: 0.150020]\n",
            "4913-8 [D loss: 0.685499, acc.: 53.85%] [G loss: 0.684275] [Time: 0.149983]\n",
            "4913 (test) [D loss: 1.078096, acc.: 46.15%] [G loss: 0.528395] [Time: 0.043827]\n",
            "4914-0 [D loss: 0.699964, acc.: 40.38%] [G loss: 0.712245] [Time: 0.147527]\n",
            "4914-1 [D loss: 0.702871, acc.: 44.23%] [G loss: 0.690359] [Time: 0.147880]\n",
            "4914-2 [D loss: 0.700261, acc.: 46.15%] [G loss: 0.680598] [Time: 0.149151]\n",
            "4914-3 [D loss: 0.701159, acc.: 55.77%] [G loss: 0.703336] [Time: 0.148768]\n",
            "4914-4 [D loss: 0.678154, acc.: 44.23%] [G loss: 0.729439] [Time: 0.149659]\n",
            "4914-5 [D loss: 0.706790, acc.: 46.15%] [G loss: 0.702588] [Time: 0.149631]\n",
            "4914-6 [D loss: 0.696704, acc.: 42.31%] [G loss: 0.696129] [Time: 0.149146]\n",
            "4914-7 [D loss: 0.688377, acc.: 50.00%] [G loss: 0.698500] [Time: 0.146749]\n",
            "4914-8 [D loss: 0.710120, acc.: 36.54%] [G loss: 0.687144] [Time: 0.149042]\n",
            "4914 (test) [D loss: 0.975191, acc.: 48.08%] [G loss: 0.604956] [Time: 0.047307]\n",
            "4915-0 [D loss: 0.688707, acc.: 51.92%] [G loss: 0.729462] [Time: 0.146852]\n",
            "4915-1 [D loss: 0.704433, acc.: 50.00%] [G loss: 0.698395] [Time: 0.150562]\n",
            "4915-2 [D loss: 0.692521, acc.: 36.54%] [G loss: 0.700037] [Time: 0.147934]\n",
            "4915-3 [D loss: 0.710120, acc.: 28.85%] [G loss: 0.702442] [Time: 0.147021]\n",
            "4915-4 [D loss: 0.702100, acc.: 46.15%] [G loss: 0.703870] [Time: 0.149382]\n",
            "4915-5 [D loss: 0.709142, acc.: 42.31%] [G loss: 0.691115] [Time: 0.150959]\n",
            "4915-6 [D loss: 0.694569, acc.: 51.92%] [G loss: 0.711214] [Time: 0.148323]\n",
            "4915-7 [D loss: 0.696853, acc.: 46.15%] [G loss: 0.687530] [Time: 0.148382]\n",
            "4915-8 [D loss: 0.704082, acc.: 40.38%] [G loss: 0.677732] [Time: 0.147238]\n",
            "4915 (test) [D loss: 1.025233, acc.: 46.15%] [G loss: 0.564665] [Time: 0.043849]\n",
            "4916-0 [D loss: 0.689000, acc.: 36.54%] [G loss: 0.719986] [Time: 0.147191]\n",
            "4916-1 [D loss: 0.691358, acc.: 44.23%] [G loss: 0.680460] [Time: 0.150887]\n",
            "4916-2 [D loss: 0.719717, acc.: 46.15%] [G loss: 0.696584] [Time: 0.147199]\n",
            "4916-3 [D loss: 0.712283, acc.: 32.69%] [G loss: 0.701361] [Time: 0.147896]\n",
            "4916-4 [D loss: 0.673594, acc.: 53.85%] [G loss: 0.679353] [Time: 0.150654]\n",
            "4916-5 [D loss: 0.712132, acc.: 42.31%] [G loss: 0.705986] [Time: 0.149056]\n",
            "4916-6 [D loss: 0.696064, acc.: 50.00%] [G loss: 0.680795] [Time: 0.147903]\n",
            "4916-7 [D loss: 0.704229, acc.: 46.15%] [G loss: 0.692060] [Time: 0.149485]\n",
            "4916-8 [D loss: 0.708502, acc.: 48.08%] [G loss: 0.661658] [Time: 0.151007]\n",
            "4916 (test) [D loss: 1.085972, acc.: 46.15%] [G loss: 0.518633] [Time: 0.044795]\n",
            "4917-0 [D loss: 0.707043, acc.: 25.00%] [G loss: 0.714636] [Time: 0.148749]\n",
            "4917-1 [D loss: 0.688786, acc.: 42.31%] [G loss: 0.691799] [Time: 0.147753]\n",
            "4917-2 [D loss: 0.706684, acc.: 46.15%] [G loss: 0.682588] [Time: 0.147228]\n",
            "4917-3 [D loss: 0.703382, acc.: 50.00%] [G loss: 0.719630] [Time: 0.147958]\n",
            "4917-4 [D loss: 0.689223, acc.: 40.38%] [G loss: 0.686021] [Time: 0.148485]\n",
            "4917-5 [D loss: 0.704920, acc.: 42.31%] [G loss: 0.701672] [Time: 0.149457]\n",
            "4917-6 [D loss: 0.688229, acc.: 44.23%] [G loss: 0.702926] [Time: 0.152744]\n",
            "4917-7 [D loss: 0.704561, acc.: 38.46%] [G loss: 0.705541] [Time: 0.148717]\n",
            "4917-8 [D loss: 0.705463, acc.: 38.46%] [G loss: 0.697568] [Time: 0.149885]\n",
            "4917 (test) [D loss: 0.990268, acc.: 50.00%] [G loss: 0.619610] [Time: 0.045317]\n",
            "4918-0 [D loss: 0.701646, acc.: 36.54%] [G loss: 0.722006] [Time: 0.147155]\n",
            "4918-1 [D loss: 0.690141, acc.: 51.92%] [G loss: 0.701238] [Time: 0.148616]\n",
            "4918-2 [D loss: 0.711464, acc.: 36.54%] [G loss: 0.695586] [Time: 0.148073]\n",
            "4918-3 [D loss: 0.703087, acc.: 50.00%] [G loss: 0.726251] [Time: 0.148460]\n",
            "4918-4 [D loss: 0.683597, acc.: 46.15%] [G loss: 0.692985] [Time: 0.151639]\n",
            "4918-5 [D loss: 0.708042, acc.: 44.23%] [G loss: 0.705810] [Time: 0.148314]\n",
            "4918-6 [D loss: 0.694676, acc.: 44.23%] [G loss: 0.727424] [Time: 0.149913]\n",
            "4918-7 [D loss: 0.694781, acc.: 38.46%] [G loss: 0.710792] [Time: 0.148717]\n",
            "4918-8 [D loss: 0.714684, acc.: 30.77%] [G loss: 0.685027] [Time: 0.149811]\n",
            "4918 (test) [D loss: 0.946104, acc.: 51.92%] [G loss: 0.695171] [Time: 0.048539]\n",
            "4919-0 [D loss: 0.691451, acc.: 46.15%] [G loss: 0.704517] [Time: 0.149953]\n",
            "4919-1 [D loss: 0.699164, acc.: 36.54%] [G loss: 0.702854] [Time: 0.150322]\n",
            "4919-2 [D loss: 0.710431, acc.: 34.62%] [G loss: 0.693920] [Time: 0.153691]\n",
            "4919-3 [D loss: 0.719654, acc.: 48.08%] [G loss: 0.711363] [Time: 0.148757]\n",
            "4919-4 [D loss: 0.689531, acc.: 46.15%] [G loss: 0.701641] [Time: 0.147635]\n",
            "4919-5 [D loss: 0.712350, acc.: 42.31%] [G loss: 0.681278] [Time: 0.147644]\n",
            "4919-6 [D loss: 0.681503, acc.: 55.77%] [G loss: 0.720004] [Time: 0.151656]\n",
            "4919-7 [D loss: 0.697715, acc.: 48.08%] [G loss: 0.688562] [Time: 0.148257]\n",
            "4919-8 [D loss: 0.693512, acc.: 44.23%] [G loss: 0.693129] [Time: 0.149345]\n",
            "4919 (test) [D loss: 1.120784, acc.: 48.08%] [G loss: 0.457571] [Time: 0.044291]\n",
            "4920-0 [D loss: 0.689355, acc.: 40.38%] [G loss: 0.720968] [Time: 0.147570]\n",
            "4920-1 [D loss: 0.701212, acc.: 34.62%] [G loss: 0.701293] [Time: 0.148312]\n",
            "4920-2 [D loss: 0.702472, acc.: 38.46%] [G loss: 0.684935] [Time: 0.150741]\n",
            "4920-3 [D loss: 0.691800, acc.: 44.23%] [G loss: 0.709418] [Time: 0.150813]\n",
            "4920-4 [D loss: 0.674361, acc.: 59.62%] [G loss: 0.709425] [Time: 0.148428]\n",
            "4920-5 [D loss: 0.708928, acc.: 48.08%] [G loss: 0.692426] [Time: 0.148027]\n",
            "4920-6 [D loss: 0.684810, acc.: 48.08%] [G loss: 0.708989] [Time: 0.147870]\n",
            "4920-7 [D loss: 0.703565, acc.: 34.62%] [G loss: 0.682426] [Time: 0.147684]\n",
            "4920-8 [D loss: 0.716587, acc.: 42.31%] [G loss: 0.695892] [Time: 0.147943]\n",
            "4920 (test) [D loss: 1.013260, acc.: 48.08%] [G loss: 0.538632] [Time: 0.047999]\n",
            "4921-0 [D loss: 0.698995, acc.: 38.46%] [G loss: 0.710962] [Time: 0.149903]\n",
            "4921-1 [D loss: 0.704898, acc.: 44.23%] [G loss: 0.700766] [Time: 0.150315]\n",
            "4921-2 [D loss: 0.693793, acc.: 44.23%] [G loss: 0.676159] [Time: 0.148620]\n",
            "4921-3 [D loss: 0.703846, acc.: 36.54%] [G loss: 0.708429] [Time: 0.148737]\n",
            "4921-4 [D loss: 0.684407, acc.: 46.15%] [G loss: 0.706428] [Time: 0.147079]\n",
            "4921-5 [D loss: 0.706363, acc.: 42.31%] [G loss: 0.673017] [Time: 0.149482]\n",
            "4921-6 [D loss: 0.690694, acc.: 50.00%] [G loss: 0.697729] [Time: 0.150135]\n",
            "4921-7 [D loss: 0.706096, acc.: 42.31%] [G loss: 0.704428] [Time: 0.148172]\n",
            "4921-8 [D loss: 0.698236, acc.: 42.31%] [G loss: 0.674536] [Time: 0.148530]\n",
            "4921 (test) [D loss: 1.079596, acc.: 50.00%] [G loss: 0.458340] [Time: 0.046160]\n",
            "4922-0 [D loss: 0.693057, acc.: 44.23%] [G loss: 0.693455] [Time: 0.149334]\n",
            "4922-1 [D loss: 0.694713, acc.: 51.92%] [G loss: 0.687368] [Time: 0.147342]\n",
            "4922-2 [D loss: 0.698318, acc.: 53.85%] [G loss: 0.699967] [Time: 0.148013]\n",
            "4922-3 [D loss: 0.703306, acc.: 38.46%] [G loss: 0.704125] [Time: 0.147737]\n",
            "4922-4 [D loss: 0.691233, acc.: 44.23%] [G loss: 0.713167] [Time: 0.149147]\n",
            "4922-5 [D loss: 0.699839, acc.: 40.38%] [G loss: 0.688048] [Time: 0.147630]\n",
            "4922-6 [D loss: 0.696949, acc.: 42.31%] [G loss: 0.714190] [Time: 0.151176]\n",
            "4922-7 [D loss: 0.701995, acc.: 36.54%] [G loss: 0.703854] [Time: 0.148519]\n",
            "4922-8 [D loss: 0.703287, acc.: 46.15%] [G loss: 0.685311] [Time: 0.154418]\n",
            "4922 (test) [D loss: 1.043367, acc.: 50.00%] [G loss: 0.516579] [Time: 0.045717]\n",
            "4923-0 [D loss: 0.701438, acc.: 36.54%] [G loss: 0.712772] [Time: 0.153194]\n",
            "4923-1 [D loss: 0.702774, acc.: 44.23%] [G loss: 0.700623] [Time: 0.147331]\n",
            "4923-2 [D loss: 0.702365, acc.: 38.46%] [G loss: 0.700945] [Time: 0.149508]\n",
            "4923-3 [D loss: 0.701651, acc.: 51.92%] [G loss: 0.718919] [Time: 0.150902]\n",
            "4923-4 [D loss: 0.684418, acc.: 42.31%] [G loss: 0.702717] [Time: 0.149662]\n",
            "4923-5 [D loss: 0.712889, acc.: 34.62%] [G loss: 0.678579] [Time: 0.147919]\n",
            "4923-6 [D loss: 0.698261, acc.: 38.46%] [G loss: 0.694551] [Time: 0.151556]\n",
            "4923-7 [D loss: 0.699613, acc.: 38.46%] [G loss: 0.687404] [Time: 0.147399]\n",
            "4923-8 [D loss: 0.701602, acc.: 42.31%] [G loss: 0.695014] [Time: 0.148578]\n",
            "4923 (test) [D loss: 1.091585, acc.: 50.00%] [G loss: 0.450859] [Time: 0.044533]\n",
            "4924-0 [D loss: 0.692369, acc.: 38.46%] [G loss: 0.721726] [Time: 0.147717]\n",
            "4924-1 [D loss: 0.706308, acc.: 42.31%] [G loss: 0.708373] [Time: 0.150736]\n",
            "4924-2 [D loss: 0.707225, acc.: 36.54%] [G loss: 0.704535] [Time: 0.150225]\n",
            "4924-3 [D loss: 0.710510, acc.: 34.62%] [G loss: 0.721030] [Time: 0.149156]\n",
            "4924-4 [D loss: 0.685678, acc.: 42.31%] [G loss: 0.710362] [Time: 0.149245]\n",
            "4924-5 [D loss: 0.711958, acc.: 28.85%] [G loss: 0.680049] [Time: 0.148312]\n",
            "4924-6 [D loss: 0.686870, acc.: 50.00%] [G loss: 0.719846] [Time: 0.149874]\n",
            "4924-7 [D loss: 0.695382, acc.: 55.77%] [G loss: 0.708254] [Time: 0.149751]\n",
            "4924-8 [D loss: 0.710537, acc.: 28.85%] [G loss: 0.719325] [Time: 0.149309]\n",
            "4924 (test) [D loss: 1.000004, acc.: 48.08%] [G loss: 0.589209] [Time: 0.044319]\n",
            "4925-0 [D loss: 0.688656, acc.: 48.08%] [G loss: 0.719950] [Time: 0.150593]\n",
            "4925-1 [D loss: 0.698224, acc.: 42.31%] [G loss: 0.699950] [Time: 0.151752]\n",
            "4925-2 [D loss: 0.701752, acc.: 38.46%] [G loss: 0.688433] [Time: 0.148328]\n",
            "4925-3 [D loss: 0.706994, acc.: 42.31%] [G loss: 0.709756] [Time: 0.149604]\n",
            "4925-4 [D loss: 0.686277, acc.: 44.23%] [G loss: 0.697511] [Time: 0.151383]\n",
            "4925-5 [D loss: 0.697924, acc.: 36.54%] [G loss: 0.706325] [Time: 0.148970]\n",
            "4925-6 [D loss: 0.682199, acc.: 53.85%] [G loss: 0.692770] [Time: 0.150226]\n",
            "4925-7 [D loss: 0.701990, acc.: 36.54%] [G loss: 0.693217] [Time: 0.148372]\n",
            "4925-8 [D loss: 0.689569, acc.: 34.62%] [G loss: 0.714264] [Time: 0.147965]\n",
            "4925 (test) [D loss: 0.993481, acc.: 48.08%] [G loss: 0.673663] [Time: 0.043931]\n",
            "4926-0 [D loss: 0.708025, acc.: 30.77%] [G loss: 0.750615] [Time: 0.148623]\n",
            "4926-1 [D loss: 0.695561, acc.: 51.92%] [G loss: 0.701473] [Time: 0.148976]\n",
            "4926-2 [D loss: 0.701028, acc.: 34.62%] [G loss: 0.695947] [Time: 0.146793]\n",
            "4926-3 [D loss: 0.707645, acc.: 40.38%] [G loss: 0.714060] [Time: 0.148810]\n",
            "4926-4 [D loss: 0.699178, acc.: 34.62%] [G loss: 0.706152] [Time: 0.149144]\n",
            "4926-5 [D loss: 0.724185, acc.: 26.92%] [G loss: 0.718414] [Time: 0.153892]\n",
            "4926-6 [D loss: 0.690699, acc.: 51.92%] [G loss: 0.699836] [Time: 0.147624]\n",
            "4926-7 [D loss: 0.695677, acc.: 38.46%] [G loss: 0.698045] [Time: 0.150956]\n",
            "4926-8 [D loss: 0.711812, acc.: 42.31%] [G loss: 0.690415] [Time: 0.149206]\n",
            "4926 (test) [D loss: 1.060714, acc.: 48.08%] [G loss: 0.533955] [Time: 0.047364]\n",
            "4927-0 [D loss: 0.693719, acc.: 34.62%] [G loss: 0.729492] [Time: 0.149291]\n",
            "4927-1 [D loss: 0.704369, acc.: 46.15%] [G loss: 0.686286] [Time: 0.149634]\n",
            "4927-2 [D loss: 0.700609, acc.: 50.00%] [G loss: 0.698212] [Time: 0.149140]\n",
            "4927-3 [D loss: 0.695044, acc.: 40.38%] [G loss: 0.720647] [Time: 0.148056]\n",
            "4927-4 [D loss: 0.695979, acc.: 42.31%] [G loss: 0.714738] [Time: 0.147127]\n",
            "4927-5 [D loss: 0.693051, acc.: 50.00%] [G loss: 0.697815] [Time: 0.148604]\n",
            "4927-6 [D loss: 0.685082, acc.: 51.92%] [G loss: 0.690954] [Time: 0.154063]\n",
            "4927-7 [D loss: 0.701877, acc.: 46.15%] [G loss: 0.678053] [Time: 0.147660]\n",
            "4927-8 [D loss: 0.697561, acc.: 46.15%] [G loss: 0.694608] [Time: 0.147408]\n",
            "4927 (test) [D loss: 1.019200, acc.: 48.08%] [G loss: 0.521724] [Time: 0.044133]\n",
            "4928-0 [D loss: 0.692685, acc.: 36.54%] [G loss: 0.737440] [Time: 0.149292]\n",
            "4928-1 [D loss: 0.698197, acc.: 36.54%] [G loss: 0.696742] [Time: 0.147709]\n",
            "4928-2 [D loss: 0.695707, acc.: 44.23%] [G loss: 0.694264] [Time: 0.148579]\n",
            "4928-3 [D loss: 0.717069, acc.: 34.62%] [G loss: 0.711186] [Time: 0.150656]\n",
            "4928-4 [D loss: 0.693338, acc.: 42.31%] [G loss: 0.682012] [Time: 0.149216]\n",
            "4928-5 [D loss: 0.715555, acc.: 32.69%] [G loss: 0.687726] [Time: 0.148589]\n",
            "4928-6 [D loss: 0.679927, acc.: 57.69%] [G loss: 0.707772] [Time: 0.147153]\n",
            "4928-7 [D loss: 0.702948, acc.: 46.15%] [G loss: 0.690182] [Time: 0.148476]\n",
            "4928-8 [D loss: 0.725996, acc.: 55.77%] [G loss: 0.686431] [Time: 0.149401]\n",
            "4928 (test) [D loss: 0.988451, acc.: 48.08%] [G loss: 0.541774] [Time: 0.043695]\n",
            "4929-0 [D loss: 0.692481, acc.: 46.15%] [G loss: 0.729800] [Time: 0.149800]\n",
            "4929-1 [D loss: 0.705781, acc.: 36.54%] [G loss: 0.693797] [Time: 0.148530]\n",
            "4929-2 [D loss: 0.701488, acc.: 36.54%] [G loss: 0.707420] [Time: 0.151645]\n",
            "4929-3 [D loss: 0.694991, acc.: 44.23%] [G loss: 0.716167] [Time: 0.148167]\n",
            "4929-4 [D loss: 0.692656, acc.: 32.69%] [G loss: 0.693750] [Time: 0.147843]\n",
            "4929-5 [D loss: 0.686585, acc.: 38.46%] [G loss: 0.698908] [Time: 0.148923]\n",
            "4929-6 [D loss: 0.687816, acc.: 59.62%] [G loss: 0.709726] [Time: 0.148321]\n",
            "4929-7 [D loss: 0.702115, acc.: 36.54%] [G loss: 0.676843] [Time: 0.147844]\n",
            "4929-8 [D loss: 0.707730, acc.: 38.46%] [G loss: 0.703100] [Time: 0.148070]\n",
            "4929 (test) [D loss: 1.065417, acc.: 48.08%] [G loss: 0.450855] [Time: 0.043788]\n",
            "4930-0 [D loss: 0.696992, acc.: 38.46%] [G loss: 0.728936] [Time: 0.147223]\n",
            "4930-1 [D loss: 0.709019, acc.: 38.46%] [G loss: 0.688060] [Time: 0.148009]\n",
            "4930-2 [D loss: 0.708358, acc.: 42.31%] [G loss: 0.695050] [Time: 0.152643]\n",
            "4930-3 [D loss: 0.706577, acc.: 28.85%] [G loss: 0.726065] [Time: 0.149188]\n",
            "4930-4 [D loss: 0.687443, acc.: 46.15%] [G loss: 0.691039] [Time: 0.152468]\n",
            "4930-5 [D loss: 0.700377, acc.: 46.15%] [G loss: 0.697265] [Time: 0.151761]\n",
            "4930-6 [D loss: 0.680827, acc.: 51.92%] [G loss: 0.713623] [Time: 0.153018]\n",
            "4930-7 [D loss: 0.700217, acc.: 50.00%] [G loss: 0.712133] [Time: 0.149894]\n",
            "4930-8 [D loss: 0.713847, acc.: 30.77%] [G loss: 0.681861] [Time: 0.149841]\n",
            "4930 (test) [D loss: 1.020981, acc.: 50.00%] [G loss: 0.487026] [Time: 0.044240]\n",
            "4931-0 [D loss: 0.693983, acc.: 40.38%] [G loss: 0.729538] [Time: 0.148583]\n",
            "4931-1 [D loss: 0.701510, acc.: 42.31%] [G loss: 0.693287] [Time: 0.149718]\n",
            "4931-2 [D loss: 0.708509, acc.: 38.46%] [G loss: 0.697445] [Time: 0.147827]\n",
            "4931-3 [D loss: 0.702347, acc.: 44.23%] [G loss: 0.706523] [Time: 0.147884]\n",
            "4931-4 [D loss: 0.693968, acc.: 42.31%] [G loss: 0.693780] [Time: 0.148377]\n",
            "4931-5 [D loss: 0.711940, acc.: 34.62%] [G loss: 0.698684] [Time: 0.149135]\n",
            "4931-6 [D loss: 0.690211, acc.: 46.15%] [G loss: 0.704663] [Time: 0.147924]\n",
            "4931-7 [D loss: 0.701601, acc.: 40.38%] [G loss: 0.689664] [Time: 0.147473]\n",
            "4931-8 [D loss: 0.701004, acc.: 42.31%] [G loss: 0.703434] [Time: 0.147806]\n",
            "4931 (test) [D loss: 1.122823, acc.: 50.00%] [G loss: 0.363679] [Time: 0.045391]\n",
            "4932-0 [D loss: 0.707111, acc.: 32.69%] [G loss: 0.718394] [Time: 0.151565]\n",
            "4932-1 [D loss: 0.710199, acc.: 34.62%] [G loss: 0.684465] [Time: 0.151876]\n",
            "4932-2 [D loss: 0.692988, acc.: 50.00%] [G loss: 0.678086] [Time: 0.153444]\n",
            "4932-3 [D loss: 0.700729, acc.: 51.92%] [G loss: 0.698421] [Time: 0.149850]\n",
            "4932-4 [D loss: 0.682683, acc.: 53.85%] [G loss: 0.684678] [Time: 0.147579]\n",
            "4932-5 [D loss: 0.701035, acc.: 34.62%] [G loss: 0.671265] [Time: 0.148991]\n",
            "4932-6 [D loss: 0.680256, acc.: 51.92%] [G loss: 0.705683] [Time: 0.148874]\n",
            "4932-7 [D loss: 0.704937, acc.: 36.54%] [G loss: 0.697323] [Time: 0.149357]\n",
            "4932-8 [D loss: 0.690379, acc.: 46.15%] [G loss: 0.685702] [Time: 0.149932]\n",
            "4932 (test) [D loss: 1.033284, acc.: 50.00%] [G loss: 0.429467] [Time: 0.043907]\n",
            "4933-0 [D loss: 0.693633, acc.: 38.46%] [G loss: 0.707872] [Time: 0.147232]\n",
            "4933-1 [D loss: 0.721425, acc.: 34.62%] [G loss: 0.700766] [Time: 0.149540]\n",
            "4933-2 [D loss: 0.698802, acc.: 46.15%] [G loss: 0.699057] [Time: 0.147369]\n",
            "4933-3 [D loss: 0.701426, acc.: 50.00%] [G loss: 0.700802] [Time: 0.149751]\n",
            "4933-4 [D loss: 0.686684, acc.: 40.38%] [G loss: 0.705260] [Time: 0.149791]\n",
            "4933-5 [D loss: 0.696006, acc.: 34.62%] [G loss: 0.696992] [Time: 0.149574]\n",
            "4933-6 [D loss: 0.680803, acc.: 53.85%] [G loss: 0.704702] [Time: 0.148215]\n",
            "4933-7 [D loss: 0.697210, acc.: 46.15%] [G loss: 0.703925] [Time: 0.148485]\n",
            "4933-8 [D loss: 0.702317, acc.: 42.31%] [G loss: 0.705797] [Time: 0.147181]\n",
            "4933 (test) [D loss: 1.068219, acc.: 48.08%] [G loss: 0.413519] [Time: 0.044487]\n",
            "4934-0 [D loss: 0.693335, acc.: 30.77%] [G loss: 0.704575] [Time: 0.148592]\n",
            "4934-1 [D loss: 0.701157, acc.: 44.23%] [G loss: 0.690586] [Time: 0.148065]\n",
            "4934-2 [D loss: 0.708507, acc.: 30.77%] [G loss: 0.688284] [Time: 0.147480]\n",
            "4934-3 [D loss: 0.707877, acc.: 36.54%] [G loss: 0.721408] [Time: 0.149167]\n",
            "4934-4 [D loss: 0.687654, acc.: 51.92%] [G loss: 0.692666] [Time: 0.147332]\n",
            "4934-5 [D loss: 0.703172, acc.: 36.54%] [G loss: 0.704125] [Time: 0.150074]\n",
            "4934-6 [D loss: 0.686518, acc.: 48.08%] [G loss: 0.701930] [Time: 0.147628]\n",
            "4934-7 [D loss: 0.707871, acc.: 36.54%] [G loss: 0.682708] [Time: 0.147789]\n",
            "4934-8 [D loss: 0.704465, acc.: 42.31%] [G loss: 0.698746] [Time: 0.150616]\n",
            "4934 (test) [D loss: 1.187955, acc.: 48.08%] [G loss: 0.331244] [Time: 0.043719]\n",
            "4935-0 [D loss: 0.695347, acc.: 32.69%] [G loss: 0.717040] [Time: 0.149691]\n",
            "4935-1 [D loss: 0.707224, acc.: 46.15%] [G loss: 0.693742] [Time: 0.148193]\n",
            "4935-2 [D loss: 0.713914, acc.: 32.69%] [G loss: 0.690791] [Time: 0.148253]\n",
            "4935-3 [D loss: 0.697274, acc.: 44.23%] [G loss: 0.718121] [Time: 0.149881]\n",
            "4935-4 [D loss: 0.669901, acc.: 59.62%] [G loss: 0.711567] [Time: 0.149371]\n",
            "4935-5 [D loss: 0.701047, acc.: 48.08%] [G loss: 0.699118] [Time: 0.148894]\n",
            "4935-6 [D loss: 0.681402, acc.: 48.08%] [G loss: 0.700685] [Time: 0.150448]\n",
            "4935-7 [D loss: 0.691502, acc.: 55.77%] [G loss: 0.685948] [Time: 0.149623]\n",
            "4935-8 [D loss: 0.708136, acc.: 40.38%] [G loss: 0.693908] [Time: 0.148115]\n",
            "4935 (test) [D loss: 0.985879, acc.: 50.00%] [G loss: 0.527356] [Time: 0.045420]\n",
            "4936-0 [D loss: 0.694401, acc.: 44.23%] [G loss: 0.737599] [Time: 0.149300]\n",
            "4936-1 [D loss: 0.700562, acc.: 40.38%] [G loss: 0.697239] [Time: 0.148005]\n",
            "4936-2 [D loss: 0.710365, acc.: 42.31%] [G loss: 0.715568] [Time: 0.149216]\n",
            "4936-3 [D loss: 0.713120, acc.: 38.46%] [G loss: 0.734131] [Time: 0.149373]\n",
            "4936-4 [D loss: 0.688507, acc.: 44.23%] [G loss: 0.683269] [Time: 0.147672]\n",
            "4936-5 [D loss: 0.704825, acc.: 34.62%] [G loss: 0.689577] [Time: 0.148374]\n",
            "4936-6 [D loss: 0.698632, acc.: 44.23%] [G loss: 0.713762] [Time: 0.147895]\n",
            "4936-7 [D loss: 0.716198, acc.: 26.92%] [G loss: 0.703629] [Time: 0.149835]\n",
            "4936-8 [D loss: 0.713342, acc.: 32.69%] [G loss: 0.695076] [Time: 0.148284]\n",
            "4936 (test) [D loss: 1.012656, acc.: 50.00%] [G loss: 0.524344] [Time: 0.044740]\n",
            "4937-0 [D loss: 0.699148, acc.: 42.31%] [G loss: 0.734089] [Time: 0.148068]\n",
            "4937-1 [D loss: 0.701725, acc.: 40.38%] [G loss: 0.689934] [Time: 0.152203]\n",
            "4937-2 [D loss: 0.700603, acc.: 36.54%] [G loss: 0.713843] [Time: 0.148847]\n",
            "4937-3 [D loss: 0.689411, acc.: 51.92%] [G loss: 0.728549] [Time: 0.147986]\n",
            "4937-4 [D loss: 0.690319, acc.: 30.77%] [G loss: 0.706295] [Time: 0.149448]\n",
            "4937-5 [D loss: 0.700282, acc.: 44.23%] [G loss: 0.711214] [Time: 0.147404]\n",
            "4937-6 [D loss: 0.681218, acc.: 48.08%] [G loss: 0.701347] [Time: 0.147866]\n",
            "4937-7 [D loss: 0.695981, acc.: 51.92%] [G loss: 0.689962] [Time: 0.148421]\n",
            "4937-8 [D loss: 0.706766, acc.: 40.38%] [G loss: 0.686448] [Time: 0.147668]\n",
            "4937 (test) [D loss: 1.013339, acc.: 50.00%] [G loss: 0.535785] [Time: 0.044316]\n",
            "4938-0 [D loss: 0.691987, acc.: 44.23%] [G loss: 0.765433] [Time: 0.148607]\n",
            "4938-1 [D loss: 0.700150, acc.: 48.08%] [G loss: 0.706627] [Time: 0.148327]\n",
            "4938-2 [D loss: 0.717068, acc.: 32.69%] [G loss: 0.705000] [Time: 0.153807]\n",
            "4938-3 [D loss: 0.701312, acc.: 40.38%] [G loss: 0.714319] [Time: 0.148389]\n",
            "4938-4 [D loss: 0.679781, acc.: 51.92%] [G loss: 0.701595] [Time: 0.149809]\n",
            "4938-5 [D loss: 0.703565, acc.: 44.23%] [G loss: 0.711273] [Time: 0.151109]\n",
            "4938-6 [D loss: 0.680352, acc.: 53.85%] [G loss: 0.715899] [Time: 0.149349]\n",
            "4938-7 [D loss: 0.696653, acc.: 50.00%] [G loss: 0.700672] [Time: 0.148585]\n",
            "4938-8 [D loss: 0.704329, acc.: 36.54%] [G loss: 0.702060] [Time: 0.147526]\n",
            "4938 (test) [D loss: 1.095421, acc.: 50.00%] [G loss: 0.481896] [Time: 0.043707]\n",
            "4939-0 [D loss: 0.668530, acc.: 40.38%] [G loss: 0.745198] [Time: 0.147865]\n",
            "4939-1 [D loss: 0.715483, acc.: 44.23%] [G loss: 0.693986] [Time: 0.148496]\n",
            "4939-2 [D loss: 0.716877, acc.: 32.69%] [G loss: 0.682671] [Time: 0.151944]\n",
            "4939-3 [D loss: 0.695801, acc.: 42.31%] [G loss: 0.720438] [Time: 0.149835]\n",
            "4939-4 [D loss: 0.681692, acc.: 51.92%] [G loss: 0.694388] [Time: 0.147957]\n",
            "4939-5 [D loss: 0.702211, acc.: 42.31%] [G loss: 0.703157] [Time: 0.149187]\n",
            "4939-6 [D loss: 0.680067, acc.: 53.85%] [G loss: 0.711521] [Time: 0.149246]\n",
            "4939-7 [D loss: 0.691847, acc.: 44.23%] [G loss: 0.699020] [Time: 0.147975]\n",
            "4939-8 [D loss: 0.690245, acc.: 57.69%] [G loss: 0.698264] [Time: 0.147877]\n",
            "4939 (test) [D loss: 1.036019, acc.: 50.00%] [G loss: 0.553427] [Time: 0.043761]\n",
            "4940-0 [D loss: 0.697958, acc.: 36.54%] [G loss: 0.733491] [Time: 0.146854]\n",
            "4940-1 [D loss: 0.702672, acc.: 48.08%] [G loss: 0.700246] [Time: 0.148846]\n",
            "4940-2 [D loss: 0.707509, acc.: 42.31%] [G loss: 0.708162] [Time: 0.149012]\n",
            "4940-3 [D loss: 0.703875, acc.: 42.31%] [G loss: 0.707613] [Time: 0.149272]\n",
            "4940-4 [D loss: 0.688471, acc.: 50.00%] [G loss: 0.721867] [Time: 0.147410]\n",
            "4940-5 [D loss: 0.700205, acc.: 44.23%] [G loss: 0.697600] [Time: 0.148910]\n",
            "4940-6 [D loss: 0.689285, acc.: 57.69%] [G loss: 0.715363] [Time: 0.147391]\n",
            "4940-7 [D loss: 0.695873, acc.: 51.92%] [G loss: 0.692665] [Time: 0.147928]\n",
            "4940-8 [D loss: 0.695909, acc.: 40.38%] [G loss: 0.676172] [Time: 0.151763]\n",
            "4940 (test) [D loss: 1.061755, acc.: 50.00%] [G loss: 0.525257] [Time: 0.045995]\n",
            "4941-0 [D loss: 0.681636, acc.: 46.15%] [G loss: 0.722612] [Time: 0.148690]\n",
            "4941-1 [D loss: 0.699379, acc.: 51.92%] [G loss: 0.693196] [Time: 0.150650]\n",
            "4941-2 [D loss: 0.696509, acc.: 34.62%] [G loss: 0.682282] [Time: 0.152393]\n",
            "4941-3 [D loss: 0.701368, acc.: 48.08%] [G loss: 0.709792] [Time: 0.148693]\n",
            "4941-4 [D loss: 0.692223, acc.: 32.69%] [G loss: 0.693858] [Time: 0.147276]\n",
            "4941-5 [D loss: 0.699412, acc.: 46.15%] [G loss: 0.690713] [Time: 0.147062]\n",
            "4941-6 [D loss: 0.678559, acc.: 48.08%] [G loss: 0.707022] [Time: 0.146872]\n",
            "4941-7 [D loss: 0.691324, acc.: 48.08%] [G loss: 0.706866] [Time: 0.148894]\n",
            "4941-8 [D loss: 0.704666, acc.: 34.62%] [G loss: 0.710240] [Time: 0.148159]\n",
            "4941 (test) [D loss: 1.038042, acc.: 50.00%] [G loss: 0.550643] [Time: 0.044114]\n",
            "4942-0 [D loss: 0.697089, acc.: 36.54%] [G loss: 0.724921] [Time: 0.147866]\n",
            "4942-1 [D loss: 0.694512, acc.: 44.23%] [G loss: 0.693136] [Time: 0.152166]\n",
            "4942-2 [D loss: 0.708496, acc.: 34.62%] [G loss: 0.692691] [Time: 0.151589]\n",
            "4942-3 [D loss: 0.702852, acc.: 42.31%] [G loss: 0.700357] [Time: 0.147478]\n",
            "4942-4 [D loss: 0.678320, acc.: 51.92%] [G loss: 0.692646] [Time: 0.150151]\n",
            "4942-5 [D loss: 0.711109, acc.: 40.38%] [G loss: 0.683398] [Time: 0.151690]\n",
            "4942-6 [D loss: 0.685570, acc.: 53.85%] [G loss: 0.713732] [Time: 0.147807]\n",
            "4942-7 [D loss: 0.695065, acc.: 46.15%] [G loss: 0.692619] [Time: 0.149433]\n",
            "4942-8 [D loss: 0.697909, acc.: 50.00%] [G loss: 0.679564] [Time: 0.147731]\n",
            "4942 (test) [D loss: 1.048509, acc.: 50.00%] [G loss: 0.529501] [Time: 0.043757]\n",
            "4943-0 [D loss: 0.697096, acc.: 46.15%] [G loss: 0.723500] [Time: 0.146919]\n",
            "4943-1 [D loss: 0.695834, acc.: 38.46%] [G loss: 0.698480] [Time: 0.147625]\n",
            "4943-2 [D loss: 0.690709, acc.: 46.15%] [G loss: 0.687075] [Time: 0.148387]\n",
            "4943-3 [D loss: 0.699150, acc.: 53.85%] [G loss: 0.713719] [Time: 0.146812]\n",
            "4943-4 [D loss: 0.681629, acc.: 44.23%] [G loss: 0.690965] [Time: 0.148079]\n",
            "4943-5 [D loss: 0.697587, acc.: 46.15%] [G loss: 0.676743] [Time: 0.148047]\n",
            "4943-6 [D loss: 0.686100, acc.: 51.92%] [G loss: 0.707339] [Time: 0.149444]\n",
            "4943-7 [D loss: 0.696596, acc.: 40.38%] [G loss: 0.686747] [Time: 0.148134]\n",
            "4943-8 [D loss: 0.707390, acc.: 55.77%] [G loss: 0.688186] [Time: 0.146828]\n",
            "4943 (test) [D loss: 1.061056, acc.: 50.00%] [G loss: 0.476579] [Time: 0.043625]\n",
            "4944-0 [D loss: 0.692871, acc.: 42.31%] [G loss: 0.749267] [Time: 0.148727]\n",
            "4944-1 [D loss: 0.697138, acc.: 44.23%] [G loss: 0.697000] [Time: 0.147376]\n",
            "4944-2 [D loss: 0.708794, acc.: 36.54%] [G loss: 0.693982] [Time: 0.147544]\n",
            "4944-3 [D loss: 0.695345, acc.: 40.38%] [G loss: 0.731800] [Time: 0.148578]\n",
            "4944-4 [D loss: 0.686781, acc.: 50.00%] [G loss: 0.700510] [Time: 0.149924]\n",
            "4944-5 [D loss: 0.700557, acc.: 50.00%] [G loss: 0.693665] [Time: 0.147388]\n",
            "4944-6 [D loss: 0.683014, acc.: 53.85%] [G loss: 0.712711] [Time: 0.150009]\n",
            "4944-7 [D loss: 0.703055, acc.: 38.46%] [G loss: 0.684569] [Time: 0.149926]\n",
            "4944-8 [D loss: 0.710447, acc.: 46.15%] [G loss: 0.678392] [Time: 0.147836]\n",
            "4944 (test) [D loss: 1.103197, acc.: 50.00%] [G loss: 0.431229] [Time: 0.043482]\n",
            "4945-0 [D loss: 0.688046, acc.: 51.92%] [G loss: 0.729572] [Time: 0.146696]\n",
            "4945-1 [D loss: 0.706998, acc.: 42.31%] [G loss: 0.687533] [Time: 0.147134]\n",
            "4945-2 [D loss: 0.714103, acc.: 30.77%] [G loss: 0.690783] [Time: 0.149250]\n",
            "4945-3 [D loss: 0.690077, acc.: 44.23%] [G loss: 0.721431] [Time: 0.147916]\n",
            "4945-4 [D loss: 0.688585, acc.: 48.08%] [G loss: 0.722200] [Time: 0.148910]\n",
            "4945-5 [D loss: 0.704828, acc.: 34.62%] [G loss: 0.694731] [Time: 0.147772]\n",
            "4945-6 [D loss: 0.681530, acc.: 57.69%] [G loss: 0.706005] [Time: 0.148393]\n",
            "4945-7 [D loss: 0.698650, acc.: 46.15%] [G loss: 0.685971] [Time: 0.150770]\n",
            "4945-8 [D loss: 0.709550, acc.: 42.31%] [G loss: 0.693334] [Time: 0.152573]\n",
            "4945 (test) [D loss: 1.172989, acc.: 50.00%] [G loss: 0.400370] [Time: 0.045737]\n",
            "4946-0 [D loss: 0.685578, acc.: 44.23%] [G loss: 0.750118] [Time: 0.149080]\n",
            "4946-1 [D loss: 0.708995, acc.: 40.38%] [G loss: 0.686591] [Time: 0.148730]\n",
            "4946-2 [D loss: 0.706059, acc.: 42.31%] [G loss: 0.701153] [Time: 0.150728]\n",
            "4946-3 [D loss: 0.696821, acc.: 48.08%] [G loss: 0.747872] [Time: 0.147958]\n",
            "4946-4 [D loss: 0.690185, acc.: 46.15%] [G loss: 0.685995] [Time: 0.150883]\n",
            "4946-5 [D loss: 0.710726, acc.: 32.69%] [G loss: 0.701605] [Time: 0.151589]\n",
            "4946-6 [D loss: 0.671293, acc.: 55.77%] [G loss: 0.705084] [Time: 0.150611]\n",
            "4946-7 [D loss: 0.703465, acc.: 36.54%] [G loss: 0.710524] [Time: 0.148175]\n",
            "4946-8 [D loss: 0.717537, acc.: 30.77%] [G loss: 0.685902] [Time: 0.148750]\n",
            "4946 (test) [D loss: 1.056228, acc.: 50.00%] [G loss: 0.516869] [Time: 0.043863]\n",
            "4947-0 [D loss: 0.688836, acc.: 46.15%] [G loss: 0.721217] [Time: 0.147362]\n",
            "4947-1 [D loss: 0.697309, acc.: 51.92%] [G loss: 0.702326] [Time: 0.149410]\n",
            "4947-2 [D loss: 0.710437, acc.: 36.54%] [G loss: 0.698454] [Time: 0.150154]\n",
            "4947-3 [D loss: 0.709669, acc.: 38.46%] [G loss: 0.719302] [Time: 0.147589]\n",
            "4947-4 [D loss: 0.679063, acc.: 48.08%] [G loss: 0.687433] [Time: 0.148038]\n",
            "4947-5 [D loss: 0.698651, acc.: 30.77%] [G loss: 0.698484] [Time: 0.149971]\n",
            "4947-6 [D loss: 0.680718, acc.: 59.62%] [G loss: 0.708821] [Time: 0.148007]\n",
            "4947-7 [D loss: 0.684942, acc.: 44.23%] [G loss: 0.692830] [Time: 0.148815]\n",
            "4947-8 [D loss: 0.688755, acc.: 53.85%] [G loss: 0.690945] [Time: 0.148768]\n",
            "4947 (test) [D loss: 1.025623, acc.: 50.00%] [G loss: 0.574888] [Time: 0.044204]\n",
            "4948-0 [D loss: 0.694851, acc.: 50.00%] [G loss: 0.708231] [Time: 0.148584]\n",
            "4948-1 [D loss: 0.702880, acc.: 40.38%] [G loss: 0.696844] [Time: 0.150392]\n",
            "4948-2 [D loss: 0.694495, acc.: 59.62%] [G loss: 0.680345] [Time: 0.156469]\n",
            "4948-3 [D loss: 0.711002, acc.: 50.00%] [G loss: 0.711184] [Time: 0.149482]\n",
            "4948-4 [D loss: 0.701479, acc.: 38.46%] [G loss: 0.712002] [Time: 0.150216]\n",
            "4948-5 [D loss: 0.707096, acc.: 44.23%] [G loss: 0.697831] [Time: 0.149829]\n",
            "4948-6 [D loss: 0.684877, acc.: 55.77%] [G loss: 0.699805] [Time: 0.148321]\n",
            "4948-7 [D loss: 0.699860, acc.: 36.54%] [G loss: 0.693010] [Time: 0.148476]\n",
            "4948-8 [D loss: 0.714656, acc.: 42.31%] [G loss: 0.690076] [Time: 0.149346]\n",
            "4948 (test) [D loss: 1.057053, acc.: 50.00%] [G loss: 0.515916] [Time: 0.044512]\n",
            "4949-0 [D loss: 0.694353, acc.: 46.15%] [G loss: 0.671868] [Time: 0.149184]\n",
            "4949-1 [D loss: 0.693646, acc.: 48.08%] [G loss: 0.701522] [Time: 0.155270]\n",
            "4949-2 [D loss: 0.693194, acc.: 48.08%] [G loss: 0.663807] [Time: 0.149930]\n",
            "4949-3 [D loss: 0.711688, acc.: 48.08%] [G loss: 0.714839] [Time: 0.150512]\n",
            "4949-4 [D loss: 0.690839, acc.: 42.31%] [G loss: 0.688637] [Time: 0.149105]\n",
            "4949-5 [D loss: 0.705300, acc.: 48.08%] [G loss: 0.698324] [Time: 0.149720]\n",
            "4949-6 [D loss: 0.686734, acc.: 50.00%] [G loss: 0.698900] [Time: 0.151721]\n",
            "4949-7 [D loss: 0.701050, acc.: 34.62%] [G loss: 0.700869] [Time: 0.155011]\n",
            "4949-8 [D loss: 0.708229, acc.: 38.46%] [G loss: 0.681091] [Time: 0.155656]\n",
            "4949 (test) [D loss: 1.048571, acc.: 50.00%] [G loss: 0.542173] [Time: 0.044579]\n",
            "4950-0 [D loss: 0.695998, acc.: 42.31%] [G loss: 0.703651] [Time: 0.148053]\n",
            "4950-1 [D loss: 0.701504, acc.: 42.31%] [G loss: 0.687006] [Time: 0.148225]\n",
            "4950-2 [D loss: 0.703153, acc.: 44.23%] [G loss: 0.697453] [Time: 0.149206]\n",
            "4950-3 [D loss: 0.692085, acc.: 46.15%] [G loss: 0.722742] [Time: 0.148246]\n",
            "4950-4 [D loss: 0.678086, acc.: 44.23%] [G loss: 0.700768] [Time: 0.150914]\n",
            "4950-5 [D loss: 0.699406, acc.: 44.23%] [G loss: 0.676035] [Time: 0.152063]\n",
            "4950-6 [D loss: 0.689613, acc.: 53.85%] [G loss: 0.703475] [Time: 0.150812]\n",
            "4950-7 [D loss: 0.695029, acc.: 53.85%] [G loss: 0.692514] [Time: 0.153776]\n",
            "4950-8 [D loss: 0.721105, acc.: 48.08%] [G loss: 0.713920] [Time: 0.150773]\n",
            "4950 (test) [D loss: 1.064491, acc.: 50.00%] [G loss: 0.509723] [Time: 0.043410]\n",
            "4951-0 [D loss: 0.693944, acc.: 40.38%] [G loss: 0.727443] [Time: 0.147678]\n",
            "4951-1 [D loss: 0.708301, acc.: 30.77%] [G loss: 0.700389] [Time: 0.147486]\n",
            "4951-2 [D loss: 0.704582, acc.: 36.54%] [G loss: 0.683693] [Time: 0.148253]\n",
            "4951-3 [D loss: 0.694500, acc.: 48.08%] [G loss: 0.727208] [Time: 0.149907]\n",
            "4951-4 [D loss: 0.678975, acc.: 48.08%] [G loss: 0.696332] [Time: 0.151310]\n",
            "4951-5 [D loss: 0.705920, acc.: 44.23%] [G loss: 0.700150] [Time: 0.151081]\n",
            "4951-6 [D loss: 0.686478, acc.: 53.85%] [G loss: 0.723709] [Time: 0.147373]\n",
            "4951-7 [D loss: 0.693026, acc.: 50.00%] [G loss: 0.711637] [Time: 0.149883]\n",
            "4951-8 [D loss: 0.700283, acc.: 42.31%] [G loss: 0.687048] [Time: 0.148972]\n",
            "4951 (test) [D loss: 0.970072, acc.: 48.08%] [G loss: 0.698443] [Time: 0.043616]\n",
            "4952-0 [D loss: 0.693582, acc.: 42.31%] [G loss: 0.741664] [Time: 0.147097]\n",
            "4952-1 [D loss: 0.689296, acc.: 44.23%] [G loss: 0.718899] [Time: 0.147891]\n",
            "4952-2 [D loss: 0.695988, acc.: 50.00%] [G loss: 0.691813] [Time: 0.149850]\n",
            "4952-3 [D loss: 0.705803, acc.: 48.08%] [G loss: 0.714746] [Time: 0.150090]\n",
            "4952-4 [D loss: 0.686816, acc.: 51.92%] [G loss: 0.696725] [Time: 0.147211]\n",
            "4952-5 [D loss: 0.690189, acc.: 48.08%] [G loss: 0.716994] [Time: 0.147316]\n",
            "4952-6 [D loss: 0.675277, acc.: 57.69%] [G loss: 0.713132] [Time: 0.148203]\n",
            "4952-7 [D loss: 0.692522, acc.: 48.08%] [G loss: 0.698673] [Time: 0.150659]\n",
            "4952-8 [D loss: 0.709357, acc.: 36.54%] [G loss: 0.687726] [Time: 0.150247]\n",
            "4952 (test) [D loss: 0.977956, acc.: 53.85%] [G loss: 0.741378] [Time: 0.045394]\n",
            "4953-0 [D loss: 0.700588, acc.: 38.46%] [G loss: 0.743242] [Time: 0.149951]\n",
            "4953-1 [D loss: 0.693683, acc.: 46.15%] [G loss: 0.715137] [Time: 0.147714]\n",
            "4953-2 [D loss: 0.703078, acc.: 38.46%] [G loss: 0.702202] [Time: 0.146853]\n",
            "4953-3 [D loss: 0.702404, acc.: 30.77%] [G loss: 0.713359] [Time: 0.151338]\n",
            "4953-4 [D loss: 0.708746, acc.: 25.00%] [G loss: 0.703193] [Time: 0.152298]\n",
            "4953-5 [D loss: 0.700213, acc.: 40.38%] [G loss: 0.706563] [Time: 0.154600]\n",
            "4953-6 [D loss: 0.689233, acc.: 57.69%] [G loss: 0.713589] [Time: 0.149325]\n",
            "4953-7 [D loss: 0.698797, acc.: 48.08%] [G loss: 0.694145] [Time: 0.149880]\n",
            "4953-8 [D loss: 0.709980, acc.: 40.38%] [G loss: 0.703336] [Time: 0.147510]\n",
            "4953 (test) [D loss: 1.039096, acc.: 50.00%] [G loss: 0.595788] [Time: 0.044179]\n",
            "4954-0 [D loss: 0.716046, acc.: 40.38%] [G loss: 0.702831] [Time: 0.149325]\n",
            "4954-1 [D loss: 0.704484, acc.: 34.62%] [G loss: 0.685592] [Time: 0.153693]\n",
            "4954-2 [D loss: 0.704961, acc.: 46.15%] [G loss: 0.680712] [Time: 0.149519]\n",
            "4954-3 [D loss: 0.700961, acc.: 48.08%] [G loss: 0.714013] [Time: 0.148352]\n",
            "4954-4 [D loss: 0.694481, acc.: 42.31%] [G loss: 0.691648] [Time: 0.146704]\n",
            "4954-5 [D loss: 0.697685, acc.: 46.15%] [G loss: 0.702016] [Time: 0.150009]\n",
            "4954-6 [D loss: 0.688637, acc.: 44.23%] [G loss: 0.714840] [Time: 0.151682]\n",
            "4954-7 [D loss: 0.710096, acc.: 48.08%] [G loss: 0.696634] [Time: 0.152677]\n",
            "4954-8 [D loss: 0.696005, acc.: 42.31%] [G loss: 0.701189] [Time: 0.151004]\n",
            "4954 (test) [D loss: 1.048205, acc.: 50.00%] [G loss: 0.611663] [Time: 0.043752]\n",
            "4955-0 [D loss: 0.683560, acc.: 48.08%] [G loss: 0.733529] [Time: 0.147842]\n",
            "4955-1 [D loss: 0.703991, acc.: 48.08%] [G loss: 0.698111] [Time: 0.147899]\n",
            "4955-2 [D loss: 0.700207, acc.: 42.31%] [G loss: 0.674568] [Time: 0.149827]\n",
            "4955-3 [D loss: 0.709464, acc.: 42.31%] [G loss: 0.708357] [Time: 0.150680]\n",
            "4955-4 [D loss: 0.688512, acc.: 38.46%] [G loss: 0.703827] [Time: 0.148038]\n",
            "4955-5 [D loss: 0.722861, acc.: 38.46%] [G loss: 0.705806] [Time: 0.148087]\n",
            "4955-6 [D loss: 0.676265, acc.: 48.08%] [G loss: 0.717795] [Time: 0.153139]\n",
            "4955-7 [D loss: 0.700636, acc.: 34.62%] [G loss: 0.687455] [Time: 0.147829]\n",
            "4955-8 [D loss: 0.707691, acc.: 38.46%] [G loss: 0.694858] [Time: 0.148593]\n",
            "4955 (test) [D loss: 1.081204, acc.: 48.08%] [G loss: 0.596139] [Time: 0.043844]\n",
            "4956-0 [D loss: 0.685454, acc.: 42.31%] [G loss: 0.732505] [Time: 0.146765]\n",
            "4956-1 [D loss: 0.694146, acc.: 46.15%] [G loss: 0.684305] [Time: 0.152707]\n",
            "4956-2 [D loss: 0.720621, acc.: 36.54%] [G loss: 0.701725] [Time: 0.149310]\n",
            "4956-3 [D loss: 0.693223, acc.: 50.00%] [G loss: 0.721379] [Time: 0.149790]\n",
            "4956-4 [D loss: 0.692384, acc.: 40.38%] [G loss: 0.697939] [Time: 0.148546]\n",
            "4956-5 [D loss: 0.699800, acc.: 50.00%] [G loss: 0.715949] [Time: 0.148937]\n",
            "4956-6 [D loss: 0.682639, acc.: 55.77%] [G loss: 0.723309] [Time: 0.147322]\n",
            "4956-7 [D loss: 0.702979, acc.: 38.46%] [G loss: 0.692954] [Time: 0.150167]\n",
            "4956-8 [D loss: 0.692748, acc.: 42.31%] [G loss: 0.692975] [Time: 0.148622]\n",
            "4956 (test) [D loss: 1.159026, acc.: 48.08%] [G loss: 0.518637] [Time: 0.044014]\n",
            "4957-0 [D loss: 0.673989, acc.: 44.23%] [G loss: 0.721630] [Time: 0.150660]\n",
            "4957-1 [D loss: 0.698908, acc.: 44.23%] [G loss: 0.693444] [Time: 0.149302]\n",
            "4957-2 [D loss: 0.700936, acc.: 44.23%] [G loss: 0.681582] [Time: 0.148721]\n",
            "4957-3 [D loss: 0.706464, acc.: 46.15%] [G loss: 0.699518] [Time: 0.149053]\n",
            "4957-4 [D loss: 0.684499, acc.: 48.08%] [G loss: 0.693330] [Time: 0.155766]\n",
            "4957-5 [D loss: 0.691211, acc.: 51.92%] [G loss: 0.690191] [Time: 0.149410]\n",
            "4957-6 [D loss: 0.691842, acc.: 59.62%] [G loss: 0.698244] [Time: 0.149103]\n",
            "4957-7 [D loss: 0.701950, acc.: 42.31%] [G loss: 0.703880] [Time: 0.151157]\n",
            "4957-8 [D loss: 0.708534, acc.: 38.46%] [G loss: 0.669048] [Time: 0.150916]\n",
            "4957 (test) [D loss: 1.125128, acc.: 50.00%] [G loss: 0.469602] [Time: 0.043979]\n",
            "4958-0 [D loss: 0.699927, acc.: 40.38%] [G loss: 0.725230] [Time: 0.151003]\n",
            "4958-1 [D loss: 0.701370, acc.: 38.46%] [G loss: 0.691313] [Time: 0.148467]\n",
            "4958-2 [D loss: 0.705618, acc.: 40.38%] [G loss: 0.700092] [Time: 0.148470]\n",
            "4958-3 [D loss: 0.693978, acc.: 48.08%] [G loss: 0.693385] [Time: 0.149901]\n",
            "4958-4 [D loss: 0.681048, acc.: 57.69%] [G loss: 0.691207] [Time: 0.148319]\n",
            "4958-5 [D loss: 0.705313, acc.: 38.46%] [G loss: 0.704326] [Time: 0.149850]\n",
            "4958-6 [D loss: 0.694361, acc.: 55.77%] [G loss: 0.705500] [Time: 0.149410]\n",
            "4958-7 [D loss: 0.693885, acc.: 40.38%] [G loss: 0.696648] [Time: 0.152669]\n",
            "4958-8 [D loss: 0.701397, acc.: 36.54%] [G loss: 0.698322] [Time: 0.149293]\n",
            "4958 (test) [D loss: 1.030911, acc.: 50.00%] [G loss: 0.536737] [Time: 0.043984]\n",
            "4959-0 [D loss: 0.683794, acc.: 46.15%] [G loss: 0.736107] [Time: 0.148118]\n",
            "4959-1 [D loss: 0.692012, acc.: 46.15%] [G loss: 0.691968] [Time: 0.148789]\n",
            "4959-2 [D loss: 0.710148, acc.: 42.31%] [G loss: 0.690672] [Time: 0.147906]\n",
            "4959-3 [D loss: 0.708763, acc.: 40.38%] [G loss: 0.718849] [Time: 0.149078]\n",
            "4959-4 [D loss: 0.677223, acc.: 48.08%] [G loss: 0.691205] [Time: 0.148357]\n",
            "4959-5 [D loss: 0.706287, acc.: 42.31%] [G loss: 0.701467] [Time: 0.150268]\n",
            "4959-6 [D loss: 0.698062, acc.: 46.15%] [G loss: 0.712332] [Time: 0.149446]\n",
            "4959-7 [D loss: 0.692219, acc.: 53.85%] [G loss: 0.686578] [Time: 0.148991]\n",
            "4959-8 [D loss: 0.702496, acc.: 34.62%] [G loss: 0.692901] [Time: 0.152107]\n",
            "4959 (test) [D loss: 1.049702, acc.: 48.08%] [G loss: 0.555327] [Time: 0.044435]\n",
            "4960-0 [D loss: 0.699478, acc.: 38.46%] [G loss: 0.731983] [Time: 0.150708]\n",
            "4960-1 [D loss: 0.697414, acc.: 42.31%] [G loss: 0.695052] [Time: 0.150166]\n",
            "4960-2 [D loss: 0.706513, acc.: 38.46%] [G loss: 0.698357] [Time: 0.150238]\n",
            "4960-3 [D loss: 0.709698, acc.: 40.38%] [G loss: 0.712854] [Time: 0.150124]\n",
            "4960-4 [D loss: 0.688120, acc.: 51.92%] [G loss: 0.687929] [Time: 0.149356]\n",
            "4960-5 [D loss: 0.710222, acc.: 36.54%] [G loss: 0.719426] [Time: 0.150798]\n",
            "4960-6 [D loss: 0.683256, acc.: 46.15%] [G loss: 0.688645] [Time: 0.150031]\n",
            "4960-7 [D loss: 0.693922, acc.: 42.31%] [G loss: 0.708008] [Time: 0.154510]\n",
            "4960-8 [D loss: 0.705791, acc.: 44.23%] [G loss: 0.691399] [Time: 0.151202]\n",
            "4960 (test) [D loss: 1.070820, acc.: 50.00%] [G loss: 0.512956] [Time: 0.044374]\n",
            "4961-0 [D loss: 0.696823, acc.: 34.62%] [G loss: 0.710482] [Time: 0.150703]\n",
            "4961-1 [D loss: 0.698782, acc.: 38.46%] [G loss: 0.706868] [Time: 0.149275]\n",
            "4961-2 [D loss: 0.709733, acc.: 32.69%] [G loss: 0.705540] [Time: 0.152913]\n",
            "4961-3 [D loss: 0.695226, acc.: 53.85%] [G loss: 0.709007] [Time: 0.151197]\n",
            "4961-4 [D loss: 0.686910, acc.: 44.23%] [G loss: 0.705832] [Time: 0.154232]\n",
            "4961-5 [D loss: 0.687573, acc.: 50.00%] [G loss: 0.701596] [Time: 0.149246]\n",
            "4961-6 [D loss: 0.676649, acc.: 51.92%] [G loss: 0.700576] [Time: 0.148123]\n",
            "4961-7 [D loss: 0.693338, acc.: 40.38%] [G loss: 0.691990] [Time: 0.146526]\n",
            "4961-8 [D loss: 0.693681, acc.: 42.31%] [G loss: 0.683273] [Time: 0.154642]\n",
            "4961 (test) [D loss: 1.129500, acc.: 50.00%] [G loss: 0.439586] [Time: 0.044591]\n",
            "4962-0 [D loss: 0.683683, acc.: 36.54%] [G loss: 0.722772] [Time: 0.148880]\n",
            "4962-1 [D loss: 0.697513, acc.: 51.92%] [G loss: 0.682194] [Time: 0.149848]\n",
            "4962-2 [D loss: 0.706194, acc.: 44.23%] [G loss: 0.695510] [Time: 0.149450]\n",
            "4962-3 [D loss: 0.702456, acc.: 34.62%] [G loss: 0.708006] [Time: 0.149725]\n",
            "4962-4 [D loss: 0.685044, acc.: 42.31%] [G loss: 0.691059] [Time: 0.149227]\n",
            "4962-5 [D loss: 0.702213, acc.: 48.08%] [G loss: 0.713067] [Time: 0.149703]\n",
            "4962-6 [D loss: 0.679611, acc.: 59.62%] [G loss: 0.710852] [Time: 0.150007]\n",
            "4962-7 [D loss: 0.696945, acc.: 40.38%] [G loss: 0.710297] [Time: 0.153334]\n",
            "4962-8 [D loss: 0.711336, acc.: 44.23%] [G loss: 0.693961] [Time: 0.147341]\n",
            "4962 (test) [D loss: 1.024320, acc.: 50.00%] [G loss: 0.549829] [Time: 0.044189]\n",
            "4963-0 [D loss: 0.687582, acc.: 40.38%] [G loss: 0.724179] [Time: 0.151477]\n",
            "4963-1 [D loss: 0.714052, acc.: 50.00%] [G loss: 0.691062] [Time: 0.147581]\n",
            "4963-2 [D loss: 0.693137, acc.: 42.31%] [G loss: 0.685315] [Time: 0.147999]\n",
            "4963-3 [D loss: 0.705864, acc.: 42.31%] [G loss: 0.715872] [Time: 0.147223]\n",
            "4963-4 [D loss: 0.689124, acc.: 40.38%] [G loss: 0.712786] [Time: 0.148439]\n",
            "4963-5 [D loss: 0.710584, acc.: 34.62%] [G loss: 0.705350] [Time: 0.149454]\n",
            "4963-6 [D loss: 0.682599, acc.: 50.00%] [G loss: 0.714255] [Time: 0.147102]\n",
            "4963-7 [D loss: 0.697583, acc.: 38.46%] [G loss: 0.683244] [Time: 0.149502]\n",
            "4963-8 [D loss: 0.709418, acc.: 26.92%] [G loss: 0.689302] [Time: 0.150378]\n",
            "4963 (test) [D loss: 1.045352, acc.: 50.00%] [G loss: 0.615242] [Time: 0.044644]\n",
            "4964-0 [D loss: 0.699682, acc.: 36.54%] [G loss: 0.729757] [Time: 0.151422]\n",
            "4964-1 [D loss: 0.680898, acc.: 53.85%] [G loss: 0.712249] [Time: 0.148787]\n",
            "4964-2 [D loss: 0.707432, acc.: 28.85%] [G loss: 0.699841] [Time: 0.152800]\n",
            "4964-3 [D loss: 0.710074, acc.: 44.23%] [G loss: 0.712881] [Time: 0.149222]\n",
            "4964-4 [D loss: 0.693307, acc.: 44.23%] [G loss: 0.689336] [Time: 0.149519]\n",
            "4964-5 [D loss: 0.700672, acc.: 40.38%] [G loss: 0.699037] [Time: 0.148366]\n",
            "4964-6 [D loss: 0.683754, acc.: 46.15%] [G loss: 0.707214] [Time: 0.147896]\n",
            "4964-7 [D loss: 0.685403, acc.: 50.00%] [G loss: 0.695973] [Time: 0.149918]\n",
            "4964-8 [D loss: 0.698575, acc.: 48.08%] [G loss: 0.693824] [Time: 0.147246]\n",
            "4964 (test) [D loss: 1.051595, acc.: 50.00%] [G loss: 0.623003] [Time: 0.043661]\n",
            "4965-0 [D loss: 0.701176, acc.: 42.31%] [G loss: 0.731787] [Time: 0.152491]\n",
            "4965-1 [D loss: 0.698907, acc.: 40.38%] [G loss: 0.693579] [Time: 0.147942]\n",
            "4965-2 [D loss: 0.711260, acc.: 36.54%] [G loss: 0.707873] [Time: 0.148239]\n",
            "4965-3 [D loss: 0.708584, acc.: 44.23%] [G loss: 0.724149] [Time: 0.149619]\n",
            "4965-4 [D loss: 0.678921, acc.: 48.08%] [G loss: 0.695782] [Time: 0.149912]\n",
            "4965-5 [D loss: 0.707311, acc.: 50.00%] [G loss: 0.693539] [Time: 0.148321]\n",
            "4965-6 [D loss: 0.675177, acc.: 57.69%] [G loss: 0.709386] [Time: 0.147841]\n",
            "4965-7 [D loss: 0.700104, acc.: 50.00%] [G loss: 0.711989] [Time: 0.147673]\n",
            "4965-8 [D loss: 0.695674, acc.: 48.08%] [G loss: 0.712611] [Time: 0.147597]\n",
            "4965 (test) [D loss: 1.156328, acc.: 51.92%] [G loss: 0.545105] [Time: 0.044701]\n",
            "4966-0 [D loss: 0.685094, acc.: 46.15%] [G loss: 0.729317] [Time: 0.148668]\n",
            "4966-1 [D loss: 0.709295, acc.: 13.46%] [G loss: 0.710068] [Time: 0.151293]\n",
            "4966-2 [D loss: 0.694406, acc.: 44.23%] [G loss: 0.686467] [Time: 0.147146]\n",
            "4966-3 [D loss: 0.723515, acc.: 38.46%] [G loss: 0.721697] [Time: 0.148603]\n",
            "4966-4 [D loss: 0.679040, acc.: 46.15%] [G loss: 0.687114] [Time: 0.152730]\n",
            "4966-5 [D loss: 0.706733, acc.: 42.31%] [G loss: 0.699105] [Time: 0.149824]\n",
            "4966-6 [D loss: 0.680573, acc.: 55.77%] [G loss: 0.694434] [Time: 0.150235]\n",
            "4966-7 [D loss: 0.698449, acc.: 42.31%] [G loss: 0.690913] [Time: 0.151680]\n",
            "4966-8 [D loss: 0.704292, acc.: 34.62%] [G loss: 0.698161] [Time: 0.148304]\n",
            "4966 (test) [D loss: 1.103767, acc.: 50.00%] [G loss: 0.571853] [Time: 0.043476]\n",
            "4967-0 [D loss: 0.681761, acc.: 36.54%] [G loss: 0.708998] [Time: 0.147768]\n",
            "4967-1 [D loss: 0.704376, acc.: 36.54%] [G loss: 0.703069] [Time: 0.147317]\n",
            "4967-2 [D loss: 0.709751, acc.: 32.69%] [G loss: 0.709411] [Time: 0.150028]\n",
            "4967-3 [D loss: 0.703241, acc.: 53.85%] [G loss: 0.719526] [Time: 0.151436]\n",
            "4967-4 [D loss: 0.684643, acc.: 50.00%] [G loss: 0.713335] [Time: 0.151086]\n",
            "4967-5 [D loss: 0.692332, acc.: 53.85%] [G loss: 0.695037] [Time: 0.148419]\n",
            "4967-6 [D loss: 0.672373, acc.: 50.00%] [G loss: 0.706641] [Time: 0.149271]\n",
            "4967-7 [D loss: 0.707125, acc.: 40.38%] [G loss: 0.705353] [Time: 0.151534]\n",
            "4967-8 [D loss: 0.701431, acc.: 32.69%] [G loss: 0.698704] [Time: 0.150690]\n",
            "4967 (test) [D loss: 1.198453, acc.: 50.00%] [G loss: 0.499632] [Time: 0.044347]\n",
            "4968-0 [D loss: 0.686628, acc.: 40.38%] [G loss: 0.721317] [Time: 0.150535]\n",
            "4968-1 [D loss: 0.700697, acc.: 38.46%] [G loss: 0.695047] [Time: 0.146415]\n",
            "4968-2 [D loss: 0.706723, acc.: 40.38%] [G loss: 0.695832] [Time: 0.148206]\n",
            "4968-3 [D loss: 0.696903, acc.: 46.15%] [G loss: 0.705875] [Time: 0.148685]\n",
            "4968-4 [D loss: 0.689835, acc.: 46.15%] [G loss: 0.698973] [Time: 0.148817]\n",
            "4968-5 [D loss: 0.704621, acc.: 34.62%] [G loss: 0.701256] [Time: 0.151083]\n",
            "4968-6 [D loss: 0.679488, acc.: 50.00%] [G loss: 0.714195] [Time: 0.149529]\n",
            "4968-7 [D loss: 0.712404, acc.: 42.31%] [G loss: 0.679655] [Time: 0.149795]\n",
            "4968-8 [D loss: 0.700107, acc.: 53.85%] [G loss: 0.715817] [Time: 0.148231]\n",
            "4968 (test) [D loss: 1.125641, acc.: 50.00%] [G loss: 0.543010] [Time: 0.044084]\n",
            "4969-0 [D loss: 0.693547, acc.: 36.54%] [G loss: 0.718846] [Time: 0.148264]\n",
            "4969-1 [D loss: 0.699663, acc.: 48.08%] [G loss: 0.714512] [Time: 0.148005]\n",
            "4969-2 [D loss: 0.726538, acc.: 34.62%] [G loss: 0.680974] [Time: 0.150885]\n",
            "4969-3 [D loss: 0.711977, acc.: 44.23%] [G loss: 0.712085] [Time: 0.148738]\n",
            "4969-4 [D loss: 0.692955, acc.: 36.54%] [G loss: 0.711323] [Time: 0.147547]\n",
            "4969-5 [D loss: 0.704317, acc.: 42.31%] [G loss: 0.709888] [Time: 0.148376]\n",
            "4969-6 [D loss: 0.670058, acc.: 57.69%] [G loss: 0.717718] [Time: 0.148666]\n",
            "4969-7 [D loss: 0.700581, acc.: 34.62%] [G loss: 0.689644] [Time: 0.151006]\n",
            "4969-8 [D loss: 0.697250, acc.: 40.38%] [G loss: 0.719678] [Time: 0.151078]\n",
            "4969 (test) [D loss: 1.094657, acc.: 50.00%] [G loss: 0.568487] [Time: 0.044156]\n",
            "4970-0 [D loss: 0.699301, acc.: 34.62%] [G loss: 0.732152] [Time: 0.148047]\n",
            "4970-1 [D loss: 0.703869, acc.: 42.31%] [G loss: 0.686015] [Time: 0.147297]\n",
            "4970-2 [D loss: 0.705939, acc.: 42.31%] [G loss: 0.697433] [Time: 0.147794]\n",
            "4970-3 [D loss: 0.720360, acc.: 48.08%] [G loss: 0.695573] [Time: 0.148560]\n",
            "4970-4 [D loss: 0.692128, acc.: 36.54%] [G loss: 0.692885] [Time: 0.147886]\n",
            "4970-5 [D loss: 0.699833, acc.: 40.38%] [G loss: 0.695924] [Time: 0.150528]\n",
            "4970-6 [D loss: 0.683901, acc.: 50.00%] [G loss: 0.704532] [Time: 0.151048]\n",
            "4970-7 [D loss: 0.688979, acc.: 34.62%] [G loss: 0.682752] [Time: 0.152598]\n",
            "4970-8 [D loss: 0.689056, acc.: 44.23%] [G loss: 0.725403] [Time: 0.150212]\n",
            "4970 (test) [D loss: 1.166459, acc.: 50.00%] [G loss: 0.459435] [Time: 0.044697]\n",
            "4971-0 [D loss: 0.699929, acc.: 36.54%] [G loss: 0.720367] [Time: 0.152451]\n",
            "4971-1 [D loss: 0.688730, acc.: 57.69%] [G loss: 0.687331] [Time: 0.150835]\n",
            "4971-2 [D loss: 0.703321, acc.: 38.46%] [G loss: 0.687734] [Time: 0.147890]\n",
            "4971-3 [D loss: 0.697113, acc.: 50.00%] [G loss: 0.713731] [Time: 0.147473]\n",
            "4971-4 [D loss: 0.686077, acc.: 55.77%] [G loss: 0.706302] [Time: 0.148564]\n",
            "4971-5 [D loss: 0.705193, acc.: 42.31%] [G loss: 0.699573] [Time: 0.149495]\n",
            "4971-6 [D loss: 0.691952, acc.: 50.00%] [G loss: 0.722419] [Time: 0.149727]\n",
            "4971-7 [D loss: 0.695972, acc.: 48.08%] [G loss: 0.698973] [Time: 0.148348]\n",
            "4971-8 [D loss: 0.701647, acc.: 36.54%] [G loss: 0.689454] [Time: 0.148625]\n",
            "4971 (test) [D loss: 1.025489, acc.: 50.00%] [G loss: 0.597762] [Time: 0.044423]\n",
            "4972-0 [D loss: 0.691162, acc.: 48.08%] [G loss: 0.748042] [Time: 0.150054]\n",
            "4972-1 [D loss: 0.699434, acc.: 40.38%] [G loss: 0.691235] [Time: 0.148534]\n",
            "4972-2 [D loss: 0.696443, acc.: 42.31%] [G loss: 0.697270] [Time: 0.148487]\n",
            "4972-3 [D loss: 0.708957, acc.: 53.85%] [G loss: 0.731707] [Time: 0.147169]\n",
            "4972-4 [D loss: 0.686234, acc.: 44.23%] [G loss: 0.697468] [Time: 0.146833]\n",
            "4972-5 [D loss: 0.700545, acc.: 42.31%] [G loss: 0.698454] [Time: 0.146993]\n",
            "4972-6 [D loss: 0.681407, acc.: 59.62%] [G loss: 0.711348] [Time: 0.148847]\n",
            "4972-7 [D loss: 0.689667, acc.: 46.15%] [G loss: 0.707449] [Time: 0.147784]\n",
            "4972-8 [D loss: 0.702252, acc.: 51.92%] [G loss: 0.717434] [Time: 0.147680]\n",
            "4972 (test) [D loss: 0.968056, acc.: 51.92%] [G loss: 0.770871] [Time: 0.043814]\n",
            "4973-0 [D loss: 0.691604, acc.: 40.38%] [G loss: 0.739851] [Time: 0.147389]\n",
            "4973-1 [D loss: 0.697604, acc.: 40.38%] [G loss: 0.706554] [Time: 0.148888]\n",
            "4973-2 [D loss: 0.701566, acc.: 44.23%] [G loss: 0.707231] [Time: 0.148839]\n",
            "4973-3 [D loss: 0.712769, acc.: 50.00%] [G loss: 0.735141] [Time: 0.148676]\n",
            "4973-4 [D loss: 0.690806, acc.: 48.08%] [G loss: 0.693076] [Time: 0.151144]\n",
            "4973-5 [D loss: 0.714774, acc.: 34.62%] [G loss: 0.709558] [Time: 0.153280]\n",
            "4973-6 [D loss: 0.686105, acc.: 57.69%] [G loss: 0.713356] [Time: 0.150791]\n",
            "4973-7 [D loss: 0.718254, acc.: 32.69%] [G loss: 0.688400] [Time: 0.148169]\n",
            "4973-8 [D loss: 0.715592, acc.: 42.31%] [G loss: 0.710055] [Time: 0.150947]\n",
            "4973 (test) [D loss: 0.993812, acc.: 50.00%] [G loss: 0.767447] [Time: 0.045644]\n",
            "4974-0 [D loss: 0.693394, acc.: 34.62%] [G loss: 0.744290] [Time: 0.151075]\n",
            "4974-1 [D loss: 0.701629, acc.: 38.46%] [G loss: 0.706993] [Time: 0.147294]\n",
            "4974-2 [D loss: 0.703211, acc.: 44.23%] [G loss: 0.693770] [Time: 0.148549]\n",
            "4974-3 [D loss: 0.706769, acc.: 44.23%] [G loss: 0.711091] [Time: 0.147503]\n",
            "4974-4 [D loss: 0.679554, acc.: 48.08%] [G loss: 0.700999] [Time: 0.148548]\n",
            "4974-5 [D loss: 0.697047, acc.: 55.77%] [G loss: 0.708762] [Time: 0.149884]\n",
            "4974-6 [D loss: 0.675494, acc.: 50.00%] [G loss: 0.732640] [Time: 0.148399]\n",
            "4974-7 [D loss: 0.698082, acc.: 36.54%] [G loss: 0.693257] [Time: 0.152460]\n",
            "4974-8 [D loss: 0.703200, acc.: 48.08%] [G loss: 0.686118] [Time: 0.149134]\n",
            "4974 (test) [D loss: 1.068824, acc.: 50.00%] [G loss: 0.570550] [Time: 0.043667]\n",
            "4975-0 [D loss: 0.683391, acc.: 42.31%] [G loss: 0.704751] [Time: 0.148249]\n",
            "4975-1 [D loss: 0.704283, acc.: 42.31%] [G loss: 0.699948] [Time: 0.149600]\n",
            "4975-2 [D loss: 0.699467, acc.: 42.31%] [G loss: 0.688509] [Time: 0.147832]\n",
            "4975-3 [D loss: 0.715198, acc.: 36.54%] [G loss: 0.709056] [Time: 0.148474]\n",
            "4975-4 [D loss: 0.681414, acc.: 48.08%] [G loss: 0.720401] [Time: 0.148239]\n",
            "4975-5 [D loss: 0.683353, acc.: 57.69%] [G loss: 0.709720] [Time: 0.149774]\n",
            "4975-6 [D loss: 0.666426, acc.: 61.54%] [G loss: 0.703253] [Time: 0.146854]\n",
            "4975-7 [D loss: 0.700073, acc.: 44.23%] [G loss: 0.682543] [Time: 0.148924]\n",
            "4975-8 [D loss: 0.697599, acc.: 46.15%] [G loss: 0.692686] [Time: 0.149168]\n",
            "4975 (test) [D loss: 1.092425, acc.: 50.00%] [G loss: 0.562882] [Time: 0.044319]\n",
            "4976-0 [D loss: 0.685095, acc.: 46.15%] [G loss: 0.740109] [Time: 0.151299]\n",
            "4976-1 [D loss: 0.695831, acc.: 46.15%] [G loss: 0.702795] [Time: 0.149353]\n",
            "4976-2 [D loss: 0.707951, acc.: 36.54%] [G loss: 0.687343] [Time: 0.149546]\n",
            "4976-3 [D loss: 0.703936, acc.: 48.08%] [G loss: 0.697949] [Time: 0.147967]\n",
            "4976-4 [D loss: 0.695177, acc.: 34.62%] [G loss: 0.717372] [Time: 0.148178]\n",
            "4976-5 [D loss: 0.695125, acc.: 42.31%] [G loss: 0.692457] [Time: 0.147723]\n",
            "4976-6 [D loss: 0.681261, acc.: 44.23%] [G loss: 0.705335] [Time: 0.147501]\n",
            "4976-7 [D loss: 0.684668, acc.: 44.23%] [G loss: 0.700746] [Time: 0.149819]\n",
            "4976-8 [D loss: 0.700103, acc.: 40.38%] [G loss: 0.679407] [Time: 0.147334]\n",
            "4976 (test) [D loss: 1.051919, acc.: 50.00%] [G loss: 0.578268] [Time: 0.043304]\n",
            "4977-0 [D loss: 0.693440, acc.: 40.38%] [G loss: 0.718626] [Time: 0.147410]\n",
            "4977-1 [D loss: 0.695380, acc.: 50.00%] [G loss: 0.691139] [Time: 0.148191]\n",
            "4977-2 [D loss: 0.706538, acc.: 30.77%] [G loss: 0.688055] [Time: 0.147142]\n",
            "4977-3 [D loss: 0.698657, acc.: 40.38%] [G loss: 0.710199] [Time: 0.148488]\n",
            "4977-4 [D loss: 0.681298, acc.: 42.31%] [G loss: 0.692267] [Time: 0.150391]\n",
            "4977-5 [D loss: 0.697692, acc.: 46.15%] [G loss: 0.686336] [Time: 0.147409]\n",
            "4977-6 [D loss: 0.678900, acc.: 53.85%] [G loss: 0.708052] [Time: 0.150568]\n",
            "4977-7 [D loss: 0.690207, acc.: 55.77%] [G loss: 0.693358] [Time: 0.147960]\n",
            "4977-8 [D loss: 0.706029, acc.: 42.31%] [G loss: 0.679778] [Time: 0.148649]\n",
            "4977 (test) [D loss: 1.172680, acc.: 51.92%] [G loss: 0.428738] [Time: 0.044865]\n",
            "4978-0 [D loss: 0.686942, acc.: 53.85%] [G loss: 0.724140] [Time: 0.148296]\n",
            "4978-1 [D loss: 0.697976, acc.: 44.23%] [G loss: 0.678558] [Time: 0.148498]\n",
            "4978-2 [D loss: 0.691875, acc.: 51.92%] [G loss: 0.672294] [Time: 0.149390]\n",
            "4978-3 [D loss: 0.700441, acc.: 44.23%] [G loss: 0.699862] [Time: 0.148315]\n",
            "4978-4 [D loss: 0.688918, acc.: 42.31%] [G loss: 0.694876] [Time: 0.149832]\n",
            "4978-5 [D loss: 0.698670, acc.: 34.62%] [G loss: 0.686058] [Time: 0.150060]\n",
            "4978-6 [D loss: 0.687277, acc.: 57.69%] [G loss: 0.710936] [Time: 0.151665]\n",
            "4978-7 [D loss: 0.696723, acc.: 50.00%] [G loss: 0.699762] [Time: 0.150692]\n",
            "4978-8 [D loss: 0.701421, acc.: 38.46%] [G loss: 0.685482] [Time: 0.150485]\n",
            "4978 (test) [D loss: 1.054874, acc.: 50.00%] [G loss: 0.564440] [Time: 0.042972]\n",
            "4979-0 [D loss: 0.675452, acc.: 51.92%] [G loss: 0.738348] [Time: 0.148121]\n",
            "4979-1 [D loss: 0.700081, acc.: 53.85%] [G loss: 0.709613] [Time: 0.151639]\n",
            "4979-2 [D loss: 0.707629, acc.: 36.54%] [G loss: 0.704318] [Time: 0.148155]\n",
            "4979-3 [D loss: 0.712821, acc.: 48.08%] [G loss: 0.722073] [Time: 0.150565]\n",
            "4979-4 [D loss: 0.684018, acc.: 44.23%] [G loss: 0.723135] [Time: 0.151231]\n",
            "4979-5 [D loss: 0.703290, acc.: 40.38%] [G loss: 0.726835] [Time: 0.148578]\n",
            "4979-6 [D loss: 0.692169, acc.: 40.38%] [G loss: 0.727904] [Time: 0.148667]\n",
            "4979-7 [D loss: 0.686499, acc.: 57.69%] [G loss: 0.704106] [Time: 0.151031]\n",
            "4979-8 [D loss: 0.728185, acc.: 40.38%] [G loss: 0.703072] [Time: 0.149283]\n",
            "4979 (test) [D loss: 0.965750, acc.: 51.92%] [G loss: 0.772638] [Time: 0.044467]\n",
            "4980-0 [D loss: 0.701809, acc.: 32.69%] [G loss: 0.743220] [Time: 0.149441]\n",
            "4980-1 [D loss: 0.693219, acc.: 42.31%] [G loss: 0.702521] [Time: 0.150623]\n",
            "4980-2 [D loss: 0.698712, acc.: 36.54%] [G loss: 0.698654] [Time: 0.148561]\n",
            "4980-3 [D loss: 0.696164, acc.: 46.15%] [G loss: 0.715057] [Time: 0.149179]\n",
            "4980-4 [D loss: 0.690953, acc.: 36.54%] [G loss: 0.723698] [Time: 0.147894]\n",
            "4980-5 [D loss: 0.703343, acc.: 36.54%] [G loss: 0.717883] [Time: 0.147941]\n",
            "4980-6 [D loss: 0.693456, acc.: 48.08%] [G loss: 0.702000] [Time: 0.150178]\n",
            "4980-7 [D loss: 0.703195, acc.: 42.31%] [G loss: 0.699312] [Time: 0.149979]\n",
            "4980-8 [D loss: 0.714840, acc.: 46.15%] [G loss: 0.682110] [Time: 0.147307]\n",
            "4980 (test) [D loss: 1.045281, acc.: 50.00%] [G loss: 0.699220] [Time: 0.045477]\n",
            "4981-0 [D loss: 0.700524, acc.: 40.38%] [G loss: 0.728389] [Time: 0.149806]\n",
            "4981-1 [D loss: 0.698288, acc.: 42.31%] [G loss: 0.697614] [Time: 0.149315]\n",
            "4981-2 [D loss: 0.692072, acc.: 40.38%] [G loss: 0.684811] [Time: 0.150694]\n",
            "4981-3 [D loss: 0.694354, acc.: 42.31%] [G loss: 0.708436] [Time: 0.149463]\n",
            "4981-4 [D loss: 0.687693, acc.: 42.31%] [G loss: 0.702902] [Time: 0.148233]\n",
            "4981-5 [D loss: 0.716087, acc.: 34.62%] [G loss: 0.693512] [Time: 0.147648]\n",
            "4981-6 [D loss: 0.695595, acc.: 46.15%] [G loss: 0.707969] [Time: 0.151937]\n",
            "4981-7 [D loss: 0.707733, acc.: 40.38%] [G loss: 0.708675] [Time: 0.153729]\n",
            "4981-8 [D loss: 0.714023, acc.: 38.46%] [G loss: 0.683732] [Time: 0.149467]\n",
            "4981 (test) [D loss: 1.066907, acc.: 51.92%] [G loss: 0.626731] [Time: 0.044109]\n",
            "4982-0 [D loss: 0.686428, acc.: 40.38%] [G loss: 0.747084] [Time: 0.150745]\n",
            "4982-1 [D loss: 0.703554, acc.: 36.54%] [G loss: 0.698618] [Time: 0.147745]\n",
            "4982-2 [D loss: 0.697104, acc.: 48.08%] [G loss: 0.680828] [Time: 0.147946]\n",
            "4982-3 [D loss: 0.696378, acc.: 44.23%] [G loss: 0.725936] [Time: 0.149748]\n",
            "4982-4 [D loss: 0.676705, acc.: 53.85%] [G loss: 0.706900] [Time: 0.149396]\n",
            "4982-5 [D loss: 0.712737, acc.: 42.31%] [G loss: 0.694480] [Time: 0.149662]\n",
            "4982-6 [D loss: 0.703161, acc.: 48.08%] [G loss: 0.684413] [Time: 0.149545]\n",
            "4982-7 [D loss: 0.704747, acc.: 44.23%] [G loss: 0.699920] [Time: 0.148351]\n",
            "4982-8 [D loss: 0.690462, acc.: 40.38%] [G loss: 0.684100] [Time: 0.147860]\n",
            "4982 (test) [D loss: 1.135240, acc.: 50.00%] [G loss: 0.573406] [Time: 0.044547]\n",
            "4983-0 [D loss: 0.690448, acc.: 40.38%] [G loss: 0.751269] [Time: 0.150553]\n",
            "4983-1 [D loss: 0.691029, acc.: 50.00%] [G loss: 0.692921] [Time: 0.147959]\n",
            "4983-2 [D loss: 0.718901, acc.: 25.00%] [G loss: 0.690419] [Time: 0.150245]\n",
            "4983-3 [D loss: 0.713682, acc.: 36.54%] [G loss: 0.719854] [Time: 0.151231]\n",
            "4983-4 [D loss: 0.676292, acc.: 50.00%] [G loss: 0.708742] [Time: 0.149150]\n",
            "4983-5 [D loss: 0.705150, acc.: 38.46%] [G loss: 0.695014] [Time: 0.150121]\n",
            "4983-6 [D loss: 0.683286, acc.: 46.15%] [G loss: 0.701103] [Time: 0.151428]\n",
            "4983-7 [D loss: 0.702141, acc.: 44.23%] [G loss: 0.707800] [Time: 0.148253]\n",
            "4983-8 [D loss: 0.688698, acc.: 53.85%] [G loss: 0.691504] [Time: 0.149211]\n",
            "4983 (test) [D loss: 1.168345, acc.: 48.08%] [G loss: 0.517511] [Time: 0.044663]\n",
            "4984-0 [D loss: 0.702333, acc.: 42.31%] [G loss: 0.747647] [Time: 0.151960]\n",
            "4984-1 [D loss: 0.706396, acc.: 34.62%] [G loss: 0.695378] [Time: 0.155372]\n",
            "4984-2 [D loss: 0.694307, acc.: 53.85%] [G loss: 0.695816] [Time: 0.149764]\n",
            "4984-3 [D loss: 0.701530, acc.: 55.77%] [G loss: 0.727450] [Time: 0.148220]\n",
            "4984-4 [D loss: 0.681115, acc.: 46.15%] [G loss: 0.710036] [Time: 0.152535]\n",
            "4984-5 [D loss: 0.717390, acc.: 26.92%] [G loss: 0.701823] [Time: 0.148472]\n",
            "4984-6 [D loss: 0.697888, acc.: 38.46%] [G loss: 0.702809] [Time: 0.149535]\n",
            "4984-7 [D loss: 0.703672, acc.: 28.85%] [G loss: 0.698818] [Time: 0.150764]\n",
            "4984-8 [D loss: 0.690173, acc.: 51.92%] [G loss: 0.701080] [Time: 0.149538]\n",
            "4984 (test) [D loss: 1.158344, acc.: 50.00%] [G loss: 0.491191] [Time: 0.044268]\n",
            "4985-0 [D loss: 0.692765, acc.: 38.46%] [G loss: 0.747411] [Time: 0.148738]\n",
            "4985-1 [D loss: 0.718864, acc.: 46.15%] [G loss: 0.700209] [Time: 0.148069]\n",
            "4985-2 [D loss: 0.699133, acc.: 48.08%] [G loss: 0.703180] [Time: 0.147751]\n",
            "4985-3 [D loss: 0.699493, acc.: 50.00%] [G loss: 0.742528] [Time: 0.146729]\n",
            "4985-4 [D loss: 0.681938, acc.: 40.38%] [G loss: 0.703319] [Time: 0.151419]\n",
            "4985-5 [D loss: 0.710951, acc.: 42.31%] [G loss: 0.685577] [Time: 0.153567]\n",
            "4985-6 [D loss: 0.691713, acc.: 55.77%] [G loss: 0.697371] [Time: 0.155376]\n",
            "4985-7 [D loss: 0.697672, acc.: 48.08%] [G loss: 0.710672] [Time: 0.150883]\n",
            "4985-8 [D loss: 0.697597, acc.: 44.23%] [G loss: 0.701655] [Time: 0.149468]\n",
            "4985 (test) [D loss: 0.988384, acc.: 51.92%] [G loss: 0.668272] [Time: 0.044611]\n",
            "4986-0 [D loss: 0.683324, acc.: 55.77%] [G loss: 0.727405] [Time: 0.149699]\n",
            "4986-1 [D loss: 0.711466, acc.: 34.62%] [G loss: 0.707620] [Time: 0.150617]\n",
            "4986-2 [D loss: 0.703770, acc.: 26.92%] [G loss: 0.702856] [Time: 0.148312]\n",
            "4986-3 [D loss: 0.704832, acc.: 50.00%] [G loss: 0.730958] [Time: 0.148945]\n",
            "4986-4 [D loss: 0.678909, acc.: 48.08%] [G loss: 0.719145] [Time: 0.151981]\n",
            "4986-5 [D loss: 0.700888, acc.: 46.15%] [G loss: 0.700633] [Time: 0.150207]\n",
            "4986-6 [D loss: 0.691463, acc.: 48.08%] [G loss: 0.695260] [Time: 0.158829]\n",
            "4986-7 [D loss: 0.691225, acc.: 53.85%] [G loss: 0.700111] [Time: 0.147660]\n",
            "4986-8 [D loss: 0.698601, acc.: 38.46%] [G loss: 0.706670] [Time: 0.151525]\n",
            "4986 (test) [D loss: 1.097697, acc.: 51.92%] [G loss: 0.587482] [Time: 0.044328]\n",
            "4987-0 [D loss: 0.690915, acc.: 40.38%] [G loss: 0.717557] [Time: 0.147496]\n",
            "4987-1 [D loss: 0.710203, acc.: 32.69%] [G loss: 0.708826] [Time: 0.148382]\n",
            "4987-2 [D loss: 0.708092, acc.: 38.46%] [G loss: 0.690593] [Time: 0.147627]\n",
            "4987-3 [D loss: 0.707400, acc.: 48.08%] [G loss: 0.712943] [Time: 0.146739]\n",
            "4987-4 [D loss: 0.681642, acc.: 42.31%] [G loss: 0.720978] [Time: 0.147266]\n",
            "4987-5 [D loss: 0.702111, acc.: 40.38%] [G loss: 0.696739] [Time: 0.151686]\n",
            "4987-6 [D loss: 0.697601, acc.: 44.23%] [G loss: 0.695721] [Time: 0.148356]\n",
            "4987-7 [D loss: 0.698555, acc.: 44.23%] [G loss: 0.713780] [Time: 0.146919]\n",
            "4987-8 [D loss: 0.709590, acc.: 38.46%] [G loss: 0.687645] [Time: 0.148650]\n",
            "4987 (test) [D loss: 1.159372, acc.: 50.00%] [G loss: 0.537194] [Time: 0.043508]\n",
            "4988-0 [D loss: 0.691930, acc.: 38.46%] [G loss: 0.713190] [Time: 0.149918]\n",
            "4988-1 [D loss: 0.691424, acc.: 50.00%] [G loss: 0.703578] [Time: 0.147247]\n",
            "4988-2 [D loss: 0.702496, acc.: 44.23%] [G loss: 0.689244] [Time: 0.149438]\n",
            "4988-3 [D loss: 0.708240, acc.: 48.08%] [G loss: 0.708959] [Time: 0.147870]\n",
            "4988-4 [D loss: 0.669293, acc.: 50.00%] [G loss: 0.696817] [Time: 0.147732]\n",
            "4988-5 [D loss: 0.707314, acc.: 36.54%] [G loss: 0.705583] [Time: 0.154173]\n",
            "4988-6 [D loss: 0.684806, acc.: 53.85%] [G loss: 0.704493] [Time: 0.148737]\n",
            "4988-7 [D loss: 0.706537, acc.: 36.54%] [G loss: 0.701878] [Time: 0.147897]\n",
            "4988-8 [D loss: 0.697996, acc.: 48.08%] [G loss: 0.671563] [Time: 0.155500]\n",
            "4988 (test) [D loss: 1.226178, acc.: 50.00%] [G loss: 0.444688] [Time: 0.044365]\n",
            "4989-0 [D loss: 0.700738, acc.: 38.46%] [G loss: 0.710592] [Time: 0.147231]\n",
            "4989-1 [D loss: 0.704019, acc.: 38.46%] [G loss: 0.712625] [Time: 0.149691]\n",
            "4989-2 [D loss: 0.700568, acc.: 38.46%] [G loss: 0.691800] [Time: 0.150872]\n",
            "4989-3 [D loss: 0.703709, acc.: 34.62%] [G loss: 0.708438] [Time: 0.148291]\n",
            "4989-4 [D loss: 0.689219, acc.: 42.31%] [G loss: 0.692756] [Time: 0.150114]\n",
            "4989-5 [D loss: 0.698979, acc.: 44.23%] [G loss: 0.698224] [Time: 0.146949]\n",
            "4989-6 [D loss: 0.695761, acc.: 48.08%] [G loss: 0.694771] [Time: 0.148052]\n",
            "4989-7 [D loss: 0.694270, acc.: 53.85%] [G loss: 0.699216] [Time: 0.148832]\n",
            "4989-8 [D loss: 0.695361, acc.: 32.69%] [G loss: 0.697420] [Time: 0.147155]\n",
            "4989 (test) [D loss: 1.199860, acc.: 50.00%] [G loss: 0.456671] [Time: 0.044755]\n",
            "4990-0 [D loss: 0.684893, acc.: 44.23%] [G loss: 0.735395] [Time: 0.147616]\n",
            "4990-1 [D loss: 0.703773, acc.: 42.31%] [G loss: 0.683068] [Time: 0.149062]\n",
            "4990-2 [D loss: 0.696412, acc.: 50.00%] [G loss: 0.685004] [Time: 0.148034]\n",
            "4990-3 [D loss: 0.706651, acc.: 48.08%] [G loss: 0.728382] [Time: 0.147190]\n",
            "4990-4 [D loss: 0.687685, acc.: 44.23%] [G loss: 0.705168] [Time: 0.153895]\n",
            "4990-5 [D loss: 0.699647, acc.: 46.15%] [G loss: 0.703251] [Time: 0.148913]\n",
            "4990-6 [D loss: 0.712178, acc.: 36.54%] [G loss: 0.701599] [Time: 0.148129]\n",
            "4990-7 [D loss: 0.697816, acc.: 32.69%] [G loss: 0.711663] [Time: 0.147551]\n",
            "4990-8 [D loss: 0.699741, acc.: 44.23%] [G loss: 0.683517] [Time: 0.147710]\n",
            "4990 (test) [D loss: 1.232022, acc.: 50.00%] [G loss: 0.438566] [Time: 0.045683]\n",
            "4991-0 [D loss: 0.705063, acc.: 36.54%] [G loss: 0.726730] [Time: 0.147646]\n",
            "4991-1 [D loss: 0.716943, acc.: 38.46%] [G loss: 0.677375] [Time: 0.147943]\n",
            "4991-2 [D loss: 0.689571, acc.: 48.08%] [G loss: 0.694520] [Time: 0.147763]\n",
            "4991-3 [D loss: 0.707618, acc.: 36.54%] [G loss: 0.715040] [Time: 0.149357]\n",
            "4991-4 [D loss: 0.690032, acc.: 44.23%] [G loss: 0.683799] [Time: 0.146850]\n",
            "4991-5 [D loss: 0.698171, acc.: 42.31%] [G loss: 0.675880] [Time: 0.147691]\n",
            "4991-6 [D loss: 0.694629, acc.: 46.15%] [G loss: 0.689647] [Time: 0.150051]\n",
            "4991-7 [D loss: 0.703939, acc.: 44.23%] [G loss: 0.703169] [Time: 0.150676]\n",
            "4991-8 [D loss: 0.696755, acc.: 38.46%] [G loss: 0.709878] [Time: 0.149428]\n",
            "4991 (test) [D loss: 1.209116, acc.: 50.00%] [G loss: 0.478370] [Time: 0.044887]\n",
            "4992-0 [D loss: 0.682273, acc.: 40.38%] [G loss: 0.725836] [Time: 0.148991]\n",
            "4992-1 [D loss: 0.701764, acc.: 38.46%] [G loss: 0.683849] [Time: 0.151335]\n",
            "4992-2 [D loss: 0.707830, acc.: 40.38%] [G loss: 0.669515] [Time: 0.147944]\n",
            "4992-3 [D loss: 0.700407, acc.: 48.08%] [G loss: 0.711401] [Time: 0.148249]\n",
            "4992-4 [D loss: 0.684002, acc.: 44.23%] [G loss: 0.688826] [Time: 0.149253]\n",
            "4992-5 [D loss: 0.702729, acc.: 34.62%] [G loss: 0.702659] [Time: 0.150346]\n",
            "4992-6 [D loss: 0.692087, acc.: 42.31%] [G loss: 0.692506] [Time: 0.148714]\n",
            "4992-7 [D loss: 0.699808, acc.: 51.92%] [G loss: 0.706351] [Time: 0.147838]\n",
            "4992-8 [D loss: 0.699411, acc.: 40.38%] [G loss: 0.699333] [Time: 0.147563]\n",
            "4992 (test) [D loss: 1.192930, acc.: 51.92%] [G loss: 0.485371] [Time: 0.043417]\n",
            "4993-0 [D loss: 0.700379, acc.: 30.77%] [G loss: 0.735106] [Time: 0.148391]\n",
            "4993-1 [D loss: 0.700572, acc.: 46.15%] [G loss: 0.698969] [Time: 0.147618]\n",
            "4993-2 [D loss: 0.707222, acc.: 40.38%] [G loss: 0.681800] [Time: 0.148676]\n",
            "4993-3 [D loss: 0.707393, acc.: 40.38%] [G loss: 0.723029] [Time: 0.150195]\n",
            "4993-4 [D loss: 0.662383, acc.: 48.08%] [G loss: 0.695402] [Time: 0.146911]\n",
            "4993-5 [D loss: 0.706612, acc.: 36.54%] [G loss: 0.703527] [Time: 0.149743]\n",
            "4993-6 [D loss: 0.687179, acc.: 50.00%] [G loss: 0.690747] [Time: 0.149981]\n",
            "4993-7 [D loss: 0.702253, acc.: 44.23%] [G loss: 0.708936] [Time: 0.148679]\n",
            "4993-8 [D loss: 0.716839, acc.: 40.38%] [G loss: 0.706464] [Time: 0.149619]\n",
            "4993 (test) [D loss: 1.008486, acc.: 50.00%] [G loss: 0.741196] [Time: 0.046837]\n",
            "4994-0 [D loss: 0.686542, acc.: 48.08%] [G loss: 0.757037] [Time: 0.148410]\n",
            "4994-1 [D loss: 0.707467, acc.: 42.31%] [G loss: 0.695684] [Time: 0.149419]\n",
            "4994-2 [D loss: 0.700951, acc.: 34.62%] [G loss: 0.694543] [Time: 0.147585]\n",
            "4994-3 [D loss: 0.705513, acc.: 59.62%] [G loss: 0.721139] [Time: 0.149317]\n",
            "4994-4 [D loss: 0.676882, acc.: 46.15%] [G loss: 0.710275] [Time: 0.148157]\n",
            "4994-5 [D loss: 0.707421, acc.: 32.69%] [G loss: 0.716941] [Time: 0.146664]\n",
            "4994-6 [D loss: 0.693265, acc.: 46.15%] [G loss: 0.710932] [Time: 0.151087]\n",
            "4994-7 [D loss: 0.710500, acc.: 34.62%] [G loss: 0.706619] [Time: 0.147639]\n",
            "4994-8 [D loss: 0.708163, acc.: 38.46%] [G loss: 0.709911] [Time: 0.149538]\n",
            "4994 (test) [D loss: 1.027085, acc.: 50.00%] [G loss: 0.808593] [Time: 0.044613]\n",
            "4995-0 [D loss: 0.683423, acc.: 40.38%] [G loss: 0.722445] [Time: 0.147202]\n",
            "4995-1 [D loss: 0.698023, acc.: 38.46%] [G loss: 0.691057] [Time: 0.147885]\n",
            "4995-2 [D loss: 0.703794, acc.: 48.08%] [G loss: 0.684655] [Time: 0.146828]\n",
            "4995-3 [D loss: 0.708148, acc.: 53.85%] [G loss: 0.706335] [Time: 0.149007]\n",
            "4995-4 [D loss: 0.672794, acc.: 50.00%] [G loss: 0.715582] [Time: 0.148429]\n",
            "4995-5 [D loss: 0.708549, acc.: 44.23%] [G loss: 0.708141] [Time: 0.148782]\n",
            "4995-6 [D loss: 0.701857, acc.: 40.38%] [G loss: 0.701583] [Time: 0.147940]\n",
            "4995-7 [D loss: 0.699392, acc.: 40.38%] [G loss: 0.711361] [Time: 0.150399]\n",
            "4995-8 [D loss: 0.714998, acc.: 30.77%] [G loss: 0.685546] [Time: 0.147619]\n",
            "4995 (test) [D loss: 1.056313, acc.: 50.00%] [G loss: 0.761537] [Time: 0.043515]\n",
            "4996-0 [D loss: 0.691216, acc.: 50.00%] [G loss: 0.743227] [Time: 0.147287]\n",
            "4996-1 [D loss: 0.700821, acc.: 42.31%] [G loss: 0.693796] [Time: 0.148413]\n",
            "4996-2 [D loss: 0.708486, acc.: 32.69%] [G loss: 0.692473] [Time: 0.148300]\n",
            "4996-3 [D loss: 0.695478, acc.: 55.77%] [G loss: 0.719311] [Time: 0.153116]\n",
            "4996-4 [D loss: 0.691292, acc.: 44.23%] [G loss: 0.679545] [Time: 0.150429]\n",
            "4996-5 [D loss: 0.709331, acc.: 34.62%] [G loss: 0.682758] [Time: 0.149642]\n",
            "4996-6 [D loss: 0.686779, acc.: 46.15%] [G loss: 0.697140] [Time: 0.149327]\n",
            "4996-7 [D loss: 0.701349, acc.: 42.31%] [G loss: 0.707419] [Time: 0.151819]\n",
            "4996-8 [D loss: 0.712118, acc.: 34.62%] [G loss: 0.706428] [Time: 0.152332]\n",
            "4996 (test) [D loss: 1.229940, acc.: 48.08%] [G loss: 0.490922] [Time: 0.045021]\n",
            "4997-0 [D loss: 0.697786, acc.: 44.23%] [G loss: 0.724569] [Time: 0.148054]\n",
            "4997-1 [D loss: 0.701567, acc.: 44.23%] [G loss: 0.712487] [Time: 0.150540]\n",
            "4997-2 [D loss: 0.705644, acc.: 42.31%] [G loss: 0.681587] [Time: 0.147558]\n",
            "4997-3 [D loss: 0.695214, acc.: 50.00%] [G loss: 0.705604] [Time: 0.153370]\n",
            "4997-4 [D loss: 0.696840, acc.: 34.62%] [G loss: 0.718728] [Time: 0.149065]\n",
            "4997-5 [D loss: 0.707000, acc.: 40.38%] [G loss: 0.711941] [Time: 0.147835]\n",
            "4997-6 [D loss: 0.696424, acc.: 46.15%] [G loss: 0.696611] [Time: 0.148366]\n",
            "4997-7 [D loss: 0.700748, acc.: 44.23%] [G loss: 0.703994] [Time: 0.148620]\n",
            "4997-8 [D loss: 0.695906, acc.: 34.62%] [G loss: 0.684295] [Time: 0.149259]\n",
            "4997 (test) [D loss: 1.173652, acc.: 46.15%] [G loss: 0.520693] [Time: 0.043650]\n",
            "4998-0 [D loss: 0.697417, acc.: 34.62%] [G loss: 0.695885] [Time: 0.151929]\n",
            "4998-1 [D loss: 0.696780, acc.: 44.23%] [G loss: 0.689461] [Time: 0.147970]\n",
            "4998-2 [D loss: 0.699015, acc.: 38.46%] [G loss: 0.705929] [Time: 0.146970]\n",
            "4998-3 [D loss: 0.692369, acc.: 50.00%] [G loss: 0.722726] [Time: 0.148582]\n",
            "4998-4 [D loss: 0.673722, acc.: 53.85%] [G loss: 0.676310] [Time: 0.147486]\n",
            "4998-5 [D loss: 0.706103, acc.: 44.23%] [G loss: 0.694379] [Time: 0.147324]\n",
            "4998-6 [D loss: 0.693755, acc.: 38.46%] [G loss: 0.702074] [Time: 0.149280]\n",
            "4998-7 [D loss: 0.695773, acc.: 51.92%] [G loss: 0.707089] [Time: 0.152259]\n",
            "4998-8 [D loss: 0.702812, acc.: 50.00%] [G loss: 0.679844] [Time: 0.148249]\n",
            "4998 (test) [D loss: 1.190223, acc.: 48.08%] [G loss: 0.480207] [Time: 0.044256]\n",
            "4999-0 [D loss: 0.709258, acc.: 32.69%] [G loss: 0.718898] [Time: 0.148111]\n",
            "4999-1 [D loss: 0.701140, acc.: 36.54%] [G loss: 0.685598] [Time: 0.148387]\n",
            "4999-2 [D loss: 0.693775, acc.: 50.00%] [G loss: 0.685366] [Time: 0.148878]\n",
            "4999-3 [D loss: 0.696113, acc.: 59.62%] [G loss: 0.693678] [Time: 0.151076]\n",
            "4999-4 [D loss: 0.683093, acc.: 51.92%] [G loss: 0.681493] [Time: 0.147754]\n",
            "4999-5 [D loss: 0.713884, acc.: 38.46%] [G loss: 0.692618] [Time: 0.149359]\n",
            "4999-6 [D loss: 0.685785, acc.: 46.15%] [G loss: 0.715105] [Time: 0.150636]\n",
            "4999-7 [D loss: 0.708916, acc.: 44.23%] [G loss: 0.682840] [Time: 0.149690]\n",
            "4999-8 [D loss: 0.715123, acc.: 38.46%] [G loss: 0.688363] [Time: 0.152300]\n",
            "4999 (test) [D loss: 1.120353, acc.: 48.08%] [G loss: 0.517281] [Time: 0.043690]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KCrddzetBYb",
        "colab_type": "code",
        "outputId": "cf92980c-3f0f-4a46-8e9f-107d13d62e08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 cgan_emoji.py 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From cgan_emoji.py:26: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From cgan_emoji.py:27: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From cgan_emoji.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-03-22 12:44:40.919466: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-03-22 12:44:40.919642: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2970a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-22 12:44:40.919671: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-03-22 12:44:40.921551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-03-22 12:44:41.038729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 12:44:41.039337: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2970bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-22 12:44:41.039366: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-03-22 12:44:41.039525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 12:44:41.039890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-22 12:44:41.040204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-22 12:44:41.041664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-22 12:44:41.043236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-03-22 12:44:41.043550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-03-22 12:44:41.044949: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-03-22 12:44:41.045581: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-03-22 12:44:41.048386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-22 12:44:41.048497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 12:44:41.048885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 12:44:41.049228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-03-22 12:44:41.049290: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-22 12:44:41.050253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-22 12:44:41.050280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-03-22 12:44:41.050290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-03-22 12:44:41.050393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 12:44:41.050776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 12:44:41.051135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "Using colab GPU\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "d_input (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 64)   1792        d_input[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 64)   0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 16, 16, 128)  73856       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 17, 17, 128)  0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 17, 17, 128)  512         zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 17, 17, 128)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 17, 17, 128)  0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 17, 17, 256)  295168      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 17, 17, 256)  1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 17, 17, 256)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 17, 17, 256)  0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "cond_d_input (InputLayer)       (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 9, 9, 512)    1180160     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          30100       cond_d_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 9, 9, 512)    2048        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 1, 100)    0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 9, 9, 512)    0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 9, 9, 100)    0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 9, 9, 612)    0           leaky_re_lu_4[0][0]              \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 9, 9, 512)    2820608     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 9, 9, 512)    2048        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 9, 9, 512)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 9, 9, 512)    0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 41472)        0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            41473       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,448,789\n",
            "Trainable params: 4,445,973\n",
            "Non-trainable params: 2,816\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "cond_g_input (InputLayer)       (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "g_input (InputLayer)            (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 100)          30100       cond_g_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 200)          0           g_input[0][0]                    \n",
            "                                                                 dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 16384)        3293184     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 8, 8, 256)    0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 256)  0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 256)  590080      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 256)  1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 16, 16, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 256)  0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 128)  295040      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 128)  0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 64)   73792       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 64, 64)   256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 64, 64, 3)    1731        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64, 64, 3)    0           conv2d_9[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 4,285,719\n",
            "Trainable params: 4,284,823\n",
            "Non-trainable params: 896\n",
            "__________________________________________________________________________________________________\n",
            "Acquiring images & labels...\n",
            "Done!\n",
            ">>> Dataset Size: 260\n",
            "Loading model...\n",
            "Generating images...\n",
            "2020-03-22 12:45:10.514699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-22 12:45:10.761921: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOAtDZmF3LIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nxzhDaBUHRg",
        "colab_type": "code",
        "outputId": "0ad90408-9681-47e9-d229-9bacbddb5f03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 classifier.py 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/EmojiGAN/cgan_emoji.py:26: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/EmojiGAN/cgan_emoji.py:27: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/EmojiGAN/cgan_emoji.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-03-22 13:11:21.091440: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-03-22 13:11:21.091639: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2298a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-22 13:11:21.091670: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-03-22 13:11:21.093637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-03-22 13:11:21.210871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 13:11:21.211506: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2298bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-22 13:11:21.211538: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-03-22 13:11:21.211737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 13:11:21.212125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-22 13:11:21.212428: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-22 13:11:21.214084: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-22 13:11:21.215602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-03-22 13:11:21.215894: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-03-22 13:11:21.217300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-03-22 13:11:21.217928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-03-22 13:11:21.220766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-22 13:11:21.220862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 13:11:21.221244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 13:11:21.221551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-03-22 13:11:21.221602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-22 13:11:21.222609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-22 13:11:21.222631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-03-22 13:11:21.222641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-03-22 13:11:21.222747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 13:11:21.223179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 13:11:21.223531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "Using colab GPU\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "classifier_input (InputLayer (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 60, 60, 64)        4864      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 56, 56, 128)       204928    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 100352)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               12845184  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 82)                10578     \n",
            "=================================================================\n",
            "Total params: 13,065,554\n",
            "Trainable params: 13,065,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Acquiring images & labels...\n",
            ">>> Dataset Size: 260\n",
            ">>> Dataset Size: 260\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 234 samples, validate on 26 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "2020-03-22 13:11:23.247553: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-22 13:11:23.512911: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "234/234 [==============================] - 3s 13ms/step - loss: 5.5251 - acc: 0.0513 - val_loss: 4.3323 - val_acc: 0.0769\n",
            "Epoch 2/100\n",
            "234/234 [==============================] - 0s 2ms/step - loss: 3.9027 - acc: 0.1795 - val_loss: 3.9470 - val_acc: 0.0769\n",
            "Epoch 3/100\n",
            "234/234 [==============================] - 0s 2ms/step - loss: 3.1398 - acc: 0.2991 - val_loss: 3.3247 - val_acc: 0.4615\n",
            "Epoch 4/100\n",
            "234/234 [==============================] - 0s 2ms/step - loss: 2.0748 - acc: 0.5342 - val_loss: 1.7019 - val_acc: 0.5000\n",
            "Epoch 5/100\n",
            "234/234 [==============================] - 0s 2ms/step - loss: 1.6148 - acc: 0.6667 - val_loss: 1.4431 - val_acc: 0.7692\n",
            "Epoch 6/100\n",
            "234/234 [==============================] - 0s 2ms/step - loss: 1.1571 - acc: 0.7692 - val_loss: 0.7894 - val_acc: 0.8462\n",
            "Epoch 7/100\n",
            "234/234 [==============================] - 0s 2ms/step - loss: 0.5978 - acc: 0.8547 - val_loss: 0.3003 - val_acc: 0.8846\n",
            "Epoch 8/100\n",
            "234/234 [==============================] - 0s 2ms/step - loss: 0.3611 - acc: 0.8675 - val_loss: 0.1989 - val_acc: 0.9231\n",
            "Epoch 9/100\n",
            "234/234 [==============================] - 0s 2ms/step - loss: 0.2924 - acc: 0.9231 - val_loss: 0.0398 - val_acc: 1.0000\n",
            "Epoch 10/100\n",
            "234/234 [==============================] - 0s 2ms/step - loss: 0.2160 - acc: 0.9274 - val_loss: 0.1004 - val_acc: 0.9615\n",
            "Epoch 11/100\n",
            "234/234 [==============================] - 0s 2ms/step - loss: 0.1625 - acc: 0.9701 - val_loss: 0.0162 - val_acc: 1.0000\n",
            "Epoch 12/100\n",
            "234/234 [==============================] - 0s 2ms/step - loss: 0.2092 - acc: 0.9359 - val_loss: 0.0205 - val_acc: 1.0000\n",
            "Epoch 13/100\n",
            "234/234 [==============================] - 0s 2ms/step - loss: 0.1453 - acc: 0.9658 - val_loss: 0.0166 - val_acc: 1.0000\n",
            "Epoch 00013: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz6x9kqqUH0h",
        "colab_type": "code",
        "outputId": "17cd07ed-3732-413b-eaf0-f721dfedb4fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 classifier.py 1 ./saved_model/classifier_weights.h5 ./saved_model/generator_weights.h5 ./saved_model/discriminator_weights.h5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/EmojiGAN/cgan_emoji.py:26: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/EmojiGAN/cgan_emoji.py:27: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/EmojiGAN/cgan_emoji.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-03-22 13:58:18.535600: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-03-22 13:58:18.535792: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x12bea00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-22 13:58:18.535823: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-03-22 13:58:18.537850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-03-22 13:58:18.633637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 13:58:18.634216: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x12bebc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-22 13:58:18.634244: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-03-22 13:58:18.634395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 13:58:18.634719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-22 13:58:18.635018: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-22 13:58:18.636540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-22 13:58:18.638243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-03-22 13:58:18.638573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-03-22 13:58:18.640285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-03-22 13:58:18.641125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-03-22 13:58:18.645152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-22 13:58:18.645282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 13:58:18.645924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 13:58:18.646701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-03-22 13:58:18.646840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-22 13:58:18.648033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-22 13:58:18.648061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-03-22 13:58:18.648072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-03-22 13:58:18.648172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 13:58:18.648575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 13:58:18.648938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "Using colab GPU\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "d_input (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 64)   1792        d_input[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 64)   0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 16, 16, 128)  73856       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 17, 17, 128)  0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 17, 17, 128)  512         zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 17, 17, 128)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 17, 17, 128)  0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 17, 17, 256)  295168      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 17, 17, 256)  1024        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 17, 17, 256)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 17, 17, 256)  0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "cond_d_input (InputLayer)       (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 9, 9, 512)    1180160     dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 100)          30100       cond_d_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 9, 9, 512)    2048        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 1, 100)    0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 9, 9, 512)    0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 9, 9, 100)    0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 9, 9, 612)    0           leaky_re_lu_4[0][0]              \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 9, 9, 512)    2820608     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 9, 9, 512)    2048        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 9, 9, 512)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 9, 9, 512)    0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 41472)        0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            41473       flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,448,789\n",
            "Trainable params: 4,445,973\n",
            "Non-trainable params: 2,816\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "cond_g_input (InputLayer)       (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "g_input (InputLayer)            (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 100)          30100       cond_g_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 200)          0           g_input[0][0]                    \n",
            "                                                                 dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 16384)        3293184     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 8, 8, 256)    0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 256)  0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 256)  590080      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 256)  1024        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 16, 16, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 256)  0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 128)  295040      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 128)  0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 64, 64, 64)   73792       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 64, 64)   256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 64, 64, 3)    1731        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64, 64, 3)    0           conv2d_11[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,285,719\n",
            "Trainable params: 4,284,823\n",
            "Non-trainable params: 896\n",
            "__________________________________________________________________________________________________\n",
            "Acquiring images & labels...\n",
            "Done!\n",
            ">>> Dataset Size: 260\n",
            "(259,)\n",
            "(1,)\n",
            "Loading model...\n",
            "(260, 64, 64, 3)\n",
            "Generating images...\n",
            "2020-03-22 13:58:48.902408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-22 13:58:49.153779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            ">>> Dataset Size: 260\n",
            ">>> Dataset Size: 260\n",
            "260/260 [==============================] - 0s 954us/step\n",
            "Accuracy: 0.8769230723381043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzk9_1S0VJya",
        "colab_type": "code",
        "outputId": "e169bbdf-26fd-41f7-e5ee-b2e9459d5476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 inception_score.py ./saved_model/generator_weights.h5 ./saved_model/discriminator_weights.h5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/EmojiGAN/cgan_emoji.py:26: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/EmojiGAN/cgan_emoji.py:27: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/EmojiGAN/cgan_emoji.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-03-22 14:13:19.964699: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-03-22 14:13:19.964876: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1c22a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-22 14:13:19.964907: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-03-22 14:13:19.966744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-03-22 14:13:20.086878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 14:13:20.087513: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1c22bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-22 14:13:20.087542: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-03-22 14:13:20.087684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 14:13:20.088052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-22 14:13:20.088319: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-22 14:13:20.089675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-22 14:13:20.091232: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-03-22 14:13:20.091535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-03-22 14:13:20.093076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-03-22 14:13:20.093791: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-03-22 14:13:20.096727: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-22 14:13:20.096849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 14:13:20.097477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 14:13:20.097855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-03-22 14:13:20.097917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-22 14:13:20.099044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-22 14:13:20.099070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-03-22 14:13:20.099081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-03-22 14:13:20.099180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 14:13:20.099576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-22 14:13:20.099944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "Using colab GPU\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Acquiring images & labels...\n",
            "Done!\n",
            ">>> Dataset Size: 260\n",
            "(259,)\n",
            "(1,)\n",
            "(260, 64, 64, 3)\n",
            "(260,)\n",
            "Complete data loading!\n",
            "2020-03-22 14:13:33.379231: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-22 14:13:33.592829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "d_input (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 32, 32, 64)   1792        d_input[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 64)   0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 16, 16, 128)  73856       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 17, 17, 128)  0           conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 17, 17, 128)  512         zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 17, 17, 128)  0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 17, 17, 128)  0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 17, 17, 256)  295168      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 17, 17, 256)  1024        conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 17, 17, 256)  0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 17, 17, 256)  0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "cond_d_input (InputLayer)       (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 9, 9, 512)    1180160     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          30100       cond_d_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 9, 9, 512)    2048        conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 1, 100)    0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 9, 9, 512)    0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 9, 9, 100)    0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 9, 9, 612)    0           leaky_re_lu_4[0][0]              \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 9, 9, 512)    2820608     concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 9, 9, 512)    2048        conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 9, 9, 512)    0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 9, 9, 512)    0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 41472)        0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            41473       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,448,789\n",
            "Trainable params: 4,445,973\n",
            "Non-trainable params: 2,816\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "cond_g_input (InputLayer)       (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "g_input (InputLayer)            (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 100)          30100       cond_g_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 200)          0           g_input[0][0]                    \n",
            "                                                                 dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 16384)        3293184     concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 8, 8, 256)    0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 256)  0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 256)  590080      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 16, 16, 256)  1024        conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 16, 16, 256)  0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 256)  0           activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 32, 32, 128)  295040      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 32, 32, 128)  512         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 32, 32, 128)  0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 128)  0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 64, 64, 64)   73792       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 64, 64, 64)   256         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 64, 64, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 64, 64, 3)    1731        activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 64, 64, 3)    0           conv2d_103[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 4,285,719\n",
            "Trainable params: 4,284,823\n",
            "Non-trainable params: 896\n",
            "__________________________________________________________________________________________________\n",
            "Loading model...\n",
            "Generating images...\n",
            "Dataset score: 1.515485405921936, Generated score: 1.4674062728881836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0XPoqYp6zBV",
        "colab_type": "code",
        "outputId": "92be5cbb-1c6f-4e9c-d868-19d364f3f251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMY0yjPJ3M0k",
        "colab_type": "code",
        "outputId": "f6759793-15eb-4091-8960-93ac2ef74c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 cgan_emoji.py 3 \"impulsive\" \"cuddle\" \"sleep\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From cgan_emoji.py:26: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From cgan_emoji.py:27: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From cgan_emoji.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-04-29 13:09:47.193532: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2020-04-29 13:09:47.198232: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000155000 Hz\n",
            "2020-04-29 13:09:47.198440: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2662a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-29 13:09:47.198474: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-04-29 13:09:47.200505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-04-29 13:09:47.316122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-29 13:09:47.316713: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2662bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-29 13:09:47.316754: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-04-29 13:09:47.316919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-29 13:09:47.317309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-29 13:09:47.317613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-29 13:09:47.319245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-29 13:09:47.320748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-29 13:09:47.321065: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-29 13:09:47.322484: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-29 13:09:47.323159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-29 13:09:47.325961: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-29 13:09:47.326071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-29 13:09:47.326505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-29 13:09:47.326834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-04-29 13:09:47.326895: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-29 13:09:47.327866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-29 13:09:47.327891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-04-29 13:09:47.327900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-04-29 13:09:47.328008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-29 13:09:47.328405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-29 13:09:47.328765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "Using colab GPU\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "d_input (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 64)   1792        d_input[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 64)   0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 16, 16, 128)  73856       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 17, 17, 128)  0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 17, 17, 128)  512         zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 17, 17, 128)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 17, 17, 128)  0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 17, 17, 256)  295168      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 17, 17, 256)  1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 17, 17, 256)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 17, 17, 256)  0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "cond_d_input (InputLayer)       (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 9, 9, 512)    1180160     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          30100       cond_d_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 9, 9, 512)    2048        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 1, 100)    0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 9, 9, 512)    0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 9, 9, 100)    0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 9, 9, 612)    0           leaky_re_lu_4[0][0]              \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 9, 9, 512)    2820608     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 9, 9, 512)    2048        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 9, 9, 512)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 9, 9, 512)    0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 41472)        0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            41473       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,448,789\n",
            "Trainable params: 4,445,973\n",
            "Non-trainable params: 2,816\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "cond_g_input (InputLayer)       (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "g_input (InputLayer)            (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 100)          30100       cond_g_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 200)          0           g_input[0][0]                    \n",
            "                                                                 dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 16384)        3293184     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 8, 8, 256)    0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 256)  0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 256)  590080      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 256)  1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 16, 16, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 256)  0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 128)  295040      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 128)  0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 64)   73792       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 64, 64)   256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 64, 64, 3)    1731        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64, 64, 3)    0           conv2d_9[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 4,285,719\n",
            "Trainable params: 4,284,823\n",
            "Non-trainable params: 896\n",
            "__________________________________________________________________________________________________\n",
            "Loading model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "2020-04-29 13:10:15.653795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-29 13:10:15.908329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "done\n",
            "done\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}